{"./":{"url":"./","title":"Introduction","keywords":"","body":"Welcome to Bond's ebook!   在GitHub中发现了一个由GitBook构建的Blog，称为Book更恰当，极其简洁，用手机查看也非常方便，甚是喜欢。于是搭建了一个，记录学习笔记，收录知识要点及分享技术经验，方便随时查阅。 个人简介 Email : 576608644@qq.com GitHub主页: https://bond-huang.github.io/huang/ ebook主页 : https://ebook.big1000.com Book说明 操作说明 点击页面左上角可以打开目录导航 点击页面上方字母A可以切换字体大小和类型（Serif & Scans），以及切换背景模式（White & Sepia & Night） 欢迎收藏交流 如需转载，请注明出处 如果文章中有注明其它出处，需转载请注明文章中的出处 Book中主要使用工具 GitBook ：构建本书 Travis-CI ：持续构建 VScode ：编写MarkDown 搭建说明 本Book搭建方式参考Lyon的分享，blogs主页：Lyon's blog "},"SUMMARY.html":{"url":"SUMMARY.html","title":"SUMMARY","keywords":"","body":"Summary Introduction SUMMARY IBM_Power_System HMC HMC-收集数据 HMC-常用命令 HMC-shell脚本使用 HMC-RMC连接 Power_System Power-小型机数据收集 OpenPower Pureflex IBM_Z&LinuxONE IBM_LinuxONE LinuxONE-数据收集 LinuxONE-学习笔记 LinuxONE-云最佳实践笔记 LinuxONE-云最佳实践KVM笔记 LinuxONE-OpenStack部署_KVM LinuxONE-OpenStack使用手册 LinxuONE-OpenShift安装配置 LinuxONE-部署Kubernetes集群 LinuxONE-Prometheus监控 IBM_Storage_System DS3-5k_Storage DS3-5K-微码升与降 DS3-5K-常见问题 DS3-5K-常用操作 DS8k_Storage DS8000-数据收集及基础 DS8000-DSCLI常用命令 DS8000-Copy_Services DS8000-Copy_Services_Manager DS8000-硬件维护 Storwize_Storage Flash_System XIV_Storage XIV-日志查看及收集 Tape_Storage TS4500-常见问题 TS7650G-虚拟带库 TS7650G-常见问题 TS7650G-安装配置 NAS_Storage Nseries-常用命令和操作 Cloud_Object_Storage SAN_Switch Switch-收集数据 Switch-常用命令 Switch-常见问题 Switch-常用脚本 SAN_Volume_Controller SVC-数据收集 SVC-远程拷贝 SVC-常用命令 SVC-Quorum磁盘 SVC-固件升级 SVC-系统性能 SVC-池mdisk卷 SVC-简单脚本 IBM_Virtualization PowerVC PowerVC-安装 PowerVM PowerVM-数据收集 PowerVM-VIOS常用命令 PowerVM-常见问题 IBM_Operating_System AIX AIX-数据收集及分析 AIX-常用命令 AIX-用户策略 AIX-HA常用操作 AIX-NIMserver AIX-TCPIP-配置IPv6 AIX-磁盘多路径 AIX-网络与通信 AIX-系统管理 AIX-系统性能 AIX-常见问题 AIX-系统或软件安装 AS400 AS400-检查&日志收集 AS400-系统基本知识 AS400-常用命令 AS400-常用操作 AS400-磁盘管理 AS400-系统性能 AS400-作业管理 AS400-子系统管理 AS400-内存池管理 AS400-网络与通信 AS400-备份与恢复 AS400-消息&消息队列 AS400-日志&日志接收器 AS400-输出队列管理 AS400-Spooled文件管理 AS400-程序开发相关 AS400-PowerHA高可用 AS400-Power虚拟化分区 AS400-系统用户管理 AS400-系统Security AS400-系统Services AS400-系统值 AS400-监控系统活动 AS400-HA_Tools_IASP_Manager AS400-文档查看及编辑 AS400-Auxiliary_Storage_Pool AS400-i_Access AS400-学习笔记 AS400-MIMIX_iCluster AS400-常见系统问题 AS400-高可用相关问题 AS400程序 CLP-基础知识 CLP-常用命令 CLP-变量基本操作 CLP-控制语句 CLP-检索可用作变量的值 AS400-PDM使用 AS400数据库 AS400-数据库基础知识 AS400-Commitment Control AS400-数据库文件管理 AS400-常用SQL RedHat RedHat-基础配置 RedHat-常用命令 RedHat-用户及用户权限 RedHat-文件和文字处理 RedHat-磁盘管理 RedHat-常用软件安装 RedHat-常见问题 RHEL学习笔记 RHEL-基础命令及操作 RHEL-文本及用户操作 RHEL-文件访问及进程管理 RHEL-服务和守护进程及SSH RHEL-日志分析及管理 RHEL-系统网络管理 RHEL-归档和传输文件 RHEL-安装和更新软件包 RHEL-访问Linux文件系统 RHEL-分析服务器及获取支持 RHEL-复习与练习 RHEL-Ansible学习笔记 Ansible-安装Ansible Ansible-实施Playbook Ansible-变量管理等 Ansible-任务控制 Ansible-常见问题 Ansible-官方实例参考 IBM_Database&Middleware&Other DB2_Database DB2-数据收集 DB2-常见SQL_messages DB2-数据库其它问题 DB2-数据库相关说明 DB2-常用操作或命令 Websphere_Application_Server WAS-数据收集 WAS-常见问题处理 WAS-其它报错处理 WAS-故障处理实例 Websphere_MQ MQ-数据收集 MQ-连接通道问题 Filenet Cognos Cognos-数据收集 Cognos-常见问题 InfoSphere_Data_Replication CDC-安装与卸载 Oracle_Database Oracle学习笔记 Oracle-安装与部署 Python Python基础学习笔记 Python学习笔记-基本数据类型 Python学习笔记-变量与运算符 Python学习笔记-循环&分支&条件 Python学习笔记-结构_包&模块 Python学习笔记-函数 Python学习笔记-面向对象 Python学习笔记-正则表达式 Python学习笔记-JSON Python学习笔记-枚举 Python学习笔记-高级语法与应用 Python学习笔记-函数式编程 Python学习笔记-爬虫学习 Python学习笔记-Pythonic Python内置模块&方法 Python-操作系统接口 Python-time模块 Python-常用内置函数 Python-array&readline Python-常用字符串方法 Python_LeetCode Python-简单题目 Python-简单题目_1 Python-中等难度 Python_AIX脚本 Python-AIX环境部署 Python-检查系统 Python-AIX配置修改 Python-AIX日常巡检 Python_爬虫 Python-视频信息爬取 Python-热点话题爬取 Python_Excel数据分析 Openpyxl-各系统环境部署 Openpyxl-Excel基础操作 Python_Flask Flask-基础环境搭建 Flask-布局及视图笔记 Flask-模板及网页布局笔记 Flask-操作请求数据 Flask-常见问题 HTML-基础学习笔记 SQLite-基础知识笔记 SQLite-常见问题 Python系统管理&自动化运维笔记 Python运维-基础知识 Python运维-打造命令行工具 Python运维-文本处理 Python运维-Linux系统管理 Python运维-Linux系统管理实例 Python运维-监控Linux系统 Python运维-文档与报告 Python_常见问题及注意事项 Python-常见问题 Python-注意事项 Python-编写脚本注意事项 Shell脚本 Shell学习笔记 Shell笔记-基础脚本 Shell笔记-条件语句 Shell笔记-循环语句 Shell笔记-处理用户输入 Shell笔记-数据呈现 Shell笔记-函数 Shell笔记-sed和gawk基础 Shell笔记-正则表达式 Shell笔记-sed编辑器 Shell笔记-gawk程序 Shell笔记-脚本控制 Shell脚本快速指南 Shell-bash脚本实例 Shell-退出码_test_expr查询表 Shell-Shtool脚本函数库 Shell-正则表达式实例 Shell-sed&gawk实例 Shell-简单的脚本实用工具 Shell-有意思的小脚本 Shell-常用方法快速查询 Shell_AIX脚本 Shell-mksysb相关脚本 Shell-PowerHA相关脚本 Shell-AIX_ksh小脚本 Shell脚本编写注意 Shell-各种shell的区别 Shell-编写脚本注意事项 Shell-sed和gawk差异 Git GitHub&Git GitHub-使用命令行 GitHub-常用操作 GitHub-常见问题 Markdown Markdown-基础用法 Markdown-查询表 Travis-CI TravisCI-基础操作 TravisCI-构建Flask项目 YAML YAML-基础学习 常用操作系统 Windows Windows-常见问题 Windows-SQL08完全卸载&安装 Windows-Excel购房贷款计算器 Windows-Excel常用函数 Windows-常用软件操作 Photoshop-基础操作 Ubuntu Ubuntu-系统安装 虚拟化平台 VMware VMware-基础操作 VMware-常见问题 Proxmox_VE QEMU QEMU-虚拟AIX系统 KVM KVM-RHEL安装部署 KVM-常用操作 KVM-虚拟机自动安装 X86_System Lenovo X86 SystemX-ASU使用 HuaWei_X86 HuaWei-系统安装 HP_X86 HP_iLO使用 HP_常见故障 存储设备 华为存储系列 HuaWei-用户基本操作 网络交换机 SMC交换机 SMC-基本操作 云平台 OpenShift OpenShift-简介 Openshift-安装 OpenShift-应用部署 Docker Docker-安装配置 Docker-部署Flask应用 IBM_Hybrid_Cloud HTML+CSS+JavaScript HTML5 HTML5-基础知识 CSS CSS3-基础 CSS3-选择器 CSS3-美化图像 CSS3-常用样式笔记 JavaScript JavaScript-基础知识 Vue-基础知识 Vue-模板语法 Vue-条件和列表渲染 Vue-组件_深入了解 Vue-注意事项 Vue-代码调试 Bootstrap Bootstrap-下载及使用 Bootstrap-布局组件 Bootstrap-插件 Bootstrap-使用实例 网页导航实例 Navigator-基础环境 Navigator-网页模板 Navigator-数据交互 简单WEB项目 System-Health-Management SHM-基础环境准备 SHM-Container初步设计 SHM-API和route SHM-Login模块及Mock后台 学习及使用中记录的笔记 Vue-CLI-使用笔记 Vue-CLI-报错记录 Vue-CLI-数据问题记录 Element_Plus-学习笔记 ECharts-基础学习笔记 Echarts-数据获取问题 "},"01-IBM_Power_System/":{"url":"01-IBM_Power_System/","title":"IBM_Power_System","keywords":"","body":"Power 简介 Power 处理器全称Performance Optimization With Enhanced RISC，是IBM公司设计开发的一种基于RISC架构的指令集体系构架（ISA)。 官方网站：https://www.ibm.com/cn-zh/it-infrastructure/power IBM 向其它开发者及制造商推广POWER架构及其它衍生产品，例如一些OpenPower系列服务器。 部分产品官方介绍：https://www.ibm.com/cn-zh/it-infrastructure/power/scale-out IBM支持 7*24小时呼叫中心：400-810-6678 IBM 用户支持中心：产品下载和更新、打开和查看案例、产品通知以及支持指南，官方连接： IBM 支持团队 内容 HMC Power_System OpenPower Pureflex "},"01-IBM_Power_System/01-HMC/":{"url":"01-IBM_Power_System/01-HMC/","title":"HMC","keywords":"","body":"HMC 简介 HMC全称是Hardware Management Console，是管理IBM Power小型机的控制台之一，也是最常用的一种。 官方资料：HMC Knowledge Center 内容 HMC-收集数据 HMC-常用命令 HMC-shell脚本使用 HMC-RMC连接 "},"01-IBM_Power_System/01-HMC/01-HMC-收集数据.html":{"url":"01-IBM_Power_System/01-HMC/01-HMC-收集数据.html","title":"HMC-收集数据","keywords":"","body":"HMC收集数据 简介 HMC 是Power小型机管理控制台之一，可以对小型机进行硬件管理和逻辑配置等。 收集数据是解决问题的关键技能，本文介绍下收集HMC一些基础日志的方法。 收集iqyylog iqyylog 主要用于受管小型机的硬件故障判断 Classic GUI V8.7以前的HMC版本有Classis界面 收集方法如下： 在HMC物理设备插上U盘，必须是FAT32格式；推荐使用U盘，如果使用其它方式插入对应媒体设备 在导航区域中，打开“Service Management” 选择选项“Transmit Service Information” 选择选项“\"Transmit Service Data to IBM”选项 通过选项“Service Data Destination”选择目标媒体，四种方式，后面三个选项通过远程WEB访问HMC是无法进行的： IBM service support system：使用RSF将服务数据发送到IBM 服务支持系统 DVD-RAM:拷贝服务数据到DVD-RAM USB memory stick:拷贝服务数据到U盘 Diskette：拷贝服务数据到软盘 在“product engineering files”选项中输入“/var/hsc/log/iqyy*” 最后点击 “send files” 完成后拔掉U盘，里面iqyy_.zip即是iqyylog Enhanced GUI V8.7以后的HMC版本就都是Enhanced GUI，并且不提供Classis界面 收集方法如下： 在HMC物理设备插上U盘，必须是FAT32格式；推荐使用U盘，如果使用其它方式插入对应媒体设备 左侧导航栏点击螺丝刀扳手图标，即“Serviceability”选项 选择选项“Service Management” 选择选项“Transmit Service Information” 选择选项“Send Problem Reports” 在“Service Data Destination”选项中选择“USB flash memory drive” 在“product engineering files”选项中输入“/var/hsc/log/iqyy*” 点击“Send Problem Reports”页面右上角的“Send Now”按钮，就可以把iqyylog数据发送到U盘了 完成后拔掉U盘，里面iqyy_.zip即是iqyylog ASMI LOG ASMI全称Advanced System Management Interface,是IBM Power小型机管理界面 ASM log会记录小型机报告的软硬件事件，在进行故障判断时候此日志也很重要 通过HMC收集方法如下： 选中需要收集的受管Power小型机 展开选项“操作” 点击选项“启动Advanced System Management(ASM)” 用admin用户登录到ASMI 选择选项“Select System Service Aids” 选择选项“Error/Event Log” 显示出事件后，在事件左侧复选框中选中需要收集的事件，当然也可以全选 然后点击“Show Details” 然后crtl+a全选，crtl+c拷贝，最后crtl+v拷贝到登录自己电脑上 收集RIO Topology Power小型机经常连接很多扩展柜，此日志对于排查I/O问题很重要 收集Resource DUMP DUMP日志对于Power小型机和AIX分区突发性严重故障的排查很重要，例如机器宕机，AIX系统挂死等 收集方法如下： 登录到HMC 选中一台受管小型机 展开选项“Serviceability” 选择选项“Manage Dumps” 弹出窗口可以看到DUMP的list，选择对应DUMP 展开窗口上面导航栏的选项“Selected” 选择选项“Copy Dump to Media”可以传到U盘或者光盘 选择选项““Copy Dump to Remote System”可以通过FTP传出来 收集pedbg 对于HMC本身问题以及HMC和Power小型机连接之间的问题排查很重要。官方链接： https://www.ibm.com/support/pages/node/688045?mhsrc=ibmsearch_a&mhq=hcpe https://www.ibm.com/support/pages/node/670577 "},"01-IBM_Power_System/01-HMC/02-HMC-常用命令.html":{"url":"01-IBM_Power_System/01-HMC/02-HMC-常用命令.html","title":"HMC-常用命令","keywords":"","body":"HMC-常用命令 HMC管理说实话用命令的很少，一般都是图形化界面，很方便；但是在一些对受管机器分区进行批量处理的时候，或者查看获取一些受管机器信息的时候，用命令查看配置或者是写脚本去抓取数据还是比较方便的。 常用命令 管理HMC命令 介绍一些常用管理HMC控制台的命令 hmcshutdown 关闭或重启HMC，示例： #立即关机 hscroot@hmc:~> hmcshutdown -t now #等1分钟后关闭 hscroot@hmc:~> hmcshutdown -t 1 #等1分钟后重启 hscroot@hmc:~> hmcshutdown -t 1 -r lshmc 列出HMC的设置，示例： #列出HMC版本信息 hscroot@hmc:~> lshmc -V #列出HMC VPD信息 hscroot@hmc:~> lshmc -v #列出HMC远程访问信息 hscroot@hmc:~> lshmc -r #列出HMC网络设置信息 hscroot@hmc:~> lshmc -n #列出HMC硬件信息 hscroot@hmc:~> lshmc -h #列出HMC NTP server信息 hscroot@hmc:~> lshmc --ntpserver lshmc命令官方说明：https://www.ibm.com/docs/zh/power9/9040-MR9?topic=commands-lshmc bkconsdata 备份硬件控制台HMC重要数据,示例： #ftp方式备份 hscroot@hmc:~> bkconsdata -r ftp -h ftpserver -u ftpuser --passwd ftppassword #nfs方式备份 hscroot@hmc:~> bkconsdata -r nfs -h 192.168.1.10 -l /tmp/hmc/backups #dvd方式备份 hscroot@hmc:~> bkconsdata -r dvd chhmc 修改硬件管理控制台（HMC）设置，示例： #修改控制名称 hscroot@hmc:~>chhmc -c network -s modify -h mynewhost #修改控制台eth0 ip hscroot@hmc:~>chhmc -c network -s modify -i eth0 -a 192.168.1.10 -nm 255.255.255.0 #修改ssh，http和web访问限制 hscroot@hmc:~>chhmc -c ssh -s enable hscroot@hmc:~>chhmc -c http -s disable hscroot@hmc:~>chhmc -c websm -s enable #添加或删除ntp服务 hscroot@hmc:~>chhmc -c xntp -s add mytimeserver.company.com hscroot@hmc:~>chhmc -c xntp -s add -a 192.168.1.32 -i eth0 hscroot@hmc:~>chhmc -c xntp -s remove mytimeserver.company.com 管理受管机器命令 所有操作都可以在HMC图形化管理界面进行操作，当需要在HMC可以用命令行对受管小型机进行相应配置操作，用命令对查看小型机信息和进行批量配置时候很有用。 mkvterm 打开受管系统中分区的虚拟终端会话，示例： #打开指定受管系统分区id为1的分区的虚拟终端会话 hscroot@hmc:~>mkvterm -m --id 1 通常采用vtmenu命令进去设备菜单，再选择对应的分区进入虚拟终端会话 rmvterm 关闭受管系统中分区的虚拟终端会话，示例： #关闭指定受管系统分区id为1的分区的虚拟终端会话 hscroot@hmc:~>rmvterm -m --id 1 分区的虚拟终端会话只允许开一个，如果想使用但是被占用，又不知道谁占用，可以用此命令关闭 lsdump 列出受管系统的dump信息，示例： #列出所有dump hscroot@hmc:~>lsdump -h #列出指定受管设备的dump hscroot@hmc:~>lsdump -m lssvcevents 列出可维护事件，示例： #列出所有维护事件 hscroot@hmc:~>lssvcevents -t hardware -d 0 #列出控制台3天内的维护事件 hscroot@hmc:~>lssvcevents -t console -d 3 #列出指定受管系统打开的维护事件 hscroot@hmc:~>lssvcevents -t hardware -m --filter \"status=open\" lsled 列出受管系统的 LED 信息，示例： #列出指定受管设备的物理attention LEDs状态 ~>lsled -m -r sa -t phys #列出指定受管设备的指定Lpar警告灯状态 ~>lsled -m -r sa -t virtuallpar --filter \"\"lpar_names=lpar1,lpar2\"\" chled 列出受管系统的 LED 状态，示例： #关闭指定受管设备的物理attention LED ~>chled -m -r sa -t phys -o off #打开指定lpar的attention LED ~>chled -m -r sa -t virtuallpar -o on -p lpar3 #关闭lpar id 为2的lapr 的attention LED ~>chled -m -r sa -t virtuallpar -o off --id 2 lssysconn 列出受管设备的连接信息，示例： #列出所有受管设备的连接信息 ~>lssysconn -r all #列出所有受管设备的连接IP和状态 lssysconn -r all -F ipaddr:state lshwres 列出受管系统的硬件资源，示例： #列出物理I/O相关信息 ~>lshwres -r io --rsubtype unit -m ~>lshwres -r io --rsubtype bus -m --filter \"units=U787A.001.*******\" ~>lshwres -r io --rsubtype slot -m --filter \"units=U787A.001.*******,\"buses=2,3\"\" -F drc_index,description, ~>lshwres -r io --rsubtype iopool -m --level pool ~>lshwres -r io --rsubtype taggedio -m --filter \"lpar_ids=1\" #列出虚拟适配器相关信息 ~>lshwres -r virtualio --rsubtype eth --level lpar -m ~>lshwres -r virtualio --rsubtype scsi -m -F --header ~>lshwres -r virtualio --rsubtype slot -m --level slot --filter \"lpar_names=lpar1\" #列出内存相关信息 ~>lshwres -r mem -m --level sys ~>lshwres -r mem -m --level lpar -R ~>lshwres -r mem -m --level lpar --filter \"\"lpar_names=lpar_1,lpar2\"\" #列出处理器相关信息 ~>lshwres -r proc -m --level sys -F installed_sys_proc_units:configurable_sys_proc_units ~>lshwres -r proc -m --level lpar #列出hca相关信息 ~>lshwres -r hca -m --level sys ~>lshwres -r hca -m --level lpar --filter \"lpar_names=lpar1\" chhwres 更改受管系统的硬件资源配置，示例： #将指定受管系统指定分区的处理器移动到指定的分区 ~>chhwres -r proc -m -o m -p -t --procs 1 #移除指定受管系统指定分区中virtual slot号为3的虚拟适配器 ~>chhwres -r virtualio -m -o r -p -s 3 lssyscfg 列出分区，分区配置文件；系统配置文件，受管系统信息；受管机架框或受管机柜信息，示例： #列出所有受管系统的配置信息 ~>lssyscfg -r sys #列出指定受管系统的配置信息 ~>lssyscfg -r sys -m #列出指定受管系统属性名称的标题 ~>lssyscfg -r lpar -m -F --header #列出指定受管系统中指定分区的配置信息 ~>lssyscfg -r lpar -m --filter \"\"lpar_names=lpar1,lpar2,lpar3\"\" #列出指定受管系统中指定分区中指定的相关信息 ~>lssyscfg -r lpar -m --filter \"\"lpar_names=lpar1,lpar2,lpar3\"\" -F name,lpar_id,state #列出指定受管系统中指定分区的profile信息 ~>lssyscfg -r prof -m --filter \"lpar_names=lpar2\" #列出指定受管系统中指定分区中的指定profile信息 ~>lssyscfg -r prof -m --filter \"lpar_ids=2,\"profile_names=prof1,prof2\"\" #列出指定受管系统的profile信息 ~>lssyscfg -r sysprof -m #列出指定受管系统中指定的某一个profile信息 ~>lssyscfg -r sysprof -m --filter \"profile_names=sysprof1\" #列出所有managed frames信息 ~>lssyscfg -r frame #列出指定managed frames信息 ~>lssyscfg -r frame -e mksyscfg 为受管系统创建分区、分区概要文件或系统概要文件，示例： #为指定受管系统创建分区 ~>mksyscfg -r lpar -m -i \"name=,profile_name=,lpar_env=aixlinux,min_mem=256,desired_mem=1024,max_mem=1024,proc_mode=ded,min_procs=1,desired_procs=1,max_procs=2,sharing_mode=share_idle_procs,auto_start=1,boot_mode=norm\" #为指定受管系统创建profile ~>mksyscfg -r prof -m -f /tmp/profcfg #为指定受管系统中的指定分区创建profile ~>mksyscfg -r prof -m -o save -p -n lspartition 列出分区信息： # Lists partitions with RMC connection as known by LparCmdRM ~> lspartition -dlpar # Lists partitions with RMC connection as known by SFP's ServiceRM ~> lspartition -sfp # 列出指定机器的分区信息 ~> lspartition -c # Invoked by InvScout directly for ext data.Return format: ~> lspartition -ix # Invoked by InvScout through lshsc.Return format: ~> lspartition -i lslparutil 列出受管系统和分区的利用率指标。该命令仅在Integrated Virtualization Manager环境中可操作: # List configuration attributes for utilization monitoring ~> lslparutil -r config # List utilization data for logical partitions ~> lslparutil -r lpar 使用示例 查看指定受管设备的lpar信息： hscroot@TEST:~> lssyscfg -r lpar -m Server-9117-570-SN65YDR6E -F --header name,lpar_id,lpar_env,state,resource_config,os_version,logical_serial_num,default_profile, curr_profile,work_group_id,shared_proc_pool_util_auth,allow_perf_collection,power_ctrl_lpar_ids,boot_mode,ipl_source,lpar_keylock,auto_start,redundant_err_path_reporting,rmc_state,rmc_ipaddr,rmc_osshutdown_capable,dlpar_mem_capable,dlpar_proc_capable,dlpar_io_capable,sync_curr_profile,uuid teacher02 9.210.114.218,10,aixlinux,Running,1,AIX 7.1 7100-04-03-1642,65YDR6EA,client08,cl ient08,none,0,0,none,norm,null,norm,0,0,active,9.210.114.218,1,1,1,1,0,08A64825-D324-4FBB-A6D3-D44143ED8AF3 teacher01 9.220.154.227,9,aixlinux,Running,1,AIX 7.1 7100-04-03-1642,65YDR6E9,client07,cli ent07,none,0,0,none,norm,null,norm,0,0,inactive,9.220.154.227,0,0,0,0,1,3E8A72FB-C815-4AAD-9754-89037455DCFC ... hscroot@TEST:~> lssyscfg -r lpar -m Server-9117-570-SN65YDR6E -F teacher02 9.210.114.218,10,aixlinux,Running,1,AIX 7.1 7100-04-03-1642,65YDR6EA,client08,client08,none,0,0,none,norm,null,norm,0,0,active,9.210.114.218,1,1,1,1,0,08A64825-D324-4FBB-A6D3-D44143 ED8AF3 teacher01 9.220.154.227,9,aixlinux,Running,1,AIX 7.1 7100-04-03-1642,65YDR6E9,client07,client07,none,0,0,none,norm,null,norm,0,0,inactive,9.220.154.227,0,0,0,0,1,3E8A72FB-C815-4AAD-9754-89037 455DCFC ... 列出RMC连接的分区信息： hscroot@TEST:~> lspartition -dlpar Partition: Active:, OS:, DCaps:, CmdCaps:, Pi nnedMem: Partition: Active:, OS:, DCaps:, CmdCaps:, Pi nnedMem: 用户权限 各用户命令使用权限参考官方文档：HMC 任务，用户角色，标识和相关联的命令 "},"01-IBM_Power_System/01-HMC/03-HMC-shell脚本使用.html":{"url":"01-IBM_Power_System/01-HMC/03-HMC-shell脚本使用.html","title":"HMC-shell脚本使用","keywords":"","body":"HMC中shell脚本使用 简介   HMC底层是Redhat，经过修改和限制后，还是相对比较封闭；一般登录是采用hscroot这个用户，此用户权限一般，很多命令没有，此用户也无法ftp。  官方有提供一些小工具去抓取一些数据，例如HMC Scanner，简单的可以直接在命令行进行输入，例如用for循环批量创建分区和分区资源的时候。 HMC Scanner   HMC Scanner可以用于HMC配置信息收集，主要是Lpar的一些重要配置信息，会自动生成一个配置表格。此工具有shell也有java，跑的时候还是比较慢，耐心等待，但是数据确实很全面的。 官方链接： HMC Scanner 由于HMC的一些局限性，我觉得此工具提供了一个很好的接口，在上面进行修改或者添加，得到自己定制的内容，也是很不错的。 命令 使用过程中发现HMC很多命令或者工具没有： hscroot用户的hmcbash中没有awk和gawk程序，有sed编辑器 没有脚本执行的命令，使用sh及./都不行 没用ftp和sftp，有scp 运算问题   近期在HMC中用hscroot用户跑一个for循环去对分区进行批量资源创建的时候，发现运算还是有点不一样。在V9R1版本和V7R7.9版本中都进行了如下运算测试： hscroot@hmc:~> for i in {2..5} > do > echo Lpar$(echo \"$i*10+1\"|bc) > done 运行后都是会报错：bash: bc: command not found，说明HMC的hscroot用户没bc计算器，用下面运算方法替代即可： hscroot@hmc:~> for i in {2..5} > do > echo Lpar$(($i*10+1)) > done 或者用方括号： hscroot@TEST:~> for i in {2..5} > do > echo Lpar$[ $i * 10 + 1 ] > done 运行后结果如下： Lpar21 Lpar31 Lpar41 Lpar51 获取分区信息   抓取HMC受管机器的已激活分区信息：所在机器名称、分区名称、分区ip、分区操作系统版本。但是HMC的hscroot用户的有很多限制，很多命令用不了，awk和gawk都用不了，重定向也被限制了，研究了一下hscroot用户也配置不了ssh免密登录。当然也可以使用HMC Scanner，抓取信息很详细，抓取后后期也需要整理，想了个办法抓取这些信息，除了输入多次密码比较麻烦，整理是还算简单。 获取信息的命令 通过机器获取对应信息 在HMC中，获取机器信息的命令如下： # 获取受管机器信息 hscroot@TEST:~> lssyscfg -r sys -F # 获取Lpar信息 hscroot@TEST:~> lssyscfg -r lpar -m Server-9117-570-SN65B4D6E -F 找一台可以ssh到HMC的机器，我找了个AIX系统，首先获取受管机器信息： # ssh hscroot@9.210.114.112 \"lssyscfg -r sys -F\" > sysinfo.txt Password: # 然后抓取受管机器名字： # awk 'BEGIN{FS=\",\"}{print $1}' sysinfo.txt > syslist.txt # cat syslist.txt Server-9117-570-SN65YDR6E Server-9117-570-SN7578HB1 Server-9131-52A-SN066HC5G Server-9117-MMA-SN10GF66F 然后获取Lpar信息（循环一次输入一次密码）： # for i in `cat syslist.txt` do ssh hscroot@9.210.114.112 \"lssyscfg -r lpar -m $i -F\" done >> lparinfo.txt Password: Password: Password: Password: # cat lparinfo.txt teacher02 9.210.114.218,10,aixlinux,Running,1,AIX 7.1 7100-04-03-1642,65YDR6EA,client08,client08,none,0,0,none,norm,null,norm,0,0,active,9.210.114.218,1,1,1,1,0,08A64825-D324-4FBB-A6D3-D44143 ED8AF3 teacher01 9.220.154.227,9,aixlinux,Running,1,AIX 7.1 7100-04-03-1642,65YDR6E9,client07,client07,none,0,0,none,norm,null,norm,0,0,inactive,9.220.154.227,0,0,0,0,1,3E8A72FB-C815-4AAD-9754-89037 455DCFC 抓取需要的信息： awk 'BEGIN{FS=\",\"; OFS=\" \"}{if ($4 == \"Running\") print $1 $6 $7 $20}' lparinfo.txt > result.txt 在AIX中设置了OFS好像没什么效果,基本上已获取了需求的信息，AIX中使用下面命令也行： awk -F, '{if ($4 == \"Running\") print $1 $6 $7 $20}' lparinfo.txt > result.txt 可以单独把ip取出来，遍历IP表去登录到系统（如果没有配置自动登录就手动输入密码）： for i in `cat ip.list`;do ssh tmpusr@$1;done 分区对应信息   如果只获取分区的IP和操作系统版本，RMC状态，LparID等，不需要对应物理机器，可以使用lspartition命令，获取的信息相对较少，但是清晰明了，字段以逗号隔开，awk命令中指定字段分隔符即可，使用示例如下： hscroot@TEST:~> lspartition -i 12,9.200.104.174,0;5,9.200.104.233,0;1,9.200.104.108,3;10,9.200.104.238,0;1,9.200.104.107, 3;1,9.200.104.19,0;3,9.200.104.231,0;1,9.200.104.172,0;2,9.200.104.173,0;7,9.200.104.235,0 输出格式为:LParID,IPaddress,active; hscroot@TEST:~> lspartition -ix 12,9.200.104.174,0,,AIX,7.1;5,9.200.104.233,0,,AIX,6.1;1,9.200.104.108,3,,AIX,6.1;10,9.200 .104.238,0,,AIX,7.1;1,9.200.104.107,3,,AIX,6.1;1,9.200.104.19,0,,AIX,7.1;3,9.200.104.231,0,,AIX,5.3;1,9.200.104.172,0,,AIX,6.1;2,9.200.104.173,0,,AIX,6.1;7,9.200.104.235,0,,AIX,7. 输出格式为:LParID,IPaddress,active,hostname,OStype,OSlevel; 抓取分区配置信息 统计所有HMC上受管机器的CPU内存信息，当然也报告Lpar名称和IP等。 首先收集HMC上受管机器的信息： # ssh hscroot@10.8.252.150 \"lssyscfg -r sys -F\" > sysinfo.txt 抓取受管机器名称： # awk 'BEGIN{FS=\",\"}{print $1}' sysinfo.txt > syslist.txt 抓取受管机器的CPU配置信息： for i in `cat syslist.txt` do ssh hscroot@10.8.252.150 \"lshwres -r proc -m $i --level sys\" > sysproc.txt done 然后筛选一下： # awk 'BEGIN{FS=\",\"}{print $1,$2,$4}' sysproc.txt > procinfo.txt 抓取受管机器的内存配置信息： for i in `cat syslist.txt` do ssh hscroot@10.8.252.150 \"lshwres -r mem -m $i --level sys\" > sysmem.txt done 然后筛选一下： # awk 'BEGIN{FS=\",\"}{print $1,$2,$4}' sysmem.txt > meminfo.txt 然后获取所有分区profile信息： for i in `cat syslist.txt` do ssh hscroot@10.8.252.150 \"lssyscfg -r prof -m $i\" done > lparprof.txt 获取分区的名称，内存和CPU配置信息： # awk 'BEGIN{FS=\",\"}{print $2,$7,$16} lparprof.txt > lparinfo.txt 发现用lshwres获取CPU内存信息也可以，并且更加方便，获取CPU信息： # for i in `cat syslist.txt` do ssh hscroot@10.8.252.150 \"lshwres -r proc -m $i --level lpar\" done > lparproc.txt 提取出来： # awk 'BEGIN{FS=\",\"}{print $1,$7}' lparproc.txt > lparprocinfo.txt 内存一样： # awk 'BEGIN{FS=\",\"}{print $2,$7,$16} lparprof.txt > lparinfo.txt 发现用lshwres获取CPU内存信息也可以，并且更加方便，获取CPU信息： # for i in `cat syslist.txt` do ssh hscroot@10.8.252.150 \"lshwres -r mem -m $i --level lpar\" done > lparmem.txt # awk 'BEGIN{FS=\",\"}{print $1,$7}' lparmem.txt > lparmeminfo.txt 说明： 物理Lpar和虚拟的vios的CPU配置信息格式有点不一样 物理Lpar和虚拟的vios内存配置信息格式一样 待补充 "},"01-IBM_Power_System/01-HMC/04-HMC-RMC连接.html":{"url":"01-IBM_Power_System/01-HMC/04-HMC-RMC连接.html","title":"HMC-RMC连接","keywords":"","body":"HMC-RMC 简介   要执行动态分区操作，需要逻辑分区与硬件管理控制台(HMC)之间的资源监视和控制(RMC)连接。RMC用作AIX和Linux逻辑分区与HMC之间的主通信信道，使用RMC可以配置用于管理普通系统情况的响应操作或脚本；如果不能针对逻辑分区执行添加或除去处理器、内存或I/O设备的操作，需要检查RMC连接是否处于活动状态。 验证RMC连接 需要超级管理员权限。 查看状态 连接到HMC命令行，输入lspartition -dlpar命令即可查看状态： hscroot@DGNSHHMC1:~> lspartition -dlpar Partition: Active:, OS:, DCaps:, CmdCaps:, PinnedMem: Partition: Active:, OS:, DCaps:, CmdCaps:, PinnedMem: Partition: Active:, OS:, DCaps:, CmdCaps:, PinnedMem: Partition: Active:, OS:, DCaps:, CmdCaps:, PinnedMem: 说明： 如果是，那么RMC连接已建立 如果是或命令结果中未显示某些逻辑分区，说明RMC连接异常 在HMC命令行运行以下命令，检查高速缓存在HMC的数据存储库中的RMC连接状态的值： hscroot@TEST:~> lssyscfg -r lpar -m 9117-570*65B4D6E -F name,rmc_state,rmc_ipaddr,rmc_ossh utdown_capable,dlpar_mem_capable,dlpar_proc_capable,dlpar_io_capable dump_9.200.104.134_not_shutdown,active,9.200.104.134,1,1,1,1 teacher02 9.200.104.218,inactive,9.200.104.218,0,0,0,0 teacher01 9.200.104.217,inactive,9.200.104.217,0,0,0,0 ..... VIOserver2,active,9.200.104.133,1,1,1,1 VIOserver1,active,9.200.104.132,1,1,1,1 说明： rmc_state属性的值必须是active或inactive,并且必须启用所有功能 如果rmc_state属性的值不是active或未将所有功能设置为1，通过运行chsysstate -m -o rebuild -r sys命令执行系统重建以刷新数据 故障排查 故障排查步骤： 验证是否禁用了HMC上的RMC防火墙端口，如果已禁用，需开启： 在导航窗格中，打开 HMC 管理，选择：更改网络设置，单击LAN适配器选项卡 选择除HMC与服务处理器相连的网卡，即配置HMC与分区网络互通的网卡，然后单击详细信息 在LAN适配器选项卡的局域网信息下，验证打开是否处于选中状态，以及分区通信状态是否显示为已启用 单击防火墙设置选项卡，确保RMC是允许的主机中显示的其中一个选项 如果RMC没有被允许，更改设置对RMC开放，最后单击确定修改配置 使用telnet来访问逻辑分区。如果无法使用telnet，那么在HMC上打开虚拟终端，以便在逻辑分区上设置网络 如果逻辑分区网络已正确设置，并且仍然没有RMC连接，那么验证是否安装了RSCT文件集 如果RSCT文件集已安装，那么从逻辑分区使用telnet访问 HMC，以验证该网络是否正常工作以及防火墙是否已被禁用 如果RSCT文件集尚未安装，那么使用AIX 安装盘来安装 通过运行df命令（需要超级用户权限）验证HMC中的/tmp文件系统是否已满，如果满了需要清理 实例说明 实例一   在近期遇到过一种情况，就是同一个HMC的A机的a系统迁移到B机的b分区上了，b系统上原有RMC连接的网络弃用了，采用a分区的网络配置，这样就导致b上的RMC连接出现问题，lspartition -dlpar,命令还是可以看到a分区系统的信息，b分区的RMC连接异常，尝试过下面几种方法（hscroot用户）： 直接运行chsysstate -m -o rebuild -r sys，不行 重新启动HMC，不行，lspartition -dlpar看到结果还是一样 在HMC上删掉a分区的配置信息（如有需要建议进行备份），然后chsysstate就可以了 注意： 如果在没有RMC连接情况下进行动态分区操作，会有提示需要在重启分区后生效，虽然看到HMC上的资源是修改后的资源数量，但是实际系统使用的还是原来的 官方文档中有提到：更改网络设置或激活逻辑分区后，RMC连接大约需要五分钟来建立连接。建议在修改配置后，尽量等几分钟再查看状态 实例二   A分区安装后，RMC使用的是IP1，后来改成了IP2，但是HMC上记录的还是IP1信息，RMC连接状态就异常，使用命令chsysstate -m -o rebuild -r sys依然是不行，在HMC上重置了此物理机器的FSP连接后，等几分钟就正常了。 实例三   HMC上列出分区信息后面可以看到AIX操作系统版本，但是当某个系统升级后，上面的信息没有更新，使用命令chsysstate -m -o rebuild -r sys等几分钟后刷新即可。 官方文档 官方参考文档：验证移动分区的RMC连接 官方参考文档：逻辑分区与HMC之间的RMC连接故障诊断 lsrsrc IBM.MCP 同一个HMC,A机器的a分区rmc使用ip 1，B机器的b分区rmc使用ip 2，现在客户把a分区的业务迁移到b分区了，b分区rmc使用的ip 也改成ip 1，a分区关闭（但是不删除），这样在这台HMC上，用lspartition -dlpar查看a分区rmc ip还是ip 1，那么b分区的rmc连接是不正常的，使用chsysstate -m -o rebuild -r sys命令不行，除非删掉a分区然后chsysstate后，b分区的RMC才正常。请问下有没有办法不删除分区，在两个分区配置同样RMC ip时候（其中一个分区关闭了），把关闭分区的rmc 的ip信息删除 http://www-01.ibm.com/support/knowledgecenter/SGVKBA_3.1.5/com.ibm.rsct315.trouble/bl507_diagrmc.htm "},"01-IBM_Power_System/02-Power_System/":{"url":"01-IBM_Power_System/02-Power_System/","title":"Power_System","keywords":"","body":"Power系列小型机 简介 IBM Power System是采用Power处理器的商用服务器，通常称为Power小型机，最新系列是Power9系列； 早期的RS/6000系列服务器和AS/400系列服务器目前都称为Power System。 目前高端产品Power E980满配： 192核Power9 SMT8 3.9GHz处理器 64TB DDR4 920GB/s内存带宽/节点 32个PCIe4槽位 or 16个I/O扩展柜（12个PCIe3每柜） 官方介绍：Power Systems 内容 Power-小型机数据收集 "},"01-IBM_Power_System/02-Power_System/01-Power-小型机数据收集.html":{"url":"01-IBM_Power_System/02-Power_System/01-Power-小型机数据收集.html","title":"Power-小型机数据收集","keywords":"","body":"Power-小型机收集数据 简介 系统日志是解决问题的关键，本文介绍下收集Power小型机故障日志一些方法，对硬件故障判断和处理很重要。 收集iqyylog HMC 是Power小型机管理控制台之一，可以对小型机进行硬件管理和逻辑配置等 HMC 受管小型机故障事件都会报告给HMC进行记录，HMC 中的iqyylog 记录了HMC 收集方法参考HMC章节内容： HMC-收集数据 收集ASMI log ASMI全称Advanced System Management Interface,是IBM Power小型机管理界面 ASMI log会记录小型机报告的软硬件事件，在进行故障判断时候此日志也很重要 HMC中收集 收集方法参考HMC章节内容： HMC-收集数据 Laptop直连收集 如果没有HMC，或者HMC不方便收集，可以通过笔记本电脑直连到设备进行收集。 Power小型机都配有两个HMC管理口，默认ip如下： Power5：192.168.2.147/192.168.3.147 Power6及以上系列：169.254.2.147/169.254.3.147 高端系列有四个口：169.254.2.147/169.254.3.147/169.254.2.147/169.254.3.147 收集方法如下： 配置laptop的IP地址，和小型机的HMC口ip段一致 将laptop连上小型机的HMC口 在laptop浏览器上输入：https://169.254.2.147 用admin用户登录到ASMI 选择选项“Select System Service Aids” 选择选项“Error/Event Log” 显示出事件后，在事件左侧复选框中选中需要收集的事件，当然也可以全选 然后点击“Show Details” 然后crtl+a全选，crtl+c拷贝，最后crtl+v拷贝到自己电脑上 收集snap Power系列小型机大多运行AIX系统，部分是AS400或者Linux，此处介绍常见的AIX系统中有硬件故障时候的日志收集，其它系统在相应系统中介绍。 AIX系统排查小型机硬件故障的snap日志收集方法如下： root用户登录到AIX系统 清除以前收集的日志，运行命令：snap -r 收集新日志，运行命令：运行命令snap -gc 日志存放目录：/tmp/ibmsupt 将目录中snap.pax.Z文件通过FTP拷贝出来即可 收集RIO Topology Power小型机经常连接很多扩展柜，此日志对于排查I/O问题很重要 收集方法同样 收集DUMP 如果是宕机自动生成的，直接去HMC上收集对应的dump就行； 如果需要检查机器问题，特别是FSP问题，需要手动生成，FSP dump生成方法如下： 用admin用户登录到ASMI 选择选项“System Service Aids” 选择选项“Error/Event Log” 选择选项“Service Processor Dump” 确认“Setting”选项是“Enabled” 点击“Initiate dump” 收集在HMC中进行，方法同样参考HMC章节内容： HMC-收集数据 "},"01-IBM_Power_System/03-OpenPower/":{"url":"01-IBM_Power_System/03-OpenPower/","title":"OpenPower","keywords":"","body":""},"01-IBM_Power_System/04-Pureflex/":{"url":"01-IBM_Power_System/04-Pureflex/","title":"Pureflex","keywords":"","body":""},"02-IBM_Z&LinuxONE/":{"url":"02-IBM_Z&LinuxONE/","title":"IBM_Z&LinuxONE","keywords":"","body":"IBM_Z&IBM_LinuxONE 简介 IBM Z 大型机:依靠具有最高安全性、性能和可用性的平台。 IBM LinuxONE是基于IBM Z硬件平台的企业级Linux平台服务器。 IBM Z mainframe官网：https://www.ibm.com/cn-zh/it-infrastructure/z IBM LinuxONE官网：https://www.ibm.com/cn-zh/it-infrastructure/linuxone 内容 IBM_LinuxONE "},"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/":{"url":"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/","title":"IBM_LinuxONE","keywords":"","body":"IBM_LinuxONE 简介   IBM LinuxONE™ 是Linux与开放源码结合而成的“巨无霸”级服务器，专为应用经济打造。通过将企业级Linux和开放源码的精华结合起来，将LinuxONE打造成为最高效、最强大和最安全的Linux平台服务器。 IBM LinuxONE官网：https://www.ibm.com/cn-zh/it-infrastructure/linuxone IBM LinuxONE在线实验室：https://csc.cn.ibm.com/linuxone/index?locale=zh_CN Open Source Software on IBM LinuxONE：https://www.ibm.com/it-infrastructure/linuxone/capabilities/open-source IBM LinuxONE CSDN主页:https://linuxone.csdn.net/ LinuxONE安装体验tomcat：部署Tomcat，体验Tomcat 内容 LinuxONE-数据收集 LinuxONE-学习笔记 LinuxONE-云最佳实践笔记 LinuxONE-云最佳实践KVM笔记 LinuxONE-OpenStack部署_KVM LinuxONE-OpenStack使用手册 LinxuONE-OpenShift安装配置 LinuxONE-部署Kubernetes集群 LinuxONE-Prometheus监控 "},"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/01-LinuxONE-数据收集.html":{"url":"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/01-LinuxONE-数据收集.html","title":"LinuxONE-数据收集","keywords":"","body":"LinuxONE-数据收集 IBM LinuxONE目前关于硬件及其维护维护的资料都是内部的，未在knowledge center中,所以此处记笔记只会记录IBM公开的信息。对于用户层面的配置以及运维资料很多，都是公开的，knowledge center和红皮书都有很多介绍，主页LinuxONE简介中有提供相关链接。个人也是初步接触在学习中， 操作系统层面故障诊断和排除官方链接:Linux on Z and LinuxONE 操作系统数据收集 使用dbginfo.sh脚本收集基本的诊断信息。官方介绍：dbginfo.sh脚本 根据系统类型收集对应的信息： SUSE Linux Enterprise Server上运行supportconfig,官方介绍：supportconfig Red Hat Enterprise Linux上运行sosreport,官方介绍：sosreport Ubuntu Server上运行sosreport "},"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/02-LinuxONE-学习笔记.html":{"url":"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/02-LinuxONE-学习笔记.html","title":"LinuxONE-学习笔记","keywords":"","body":"LinuxONE-学习笔记 个人在听课学习中记录的要点，不是系统性的操作文档或者功能介绍文档，方便自己随手翻阅巩固知识点。 LinuxONE-基础 机器和HMC基础知识： HMC是用户管理多台LinuxONE的控制台，和Power的HMC差不多 SE 是一台LinuxONE的控制节点，主备模式，保存微码、license、VPD和profile 如果关闭两台SE，不影响LinuxONE运行，但是无法进行管理 一定要做好SE备份，两台SE硬盘全坏了就会丢失LinuxONE配置信息，没有备份无法恢复 系统操作员的操作都可以通过HMC完成，涉及到硬件维护的需要在SE本地完成（微码升级新版本可以通过HMC） Execption：红色\"x\"标记，表示资源\"not accetptable\",不代表有严重问题，和Power的HMC里面的严重程度不一样 LinuxONE目前虚拟化主要使用DPM(Dynamic Partition Manager),支持用户动态修改逻辑分区 一个逻辑分区的Processor只能选择Shared或者Dedicated FCP占用一个设备号，网络设备占用三个设备号 HMC中Tasks index菜单列出当前用户能够做的操作的清单 分区启动方式中“none”通常是用作调试，逻辑分区可以启动，资源会获取到，不会去启动操作系统 操作系统是以“device number”来驱动使用HBA卡的 DPM Storage Group管理功能可以模拟逻辑分区操作去检查FCP的path和lun的可用性，点击“Connection Report”会触发，并且生成一个报告 LinuxOne逻辑分区安装 安装分区注意 安装分区知识点： z15 T01最多可同时激活85个LPAR,z15 T02最多可同时激活40个LPAR Linux操作系统启动中需要手动安装就配置kickstart.cfg脚本,自动安装就不需要 在RHEL7版本中系统生成的网卡设备名称是什么在rd.znet中输入设备号0.0.0016,0.0.0017,0.0.0018,生成设备名enccw0.0.0016，在redhat8中是enc开头，enc13 逻辑分区的vNIC及SG attached操作完成后建议将Boot设置成NONE，然后进行一次分区的Start/Stop操作，以便将资源加载到配置中 LinuxONE使用脚本安装时，kickstart可以通过以下两种方式指定并传给内核： 在HMC Console中手工输入应答指定 在RPM文件中通过inst.ks选项指定 如果采用手工安装并且选项GUI会TUI界面方式，操作工作站或笔记本需连接到逻辑分区OSA vNIC的连接网络 只使用HMC上的U盘进行逻辑分区的Linux操作系统安装时，必须满足的条件： HMC的ETH1与SE的EM4连接在同一交换机 用作系统盘的SG状态为Complete并已Attach到逻辑分区上 逻辑分区安装完成后,可以在线添加磁盘卷（LUN),不需要重启 开始逻辑分区操作系统安装前需要完成的工作： 完成逻辑分区网卡定义 获取逻辑分区volume信息 获取伙计分区ip及vlan信息 逻辑分区分配物理I/O端口时需要考虑的维度： 按I/O板卡打散分配 按I/O Drawer打散分配 Partition Details-Network说明 在HMC中DMP进行虚拟网卡管理菜单说明： name是给HMC查看分区使用，不会传递到操作系统中，可以根据自己喜好自定义 Device Number就是设备号，也是操作系统里面的设备号；创建时候可以自定义，不定义的话微码会自动分配，同一个逻辑分区不能重复，不同的逻辑分区可以重复 Adapter name分四段，第一段网卡类型，例如：OSA或RoCE,第二段是AdapterID,第三段是卡所在I/O抽屉的位置编号，第四段是槽位号；在创建虚拟网卡选择对应物理设备时候，要注意看此网卡信息 Adapter port，OSA一般为0或RoCE一般为1 card typy是完整的网卡信息 Vlan ID在HMC操作中很少用到 MAC address在网络连通启动时候才显示 FCP链路信息查看 安装准备时候，需要查看FCP链路信息： 进入需要安装系统对应的SG里面，检查下状态是否是complete 在VOLUMES选项下面会看到vol，根据Type类型选择对应卷点击GET DETAILS会出现盘卷对应的信息 如果做了一个逻辑分区定义，如果从来没有start，就会发现GET DETAILS是点不了的 INS文件说明 文件示例: * minimal lpar ins file images/kernel.img 0x00000000 images/initrd.img 0x02000000 images/genericdvd.prm 0x00010480 images/initrd.addrsize 0x00010408 说明： 第一行是个注释行 第二行开始用来标识说明内核启用需要的文件路径 PRM文件 rd.znet=qeth,0.0.0013,0.0.0014,0.0.0015,layer2=1: 用来定义网卡，qeth是OSA驱动程序名称 0.0.0013是三个device number，一个网卡会占用三个设备号，前面的0.0.最好建议带上 layer2=1用来设定OSA虚拟网卡运行在哪一层模式，一般建议2层，可以打开监听模式，可以做网桥等等 ip=182.158.10.129:::255.255.255.0:bp01b1:enccw0.0.0013:off： 用来定义逻辑分区启动后网卡上使用的IP地址，用冒号分隔，如果中间参数不需要输入，也需要加入冒号进行隔离 格式说明：ip:dns信息:网关信息:掩码:hostname:网卡的设备名:状态 inst.ks=ftp://182.158.10.100/pub/ks/rhel77_bp01b1_ks.cfg： 这是用脚本安装方式配置，传给安装程序的参数，定义KICKSTART文件位置 如果手动安装不需要KICKSTART脚本，把inst.ks改成inst.repo，后面内容指向安装文件所在的目录即可 rd.multipath=1： 如果是FCP磁盘一般需要配置此行 启动介质默认没有带multipath，多路径磁盘会在操作系统上认到多个磁盘，路径不会整合，可能会导致系统装好了，但是启动不了 rd.zfcp=0.00003,500507680c31cd11,0000000000000000： 系统盘卷的FCP链路信息，一般有多个 第一段FCP是设备号，第二段是对端磁盘盘控HBA卡端口的wwpn，第三段是磁盘卷lun id kickstart脚本 可以实现自动化安装部署内容： 定义用户组和用户的创建 盘卷分区或逻辑卷定义 除一定义的vNIC之外的其它网卡网络设置定义 定义软件仓库定义repo 额外按的软件包，定义需要安装的安装包必须要在之前定义repo里面能够找到 系统安装完成后的配置，%post内容是在安装好的操作系统中以root身份对系统进行的操作，每一行就是一条命令 "},"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/03-LinuxONE-云最佳实践笔记.html":{"url":"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/03-LinuxONE-云最佳实践笔记.html","title":"LinuxONE-云最佳实践笔记","keywords":"","body":"LinuxOne-云最佳实践笔记 学习IBM官方云最佳实践视频做的笔记，视频地址：LinuxONE高密度云最佳实践成长之路 (KVM版） LinuxOne云计算参考架构 多层级虚拟划技术： LinuxONE全面支持涵盖逻辑分区、虚机、容器得多层级虚拟胡技术 单机可承载高达：85个逻辑分区，8000个虚拟机，240万个容器 多层级混合架构及多云融合解决方案 容器云层级：支持Docker,K8S,Openshift等主流选择 虚拟机层级：支持基于Openstack得各种解决 逻辑分区级：支持将Lpar纳管，实现分区及OS自动化部署 多云化扩展：支持MCM等多云解决方案，CI/CD等 LinuxOne云计算整体架构 LinuxOne云计算主要解决方案： 企业级Openstack方案：IBM Cloud Infrastructure Center 社区支持的Openstack on LinuxOne解决方案 RedHat OpenShit on LinuxONE 基于Prometheus+Grafana的全面监控解决方案 利用DPM实现分区创建与管理 DMP DMP全称Dynamic Partition Management，LinuxONE LPAR&DMP优势： LPAR在满足分区隔离EAL5+标准的基础上，实现CPU、网卡、HBA卡的共享 DLPAR可以在线动态实现分区管理，如创建分区，删除分区，动态调整分区资源等 创建Storage Group 创建Storage Group步骤： 进入HMC主页面 选择目标LinuxONE机器 在“Configuretion”选项里面选择“Configure Storage” 在“STORAGE CARDS”选项中设定HBA卡类型，有两种：FICON Cards和FCP cards，通常使用FCP类型 在“CREATE STORAGE GROUP”选项中可以选择“Templates”或“Without Templates” 选择“Without Templates”后，接着设置通道数量： Tpye选项：之前设置了HBA卡类型时FCP就会默认时FCP Shearability：允许被多个分区使用，选择“Shared”并设置分区数量 Connecttvity：如果独占一个分区，并设置4通道，会生成4个wwpn；如果共享10个分区，通道数量是4，那么会生成40个wwpn Optimized for 2nd level virtualization：可以为Z/VM的虚拟机涉及虚拟wwpn数量 “Add Storage Volumes”对话框：用来设定磁盘数量和大小，主要两种类型： Boot类型用于操作系统安装 Data类型用于数据 “Name and duplicate”对话框：设定Storage Group的名字和描述；“Duplicate the storage group”可以快速的将当前设定的Storage Group进行复制 最后是Storage Group的概览确认，核对清楚确认无误后提交 “Manually Send Request”：会自动生成一个文本，里面描述了生成的wwpn，可以下载文本给存储工程师进行划zone等操作 最后点击“Finish”，Storage Group创建完成   SG里面添加的volumes没有在存储端实际添加磁盘，只是对SG里磁盘数量、大小和类型做一个标记，等SG创建完成后，需要在存储端添加对应的磁盘，SG会定期检查存储实际添加的磁盘数据、大小，如果不一致，会提示不匹配 创建LPAR 创建Lpar步骤： 进入HMC主页面 选择相应的主机 选择选项“configuration” 选择选项“New partition” 进入创建LPAR引导界面: Name：设置Lpar名称和Partition Type(如果是Linux选择Linux) Processors：分配给分区的逻辑CPU;支持独占和共享模式 Memory：“Memory”是操作系统启动后获取的内存；“Max Memory”指分区启动后可以动态调整的最大值 NetWork：添加网卡，列表中有所有网卡 Storage：添加Storage Group，列表中有所有创建的Storage Group，只有状态为Complete的SG才可以被使用 Boot：设定启动类型，支持多种类型：FTP、SAN等等 Redhat与SUSE在LinuxONE 安装RedHat操作系统 利用FTP server上boot开始系统安装 设定FTP启动，步骤如下： 选中分区选项“Partition Details”选项 点击“boot”选项 在“Boot from”选项中选择“FTP server” 在对应选项中填入FTP服务器的信息 在“INS file”中选定ins文件   启动分区后会读取FTP里面的文件，会出现“Operating System Messages”界面，RedHat安装方式采用的配置文件方式，会提示等待输入配置文件。 设置安装参数并启动VNC 安装参数配置是一个文本的配置文件，即之前学习过的PRM文件： 第一行是FTP安装源的路径 第二行配置用到的网卡信息，例如layer类型，假如添加的网卡叫3000，那么需要输入3000、3001和3002，是LinuxONE上独有的，规则如下： 3000代表读 3001代表写 3002代表data 第三行配置分区信息：IP、网关、掩码及hostname 接下来四行是配置目标存储的路径 最后“vnc”表示会启用vnc service去安装 在“Operating System Messages”界面输入刚才准备的参数，建议三行粘贴一次 所有配置文件输入完成后，输入英文符号点号，输入回车即可提交 配置参数无误，会出现启动vnc的提示：首先要通过ssh连接到机器，会自动启动vnc service 登录VNC完成后续安装 登录vnc后步骤： 设置语言 然后是设置面板：主要设定都可以在此设定，例如软件包等 设定完成后点击“Begin installation” 等待几分钟，提示“Complete”代表安装完成 点击“Reboot”重启 安装SUSE操作系统 利用FTP server上boot开始系统安装 步骤如下： 选中分区选择“Partition Details”选项 点击“boot”选项 在“Boot from”选项中选择“FTP server” 在对应选项中填入FTP服务器的信息 在“INS file”中选定ins文件 点击保存，然后启动分区：选中分区，选择Daily--Start 分区启动完成后提示“success” 启动完成后，选中分区，选择Daily--Operating System Messages 设置安装参数并启动VNC   打开“Operating System Messages”后可以看到和RedHat差不多界面，不过RedHat采用的是配置文件模式，SUSE采用的是交互式模式，步骤如下： 选择“1”：“Start installation” 继续选择“1”：“Installation”开始安装 选择安装方式，这里选择的是“Network”，其它方式暂不支持 选择网络安装方式，这里选的是“FTP\" 配置网卡，会列出当前分区已经配置的网卡，选择对应的网卡 输入端口值，默认情况下是“0”，如果是接在第二个口，选择“1” 设置网卡的三个通道地址，设定读通道地址（0.0.0001）、写通道地址（0.0.0002）及data通道地址（0.0.0003） 设置layer：根据网络需求设置对应类型 设置IP地址、掩码及网关，敲回车继续 设置name server：如果有就设定，没有就空着 设置domain：如果有就设定，没有就空着 设置FTP服务器的地址 设置安装介质的路径 设置FTP用户名和密码 提示是否使用HTTP proxy，如果环境里面没有网络代理就设置“No” 最后提示后续安装的方式，例如选择“vnc”，然后设置vnc的密码 设置完成后就可以通过vnc进行连接： 打开vnc客户端 在“VNC Server”选项里面输入目标端地址：IP:1，代表连接的目标5901端口 输入密码，点击“OK”继续 登录VNC完成后续安装 启动VNC后步骤： 设置语言：默认English，并同意协议后点击“next” 配置磁盘：点击“Configure ZFCP Disks” 在“Configure ZFCP Device”界面点击“Add”进行添加 “Channel ID”对应的是Storage Group里面的device ID，会自动扫描，下拉菜单选择对应即可 在“Configure ZFCP Device”界面里会看到添加的disks 点击“next”继续 在“Registration”界面提示是否注册，跳过即可 “Suggested Partitioning”界面会显示磁盘默认分区情况，如果想定制点击“Create Partition Setup” 选择时区：选择对应时区即可 “Local Users”：创建用户，不是必须选项，可以创建也可以跳过 设置root密码，点击“next”继续 “Installation Settings”：会显示当前SUSE系统的相关配置 确认无误后点击“Install”开始安装 等待几分钟后即可安装完成 设置从SAN启动操作系统   在LinuxONE中，任何操作系统安装完成后，都需要把boot选项从之前的FTP改成SAN启动，否则系统会无法启动，步骤如下： 选中分区选择“Partition Details”选项 点击“boot”选项 在“Boot from”选项中选择“Storage Group(SAN)” 然后自动列出Storage Group里的boot磁盘，选择对应即可 然后保存 最后将操作系统stop然后start后，整个操作系统即安装完成。 利用ECS实现LinuxONE LPAR的 批量安装部署 Enterprise Cloud Systems LinuxONE ECS介绍 端到端的LinuxONE及SAN存储资源自动化管理解决方案： 自动化LinuxONE分区部署 自动创建存储卷和交换机zone 根据魔棒自动安装Linux操作系统 标准化LinuxONE资源配置流程 通过角色管理实现资源管理审批流程 完备的部署日志 通过Prometheus和Grafana全面监控LinuxONE系统 多合一LinuxONE设备一站管理 通过添加可选的存储日志分析和监控组件实现SAN fabric拓扑自动生成、SAN fabric日志、告警及问题诊断分析 核心功能 资源部署： 一键部署：在获取LinuxONE和存储设备操作权限的前提下，ECS可以实现一键部署分区、配置存储、及安装操作系统 标准部署流程：LinuxONE、存储、管理员分别配置自己的管理网络范围内的i元，并最终完成系统安装 主流操作系统支持：支持主流企业级操作系统RedHat和SUSE的自动化安装 工作流体系： 自定义部署流程：管理员通过配置指定需要ECS自动完成的系统配置 资源操作全流程追踪：准确记录资源操作，确保任何资源所有的操作可以追溯 资源监控： 基于开源的监控：基于Prometheus及Grafana对逻辑分区以及操作系统进行监控 资源展示、统计、报警：根据用户需求宁或定制展示LinuxONE和存储资源内容，实现监控、数据统计及预警 权限控制： 多种管理员角色：ECS针对LinuxONE的资源部署类型进行了角色划分，共分为LinuxONE管理吗，存储管理员，网络管理员以及一个超级管理员，并针对各角色赋予不同管理权限 平台整合： RESTful API接入：ECS支持第三方系统通过RESTful API接入 平台特性 ECS平台特性： 跨数据中心管理：ECS可以轻松完成跨数据中的LinuxONE管理，适应用户多数据中心的运行环境 批量部署：支持批量部署，帮助用户快速完成环境部署 高度灵活：ECS是基于容器的云原生应用，部署灵活，可适用于各种部署要求 技术支持：ECS全程由IBM中国团队研发，可以方便的伟本土用户提供技术支持 平台优势 互联互通：助力LinuxONE上云，轻松整合多云管理平台 降低运维成本：有效降低运维人员对LinuxONE技能的依赖，大幅提高运维效率 监视风险：标准、灵活、透明的部署流程，安全可靠 可视化监控：简单易用的监控模块，快速定位问题 通过LinuxONE ECS进行部署 一键部署： LinuxONE管理员配置 HMC信息 保存系统mage的FTP服务器 存储管理员配置 SVC授权信息 SAN Switch授权信息 启动存储自动操作模式 一键部署 填写必要的参数（内存，CPU等）后，一键自动部署LinuxONE分区、存储以及操作系统 标准部署： LinuxONE管理员： 提交LinuxONE分区相关配置信息 分区创建成功，移交存储管理员 存储管理员 查看WWMPN 配置存储设备 配置成功后在ECS确认 ECS检查存储状态成功，移交网络管理员 网络管理员 配置网络参数并提交 Linux自动安装 所有管理员确认后自动进行操作系统安装及网络配置 批量部署：  导入安装计划CSV文件自动批量部署，这种情况适合新安装LinuxONE场景。在CSV里面写入对应配置信息，导入后自动解析并批量部署。 监控、日志及问题智能分析诊断 主要功能： 基础设施地图 主机拓扑/卷视图 主机带外管理 问题捕捉，问题定位，问题诊断 错误关联性分析 SAN fabric拓扑以及资源视图 SAN fabric资源状态以及改进分析 "},"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/04-LinuxONE-云最佳实践KVM笔记.html":{"url":"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/04-LinuxONE-云最佳实践KVM笔记.html","title":"LinuxONE-云最佳实践KVM笔记","keywords":"","body":"LinuxOne-云最佳实践KVM笔记 学习IBM官方云最佳实践视频做的笔记，视频地址：LinuxONE高密度云最佳实践成长之路 (KVM版） IBM 官方红皮书：RedbooksFront coverVirtualization Cookbookfor IBM Z Volume 5KVM KVM on LinuxONE 安装与管理 KVM host 准备 KVM on LinuxONE 基本架构： 每台LinuxONE都内置了硬件虚拟化微码，无需任何软件的支持，即可把LinuxONE分成很多个分区，分区间报纸EAL 5+ 基本的安全等级 在分区内部，KVM作为软件实现的虚拟化扩展了LinuxONE的虚拟能力 KVM由kernel模块KVM（虚拟处理器和内存）和运行在用户态的QEMU（虚拟网络和I/O）两部分构成 每个VM是KVM host的一个进程，每个VM的VCPU是属于这个进程的一个线程 KVM的管理方式： KVM可以通过libvirt组件进行方便的管理 大规模的资源管理一般是通过OpenStack来进行 少量的KVM可以通过virsh命令行或者图形界面Virt-Manager来管理 Cockpit是基于web方式，比较轻量的一种管理方式 KVM host的版本要求： LinuxONE 从SUSE 12 SP1或RHEL 7.5-ALT之后支持Linux发行版的KVM 对RHEL，目前推荐RHEL 7.6-ALT或者RHEL8.1，建议打上最新的kernel fix 对SUSE，目前推荐SUSE12 SP4 KVM host 软件安装 以RHEL7.6-ALT为例，演示KVM在LinuxONE上的环境准备和使用：1）安装RHEL7.6-ALT，更新到最新的kernel补丁，设置操作系统的yum源；2）安装下面所示的KVM相关软件（包括基本软件，性能监控和管理软件）： # yum install qumu-kvm libvirt virt-install \\ libvirt-python virt-manager libvirt-client virt-top 3）安装完成后，可以启动libvirtd service，或者重启KVM host；4）如果要使用图形化界面对KVM管理，需要安装做梦软件的vncserver： # yum install @gnome-desktop tigervnc-server 5）如果不适用图形界面，可以使用virsh-install来安装虚拟机，用virsh来管理虚机。 KVM 图形界面管理 以vnc为例 执行vncserver，设置好vnc password 用vnc client例如vncreviewer连接KVM host， 启动VMManager（Vitual Machine Manager） 创建和复制虚机 创建虚拟机 图形化安装步骤如下： 将RHEL 7.6的IOS（注意：VM不用7.6-ALT版本）上传到KVM host /var/lib/libvirt/images目录下，这个目录是缺省存放VM镜像的地方，空间需要保持足够使用。 在Vitual Machine Manager中点击“New VM”开始创建 在“Use ISO image”选项中选择需要安装的ISO文件 选择虚机的内存大小和CPU数量 根据实际需求更改磁盘的大小 输入虚机的名字，修改网卡，如果没有特别要求，macvtap方式性能较好，用bridge方式接入到已有的一张网卡， 点击完成后，出现了安装画面，配置各项配置：时区，安装的软件包，分区划分，网络配置，root密码等 最后选择“begin install”后开始安装 等待安装完成，回车后虚机重启   还可以通过virt-install命令来安装虚拟机，直接使用virt-install命令即可，在命令中设置各项配置，命令示例如下： # virt-install --name kvmtest01 --memory 2048 -vcpus 2 \\ --disk path=/var/lib/libvirt/images/kvmtest01_vol001.img,size=10 \\ --network network:macvtap-net \\ --cdrom /var/lib/libvirt/images/RHEL-7.6-20181010.0-Server-s390x-dvd1.iso 说明： 如果写入了size=10表示新创建一个10G大小的磁盘 如果先创建好了磁盘，可以用--import方式来使用已有磁盘   虚机启动成功后，进入到安装界面，跟之前基本一样配置各项配置：时区，安装的软件包，分区划分，网络配置，root密码等。最后回车重启虚机即可。 Clone虚机   可以定义一个标准的模板，后面可以使用Clone方式快速得到新的分区，省掉每个虚机重新安装，打补丁安装软件的过程，步骤如下： 关掉要Clone的虚机 选择虚机，点击右键，选择Clone 填入虚机名称，选择磁盘设置，点击Clone及Clone完成 虚机的性能监控   KVM VM的性能监控可以使用virt-top命令，这个命令可以看到哪些分区消耗处理器或内存比较多。结合VM里的应用，确认是否有性能问题。virt-top是一个单独的rpm包，在安装KVM相关组件的时候建议安装上。 直接使用virt-top命令即可启用，主要内容： 磁盘的读和写情况 网络的接受和发送情况 虚机占用的处理器占整个虚机百分比情况 虚机占用的内存占整个虚机百分比情况 基于KVM的OpenStack解决方案 OpenStack介绍以及应用场景 简介： OpenStack是一个开源的IaaS层云管理产品 距今已有10年历史，发布了已经有20多个版本 完全开源，得到了众多厂商的支持，功能愈来愈丰富和稳定 OpenStack主要包含计算、网络和存储三大模块 用户通过一个portal管理计算、存储和网络资源 基于LinuxONE的OpenStack已经得到了社区的支持 在rdo网站上可以使packstack快速安装OpenStack 可以利益rdo提供的安装包，自行进行安装 云上应用场景： 公有云：OpenStack涉及初衷是服务于公有云，其中的租户设计伟公有云奠定了基础 私有云：OpenStack在中国市场大多作为企业内部私有云建设 混合云：OpenStack本身可以纳管KVM等虚拟化环境，作为混合云管理的工具 OpenStack在LinuxONE上的解决方案 OpenStack分为计算节点和管理节点： 管理节点使用三个节点实现高可用，可安装在LinuxONE平台或X86平台，对计算节点进行管理 计算节点可以有多个，可按照在LinuxONE和X86平台 网络可分为管理、存储和业务网络。 OpenStack在LinuxONE上的优势 OpenStack在LinuxONE上的优势： 更强的计算能力，管理更大规模的工作负载 LinuxONE拥有最快CPU，用于KVM或z/VM虚拟化常见可以提高须立即性能 在同等CPU单位下，可以提供更多虚拟机，实现大规模工作负载和整合与管理 更高的存储性能，支持FC SAN协议 通常X86的存储支持IP SAN，LinuxONE既支持IP SAN也支持FC SAN 存储 FC SAN 提供更低的时延、速度更快、更稳定 更强的扩展能力，包括横向扩展和纵向扩展 当云平台的资源匮乏时，在LinuxONE上可以在线快速扩展计算节点 当某个计算节点资源匮乏时，可以在线快速纵向扩展几点节点的计算资源 OpenStack WEB界面示例 示例图如下： 待补充 "},"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/05-LinuxONE-OpenStack部署_KVM.html":{"url":"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/05-LinuxONE-OpenStack部署_KVM.html","title":"LinuxONE-OpenStack部署_KVM","keywords":"","body":"LinuxONE-OpenStack on KVM安装手册 学习IBM官方云最佳实践视频做的笔记，步骤基本摘自官方手册，手册地址：LinuxONE高密度云最佳实践成长之路 (KVM版） 部署环境   本文档部署OpenStack Train 版本，基于LinuxONE的硬件环境，每个Lpar有2个网卡，一个网卡为管理网，为OpenStack提供api交互，另外一块网卡为虚拟机业务网，次网卡不需要配置ip地址，网卡属性需要设置为bridge_role=primary。本次yum源使用rdo提供的源。OpenStack平台内部的用户比较多，为了方便读者部署，所有OpenStack的用户的密码均设置为openstack。 hostname IP OS kernal Hardware Nic controller 172.16.36.177 RHEL release8.0 4.18.0-80.el8.s390x 2c4G50G 管理enc3000业务enc3100 compute 172.16.36.176 RHEL release8.0 4.18.0-80.el8.s390x 2c4G50G 管理enc3000业务enc3100 下图为部署的基本架构图： 前期准备 配置YUM源 配置参考及步骤如下： [root@controller ~]# cat /etc/yum.repos.d/openstack.repo [rdo-train-upstream] name=rdo-train-upstream baseurl=https://trunk.rdoproject.org/centos8-train/puppet-passed-ci/ enabled=1 gpgcheck=0 [rdo-train-linuxone-deps] name=rdo-train-linuxone-deps baseurl=http://linuxone.cloud.marist.edu:8080/repos/rdo/rhel8.0/deps/ enabled=1 gpgcheck=0 [root@controller ~]# 关闭防火墙和selinux 配置参考及步骤如下： [root@controller ~]# systemctl stop firewalld [root@controller ~]# setenforce 0 setenforce: SELinux is disabled [root@controller ~]# sed -ri '/^[^#]*SELINUX=/s#=.+$#=disabled#' /etc/selinux/config 安装/配置 ntp 服务 在controller上配置配置ntp server： [root@controller ~]# yum install chrony -y [root@controller ~]# vim /etc/chrony.conf allow 172.16.36.0/24 [root@controller ~]# systemctl restart chronyd.service && systemctl enable chronyd.service 在compute节点配置ntp server为controller节点的ip地址: [root@compute ~]# vim /etc/chrony.conf server 172.16.36.177 iburst 重启服务: [root@compute ~]# systemctl restart chronyd.service && systemctl enable chronyd.service 配置hosts 解析: [root@controller ~]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 172.16.36.177 controller 172.16.36.176 compute [root@controller ~]# [root@compute ~]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 172.16.36.177 controller 172.16.36.176 compute [root@compute ~]# 安装数据库 OpenStack 使用Mariadb数据库存储内部数据，此步骤只需要在controller节点执行: [root@controller ~]# yum install mariadb mariadb-server python2-PyMySQL -y 添加配置文件: [root@controller ~]# cat /etc/my.cnf.d/openstack.cnf [mysqld] bind-address = 172.16.36.177 default-storage-engine = innodb innodb_file_per_table = on max_connections = 4096 collation-server = utf8_general_ci character-set-server = utf8 启动服务: [root@controller ~]# systemctl enable mariadb.service && systemctl start mariadb.service Created symlink /etc/systemd/system/mysql.service → /usr/lib/systemd/system/mariadb.service. Created symlink /etc/systemd/system/mysqld.service → /usr/lib/systemd/system/mariadb.service. Created symlink /etc/systemd/system/multi-user.target.wants/mariadb.service → /usr/lib/systemd/system/mariadb.service. [root@controller ~]# 安装rabbitmq 服务 Rabbitmq 服务为OpenStack提供了消息队列服务，用于各模块间的异步调用，此步骤只需要在controller节点执行: [root@controller ~]# yum install rabbitmq-server -y 启动服务: [root@controller ~]# systemctl enable rabbitmq-server.service && systemctl start rabbitmq-server.service [root@controller ~]# 为rabbitmq添加用户，并赋予权限: [root@controller ~]# rabbitmqctl add_user openstack openstack warning: the VM is running with native name encoding of latin1 which may cause Elixir to malfunction as it expects utf8. Please ensure your locale is set to UTF-8 (which can be verified by running \"locale\" in your shell) Adding user \"openstack\" ... [root@controller ~]# [root@controller ~]# rabbitmqctl set_permissions openstack \".*\" \".*\" \".*\" warning: the VM is running with native name encoding of latin1 which may cause Elixir to malfunction as it expects utf8. Please ensure your locale is set to UTF-8 (which can be verified by running \"locale\" in your shell) Setting permissions for user \"openstack\" in vhost \"/\" ... [root@controller ~]# 安装memcached 服务 Memcache 服务为OpenStack 提供缓存服务，此步骤只需要在controller节点执行: [root@controller ~]# yum install memcached python-memcached -y 编辑配置文件: [root@controller ~]# cat /etc/sysconfig/memcached PORT=\"11211\" USER=\"memcached\" MAXCONN=\"1024\" CACHESIZE=\"64\" OPTIONS=\"-l 127.0.0.1,::1,controller\" [root@controller ~]# 启动服务，并配置开机自启: [root@controller ~]# systemctl enable memcached.service && systemctl start memcached.service 安装etcd服务 安装： [root@controller ~]# yum install memcached python-memcached -y 编辑配置文件: [root@controller ~]# cat /etc/sysconfig/memcached PORT=\"11211\" USER=\"memcached\" MAXCONN=\"1024\" CACHESIZE=\"64\" OPTIONS=\"-l 127.0.0.1,::1,controller\" [root@controller ~]# 启动服务，并配置开机自启: [root@controller ~]# systemctl enable memcached.service && systemctl start memcached.service 跟刚才一模一样，回头研究下是否有误。 安装OpenStack客户端 安装命令如下： [root@controller ~]# yum install python3-openstackclient -y 安装keystone 认证服务 Keystone 为OpenStack提供认证服务，此组件安装到controller节点。 创建keystone数据库 配置参考及步骤如下： [root@controller ~]# mysql Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 9 Server version: 10.3.17-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]> CREATE DATABASE keystone; Query OK, 1 row affected (0.000 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'localhost' IDENTIFIED BY 'openstack'; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON keystone.* TO 'keystone'@'%' IDENTIFIED BY 'openstack'; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]> flush privileges; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]> \\q Bye [root@controller ~]# 安装并配置keystone服务 安装命令： [root@controller ~]# yum install openstack-keystone httpd mod_wsgi -y 修改配置： [root@controller ~]# vim /etc/keystone/keystone.conf ... [database] ... connection = mysql+pymysql://keystone:openstack@controller/keystone ... [token] provider = fernet 同步数据库: [root@controller ~]# su -s /bin/sh -c \"keystone-manage db_sync\" keystone 生成fernet key: [root@controller ~]# keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone [root@controller ~]# keystone-manage credential_setup --keystone-user keystone --keystone-group keystone 创建用户: [root@controller ~]# keystone-manage bootstrap --bootstrap-password openstack \\ --bootstrap-admin-url http://controller:5000/v3/ \\ --bootstrap-internal-url http://controller:5000/v3/ \\ --bootstrap-public-url http://controller:5000/v3/ \\ --bootstrap-region-id RegionOne 修改httpd配置文件: [root@controller ~]# vim /etc/httpd/conf/httpd.conf ServerName controller 创建软连接: [root@controller ~]# ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/ 启动服务: [root@controller ~]# systemctl enable httpd.service && systemctl start httpd.service Created symlink /etc/systemd/system/multi-user.target.wants/httpd.service → /usr/lib/systemd/system/httpd.service. 创建认证的配置文件，里面包含着认证信息，当我们需要操作OpenStack内部资源时，需要执行下这个文件: [root@controller ~]# cat admin.rc export OS_USERNAME=admin export OS_PASSWORD=openstack export OS_PROJECT_NAME=admin export OS_USER_DOMAIN_NAME=Default export OS_PROJECT_DOMAIN_NAME=Default export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 执行环境变量，做OpenStack的认证信息: [root@controller ~]# source admin.rc 创建user 的role，以后如果做多租户会需要用到: [root@controller ~]# openstack role create user 验证keystone服务是否可用 验证示例如下,若有类似的输出则证明安装成功： [root@controller ~]# openstack user list +----------------------------------+--------+ | ID | Name | +----------------------------------+--------+ | 45085728834a40e489d74b444da4a3e8 | admin | +----------------------------------+--------+ 安装glance服务 Glance服务为OpenStack提供镜像服务， 提供了镜像的上传下载等功能。此步骤在controller节点上执行。 创建glance数据库并配置用户 配置参考及步骤如下： [root@controller ~]# mysql Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 17 Server version: 10.3.17-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]> CREATE DATABASE glance; Query OK, 1 row affected (0.000 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'localhost' \\ IDENTIFIED BY \"openstack\"; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON glance.* TO 'glance'@'%' IDENTIFIED BY \"openstack\"; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]>\\q Bye [root@controller ~]# 在OpenStack中创建glane用户等 创建glance 用户: [root@controller ~]# . admin.rc [root@controller ~]# openstack user create --domain default --password-prompt glance User Password: openstack Repeat User Password: openstack +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | 0cb2e95340054ec892a0acd10e841161 | | name | glance | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ [root@controller ~]# 把glance用户添加到admin 角色: [root@controller ~]# openstack role add --project service --user glance admin 创建glance service: [root@controller ~]# openstack service create --name glance \\ > --description \"OpenStack Image\" image +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Image | | enabled | True | | id | 2288021c18674358a5c25bf2bf25e21a | | name | glance | | type | image | +-------------+----------------------------------+ [root@controller ~]# 创建endpoint: [root@controller ~]# openstack endpoint create --region RegionOne image public http://controller:9292 [root@controller ~]# openstack endpoint create --region RegionOne \\ image internal http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 2adcace3a6014c78924d81b9ebed67a6 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 2288021c18674358a5c25bf2bf25e21a | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ [root@controller ~]# openstack endpoint create --region RegionOne \\ image admin http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | ced28f385031456daa8f2b488f3cd154 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 2288021c18674358a5c25bf2bf25e21a | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ [root@controller ~]# 安装配置glance服务 安装命令： [root@controller ~]# yum install openstack-glance -y 修改配置文件： [root@controller ~]# vim /etc/glance/glance-api.conf [database] connection = mysql+pymysql://glance:openstack@controller/glance [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = glance password = openstack [paste_deploy] flavor = keystone [glance_store] stores = file,http default_store = file filesystem_store_datadir = /var/lib/glance/images/ 同步数据库: [root@controller ~]# su -s /bin/sh -c \"glance-manage db_sync\" glance 启动服务: [root@controller ~]# systemctl enable openstack-glance-api.service && systemctl start openstack-glance-api.service Created symlink /etc/systemd/system/multi-user.target.wants/openstack-glance-api.service → /usr/lib/systemd/system/openstack-glance-api.service. 验证glance服务是否可用 尝试上传一个镜像: [root@controller ~]# openstack image create \"rhel8\" --file rhel-guest-image-8.0-1854.s390x.qcow2 --property architecture=s390x --disk-format qcow2 --container-format bare --public 查看上传的镜像,若上传成功则证明服务可用: [root@controller ~]# glance image-list +--------------------------------------+-------+ | ID | Name | +--------------------------------------+-------+ | 1856b595-5726-4d95-9bfe-9379945e9132 | rhel8 | +--------------------------------------+-------+ 安装Placement服务   Placement 肩负着这样的历史使命，最早在 Newton 版本被引入到 openstack/nova repo，以 API 的形式进行孵化，所以也经常被称呼为 Placement API。它参与到 nova-scheduler 选择目标主机的调度流程中，负责跟踪记录 Resource Provider 的 Inventory 和 Usage，并使用不同的 Resource Classes 来划分资源类型，使用不同的 Resource Traits 来标记资源特征。此步骤在controller节点执行。 创建placement数据库 配置参考及步骤如下： [root@controller ~]# mysql Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 26 Server version: 10.3.17-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]> CREATE DATABASE placement; Query OK, 1 row affected (0.000 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'localhost' IDENTIFIED BY 'openstack'; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON placement.* TO 'placement'@'%' IDENTIFIED BY 'openstack'; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]> \\q Bye [root@controller ~]# 在OpenStack中创建placement用户 配置参考及步骤如下： [root@controller ~]# openstack user create --domain default --password-prompt placement User Password: openstack Repeat User Password: openstack +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | 17c732ee090543c2b9b3821adce25397 | | name | placement | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ 将placement配置为admin角色: [root@controller ~]# openstack role add --project service --user placement admin 创建placement service: [root@controller ~]# openstack service create --name placement \\ > --description \"Placement API\" placement +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Placement API | | enabled | True | | id | 02294d6fc6424f89a767f9d3d44994d8 | | name | placement | | type | placement | +-------------+----------------------------------+ 创建placement 的endpoint: [root@controller ~]# openstack endpoint create --region RegionOne \\ placement public http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 2523b444c9c24776ae700aaea6f25937 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 02294d6fc6424f89a767f9d3d44994d8 | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+ [root@controller ~]# openstack endpoint create --region RegionOne \\ placement internal http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | e75f70b88fbc42588f309b6fa19c3650 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 02294d6fc6424f89a767f9d3d44994d8 | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+ [root@controller ~]# openstack endpoint create --region RegionOne \\ placement admin http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 8e280614b8384c7ca45e227a2a28e27d | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 02294d6fc6424f89a767f9d3d44994d8 | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+ 安装配置placement 安装命令： [root@controller ~]# yum install openstack-placement-api -y 修改配置文件: [root@controller ~]# vim /etc/placement/placement.conf [placement_database] connection = mysql+pymysql://placement:openstack@controller/placement [api] auth_strategy = keystone [keystone_authtoken] auth_url = http://controller:5000/v3 memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = placement password = openstack ## [root@controller ~]# vim /etc/httpd/conf.d/00-placement-api.conf Listen 8778 WSGIProcessGroup placement-api WSGIApplicationGroup %{GLOBAL} WSGIPassAuthorization On WSGIDaemonProcess placement-api processes=3 threads=1 user=placement group=placement WSGIScriptAlias / /usr/bin/placement-api = 2.4> ErrorLogFormat \"%M\" ErrorLog /var/log/placement/placement-api.log #SSLEngine On #SSLCertificateFile ... #SSLCertificateKeyFile ... Alias /placement-api /usr/bin/placement-api SetHandler wsgi-script Options +ExecCGI WSGIProcessGroup placement-api WSGIApplicationGroup %{GLOBAL} WSGIPassAuthorization On = 2.4> Require all granted Order allow,deny Allow from all 同步数据库: [root@controller ~]# su -s /bin/sh -c \"placement-manage db sync\" placement Placement服务没有以单独的服务运行，而是和httpd集成到一起，重启httpd服务: [root@controller ~]# systemctl restart httpd 安装nova服务 Nova 是OpenStack 的计算模块，旨在于管理每个compute节点的虚拟机，比如虚拟机的start/stop/resize等。 控制节点执行 创建相关数据库 配置参考及步骤如下： [root@controller ~]# mysql Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 29 Server version: 10.3.17-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]> CREATE DATABASE nova_api; Query OK, 1 row affected (0.000 sec) MariaDB [(none)]> CREATE DATABASE nova; Query OK, 1 row affected (0.000 sec) MariaDB [(none)]> CREATE DATABASE nova_cell0; Query OK, 1 row affected (0.000 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'localhost' \\ -> IDENTIFIED BY 'openstack'; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova_api.* TO 'nova'@'%' IDENTIFIED BY 'openstack'; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'localhost' IDENTIFIED BY 'openstack'; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova.* TO 'nova'@'%' IDENTIFIED BY 'openstack'; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'localhost' IDENTIFIED BY 'openstack'; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON nova_cell0.* TO 'nova'@'%' IDENTIFIED BY 'openstack'; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]> \\q Bye 在OpenStack中添加nova用户 创建步骤如下： [root@controller ~]# openstack user create --domain default --password-prompt nova User Password: openstack Repeat User Password: openstack +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | f2e10eac7b4e4ef88b074e7669605609 | | name | nova | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ 为nova用户添加admin角色: [root@controller ~]# openstack role add --project service --user nova admin 添加nova service [root@controller ~]# openstack service create --name nova \\ --description \"OpenStack Compute\" compute +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Compute | | enabled | True | | id | dd4e9da63e774665958fa409efa65f30 | | name | nova | | type | compute | +-------------+----------------------------------+ 创建endpoint: [root@controller ~]# openstack endpoint create --region RegionOne \\ compute public http://controller:8774/v2.1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 53a71290cc214a06a6665d081cfa0782 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | dd4e9da63e774665958fa409efa65f30 | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1 | +--------------+----------------------------------+ [root@controller ~]# openstack endpoint create --region RegionOne \\ compute internal http://controller:8774/v2.1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | af529989702a44249f581d2454d91219 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | dd4e9da63e774665958fa409efa65f30 | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1 | +--------------+----------------------------------+ [root@controller ~]# [root@controller ~]# openstack endpoint create --region RegionOne \\ compute admin http://controller:8774/v2.1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 9c2ac43f49e74b56aa1042291668044f | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | dd4e9da63e774665958fa409efa65f30 | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1 | +--------------+----------------------------------+ 安装nova相关包 命令如下： [root@controller ~]# yum install openstack-nova-api openstack-nova-conductor \\ openstack-nova-novncproxy openstack-nova-scheduler -y 修改配置文件 参考如下： [root@controller ~]# vim /etc/nova/nova.conf [DEFAULT] enabled_apis = osapi_compute,metadata transport_url = rabbit://openstack:openstack@controller:5672 my_ip = 172.16.36.177 use_neutron = true firewall_driver = nova.virt.firewall.NoopFirewallDriver [database] connection = mysql+pymysql://nova:openstack@controller/nova [api_database] connection = mysql+pymysql://nova:openstack@controller/nova_api [api] auth_strategy = keystone [keystone_authtoken] www_authenticate_uri = http://controller:5000/ auth_url = http://controller:5000/ memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = nova password = openstack [vnc] enabled = false [glance] api_servers = http://controller:9292 [oslo_concurrency] lock_path = /var/lib/nova/tmp [placement] region_name = RegionOne project_domain_name = Default project_name = service auth_type = password user_domain_name = Default auth_url = http://controller:5000/v3 username = placement password = openstack 同步及启动 同步数据库： [root@controller ~]# su -s /bin/sh -c \"nova-manage api_db sync\" nova [root@controller ~]# su -s /bin/sh -c \"nova-manage cell_v2 map_cell0\" nova [root@controller ~]# su -s /bin/sh -c \"nova-manage cell_v2 create_cell --name=cell1 --verbose\" nova 29f46528-001d-48c4-a243-717d449581ba [root@controller ~]# su -s /bin/sh -c \"nova-manage db sync\" nova /usr/lib/python3.6/site-packages/pymysql/cursors.py:165: Warning: (1831, 'Duplicate index `block_device_mapping_instance_uuid_virtual_name_device_name_idx`. This is deprecated and will be disallowed in a future release') result = self._query(query) /usr/lib/python3.6/site-packages/pymysql/cursors.py:165: Warning: (1831, 'Duplicate index `uniq_instances0uuid`. This is deprecated and will be disallowed in a future release') result = self._query(query) [root@controller ~]# su -s /bin/sh -c \"nova-manage cell_v2 list_cells\" nova +-------+--------------------------------------+------------------------------------------+-------------------------------------------------+----------+ | 名称 | UUID | Transport URL | 数据库连接 | Disabled | +-------+--------------------------------------+------------------------------------------+-------------------------------------------------+----------+ | cell0 | 00000000-0000-0000-0000-000000000000 | none:/ | mysql+pymysql://nova:****@controller/nova_cell0 | False | | cell1 | 29f46528-001d-48c4-a243-717d449581ba | rabbit://openstack:****@controller:5672/ | mysql+pymysql://nova:****@controller/nova | False | +-------+--------------------------------------+------------------------------------------+-------------------------------------------------+----------+ [root@controller ~]# 启动服务: [root@controller ~]# systemctl enable \\ openstack-nova-api.service \\ openstack-nova-scheduler.service \\ openstack-nova-conductor.service \\ openstack-nova-novncproxy.service [root@controller ~]# systemctl start \\ openstack-nova-api.service \\ openstack-nova-scheduler.service \\ openstack-nova-conductor.service \\ openstack-nova-novncproxy.service [root@controller ~]# 计算节点执行 安装及配置 安装nova-compute 包： [root@compute ~]# dnf module disable virt [root@compute ~]# yum install openstack-nova-compute -y 修改配置文件: [root@compute ~]# vim /etc/nova/nova.conf [DEFAULT] enabled_apis = osapi_compute,metadata transport_url = rabbit://openstack:openstack@controller:5672 my_ip =172.16.36.176 use_neutron = true firewall_driver = nova.virt.firewall.NoopFirewallDriver compute_driver = libvirt.LibvirtDriver config_drive_format = iso9660 force_config_drive = True flat_injected=true [api] auth_strategy = keystone [keystone_authtoken] www_authenticate_uri = http://controller:5000/ auth_url = http://controller:5000/ memcached_servers = controller:11211 auth_type = password project_domain_name = Default user_domain_name = Default project_name = service username = nova password = openstack [vnc] enabled=false [glance] api_servers = http://controller:9292 [oslo_concurrency] lock_path = /var/lib/nova/tmp [placement] region_name = RegionOne project_domain_name = Default project_name = service auth_type = password user_domain_name = Default auth_url = http://controller:5000/v3 username = placement password = openstack [libvirt] virt_type = kvm cpu_mode = none use_usb_tablet = False inject_partition = -2 启动服务: [root@compute ~]# systemctl restart libvirtd.service openstack-nova-compute.service \\ && systemctl enable libvirtd.service openstack-nova-compute.service 验证nova模块是否正常 列出的服务都是up即为正常: [root@controller ~]# openstack compute service list --service nova-compute +----+--------------+---------+------+---------+-------+----------------------------+ | ID | Binary | Host | Zone | Status | State | Updated At | +----+--------------+---------+------+---------+-------+----------------------------+ | 5 | nova-compute | compute | nova | enabled | up | 2020-04-21T09:10:26.000000 | +----+--------------+---------+------+---------+-------+----------------------------+ [root@controller ~]# su -s /bin/sh -c \"nova-manage cell_v2 discover_hosts --verbose\" nova Found 2 cell mappings. Skipping cell0 since it does not contain hosts. Getting computes from cell 'cell1': 29f46528-001d-48c4-a243-717d449581ba Checking host mapping for compute host 'compute': 68fd1fa7-5074-48c6-8f6a-d6afd490dadc Creating host mapping for compute host 'compute': 68fd1fa7-5074-48c6-8f6a-d6afd490dadc Found 1 unmapped computes in cell: 29f46528-001d-48c4-a243-717d449581ba [root@controller ~]# [root@controller ~]# nova service-list +--------------------------------------+----------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+ | Id | Binary | Host | Zone | Status | State | Updated_at | Disabled Reason | Forced down | +--------------------------------------+----------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+ | a1d58917-55eb-4936-b59f-f7a01e5062cb | nova-conductor | controller | internal | enabled | up | 2020-04-21T09:11:28.000000 | - | False | | 70577e8a-9352-4304-a322-570903d9c70f | nova-scheduler | controller | internal | enabled | up | 2020-04-21T09:11:29.000000 | - | False | | 98931cb3-19ee-487e-9e1f-45872c519749 | nova-compute | compute | nova | enabled | up | 2020-04-21T09:11:36.000000 | - | False | +--------------------------------------+----------------+------------+----------+---------+-------+----------------------------+-----------------+-------------+ [root@controller ~]# 安装neutron服务 Neutron 服务为OpenStack提供SDN 服务，为虚拟机提供虚拟网络。 控制节点执行 创建neutron数据库 配置参考及步骤如下： [root@controller ~]# mysql Welcome to the MariaDB monitor. Commands end with ; or \\g. Your MariaDB connection id is 101 Server version: 10.3.17-MariaDB MariaDB Server Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. MariaDB [(none)]> CREATE DATABASE neutron; Query OK, 1 row affected (0.000 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'localhost' \\ IDENTIFIED BY 'openstack'; Query OK, 0 rows affected (0.001 sec) MariaDB [(none)]> GRANT ALL PRIVILEGES ON neutron.* TO 'neutron'@'%' IDENTIFIED BY 'openstack'; Query OK, 0 rows affected (0.000 sec) MariaDB [(none)]>\\q 用户创建 创建neutron用户并赋予admin权限： [root@controller ~]# openstack user create --domain default --password-prompt neutron User Password: openstack Repeat User Password: openstack +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | default | | enabled | True | | id | 94ac1191b9a84ef581fa1ac65e2b40a0 | | name | neutron | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ [root@controller ~]# openstack role add --project service --user neutron admin 创建neutron service: [root@controller ~]# openstack service create --name neutron \\ --description \"OpenStack Networking\" network +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Networking | | enabled | True | | id | 5fd0d75fcd0f470fa26202dbb34dc0e2 | | name | neutron | | type | network | +-------------+----------------------------------+ 创建endpoint: [root@controller ~]# openstack endpoint create --region RegionOne \\ network public http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 700d0ba978654bdc94374da2dcca9554 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 5fd0d75fcd0f470fa26202dbb34dc0e2 | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ [root@controller ~]# openstack endpoint create --region RegionOne \\ network internal http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | f1e236c9fe7d41bea80235aade1f6c51 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 5fd0d75fcd0f470fa26202dbb34dc0e2 | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ [root@controller ~]# openstack endpoint create --region RegionOne \\ network admin http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 96610eaf1ad14d828035b91457b06f47 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 5fd0d75fcd0f470fa26202dbb34dc0e2 | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ [root@controller ~]# 安装neutron相关包: [root@controller ~]# yum install openstack-neutron-ml2 \\ openstack-neutron-openvswitch openstack-neutron python3-neutronclient -y 修改配置文件: [root@controller ~]# vim /etc/neutron/neutron.conf [DEFAULT] notify_nova_on_port_status_changes = true notify_nova_on_port_data_changes = true core_plugin = ml2 auth_strategy = keystone transport_url = rabbit://openstack:openstack@controller bind_host=172.16.36.177 [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = openstack [database] connection = mysql+pymysql://neutron:openstack@controller/neutron [nova] # ... auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = openstack [oslo_concurrency] lock_path = /var/lib/neutron/tmp vim /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = local,flat,vlan tenant_network_types = flat,vlan mechanism_drivers =openvswitch [ml2_type_flat] flat_networks =* [ml2_type_vlan] network_vlan_ranges =vlan [ml2_type_gre] [ml2_type_vxlan] [securitygroup] enable_security_group = True firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver [l2pop] [database] [agent] l2_population=False polling_interval=2 arp_responder=False [ovs] enable_tunneling=False integration_bridge=br-int bridge_mappings=vlan:br-ex [root@controller ~]# cat /etc/neutron/plugins/ml2/openvswitch_agent.ini [ml2] type_drivers = local,flat,vlan tenant_network_types = flat,vlan mechanism_drivers =openvswitch [ml2_type_flat] flat_networks =* [ml2_type_vlan] network_vlan_ranges =vlan [ml2_type_gre] [ml2_type_vxlan] [securitygroup] enable_security_group = True firewall_driver = neutron.agent.linux.iptables_firewall.OVSHybridIptablesFirewallDriver [l2pop] [database] [agent] l2_population=False polling_interval=2 arp_responder=False [ovs] enable_tunneling=False integration_bridge=br-int bridge_mappings=vlan:br-ex [root@controller ~]# vim /etc/neutron/metadata_agent.ini [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = openstack [root@controller ~]# vim /etc/nova/nova.conf [neutron] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = openstack service_metadata_proxy = true metadata_proxy_shared_secret =openstack 创建软连接: [root@controller~]#ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini 同步数据库: [root@controller ~]# su -s /bin/sh -c \"neutron-db-manage --config-file /etc/neutron/neutron.conf \\ --config-file /etc/neutron/plugins/ml2/ml2_conf.ini upgrade head\" neutron INFO [alembic.runtime.migration] Context impl MySQLImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. 正在对 neutron 运行 upgrade... INFO [alembic.runtime.migration] Context impl MySQLImpl. INFO [alembic.runtime.migration] Will assume non-transactional DDL. INFO [alembic.runtime.migration] Running upgrade -> kilo INFO [alembic.runtime.migration] Running upgrade kilo -> 354db87e3225 INFO [alembic.runtime.migration] Running upgrade 354db87e3225 -> 599c6a226151 INFO [alembic.runtime.migration] Running upgrade b12a3ef66e62 -> 97c25b0d2353 INFO [alembic.runtime.migration] Running upgrade 97c25b0d2353 -> 2e0d7a8a1586 INFO [alembic.runtime.migration] Running upgrade 2e0d7a8a1586 -> 5c85685d616d 网络配置 创建网桥： [root@controller ~]# systemctl start openvswitch [root@controller ~]# systemctl enable openvswitch [root@controller ~]# ovs-vsctl add-br br-ex [root@controller ~]# ovs-vsctl add-port br-ex enc3100 #此网卡为业务网卡 [root@controller ~]# ovs-vsctl show f8a27ca8-e2f9-4b9a-9208-a25efd0b8fff Bridge br-ex Port br-ex Interface br-ex type: internal Port \"enc3100\" Interface \"enc3100\" ovs_version: \"2.11.0\" [root@controller ~]# 配置网卡为bridge_role，若不配置虚拟机网络会不通: [root@controller ~]#chzdev 0.0.3100 bridge_role=primary [root@controller ~]# chzdev -e 0.0.3100 修改配置文件 修改系统的配置文件： [root@controller ~]# vim /etc/sysctl.conf net.ipv4.tcp_keepalive_intvl = 1 net.ipv4.tcp_keepalive_probes = 5 net.ipv4.tcp_keepalive_time = 5 net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 net.bridge.bridge-nf-call-arptables = 1 net.ipv4.ip_forward = 1 [root@controller ~]# sysctl -p 启动服务 启动步骤如下： [root@controller ~]# systemctl start neutron-server.service neutron-openvswitch-agent.service neutron-metadata-agent.service neutron-openvswitch-agent.service [root@controller ~]# systemctl enable neutron-server.service neutron-openvswitch-agent.service neutron-metadata-agent.service neutron-openvswitch-agent.service Created symlink /etc/systemd/system/multi-user.target.wants/neutron-server.service → /usr/lib/systemd/system/neutron-server.service. Created symlink /etc/systemd/system/multi-user.target.wants/neutron-openvswitch-agent.service → /usr/lib/systemd/system/neutron-openvswitch-agent.service. Created symlink /etc/systemd/system/multi-user.target.wants/neutron-metadata-agent.service → /usr/lib/systemd/system/neutron-metadata-agent.service. [root@controller ~]# 在计算节点执行 安装neutron-openvswitch 服务: [root@compute ~]# yum install openstack-neutron-ml2 openstack-neutron-openvswitch ebtables ipset -y 改配置文件，可以复用控制节点的配置文件: [root@compute ml2]# pwd /etc/neutron/plugins/ml2 [root@compute neutron]# scp controller:/etc/neutron/neutron.conf . The authenticity of host 'controller (172.16.36.177)' can't be established. ECDSA key fingerprint is SHA256:aZZ6eV1fv07ZBk1A3qjv/dlmGeSIsmWThYlebsRIy/A. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added 'controller' (ECDSA) to the list of known hosts. root@controller's password: neutron.conf 100% 39KB 1.9MB/s 00:00 把ip改成本节点的ip地址: [root@compute neutron]# vim neutron.conf bind_host=172.16.36.176 [root@compute ml2]# scp controller:/etc/neutron/plugins/ml2/ml2_conf.ini . [root@compute ml2]# scp controller:/etc/neutron/plugins/ml2/openvswitch_agent.ini . 修改nova.conf: [root@compute ml2]# vim /etc/nova/nova.conf [neutron] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = openstack 创建网桥: [root@compute ml2]# systemctl start openvswitch [root@compute ml2]# ovs-vsctl add-br br-ex [root@compute ml2]# ovs-vsctl add-port br-ex enc3100 配置网卡为bridge_role: [root@controller ~]# chzdev 0.0.3100 bridge_role=primary [root@controller ~]# chzdev -e 0.0.3100 启动服务: [root@compute ml2]# systemctl enable neutron-openvswitch-agent.service openvswitch [root@compute ml2]# systemctl restart neutron-openvswitch-agent.service openstack-nova-compute.service openstack-nova-api [root@compute ml2]# 验证服务 若是笑脸则证明服务正常： [root@controller ml2]# neutron agent-list neutron CLI is deprecated and will be removed in the future. Use openstack CLI instead. +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ | id | agent_type | host | availability_zone | alive | admin_state_up | binary | +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ | 1816c0ed-c633-45f4-b7b9-12a8a553aabc | Metadata agent | controller | | :-) | True | neutron-metadata-agent | | 1ca845c3-85d6-44cc-9a8e-10bedd1828ea | Open vSwitch agent | controller | | :-) | True | neutron-openvswitch-agent | | e8bd8275-db99-48f2-9af9-0c659ba83d9f | Open vSwitch agent | compute | | :-) | True | neutron-openvswitch-agent | +--------------------------------------+--------------------+------------+-------------------+-------+----------------+---------------------------+ [root@controller ml2]# 安装dashboard dashboard 是为OpenStack提供web管理界面，更方便的管理Openstack，降低了使用成本。 安装配置 安装命令如下： [root@controller ~]# yum install openstack-dashboard -y 修改配置文件: [root@controller ~]# vim /etc/openstack-dashboard/local_settings OPENSTACK_HOST = \"controller\" ALLOWED_HOSTS = ['*', ] SESSION_ENGINE = \"django.contrib.sessions.backends.cache\" CACHES = { 'default': { 'BACKEND': 'django.core.cache.backends.memcached.MemcachedCache', 'LOCATION': 'controller:11211', } } OPENSTACK_KEYSTONE_URL = \"http://%s:5000/v3\" % OPENSTACK_HOST OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True OPENSTACK_API_VERSIONS = { 'identity': 3, \"image\": 2, \"volume\": 3, } OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = 'Default' OPENSTACK_KEYSTONE_DEFAULT_ROLE = \"user\" OPENSTACK_NEUTRON_NETWORK = { 'enable_distributed_router': False, 'enable_firewall': False, 'enable_ha_router': False, 'enable_lb': False, 'enable_quotas': True, 'enable_security_group': True, 'enable_vpn': False, 'profile_support': None, } TIME_ZONE = \"UTC\" [root@controller ~]# vim /etc/httpd/conf.d/openstack-dashboard.conf WSGIApplicationGroup %{GLOBAL} 重启服务: [root@controller ~]# systemctl restart httpd.service memcached.service   此时使用浏览器访问，在浏览器中访问http://ip/dashboard若此时正常访问则证明搭建成功，若访问不到，则需要在/etc/openstack-dashboard/local_settings最后添加: WEBROOT = '/dashboard/' LOGIN_URL = '/dashboard/auth/login/' LOGOUT_URL = '/dashboard/auth/logout/' LOGIN_REDIRECT_URL = '/dashboard/' 添加完后，重启httpd和memcached服务再重试使用web登录。 "},"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/06-LinuxONE-OpenStack使用手册.html":{"url":"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/06-LinuxONE-OpenStack使用手册.html","title":"LinuxONE-OpenStack使用手册","keywords":"","body":"LinuxONE-OpenStack云平台使用手册 结合上机实践步骤，简单用文字记录使用手册，官方手册图文并茂，手册地址：LinuxONE高密度云最佳实践成长之路 (KVM版） OpenStack简介   OpenStack是一个开源的云计算管理平台项目，是一系列软件开源项目的组合。由NASA(美国国家航空航天局)和Rackspace合作研发并发起，以Apache许可证（Apache软件基金会发布的一个自由软件许可证）授权的开源代码项目。 官方网站：https://www.openstack.org/官方文档：https://docs.openstack.org/GitHub：https://github.com/openstack/openstack 普通用户使用手册 在浏览器中输入http://IP/dashboard会看进入到登录界面。 实例 创建实例 步骤如下： 在项目>计算>实例页面的右上角点击创建实例 输入实例名称、数量，选择虚拟机模板 在源界面选择镜像，点击右侧向上的箭头表示选中，若已选中点击下一步 在示例类型界面选择实例类型，点击右侧向上的箭头表示选中，若已选中点击下一步 选择网络（右侧向上的箭头表示选中）后并点击创建实例 在项目>计算>实例页面可以查看创建的实例 等待示例状态为运行 虚拟机关机 步骤如下： 在项目>计算>实例页面选中需要关闭的实例 在项目>计算>实例页面的右上角点击更多操作 在下来菜单中选中关闭实例 在项目>计算>实例页面可以查看实例状态 虚拟机开机 步骤如下： 在项目>计算>实例页面中实例列表后面动作列，点击启动实例 在项目>计算>实例页面可以查看实例状态 使用console 进入操作系统 输入如下命令查看test的信息： # openstack server show test   查看host和instance_name，示例中DX1ALAPP2为承载虚拟机的host, 虚拟机的instance_name为instance-000000cd，登录到DX1ALAPP2进入虚拟机： # virsh console instance-000000cd 更改虚拟机配置   系统上线之后，随着生产的需要很可能需要对现有的虚拟机更改配置，比如扩展CPU,内存或磁盘。示例虚拟机的ip为16.35.161，示例大小为2C1G5G，步骤如下： 在项目>计算>实例页面中动作列选项对应实例下拉菜单中找到调整实例大小 弹出调整实例大小对话框，在新的实例类型选项中写入新的大小,格式:2c1g10g 在调整实例大小对话框点击调整大小 在项目>计算>实例页面中实例列表后面动作列选项对应实例下拉菜单中点击确认调整大小/迁移 在项目>计算>实例页面可以查看实例类型是否调整 虚拟机救援   当虚拟机密码忘记或者发生故障进不去操作系统时，可以使用此功能把虚拟机的系统盘临时作为第二块盘挂载到操作系统，进行虚拟机救援，类似于物理机的救援模式。 在项目>计算>实例页面中动作列选项对应实例下拉菜单中找到救援云主机 在对话框救援云主机中选择ubuntu-rescue这个镜像（根据实际需求），点击确认 进入系统后，挂载/dev/vdb 到系统即可进行修改 重建实例   当一个虚拟机物理在计划内或者计划外想要之前虚拟机的IP和配置时可以进行重建，此时虚拟机的disk会被重新配置。之前的cpu、内存、网络会被保留。 在项目>计算>实例页面中动作列选项对应实例下拉菜单中找到重建实例 在对话框重建实例中选择镜像点击重建实例即可 虚拟机热迁移 热迁移这个动作只能用管理员来执行，所以先点击管理员，再找到对应的实例，点击实例热迁移： 在项目>计算>实例页面中动作列选项对应实例下拉菜单中找到实例热迁移 选择新的目标主机，若有共享存储，则直接选择提交， 若没有共享存储，要把块迁移选项勾选然后点击提交 镜像 创建镜像 命令如下： # openstack image create \"rhel7\" --file rhel7-compress.qcow2 \\ --property architecture=s390x --disk-format qcow2 \\ --container-format bare --public 查看镜像 在主菜单项目>计算>镜像页面中可以查看创建的镜像。 网络 查看SDN网络拓扑   在项目>网络>网络拓扑页面中可以查看网络拓扑，当前网络拓扑不仅可以看到当前网络，还可以看到所关联的虚拟机。 查看当前网络 在项目>网络>网络页面中可以查看当前网络状态。 添加安全规则 示例添加ssh： 点击项目>网络>安全组>管理规则 点击添加规则后点击定制TCP规则 选择最后一项SSH,然后点击添加 通过终端ssh到此实例进下测试 管理员用户使用手册 创建网络 步骤如下： 在项目>网络>网络页面中右上角点击创建网络选项 在创建网络对话框中输入配置（根据需求）：名称，项目，网络类型，物理网络，勾选启动管理员状态、外部网络，创建子网，写入可用域提示 在子网选项中填入子网名称，网络地址和网关等 在子网详情中根据需求是否DHCP，然后点击创建即可 创建Flavor   Flavor作为虚拟机的配置，当创建虚拟机时需要为其选择一个Flavor，也就定义了虚拟机的配置，比如1C2G120G： 在主菜单计算下实例类型页面中右上角点击创建实例类型选项 填入需求信息点击创建实例类型即可 在主菜单计算下实例类型页面中可以查看创建的实例类型 创建主机聚合   主机聚合作为kvm host的逻辑隔离，换言之可以指定虚拟机创建在哪个区域。下面创建主机聚合： 在项目>计算>主机聚合页面中右上角点击创建主机聚合选项 在创建主机聚合对话框中主机聚合信息中填入名称及可用域 在创建主机聚合对话框中管理聚合内的主机中增加主要到这个聚合 点击创建即可 在项目>计算>主机聚合页面中可以查看创建的主机聚合 创建项目 步骤如下： 在项目>项目>项目页面中右上角点击创建项目选项 在对话框创建项目的选项项目信息中填入对应的信息 选项配额中为项目输入配额（根据需求来填写） 点击创建项目 在项目>项目>项目页面查看创建的项目 创建用户并关联项目 步骤如下： 在主菜单身份管理下选择用户 在用户页面右上角点击创建用户选项 在创建用户对话框中选择项目并填写密码等信息 尝试用刚刚创建的用户登陆平台 "},"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/07-LinxuONE-OpenShift安装配置.html":{"url":"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/07-LinxuONE-OpenShift安装配置.html","title":"LinxuONE-OpenShift安装配置","keywords":"","body":"LinuxONE-OpenShift在LinuxONE上的安装配置_KVM   学习IBM官方LinuxONE高密度云最佳实践视频做的笔记，步骤基本摘自官方，结合上机实践步骤，整理成此文档方便查阅巩固知识。官方地址：LinuxONE高密度云最佳实践成长之路 (KVM版） OpenShift简介   OpenShift是由红帽（RedHat）开发的容器化软件解决方案，这是基于企业级Kubernetes管理的平台即服务（PaaS）。OKD是嵌入在Red Hat OpenShift中的上游Kubernetes发行版。  OpenShift 虚拟化是红帽OpenShift的一项功能，其将每个虚拟机（VM）封装在特殊容器内，便于您对传统应用以及新的云原生工作负载和无服务器工作负载进行现代化改造，且全部可通过单一的 Kubernetes 原生架构进行管理。 官方网站：https://www.openshift.com/官方中文网站：https://www.redhat.com/zh/technologies/cloud-computing/openshiftOpenShift Kubernetes中文社区：https://www.kubernetes.org.cn/tags/openshift OKD GitHub：https://github.com/openshift/origin 系统环境说明 介绍配置安装配置的环境。 宿主机系统信息 为了使用KVM支持，测试使用的是Red Hat Enterprise Linux 7.6 ALT版本，系统信息如下： Static hostname: lpar07 Icon name: computer Machine ID: d93aa775a60e4447bb1746db80a9eecb Boot ID: c5c2b1a68cda4c4283d65f70c9cf2555 Operating System: Red Hat Enterprise Linux Server 7.6 (Maipo) CPE OS Name: cpe:/o:redhat:enterprise_linux:7.6:GA:server Kernel: Linux 4.14.0-115.el7a.s390x Architecture: s390x Openshift 集群环境参数 集群环境参数如下： 1台Bootstrap主机: 192.168.122.30 3台Master主机: 192.168.122.31-33 2台Worker主机: 192.168.122.34-35 实验环境需使用的代理服务器: http://172.16.15.192:3128/ 实验环境KVM子网: 192.168.122.0/24 实验环境KVM网关: 192.168.122.1 实验环境主域名: example.com Openshift集群名: ocp 软件包 需求的软件包如下： # yum install libvirt virt-install libvirt-daemon-kvm httpd # wget http://172.16.27.78/pub/Packages/haproxy-1.5.18-9.el7.s390x.rpm # yum install haproxy-1.5.18-9.el7.s390x.rpm 宿主机准备工作 配置DNS服务（使用dnsmasq服务） DNS服务配置是依据Openshift安装的官方文档要求，官方文档：User-provisioned DNS requirements 配置主机的正向及反向域名解析 请注意确认在原始hosts文件中没有以上IP地址的任何记录，如果有请先删除后再操作： # cat <> /etc/hosts 192.168.122.1 lpar07.ocp.example.com 192.168.122.1 api.ocp.example.com 192.168.122.1 api-int.ocp.example.com 192.168.122.30 bootstrap.ocp.example.com 192.168.122.31 master-0.ocp.example.com 192.168.122.32 master-1.ocp.example.com 192.168.122.33 master-2.ocp.example.com 192.168.122.31 etcd-0.ocp.example.com 192.168.122.32 etcd-1.ocp.example.com 192.168.122.33 etcd-2.ocp.example.com 192.168.122.34 worker-0.ocp.example.com 192.168.122.35 worker-1.ocp.example.com EOF 配置集群的服务记录及泛域名解析记录 配置如下： # cat 启动系统的dnsmasq服务 启动命令如下： # systemctl start dnsmasq 配置libvirt的缺省网络 配置方法如下： # systemctl start libvirtd # cat net-default.xml default $(virsh net-uuid default | head -1) EOF # virsh net-define net-default.xml # virsh net-destroy default # virsh net-start default 注意： 因为低版本的libvirt暂不支持泛域名解析，所以配置内部DNS服务，使其将虚拟机的DNS请求发送到系统的DNS服务 配置MAC和IP绑定，实现固定的IP地址分配，使Openshift的各个虚拟机每次启动都可以获得固定的IP地址 配置Apache服务器 用来提供ignition文件供Openshift集群的各虚拟机初始化。 编辑修改/etc/httpd/conf/httpd.conf文件 修改信息如下： ... #Listen 12.34.56.78:80 Listen 81 ... ScriptAlias /cgi-bin/ \"/var/www/cgi-bin/\" ScriptAlias /openstack/latest/ \"/var/www/cgi-bin/\" ... 说明： 修改apache的监听端口为81 ，避免和openshift的http服务冲突 增加script alias的路径供openshift节点启动时获取ignition文件 创建CGI脚本 根据客户机的IP地址提供对应的ignition文件： # cat /var/www/cgi-bin/user_data #!/usr/bin/perl $client = $ENV{\"REMOTE_ADDR\"}; $fname = \"/var/www/html/ocp/$client.ign\"; print \"Content-Type:text/plain\\r\\n\\r\\n\"; if (open(FH, \"创建iptables规则 将ignition文件的http请求重新定向到apache服务的真实地址: # iptables -A PREROUTING -p tcp -d 169.254.169.254 \\ --dport 80 -j DNAT --to 192.168.122.1:81 -t nat 配置NFS服务 目前主机上的Openshift仅支持NFS作为提供persistent volume的存储介质： # mkdir /openshift # cat /etc/exports /openshift *(rw,sync,no_wdelay,no_root_squash,insecure,fsid=0) EOF # systemctl start nfs-server # showmount -e Export list for lpar07: /openshift * 配置负载均衡服务   这里使用haproxy提供负载均衡服务，将API/HTTP/HTTPS等请求分发到对应节点。配置是依据 Openshift安装的官方文档需求，配置示例如下： # cat /etc/haproxy/haproxy.cfg global log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon stats socket /var/lib/haproxy/stats ssl-default-bind-ciphers PROFILE=SYSTEM ssl-default-server-ciphers PROFILE=SYSTEM defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 listen stats bind *:8080 mode http log global maxconn 10 clitimeout 100s srvtimeout 100s contimeout 100s timeout queue 100s stats enable stats hide-version stats refresh 30s stats show-node stats uri /stats frontend ocp_api bind *:6443 mode tcp option tcplog default_backend ocp_api_servers backend ocp_api_servers mode tcp balance source server server0 192.168.122.30:6443 check server server1 192.168.122.31:6443 check server server2 192.168.122.32:6443 check server server3 192.168.122.33:6443 check frontend ocp_config bind *:22623 mode tcp option tcplog default_backend ocp_config_servers backend ocp_config_servers mode tcp balance source server server0 192.168.122.30:22623 check server server1 192.168.122.31:22623 check server server2 192.168.122.32:22623 check server server3 192.168.122.33:22623 check frontend ocp_http bind *:80 mode tcp option tcplog default_backend ocp_http_servers backend ocp_http_servers mode tcp server server4 192.168.122.34:80 check server server5 192.168.122.35:80 check frontend ocp_https bind *:443 mode tcp option tcplog default_backend ocp_https_servers backend ocp_https_servers mode tcp server server4 192.168.122.34:443 check server server5 192.168.122.35:443 check EOF # systemctl start haproxy 具体可参考官方说明：Networking requirements for user-provisioned infrastructure 下载安装文件 下载openshift-install-linux 下载地址：openshift-install-linux.tar.gz下载并解压安装程序到/usr/local/bin： # cd /usr/local/bin # wget -O- https://mirror.openshift.com/pub/openshift-v4/s390x/clients/ocp/latest/openshift-install-linux.tar.gz | tar zxf - 下载openshift-client-linux 下载地址：openshift-client-linux.tar.gz下载并解压Openshift客户端命令行工具到/usr/local/bin: # cd /usr/local/bin # wget -O- https://mirror.openshift.com/pub/openshift-v4/s390x/clients/ocp/latest/openshift-client-linux.tar.gz | tar zxf - 下载OS磁盘镜像文件 下载地址：rhcos-4.2.18-s390x-qemu.qcow2 # cd /root # wget https://mirror.openshift.com/pub/openshift-v4/s390x/dependencies/rhcos/4.2/latest/rhcos-4.2.18-s390x-qemu.qcow2 # mv rhcos-4.2.18-s390x-qemu.qcow2 rhcos-4.2.18-s390x-qemu.qcow2.gz 说明： 下载可能需要使用代理服务器 下载的qcow2文件后缀名缺失，实际是压缩过的文件，需解压后使用 生成ignition文件 下载pull-secret.txt文件   Pull-Secret需要登录RedHat网站下载，该文件含有用来下载容器镜像的密钥，同时用来将OCP集群关联到Red Hat账户，下载地址：Pull Secret 创建或使用已有的SSH密钥   密钥是用来SSH登录到OCP集群里面各节点获得Shell访问权限，可以使用现有的密钥，也可以生成一对新的密钥。以下命令可以用来生成一对无密码保护的新RSA密钥： # ssh-keygen -t rsa -N \"\" -f /root/.ssh/id_rsa 创建install-config.yaml文件   install-config.yaml文件是Openshift安装工具的配置文件，它会通过这个配置文件来生成集群的 ignition 文件。创建目录/root/ocp并将install-config.yaml文件创建在该目录下: # mkdir /root/ocp # cd /root/ocp # vi install-config.yaml apiVersion: v1 baseDomain: example.com proxy: httpProxy: http://172.16.15.192:3128 httpsProxy: http://172.16.15.192:3128 noProxy: localhost,localhost.localdomain,.example.com,192.168.122.0/24 compute: - hyperthreading: Enabled name: worker replicas: 2 controlPlane: hyperthreading: Enabled name: master replicas: 3 metadata: name: ocp networking: clusterNetwork: - cidr: 10.128.0.0/14 hostPrefix: 23 networkType: OpenShiftSDN serviceNetwork: - 172.30.0.0/16 platform: none: {} pullSecret: 'put your pull-secret here (a)' sshKey: 'put your ssh public key here (b)' 说明： 在(a)处填入之前下载的pull-secret.txt的内容（仅一行） 在(b)处填入已有的SSH公钥或上一步生成的/root/.ssh/id_rsa.pub文件的内容（仅一行） 查看： # ls /root/ocp install-config.yaml 用安装工具生成ignition文件   ignition文件是用来初始化Openshift集群中各节点的配置文件。Openshift使用RedHat CoreOS作为运行容器的操作系统，系统安装的过程中，会自动寻找ignition文件并按里面的定义来完成系统的初始化及安装和配置Openshift环境。 生成ignition文件 生成步骤如下： # ls /root/ocp/install-config.yaml /root/ocp/install-config.yaml # openshift-install create manifests --dir=/root/ocp # openshift-install create ignition-configs --dir=/root/ocp 命令运行后，install-config.yaml会被自动删除，同时会生成如下的文件： /root/ocp ├── auth │ ├── kubeadmin-password │ └── kubeconfig ├── bootstrap.ign ├── master.ign ├── metadata.json └── worker.ign 修改文件权限 修改文件权限并为每个节点生成一个对应的拷贝: # chmod 644 /root/ocp/*.ign # mkdir /var/www/html/ocp # cp /root/ocp/bootstrap.ign /var/www/html/ocp/192.168.122.30.ign # cp /root/ocp/master.ign /var/www/html/ocp/192.168.122.31.ign # cp /root/ocp/master.ign /var/www/html/ocp/192.168.122.32.ign # cp /root/ocp/master.ign /var/www/html/ocp/192.168.122.33.ign # cp /root/ocp/worker.ign /var/www/html/ocp/192.168.122.34.ign # cp /root/ocp/worker.ign /var/www/html/ocp/192.168.122.35.ign 启动KVM虚拟机开始安装 准备磁盘镜像文件 为每个虚拟机准备一个磁盘镜像文件： # cd /root # gunzip rhcos-4.2.18-s390x-qemu.qcow2.gz # cp rhcos-4.2.18-s390x-qemu.qcow2 /var/lib/libvirt/images/bootstrap.qcow2 # cp rhcos-4.2.18-s390x-qemu.qcow2 /var/lib/libvirt/images/master-0.qcow2 # cp rhcos-4.2.18-s390x-qemu.qcow2 /var/lib/libvirt/images/master-1.qcow2 # cp rhcos-4.2.18-s390x-qemu.qcow2 /var/lib/libvirt/images/master-2.qcow2 # cp rhcos-4.2.18-s390x-qemu.qcow2 /var/lib/libvirt/images/worker-0.qcow2 # cp rhcos-4.2.18-s390x-qemu.qcow2 /var/lib/libvirt/images/worker-1.qcow2 启动虚拟机开始安装 启动虚拟机开始安装: # virt-install --name bootstrap --ram 16384 --vcpus 4 \\ --disk /var/lib/libvirt/images/bootstrap.qcow2 \\ --network mac=52:54:00:6A:00:30,network=default \\ --import --noautoconsole # virt-install --name master-0 --ram 16384 --vcpus 4 \\ --disk /var/lib/libvirt/images/master-0.qcow2 \\ --network mac=52:54:00:6A:00:31,network=default \\ --import --noautoconsole # virt-install --name master-1 --ram 16384 --vcpus 4 \\ --disk /var/lib/libvirt/images/master-1.qcow2 \\ --network mac=52:54:00:6A:00:32,network=default \\ --import --noautoconsole # virt-install --name master-2 --ram 16384 --vcpus 4 \\ --disk /var/lib/libvirt/images/master-2.qcow2 \\ --network mac=52:54:00:6A:00:33,network=default \\ --import --noautoconsole # virt-install --name worker-0 --ram 8192 --vcpus 4 \\ --disk /var/lib/libvirt/images/worker-0.qcow2 \\ --network mac=52:54:00:6A:00:34,network=default \\ --import --noautoconsole # virt-install --name worker-1 --ram 8192 --vcpus 4 \\ --disk /var/lib/libvirt/images/worker-1.qcow2 \\ --network mac=52:54:00:6A:00:35,network=default \\ --import --noautoconsole 安装进度监控及后续配置 监控bootstrap进度 注意等待bootstrap完成后再继续下一步: # openshift-install --dir=/root/ocp wait-for bootstrap-complete --log-level=info 监控集群访问状态 注意等待oc命令可以正常访问集群后再继续下一步： # mkdir /root/.kube # cp /root/ocp/auth/kubeconfig /root/.kube/config # oc whoami # oc get clusteroperators 配置持久卷供内部镜像源使用 步骤如下： # cat config.yaml apiVersion: v1 kind: PersistentVolume metadata: name: pv4iro spec: accessModes: - ReadWriteMany - ReadWriteOnce capacity: storage: 100Gi nfs: path: /openshift server: 192.168.122.1 persistentVolumeReclaimPolicy: Recycle volumeMode: Filesystem EOF # oc create -f config.yaml # oc patch configs.imageregistry.operator.openshift.io/cluster \\ --type merge --patch '{\"spec\":{\"storage\":{\"pvc\":{\"claim\":\"\"}}}}' 监控集群安装进度并完成安装 监控集群安装进度并完成安装: # openshift-install --dir=/root/ocp wait-for install-complete --log-level=info 确认集群运行状态 确认集群运行状态: # oc get clusteroperators NAME VERSION AVAILABLE PROGRESSING DEGRADED SINCE authentication 4.2.20 True False False 60m cloud-credential 4.2.20 True False False 75m cluster-autoscaler 4.2.20 True False False 68m console 4.2.20 True False False 65m dns 4.2.20 True False False 74m image-registry 4.2.20 True False False 61m ingress 4.2.20 True False False 69m insights 4.2.20 True False False 75m kube-apiserver 4.2.20 True False False 73m kube-controller-manager 4.2.20 True False False 72m kube-scheduler 4.2.20 True False False 71m machine-api 4.2.20 True False False 75m machine-config 4.2.20 True False False 75m marketplace 4.2.20 True False False 69m monitoring 4.2.20 True False False 66m network 4.2.20 True False False 73m node-tuning 4.2.20 True False False 70m openshift-apiserver 4.2.20 True False False 71m openshift-controller-manager 4.2.20 True False False 72m openshift-samples 4.2.20 True False False 70m operator-lifecycle-manager 4.2.20 True False False 73m operator-lifecycle-manager-catalog 4.2.20 True False False 73m operator-lifecycle-manager-packageserver 4.2.20 True False False 71m service-ca 4.2.20 True False False 75m service-catalog-apiserver 4.2.20 True False False 71m service-catalog-controller-manager 4.2.20 True False False 71m storage 4.2.20 True False False 70m 确认集群运行正常（如上所示）后，可以尝试访问控制台: 访问网址：https://console-openshift-console.apps.ocp.example.com/ 用户名：kubeadmin 密码：（密码可从/root/ocp/auth/kubeadmin-password文件中获取） 注意：因域名解析的问题，需要将宿主机作为浏览器的代理服务器才可以访问创建好的OCP环境 "},"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/08-LinuxONE-部署Kubernetes集群.html":{"url":"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/08-LinuxONE-部署Kubernetes集群.html","title":"LinuxONE-部署Kubernetes集群","keywords":"","body":"LinuxONE-通过RKE在LinuxONE上自动化部署Kubernetes集群   学习IBM官方LinuxONE高密度云最佳实践视频做的笔记，步骤基本摘自官方，结合上机实践步骤，整理成此文档方便查阅巩固知识。官方地址：LinuxONE高密度云最佳实践成长之路 (KVM版） Kubernetes简介   Kubernetes又称为k8s（首字母为k、首字母与尾字母之间有8个字符、尾字母为s，简称 k8s）或者简称为 \"kube\"，是一种可自动实施Linux容器操作的开源平台。最初由Google的工程师开发和设计。 Kubernetes官网：https://kubernetes.io/Kubernetes中文社区：https://www.kubernetes.org.cn/Kubernetes中文文档：https://kubernetes.io/zh/docs/concepts/overview/what-is-kubernetes/Kubernetes红帽官方简介：https://www.redhat.com/zh/topics/containers/what-is-kubernetes 部署结构   RKE是本身作为一个部署工具，可以运行在Kubernetes集群中的节点上，也可以运行在单独的一个节点。本示例四以一个三节点的kubernets集群（由于需要通过Internet获取Kubernetes的镜像，所以要求3个Kubernetes节点可以直接访问docker.io镜像库）为例，信息如下： IP address Hostname Role Config 192.168.122.158 rke1 cluster node 2c/4g 192.168.122.147 rke2 cluster node 2c/4g 192.168.122.151 rke3 cluster node 2c/4g 192.168.122.1/172.16.27.86 ubu1 deploy node 准备工作 在每个Kubernetes节点上完成。 防火墙配置 关闭firewalld： # systemctl stop firewalld # systemctl disable firewalld 关闭selinux： # setenforce 0 编辑/etc/selinux/config并配置: SELINUX=disabled 安装docker-ce 创建一个新的工作组： # groupadd docker 下载Docker-ce的binary: # wget -O https://download.docker.com/linux/static/stable/s390x/docker-18.06.3-ce.tgz # tar xfz docker-18.06.3-ce.tgz # cp docker/* /usr/bin/​ 创建docker-ce的systemd服务配置 创建文件/usr/lib/systemd/system/docker.service: [Unit] Description=Docker Application Container Engine Documentation=https://docs.docker.com After=network-online.target docker.socket firewalld.service Wants=network-online.target Requires=docker.socket [Service] Type=notify # the default is not to use systemd for cgroups because the delegate issues still # exists and systemd currently does not support the cgroup feature set required # for containers run by docker ExecStart=/usr/bin/dockerd -H fd:// ExecReload=/bin/kill -s HUP $MAINPID LimitNOFILE=1048576 # Having non-zero Limit*s causes performance problems due to accounting overhead # in the kernel. We recommend using cgroups to do container-local accounting. LimitNPROC=infinity LimitCORE=infinity # Uncomment TasksMax if your systemd version supports it. # Only systemd 226 and above support this version. TasksMax=infinity TimeoutStartSec=0 # set delegate yes so that systemd does not reset the cgroups of docker containers Delegate=yes # kill only the docker process, not all processes in the cgroup KillMode=process # restart the docker process if it exits prematurely Restart=on-failure StartLimitBurst=3 StartLimitInterval=60s [Install] WantedBy=multi-user.target​ 创建文件/usr/lib/systemd/system/docker.socket: [Unit] Description=Docker Socket for the API PartOf=docker.service [Socket] ListenStream=/var/run/docker.sock SocketMode=0660 SocketUser=root SocketGroup=docker [Install] WantedBy=sockets.target 启动docker: # systemctl start docker # systemctl enable docker​ 创建新用户 由于rke不能使用root用户部署，所以需要在每个节点上创建一个新的用户： # useradd -g docker -d /home/user1 -m user1 创建密码,用于deploy节点ssh访问: # passwd user1 获取RKE s390x版本 在deploy节点上获取RKE-s390x工具: # wget https://releases.s3.cn-northwest-1.amazonaws.com.cn/rke-s390x # chmod +x rke-s390x # cp rke-s390x /usr/bin/rke 设置ssh免密码登陆 设置如下： $ ssh-copy-id user1@rke1 $ ssh-copy-id user1@rke2 $ ssh-copy-id user1@rke3 配置rke 配置文件   在deploy节点上，创建cluster.yml文件，内容如下（可以根据环境，调整nodes信息，包括ip地址，访问用户，role）： nodes: - address: 192.168.122.158 port: \"22\" internal_address: \"\" role: - controlplane - worker - etcd hostname_override: \"\" user: user1 docker_socket: /var/run/docker.sock ssh_key: \"\" ssh_key_path: ~/.ssh/id_rsa ssh_cert: \"\" ssh_cert_path: \"\" labels: {} taints: [] - address: 192.168.122.147 port: \"22\" internal_address: \"\" role: - controlplane - worker - etcd hostname_override: \"\" user: user1 docker_socket: /var/run/docker.sock ssh_key: \"\" ssh_key_path: ~/.ssh/id_rsa ssh_cert: \"\" ssh_cert_path: \"\" labels: {} taints: [] - address: 192.168.122.151 port: \"22\" internal_address: \"\" role: - controlplane - worker - etcd hostname_override: \"\" user: user1 docker_socket: /var/run/docker.sock ssh_key: \"\" ssh_key_path: ~/.ssh/id_rsa ssh_cert: \"\" ssh_cert_path: \"\" labels: {} taints: [] services: etcd: image: \"\" extra_args: {} extra_binds: [] extra_env: [] external_urls: [] ca_cert: \"\" cert: \"\" key: \"\" path: \"\" uid: 0 gid: 0 snapshot: null retention: \"\" creation: \"\" backup_config: null kube-api: image: \"\" extra_args: {} extra_binds: [] extra_env: [] service_cluster_ip_range: 10.43.0.0/16 service_node_port_range: \"\" pod_security_policy: false always_pull_images: false secrets_encryption_config: null audit_log: null admission_configuration: null event_rate_limit: null kube-controller: image: \"\" extra_args: {} extra_binds: [] extra_env: [] cluster_cidr: 10.42.0.0/16 service_cluster_ip_range: 10.43.0.0/16 scheduler: image: \"\" extra_args: {} extra_binds: [] extra_env: [] kubelet: image: \"\" extra_args: {} extra_binds: [] extra_env: [] cluster_domain: cluster.local infra_container_image: \"\" cluster_dns_server: 10.43.0.10 fail_swap_on: false generate_serving_certificate: false kubeproxy: image: \"\" extra_args: {} extra_binds: [] extra_env: [] network: plugin: flannel options: {} mtu: 0 node_selector: {} update_strategy: null authentication: strategy: x509 sans: [] webhook: null addons: \"\" addons_include: system_images: etcd: ibmcom/etcd-s390x:3.2.24 alpine: openjupyter/rke-tools-s390x:v0.1.52 nginx_proxy: openjupyter/rke-tools-s390x:v0.1.52 cert_downloader: openjupyter/rke-tools-s390x:v0.1.52 kubernetes_services_sidecar: openjupyter/rke-tools-s390x:v0.1.52 kubedns: rancher/k8s-dns-kube-dns:1.15.0 dnsmasq: rancher/k8s-dns-dnsmasq-nanny:1.15.0 kubedns_sidecar: rancher/k8s-dns-sidecar:1.15.0 kubedns_autoscaler: rancher/cluster-proportional-autoscaler:1.7.1 coredns: rancher/coredns-coredns:1.6.7-s390x coredns_autoscaler: openjupyter/cluster-proportional-autoscaler-s390x:1.7.1 kubernetes: gcr.io/google_containers/hyperkube-s390x:v1.17.4 flannel: quay.io/coreos/flannel:v0.11.0-s390x flannel_cni: openjupyter/flannel-cni-s390x:v0.3.0 calico_node: ibmcom/calico-node:v3.5.2.1 calico_cni: ibmcom/calico-cni:v3.5.2.1 calico_controllers: ibmcom/calico-kube-controllers:v3.5.2.1 calico_ctl: ibmcom/calico-ctl:v2.0.2 calico_flexvol: rancher/calico-pod2daemon-flexvol:v3.13.0 canal_node: rancher/calico-node:v3.13.0 canal_cni: rancher/calico-cni:v3.13.0 canal_flannel: rancher/coreos-flannel:v0.11.0 canal_flexvol: rancher/calico-pod2daemon-flexvol:v3.13.0 weave_node: weaveworks/weave-kube:2.5.2 weave_cni: weaveworks/weave-npc:2.5.2 pod_infra_container: ibmcom/pause:3.1 ingress: ibmcom/nginx-ingress-controller:0.23.1 ingress_backend: openjupyter/defaultbackend-s390x:1.4 metrics_server: rancher/metrics-server:v0.3.6 windows_pod_infra_container: rancher/kubelet-pause:v0.1.3 ssh_key_path: ~/.ssh/id_rsa ssh_cert_path: \"\" ssh_agent_auth: false authorization: mode: rbac options: {} ignore_docker_version: false kubernetes_version: \"\" private_registries: [] ingress: provider: \"\" options: {} node_selector: {} extra_args: {} dns_policy: \"\" extra_envs: [] extra_volumes: [] extra_volume_mounts: [] update_strategy: null cluster_name: \"\" cloud_provider: name: \"\" prefix_path: \"\" addon_job_timeout: 0 bastion_host: address: \"\" port: \"\" user: \"\" ssh_key: \"\" ssh_key_path: \"\" ssh_cert: \"\" ssh_cert_path: \"\" monitoring: provider: \"\" options: {} node_selector: {} update_strategy: null replicas: null restore: restore: false snapshot_name: \"\" dns: null 如果使用自动创建集群初始化配置文件： $ rke config --name cluster.yml 部署Kubernetes集群 在cluster.yml文件所在的目录运行如下命令： $ rke up 如果指向指定配置文件： $ rke up --config /tmp/cluster.yml 配置kubectl rke部署结束后，会生成kube_config_cluster.yml文件，需要放在默认的kubectl配置路径下： mkdir .kube cp kube_config_cluster.yml .kube/config 下载kubectl: wget https://dl.k8s.io/v1.18.0/kubernetes-client-linux-s390x.tar.gz tar xf kubernetes-client-linux-s390x.tar.gz cp kubernetes/client/bin/kubectl /usr/bin 验证kubectl是否工作 验证信息如下表： IP address Status Role Age Version 192.168.122.147 Ready controlplane,etcd,worker 9d v1.17.4 192.168.122.151 Ready controlplane,etcd,worker 9d v1.17.4 192.168.122.158 Ready controlplane,etcd,worker 9d v1.17.4 系统中心访问方式 ssh到ubu1(172.16.27.86)上，可以访问该三节点的Kubernetes集群: IP address User Password 172.16.27.86 root zlinux 192.168.122.158 root zlinux 192.168.122.147 root zlinux 192.168.122.151 root zlinux "},"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/09-LinuxONE-Prometheus监控.html":{"url":"02-IBM_Z&LinuxONE/01-IBM_LinuxONE/09-LinuxONE-Prometheus监控.html","title":"LinuxONE-Prometheus监控","keywords":"","body":"LinuxONE-基于普罗米修斯的监控管理   学习IBM官方LinuxONE高密度云最佳实践视频做的笔记，内容基本摘自官方，结合上机实践步骤，整理成此文档方便查阅巩固知识。官方地址：LinuxONE高密度云最佳实践成长之路 (KVM版） Prometheus项目及架构介绍 Prometheus为CNCF的第二个毕业项目。 LinuxONE环境的监控 主流监控产品对LinuxONE的支持：Zabbix和Prometheus。Zabbix简介： Zabbix是传统的监控，使用C和PHP语言编写，数据库使用关系数据库 Zabbix是采用推送方式到server端 Zabbix推荐监控传统环境 Prometheus简介： Prometheus，云原生监控系统，使用Go语言编写 Prometheus采用抓取方式 Prometheus推荐部署在云环境，容器平台等 Prometheus基本架构 Prometheus基本架构图：数据采集（exproters/jobs）： Prometheus Server将部署在目标上的exproters/jobs暴露出来的metrice采集到（Pull）到时许数据库中 TSDB是Prometheus定制的时序数据库，存储在本地磁盘 Prometheus可以对抓取的数据进行高效压缩 服务发现（Service discovery）： 监控目标多的时候，可以自动化抓取监控目标 支持主流服务发现机制，例如kubernetes 数据可视化： Prometheus WEB UI一般用作配置管理，查询或者调试，一般不用与监控数据的可视化 Grafana是单独开源项目，通过Grafana的看板，将数据信息在可视化界面中展现，实现资源状态的监控 支持API clients，可以通过Prometheus server通过查询语言接入到自定义的管理界面 提交的查询给时序数据库，然后在Grafana可视化，查询通过PromQL查询语言，是Prometheus自己的查询语言 事件告警（Prometheus AlertManager，Grafana Alert/Notification）： 根据定义的告警规则，对接受的警告进行处理，发出事件告警 支持pagerduty，Email以及企业微信 对监控目标的广泛支持-Exporters/客户端开发库 对监控目标的广泛支持： Prometheus通过Exporter采集被监控目标的监控数据（Metrice） Prometheus项目同时提供官方（official）的exprotes： GitHub链接：https://github.com/prometheus Prometheus官方exporters一般都提供s390x二进制安装包 Prometheus官网同时提供第三方的exporters： 官方链接：http://prometheus.io/docs/instrumenting/exporters/ 第三方exporters可能不提供s390x版本，需自行编译后运行在LinuxONE平台 使用Prometheus的开发库可以定制化开发exproters： 现有的exporters无法满足需求 需要监控用户应用的特有目标 官方和第三方提供了多种语言开发库，链接：http://prometheus.io/docs/instrumenting/clientlibs/ Prometheus的可扩展性及高可用 Federation联邦机制： Federation运行一个Prometheus server从另一个Prometheus server获取metrice 监控集群： 通过Federation搭建监控集群，实现监控平台的高可用和扩展性 多级部署： 通过Federation进行多级部署，可提供聚合的全局监控视图和本地视图 Prometheus用于容器平台的监控 Prometheus用于容器平台的监控： Prometheus已经成为容器平台监控的标准，被广泛用于Kubernetes集群监控 Prometheus + Grafana是Kubernetes集群监控系统的重要组成部分 Prometheus用于容器平台的监控图示： Prometheus用于OpenShift容器平台的监控 Prometheus用于OpenShift容器平台的监控： OCP内置了Prometheus组件 OCP缺省使用Prometheus，Grafana监控Cluster运行状态 RedHat不建议使用内置的Prometheus监控框架监控用户metrice，如需针对应用服务进行监控，可以单独部署所需的集中监控实例 LinuxONE集中监控方案及服务介绍 LinuxONE集中监控方案功能概览 LinuxONE集中监控方案功能概览：全栈集中监控： LinuxONE整机--Lpar--Linux--Application 虚拟机--容器--service--IT Infrastructure 使用Grafane进行图形化展示 LinuxONE集中监控方案服务提供 LinuxONE集中监控方案服务提供： 架构设计：弹性的架构涉及，监控系统容量规则，高可用涉及 安装部署：容器化或非容器化监控环境部署，自动化采集端部署及服务发现配置 数据收集：Prometheus Exporters在LinuxONE平台上的部署及定制，例如Libvirt,Oracle,SNMP,zHMC,hyptop,Process等 数据存储：可定制的存储方案，支持不同时效性的监控需求和历史数据存储及查询 数据展示：客户化数据展示方式，Grafana dashboard定制开发 事件报警：客户化的报警机制，可以通过邮件、微信等方式报警以及报警策略的设计定制 监控图示及Demo LinuxONE监控示例 服务器集中监控界面   将多台LinuxONE整机的CPU使用率集中在Grafana的一张图中显示，实现集中显示，数据来源基于hyptop命令输出，图示如下： 分区监控界面   LinuxONE Lpar资源使用情况，数据来源是hyptop collector，可以快速定位需要关注的逻辑分区，发现异常后可进一步分析具体操作系统或应用，图示如下： 操作系统监控   数据来源是Prometheus Node Exproter，可以进一步分析操作系统运行情况，图示如下： 监控目标自动化部署及服务发现 监控目标自动化部署及服务发现： 监控目标自动化部署（Ansible）及服务发现 服务发现（SD）主要用于大规模环境部分，Prometheus支持多种服务发现方式：https://github.com/prometheus/prometheus/tree/master/discovery 最简单基于文件的SD作为示例解释服务发现机制：prometheus.yml文件： # A scrope configuration containing exactly one endpoint to scrape: # Here it's Prometheus itself. scrope_configs: # The job name is added as a label `job=` to any timeseries scraped form this config. - job_name:file file_sd_configs: - files: - '*.json' filesd.json文件： { { \"targets\": [ \"localhost:9100\" ], \"labels\":{ \"team\": \"infra\", \"job\": \"node\" } }, { \"targets\": [ \"localhost:9090\" ], \"labels\":{ \"team\": \"monitoring\", \"job\": \"prometheus\" } } } Alertmanager报警：企业微信 Alertmanager内置了对企业微信的支持，链接：https://prometheus.io/docs/alerting/configuration/#wechat_config Alertmanager报警：邮件   Alertmanager支持email报警，灵活配置，内外可以通过配置邮件转发服务联系外网SMTO服务器进行报警邮件发送，链接：https://prometheus.io/docs/alerting/configuration/#email_config "},"03-IBM_Storage_System/":{"url":"03-IBM_Storage_System/","title":"IBM_Storage_System","keywords":"","body":"IBM_Storage_System 简介 IBM 数据存储：面向混合多云的数据优先基础结构。 官方网站：https://www.ibm.com/cn-zh/it-infrastructure/storage IBM支持 7*24小时呼叫中心：400-810-6678 IBM 用户支持中心：产品下载和更新、打开和查看案例、产品通知以及支持指南，官方连接： IBM 支持团队 内容 DS3-5k_Storage DS8k_Storage Storwize_Storage Flash_System XIV_Storage Tape_Storage NAS_Storage Cloud_Object_Storage SAN_Switch SAN_Volume_Controller "},"03-IBM_Storage_System/01-DS3-5k_Storage/":{"url":"03-IBM_Storage_System/01-DS3-5k_Storage/","title":"DS3-5k_Storage","keywords":"","body":"DS3-5k_Storage 简介   IBM System Storage DS3000 - DS5000系列是IBM前些年的中低端存储，早已停产被Storwize系列存储替代，目前只有少量客户还在使用中。 内容 DS3-5K-微码升与降 "},"03-IBM_Storage_System/01-DS3-5k_Storage/01-DS3-5K-微码升与降.html":{"url":"03-IBM_Storage_System/01-DS3-5k_Storage/01-DS3-5K-微码升与降.html","title":"DS3-5K-微码升与降","keywords":"","body":"DS3-5K-微码升与降 IBM 早已不更新微码了，遇到微码问题一般还是建议升级解决，如果极端情况下需要对微码降级才能解决问题（高风险，可能丢失配置），管理终端（DS Storage Manager Client）可以降级较小版本，可以通过串口去降级大一点的版本，以前搞过几次，但是都是在没有数据的情况下做的。 微码升级 通过DS Storage Manager Client就可以升级，注意事项： 升级一般没什么问题，建议保存下配置，或者收个数据，数据里面有配置信息 升级微码前确保DS Storage Manager Client同时连接到了两个控制器 依次升级微码和微码对应NVSRAM 微码降级 小版本降级可以使用DS Storage Manager Client，和升微码步骤一样，里面也有命令行的方式，没试过，这里主要介绍串口降级方法。串口降级注意事项： 小版本降级微码有可能导致数据丢失，例如array状态不正常，应该先备份数据和存储配置等 大版本降级配置会丢失，建议一定要保存存储配置 DS3512等低端的存储串口是PS/2接口的，DS5100等是RS232串口线 串口速率一般设置在9600-115200之间，建议115200，这是波特率，设置最大对于传微码也是龟速 设置更改 连接好串口，会有很多乱码，持续按ctrl+break直到出现如下字符（有时候提示不是这个，没记错有时候是提示按ESC的）： Press within 5 seconds: for Service Interface, for baud rate 按ESC进入登陆模式，提示输入用户名和密码，默认用户：shellUsr，默认密码：wy3oo&w4登录成功后输入大写M调出“BOOT OPERATIONS MENU”： -> M BOOT OPERATIONS MENU 1) Perform Isolation Diagnostics 10) Serial Interface Mode Menu 2) Download Permanent File 11) Display Hardware Configuration 3) Reserved 12) Change Hardware Configuration Menu 4) Dump NVSRAM Group 13) Development Options Menu 5) Patch NVSRAM Group 14) Display Memory Error Log 6) Set Real Time Clock 15) Manufacturing Setup Menu 7) Display Board Configuration R) Restart Controller 8) Special Services Menu Q) Quit Menu 9) Display Exception Message 输入“12”进入“display hardware configuration” Enter Selection: 12 CHANGE HARDWARE CONFIGURATION MENU -------SOFTWARE SWITCH OPTION-------- --CURRENT-- --DEFAULT-- 1) Switch #1 (PCI Device Config Disable) Default Off 2) Switch #2 (Manufacturing Diagnostics) Default Off 3) Switch #3 (Invoke Boot Menu) Default Off 4) Switch #4 (Continuous Diagnostics) Default Off ----------SOFTWARE OPTION------------ --CURRENT-- 5) Option #1 (Extensive Diagnostics) Off 6) Option #2 (Diagnostics Disable) Off 7) Option #3 (Autoload Disable) Off 8) Option #4 (Network Enable) Off (NVSRAM Enabled) R) Reset all options C) Cancel all changes and quit H) Help Q) Quit Menu 输入“7”选择Option #3，将“autoload disable”改为为On提示更改值时候输入“1”： Enter new value for Option #3: 1 CHANGE HARDWARE CONFIGURATION MENU -------SOFTWARE SWITCH OPTION-------- --CURRENT-- --DEFAULT-- 1) Switch #1 (PCI Device Config Disable) Default Off 2) Switch #2 (Manufacturing Diagnostics) Default Off 3) Switch #3 (Invoke Boot Menu) Default Off 4) Switch #4 (Continuous Diagnostics) Default Off ----------SOFTWARE OPTION------------ --CURRENT-- 5) Option #1 (Extensive Diagnostics) Off 6) Option #2 (Diagnostics Disable) Off 7) Option #3 (Autoload Disable) On 8) Option #4 (Network Enable) Off (NVSRAM Enabled) R) Reset all options C) Cancel all changes and quit H) Help Q) Quit Menu 输入q保存退出，控制器会自动重启。分别在两个控制器上执行以上操作，启动过程中看到两个控制器都显示network ready即可： Send for Service Interface or baud rate change Kernel initialization complete Acquiring network parameters for interface esmc0 using DHCP DHCP failed to obtain a lease for interface esmc0 Network Ready 微码降级 开始降级步骤： 进入BOOT OPERATIONS MENU 选择选项“2”：Download Permanent File 提示：Please start the XMODEM send process now... 在弹出对话框中选择匹配的微码文件，然后点击send开始传输 传输过程比较慢，耐心等待 两个控制器可以同时进行，两个控制器都降级完成后，一样进入“BOOT OPERATIONS MENU”将下面选项改回成“Off”： 7) Option #3 (Autoload Disable) Off 重启控制器，当看到显示“sodmain complete”时候，说明降级成功。 "},"03-IBM_Storage_System/01-DS3-5k_Storage/02-DS3-5K-常见问题.html":{"url":"03-IBM_Storage_System/01-DS3-5k_Storage/02-DS3-5K-常见问题.html","title":"DS3-5K-常见问题","keywords":"","body":"DS3-5K-常见问题 LUN相关 修改缓存设置Error1011 在尝试修改缓存设置时，报错示例如下： Error 1011 - A management connection to the controller in slot B must be defined to complete this operation.   报错原因是DS Storage Manager软件只连接了A控，未连接到B控，但是这个LUN的Preferred Path在B控上面。解决方法建议： DS Storage Manager连接双控制器 如果无法连双控，DS Storage Manager临时连接到B控上 如果也无法连到B控，更改Preferred Path到A控，然后再进行修改缓存设置操作 待补充 "},"03-IBM_Storage_System/01-DS3-5k_Storage/03-DS3-5K-常用操作.html":{"url":"03-IBM_Storage_System/01-DS3-5k_Storage/03-DS3-5K-常用操作.html","title":"DS3-5K-常用操作","keywords":"","body":"DS3-5K-常用操作 数据收集 ASD收集 All Support Data(ASD)收集步骤如下： 主菜单中选择选项Advanced 选择选项Troubleshooting 选择选项Collect All Support Data ... 进入Collect All Support Data对话框： File输入框中输入需要保存日志的路径及名称，名称自定义 然后点击Start开始收集，时间取决于扩展柜和硬盘的个数，大概5-15分钟 生成的zip格式的文件即为ASD 注意事项： 确保DS Storage Manager同时连接DS3-5K的两个控制器，才能获得两个控制器的串口命令输出 如果是单连一个控制器的话，那么stateCaptureData.dmp文件只能获得当前连接控制器的串口命令输出 如果不具备同时连接两个控制器的条件，可以尝试分别连接两个控制器，收集两份All Support Data LUN相关 查看或更改Preferred Path 查看或更改步骤如下： 进入Storage & Copy Services管理页面 选中需要查看或修改的LUN，点击右键 选择Change选项 选择Ownership/Preferred Path选项 选择首选路径，例如Controller in Slot A，Preferred的路径后面会显示Preferred 查看更改Cache Settings 查看或更改步骤如下： 进入Storage & Copy Services管理页面 选中需要查看或修改的LUN，点击右键 选择Change选项 选择Cache Settings选项 进入Change Cache Settings对话框： 列表中可以选择需要查看或修改的LUN，右上角有Select all选择框可以选择所有LUN 缓存属性：Enable read caching Enable dynamic cache read prefetch 缓存属性：Enable write caching Enable write caching without batteries Enable write caching with mirroring 缓存属性说明： 默认开启read caching，里面只有一个选项 对于write caching： 如果有电池使用，开启Enable write caching with mirroring 如果电池故障了由于设备老旧不更换，或者有电池没问题也不用，开启Enable write caching without batteries 待补充 "},"03-IBM_Storage_System/02-DS8k_Storage/":{"url":"03-IBM_Storage_System/02-DS8k_Storage/","title":"DS8k_Storage","keywords":"","body":"DS8K_Storage 简介 IBM DS8000系列存储是IBM 高端存储系列。IBM DS8900F是使用最先进的POWER9™处理器技术构建的新一代企业数据系统。 最新产品官方介绍：IBM DS8900F 内容 DS8000-数据收集 DS8000-DSCLI常用命令 "},"03-IBM_Storage_System/02-DS8k_Storage/01-DS8000-数据收集及基础.html":{"url":"03-IBM_Storage_System/02-DS8k_Storage/01-DS8000-数据收集及基础.html","title":"DS8000-数据收集及基础","keywords":"","body":"DS8000-数据收集及基础 DS8000基础 DS8000发行说明 官方参考链接： DS8000 Release notes 事件/消息及参考代码 官方参考链接： DS8880 8.5.4 System reference codes overview DS8880 8.5.4 Service request numbers DS8880 8.5.4 Progress codes overview DS8880 8.5.4 Messages DS8880 8.5.4 Management console error codes (0xxx, Exxx - Hxxx) DS8880 8.5.4Events list DS8870 7.4 DS8000 Storage Management GUI console messages 数据收集   DS8000系列存储一般硬件故障，例如硬盘，在Serviceable Events菜单中就可以查看判断，复杂点的需要收集PE Package等。 收集PE Package 最常用的日志，大部分故障都可以通过此日志去判断分析。 一般使用U盘收集收集步骤如下： 将U盘插在DS8000存储MC的USB口上，必须为FAT32格式 用CE用户登录到MC 展开选项\"Storage Facility Management\" 选择对应的\"Storage Facility\",格式：2423-951*75MA7HX 选择选项\"SF Image #1\" 在\"SF Image#1\"菜单中选择\"Data Collection Tasks\" 点击选项\"Perform Data Collection On Demand\" 弹出对话框使用默认选项\"General PE Package\",点击\"Continue\"继续 对话框中使用默认选项\"New General PE Package\",点击\"Continue\"继续 下一个对话框中，一定要将选项\"Auto Offload\"取消掉，默认是选择的 等待PE Package收集，大概15分钟 收集结束后，弹出对话框名称为\"Offload Sub-Packages - SF Image #1\",将\"List of Sub-Packages\"下面的选项全部选中，然后点击选项\"Offload\" Offload完成只会，会弹出对话框提示生成了一个Serviceable Event，SRC为BEB00010,点击\"OK\"继续 下一个对话框中点击\"Cancel\"继续 打开\"Service Focal Point\"(点击左下角扳手图标) 点击确认查看\"Open\"状态的Serviceable Events 对话框中显示Open状态的事件，找到之前提示Problem编号的事件，SRC为BEB00010（一般是最新的事件） 在事件左边\"Select\"列选择框中勾上选中事件 点击对话框左上方选项\"Selected\"，会看到操作选项 选择选项\"Manage Problem Data\"并点击 弹出对话框会列出之前生成的Package文件，Ctrl+A全部选中，然后点击\"Offload to Media\" 弹出对话框中选择\"Copy to USB memory stick\",点击\"OK\"继续 提示完成后拔出U盘即可 PE Package一般有100M左右，太大或者太小可能不正常。一般包含如下文件： collectedCodeLevels.All.2107-941-75WH210.htm collectedCodeLevels.All.4349A49-R988MAV.htm CasTrace HMCa.unzipthis Lpar0.tar.gz Lpar1.tar.gz SFI-1.info ctsnap.SF75DG450ESS01.10160925.tar.gz ctsnap.SF75DG450ESS11.10160927.tar.gz ctsnap.DS8000C.09051615.tar.gz actzuict.dat iqyvpd.dat iqyvpdc.dat iqyylog.log problems.xml refcode.dat 其它日志 DS8000如果出现性能问题，或者AIX分区宕机，只有PE Package是不够的，还需要收集State Save或AIX Dump。State Save类型很多，主要有LPAR State Save和DA State Save。 此类日志收集比较少，并且需要在IBM 专业人员指引下根据不同的故障类型收集对应的日志。 "},"03-IBM_Storage_System/02-DS8k_Storage/02-DS8000-DSCLI常用命令.html":{"url":"03-IBM_Storage_System/02-DS8k_Storage/02-DS8000-DSCLI常用命令.html","title":"DS8000-DSCLI常用命令","keywords":"","body":"DS8000-DSCLI常用命令   DSCLI全称DS command-line interface，是管理DS8000系列存储的常用工具，DS8000的MC系统上有集成，也可以下载到个人终端上，在IBM fixcentral中有下载。DSCLI命令官方说明链接： DS8880 8.5.4 CLI commands DS8880 Command-line interface 登录使用 MC上使用 在MC上的空白处右键，既有打开DSCLI选项，点击打开输入用户密码即可管理此DS8000存储。 PC终端   从IBM fixcentral中下载DSCLI安装后，运行程序，输入dscli命令后根据提示输入IP地址、用户名及密码即可连上对于的DS8000存储，登录成功后会有存储名称提示，注意核对序列号避免出错。 常用命令 查看类命令 命令lsrank，示例如下： dscli> lsrank ID Group State datastate Array RAIDtype extpoolID stgtype =========================================================== R0 0 Normal Normal A0 5 P0 fb R1 0 Normal Normal A1 5 P0 fb R2 0 Normal Normal A2 5 P0 fb 命令lsarraysite，示例如下： dscli> lsarraysite arsite DA Pair dkcap (10^9B) State Array =========================================== S1 0 300.0 Assigned A32 S2 0 300.0 Assigned A15 S3 0 300.0 Assigned A30 S4 0 300.0 Assigned A13 命令lsarray，示例如下： dscli> lsarray Array State Data RAIDtype arsite Rank DA Pair DDMcap (10^9B) ================================================================== A0 Assigned Normal 5 (7+P) S34 R0 18 400.0 A1 Assigned Normal 5 (6+P+S) S32 R1 18 400.0 A2 Assigned Normal 5 (7+P) S23 R2 5 300.0 A3 Assigned Normal 5 (6+P+S) S28 R3 7 300.0 命令lsextpool，示例如下： dscli> lsextpool Name ID stgtype rankgrp status availstor (2^30B) %allocated available reserved numvols ====================================================================================== Pool P0 fb 0 below 5160 82 330227 3072 527 Pool P1 fb 1 below 5160 82 330235 3072 527 命令lsfbvol，示例如下： dscli> lsfbvol Name ID accstate datastate configstate deviceMTM datatype extpool cap (2^30B) cap (10^9B) cap (blocks) ====================================================================================================== E980PRD_IBASE 1000 Online Normal Normal 2107-099 FB 520PV P0 70.0 75.2 146800640 E980PRD_IBASE 1001 Online Normal Normal 2107-099 FB 520PV P0 70.0 75.2 146800640 ... E980PRD_IASP 1200 Online Normal Normal 2107-A04 FB 520P P0 65.7 70.6 137822208 E980PRD_IASP 1201 Online Normal Normal 2107-A04 FB 520P P0 65.7 70.6 137822208 命令lsddm，示例如下： dscli> lsddm ID DA Pair dkcap (10^9B) dkuse arsite State =============================================================================== IBM.2107-D02-04XXB/R1-P1-D1 0 800.0 array member S6 Normal IBM.2107-D02-04XXB/R1-P1-D2 0 800.0 array member S1 Normal IBM.2107-D02-04XXB/R1-P1-D3 0 800.0 array member S5 Normal IBM.2107-D02-04XXB/R1-P1-D4 0 800.0 array member S2 Normal IBM.2107-D02-04XXB/R1-P1-D5 0 800.0 spare required S3 Normal 命令lsioport，示例如下： dscli> lsioport ID WWPN State Type topo portgrp ============================================================================== I0000 50050763080011XD Communication established Fibre Channel-SW SCSI-FCP 0 I0001 50050763080051XD Communication established Fibre Channel-SW SCSI-FCP 0 I0002 50050763080091XD Communication established Fibre Channel-SW SCSI-FCP 0 I0003 500507630800D1XD Communication established Fibre Channel-SW SCSI-FCP 0 命令lshostconnect，示例如下： dscli> lshostconnect Name ID WWPN HostType Profile portgrp volgrpID ESSIOport ================================================================================ E980PRD_IBASE_1A 0000 10000090FAF6D5A4 iSeries IBM iSeries - OS/400 0 V0 I0000 E980PRD_IBASE_1B 0001 10000090FAF5E642 iSeries IBM iSeries - OS/400 0 V0 I0330 ... E980PRD_IASP_1A 0004 100000109B0E0A40 iSeries IBM iSeries - OS/400 0 V2 I0001 E980PRD_IASP_1B 0005 10000090FAF5EC2A iSeries IBM iSeries - OS/400 0 V2 I0300 命令lsvolgrp，示例如下： dscli> lsvolgrp Name ID Type ======================================= E980PRD_IBASE V0 OS400 Mask E980PRD_IASP V2 OS400 Mask E980PRD_IASP V3 OS400 Mask ... All CKD V10 FICON/ESCON All ... All Fixed Block-512 V20 SCSI All All Fixed Block-520 V30 OS400 All 修改类命令 Copy Services命令 FlashCopy命令 FlashCopy命令： 命令 说明 commitflash 用于灾难恢复，完成部分形成的全局镜像一致性组 resyncflash 使用-record和-persist参数建立的现有FlashCopy对的时间点副本 lsflash 显示FlashCopy关系列表以及列表中每个FlashCopy关系的状态信息 mkflash 启动从源卷到目标卷的时间点复制 reverseflash 反转FlashCopy关系 revertflash 用户灾难恢复，从当前正在形成的全局镜像一致性组中恢复以前的全局镜像一致性组 rmflash 删除FlashCopy关系 unfreezeflash 重置一个 FlashCopy 一致性组，该组以前在发出mkflash或resyncflash命令时使用-freeze参数建立 setflashrevertible 作为FlashCopy关系一部分的FlashCopy卷对修改为revertible "},"03-IBM_Storage_System/02-DS8k_Storage/03-DS8000-Copy_Services.html":{"url":"03-IBM_Storage_System/02-DS8k_Storage/03-DS8000-Copy_Services.html","title":"DS8000-Copy_Services","keywords":"","body":"Copy Services 官方参考链接： DS8870 7.3 Copy Services DS8880 8.5.4 Copy Services DS8880 8.5.4 IBM Copy Services Manager DS8880 8.5.4 Copy Services commands DS8880 8.5.4 Copy Services functions DS8880 8.5.4 Copy Services functions with IBM i operating system 官方参考红皮书： IBM DS8000 Copy Services Updated for IBM DS8000 Release 9.1 IBM DS8000 Safeguarded Copy(Updated for DS8000 Release 9.2.1) Copy Services简介 Point-in-time copy functions FlashCopy   FlashCopy支持在DS8000存储系统中创建卷或一组数据（卷的子集）的时间点副本。使用 FlashCopy，两个副本都可以立即用于读取和写入操作： FlashCopy也称为时间点复制、快速复制或零时间复制（t0复制） 设置FlashCopy操作时，会在源卷和目标卷之间建立关系，并创建源卷的位图 创建此关系和位图后，可以访问目标卷，就好像所有数据都已物理复制一样 如果使用后台复制选项建立FlashCopy，则实际数据会从源卷复制到目标卷： 如果在后台复制期间访问源卷或目标卷，FlashCopy将管理这些I/O请求，并促进对源副本和目标副本的读取和写入 当所有数据都复制到目标时，FlashCopy关系结束，除非它被设置为持久关系（例如，用于增量复制） 在所有数据复制到目标之前，用户可以随时撤销FlashCopy关系 FlashCopy操作可以在任何类型的卷之间执行，无论是完全配置还是精简配置，具有大范围或小范围 Remote Pair FlashCopy (Preserve Mirror)   Remote Pair FlashCopy或Preserve Mirror克服了之前将FlashCopy复制到高速镜像源卷上的解决方案的缺点： 此配置可以减少FlashCopy后台复制和高速镜像重新同步正在进行时存在的恢复点目标(RPO) Remote Pair FlashCopy为数据复制、数据迁移、远程复制和灾难恢复任务提供了解决方案 Preserve Mirror保留了现有的FULL DUPLEX的Metro Mirror状态 Cascading FlashCopy   从DS8000 8.3版本开始，卷既可以是一个FlashCopy关系中的源，也可以是第二个FlashCopy关系中的目标，称为Cascading FlashCopy。 Business-continuity functions   DS8000提供了一组灵活的数据镜像技术，允许在两个或多个存储系统上的卷之间进行复制，可以将这些功能用于数据备份和灾难恢复等目的。 Metro Mirror   Metro Mirror是两个DS8000之间的同步复制解决方案，其中在I/O被认为完成之前，本地和远程卷上的写入操作都已完成： Metro Mirror用于在存储系统发生故障时不会丢失数据的环境。 由于在考虑写入完成之前，数据会同步传输到二级存储系统，因此主存储和二级存储系统之间的距离会影响应用程序对写入的响应时间 Metro Mirror支持的距离为300公里（186 英里） Global Copy   Global Copy是一种异步远程复制功能，可用于比高速镜像更长的距离。 Global Copy适用于远程数据迁移、异地备份以及几乎无限距离传输非活动数据库日志： Global Copy也用作Global Mirror的数据传输机制 使用Global Copy，在将数据复制到从存储系统之前，在主存储系统上完成写操作，从而避免主系统的性能受到写到从存储系统所需的时间的影响。这种方法允许站点相隔很远的距离 写入主DS8000的所有数据都会传输到辅助DS8000，但不一定按照写入主DS8000的顺序。这种方法意味着辅助节点上的数据不是时间一致的 使用辅助卷上的数据需要使用一些技术来确保一致性 Global Mirror   Global Mirror是两站点、长距离、异步、远程复制技术。该解决方案基于现有的Global Copy和FlashCopy功能： 使用Global Mirror，主机写入主站点存储系统的数据异步镜像到备站点存储系统，在远程站点自动维护一致的数据副本 Global Mirror操作提供了支持本地和远程站点之间无限距离的操作的好处，这些操作仅受网络能力和通道扩展技术的限制 它还可以在远程站点提供一致且可重新启动的数据副本，对本地站点的应用程序影响最小 通过支持故障转移和故障恢复模式保持本地和远程站点的有效同步的能力有助于减少在计划内或计划外中断后切换回本地站点所需的时间 通过特殊的管理步骤（在本地主存储单元的控制下），通过在远程站点的存储单元上使用FlashCopy，自动维护和定期更新数据的一致副本 Three-site Metro/Global Mirror with Incremental Resync   Metro/Global Mirror将Metro Mirror和Global Mirror结合在一起，以提供实施3站点灾难恢复解决方案的可能性： 生产系统正在使用本地站点的存储，该存储使用Metro Mirror同步复制到中间站点 Metro Mirror关系的辅助卷进一步用作级联Global Mirror关系的主卷，将数据复制到远程灾难恢复站点   此配置为在各种灾难情况下的恢复提供了弹性和灵活的解决方案。用户还可以从将数据同步复制到充当中间站点的关闭位置中受益。它还可以跨越几乎无限的距离复制数据，可以在每个位置随时提供数据一致性。   使用增量重新同步，可以更改复制关系的复制目标目的地，而无需数据的完整副本。 例如，当中间站点因灾难而发生故障时，可以使用此功能： 在这种情况下，会建立一个从本地到远程站点的Global Mirror，绕过中间站点 当中间站点再次可用时，增量重新同步用于将其带回Metro/Global Mirror设置 IBM Multiple Target Peer-to-Peer Remote Copy   多目标对等远程复制(PPRC)通过提供在单个主卷上具有两个PPRC关系的能力以及另一个远程站点提供额外数据保护的能力，从而增强了多站点灾难恢复环境。多目标PPRC提供以下增强功能： 将数据从一个主（本地）站点镜像到两个辅助（远程）站点 在以下灾难恢复解决方案中提供增强的功能和灵活性： 同步复制 异步复制 同步复制和异步复制配置的组合 改进了级联Metro/Global Mirror配置并简化了一些过程 在多目标PPRC之前，主卷可以仅将数据镜像到一个辅助卷。使用多目标PPRC，同一个主卷可以有多个目标，从而允许将数据从单个主站点镜像到两个目标站点 IBM官方参考链接： DS8880 8.5.4 How Metro/Global Mirror works DS8880 8.5.4 Metro/Global Mirror planning considerations SafeGuarded Copy   SafeGuarded Copy(SGC)是从DS8880开始提供的一项功能，可为关键数据提供逻辑损坏保护。SafeGuarded Copy功能提供了多个备份副本，可以在恶意软件、黑客攻击、恶意破坏以及任何可能导致逻辑损坏或破坏主数据的操作的情况下恢复： 主机无法访问受保护的副本 受保护的备份副本（SG备份）可以安排为每天定期创建多次（例如，每小时备份副本） 这些备份副本可用于将数据恢复到指定的时间点 受保护的备份副本可用于诊断从验证到恢复的生产问题   SafeGuarded Copy通过IBM Copy Services Manager(CSM)6.2.3及更高版本或GDPS 4.2及更高版本进行管理。通过任一管理工具，都可以定义SG备份的过期规则、创建和恢复。 待补充 "},"03-IBM_Storage_System/02-DS8k_Storage/04-DS8000-Copy_Services_Manager.html":{"url":"03-IBM_Storage_System/02-DS8k_Storage/04-DS8000-Copy_Services_Manager.html","title":"DS8000-Copy_Services_Manager","keywords":"","body":"DS8000-Copy Services Manager   IBM Copy Services Manager除了应用于IBM DS8000系列存储，还可以用于Spectrum Virtualize-based storage等。本内容主要学习及记录DS8000上应用。官方相关参考链接： CSM6.2.12-Using Copy Services Manager on the DS8000 CSM6.2.12-Applying license files after installation or migration, or updating licenses 登录 WEB GUI 使用WEB浏览器登录地址示例： https://xxx.xxx.xxx.xxx:9559/CSM/ 用户: csmadmin, 默认密码: passw0rd CSM CLI Copy Services Manager command-line interface. 待补充 "},"03-IBM_Storage_System/02-DS8k_Storage/10-DS8000-硬件维护.html":{"url":"03-IBM_Storage_System/02-DS8k_Storage/10-DS8000-硬件维护.html","title":"DS8000-硬件维护","keywords":"","body":"DS8000-常见维护 记录常见维护过程及注意事项。 待补充 "},"03-IBM_Storage_System/03-Storwize_Storage/":{"url":"03-IBM_Storage_System/03-Storwize_Storage/","title":"Storwize_Storage","keywords":"","body":""},"03-IBM_Storage_System/04-Flash_System/":{"url":"03-IBM_Storage_System/04-Flash_System/","title":"Flash_System","keywords":"","body":""},"03-IBM_Storage_System/05-XIV_Storage/":{"url":"03-IBM_Storage_System/05-XIV_Storage/","title":"XIV_Storage","keywords":"","body":"XIV_Storage 简介   IBM XIV Storage System is a high-end, open, disk-storage system. The XIV system has an innovative grid architecture designed to deliver the highest levels of reliability, performance, scalability and functionality at low overall cost, while eliminating complexity and providing unprecedented ease of management. IBM 官方网站：IBM XIV Storage System IBM XIV 知识中心：IBM XIV Storage System documentation 内容 XIV-数据收集 "},"03-IBM_Storage_System/05-XIV_Storage/01-XIV-日志查看及收集.html":{"url":"03-IBM_Storage_System/05-XIV_Storage/01-XIV-日志查看及收集.html","title":"XIV-日志查看及收集","keywords":"","body":"XIV-日志查看及收集 XIV System Data类似于DS8000的PEpackage，在XIV里面称作XRAY。 XIV GUI日志查看 通过XIV GUI查看很方便，在左侧“系统”菜单中可以查看： 所有系统警报 所有系统事件 在左侧“监视”菜单中可以查看： 系统：菜单点击后可以看到整个AIV存储3D视图，鼠标指向某个设备（例如硬盘）就会显示对应的信息，包括状态和事件 统计信息：菜单可以看到系统性能概况 警报：系统警报信息 事件：系统事件 Qos性能类：性能限制组信息 数据收集 XIV System Data类似于DS8000的PEpackage，在XIV里面称作XRAY。 老版本收集XRAY   老版本GUI中没有收集XRAY的选项，需要通过终端（需安装XCLI，在IBM fix central中有下载）连上存储通过运行收集日志的程序进行收集。收集步骤如下： 将laptop网口IP获取设置成DHCP模式 将laptop链接到Patch panel上module 5 的laptop port 会自动获取一个14.10.202.xx的地址，如果没用，手动设置laptop地址 检查是否能ping通地址14.10.202.250，不可以继续检查网络 在laptop上的命令行执行收集程序，运行命令：xary collect 14.10.202.250 收集完成后会自动Offload到laptop上运行xray_collect.exe的目录下 注意： 如果XIV的微码是10.1或以上，使用xray_collect_v2.0.1.exe文件 如果低于此版本，使用xray_collect.exe文件 两个文件在对于的微码的包里面，微码下载也是在IBM fix central XIV GUI收集XRAY   从XIV GUI2.4.1版本开始，XIV支持用GUI的方式收集XRAY。XIV的GUI在IBM fix central中有下载，里面包含XCLI，下载安装完成后发现还有演示模式，这是个很不错的功能，可以在模拟环境下对XIV进行一些操作，方便学习及测试操作。收集步骤如下： 启动XIV GUI程序，然后登录，用户：technician，密码：teChn1cian 选中需要收集XRAY的XIV系统 在菜单栏选中并点击“Help” 下拉菜单中选中并点击“Support Logs...” 弹出对话框“Get Support Logs”，点击“Collect” 收集完成后，对话框中“System Log File Name”里面会列出当前系统里面的日志信息 选择刚才时间点收集的日志，点击“Browse”选择存放位置 最后点击“Get”即完成收集 在一些新的GUI版本中，收集选项有所改变，但是大致上差不多： 登录到AIV GUI 选中对应XIV系统后 在菜单栏选中并点击“工具（t）” 在展开菜单中选择“收集支持日志”点击后弹出对话框“收集并发送支持日志” 点击“启动”开始收集XARY XIV GUI收集容量报告 步骤如下： 登录到AIV GUI 选中对应XIV系统后 在菜单栏选中并点击“工具（t）” 在展开菜单中选择“生成容量报告”点击 点击“启动”开始收集 TA tool使用 IBM XIV存储工程师使用，不作详述。 "},"03-IBM_Storage_System/06-Tape_Storage/":{"url":"03-IBM_Storage_System/06-Tape_Storage/","title":"Tape_Storage","keywords":"","body":"Tape_Storage 简介 磁带存储设备或者虚拟磁带存储设备。 内容 "},"03-IBM_Storage_System/06-Tape_Storage/05-TS4500-常见问题.html":{"url":"03-IBM_Storage_System/06-Tape_Storage/05-TS4500-常见问题.html","title":"TS4500-常见问题","keywords":"","body":"TS4500-常见问题 用户及密码问题 解锁administrator   使用Access Recovery按钮解锁管理员密码。当按下Access Recovery按钮时，有15分钟的时间登录磁带库并使用临时密码（用户admin，密码admin）重置管理员密码。参考链接： TS4500面板示意图：TS4500 tape library Display panel 解锁密码官方链接：TS4500 tape library Unlocking the administrator password 待补充 "},"03-IBM_Storage_System/06-Tape_Storage/10-TS7650G-虚拟带库.html":{"url":"03-IBM_Storage_System/06-Tape_Storage/10-TS7650G-虚拟带库.html","title":"TS7650G-虚拟带库","keywords":"","body":"TS7650G-虚拟带库 官方文档 安装配置官方文档链接： Installing the TS7650G Appliance Configuring the TS7650G 3958 DD4, DD5, and SM2 维护相关官方文档链接： 3958 DD4 and DD5 ProtecTIER server for the TS7650G (Gateway), ProtecTIER V3.4.3 TSSC for the TS7650G (Gateway), ProtecTIER V3.4.3 FRU replacement for TS7650G systems for the TS7650G TSSC IBM TS3000 System Console 7.2.9 默认用户service，默认密码service TS7650G 验证集群TS7650G的以太网连接 命令kudzu查看输出以确保以太网卡具有正确的端口分配： kudzu -p -c network | grep -A3 \"device:\" 命令ethtool验证是否在每个端口上检测到链路并按照客户网络配置的预期运行： ifconfig eth1 up ethtool eth1 官方参考链接：Verifying the Ethernet connections for the clustered TS7650G 3958 DD6 for the TS7650G (Gateway) 3958 DD6, ProtecTIER version 3.4.3 待补充 "},"03-IBM_Storage_System/06-Tape_Storage/11-TS7650G-常见问题.html":{"url":"03-IBM_Storage_System/06-Tape_Storage/11-TS7650G-常见问题.html","title":"TS7650G-常见问题","keywords":"","body":"TS7650G-常见问题 TS7650G服务问题 vtfd服务 vtfd in shutdown mode   当使用命令service vtfd shutdown执行后，在使用service vtfd start命令或者菜单执行启动后，都会提示shutdown mode，无法启动，即使重启或者初始化都不行，提示示例如下： ... Starting VTFD [ Fail ] Error installing appliance: Failed to run config item startvtfd: ; vtfd: vtfd in shutdown mode, cannot start service install Failed Error running module PT::PTConfig::Install, install Failed ERROR: Failed to configure node, error: Exited with RC != 0 (RC = 1) End Processing Procedure Successfully 使用命令service vtfd init进行初始化，示例如下： node1: /opt/dtc/ptadmin> service vtfd status vtfd is stopped vtfd: vtfd in shutdown mode. node1: /opt/dtc/ptadmin> service vtfd init calling stat fs fast Starting vtfd: [ OK ] node1: /opt/dtc/ptadmin> service vtfd status vtfd (pid 24168) is running... vtfd in fenced mode 使用选项1) Display services status查看服务状态： Service Status ============================== cman UP clvmd UP gfs UP vtfd FENCED ptrasd UP gmgnt UP 检查现象及处理步骤： 检查文件系统，用作虚拟带库得文件系统如果没挂载，可能是先TS7650G机器再启动外置存储，重新启动即可 如果是更换了后端存储但未配置，重新配置了TS7650G，重启没有用，建议： 先配置后端存储，映射给TS7650G后进行配置，没问题后再去查看或手动启动服务 重新安装TS7650G的系统及ProtecTIER软件 更多情况处理官方参考链接：Recovering from FENCE condition on ProtecTIER 网络问题 网卡   执行Configure ProtecTIER node时候，提示某个必要网卡缺失，例如eth1，导致配置失败，使用ifconfig -a查看也发现缺失，查看eth1配置文件，缺少MAC地址等信息加上即可： node1: /etc/sysconfig/network-scripts> cat ifcfg-eth1 BOOTPROTO=none MASTER=bond0 HWADDR=90:e2:ba:12:91:85 ONBOOT=yes SLAVE=yes DEVICE=eth1 磁盘问题 磁盘能显示已配置，但是文件系统里面没有   重新安装系统后，配置全清理了，但是安装过程中磁盘还分配给分区，进入系统后能够认到磁盘，但是ProtecTIER Service Menu菜单里面看不到未使用的磁盘，df -g也没显示有配置。建议直接删掉映射，磁盘删掉重新进行配置。 End Of Call 官方参考链接：End-of-call procedure for the TS7650 Appliance or TS7650G (Gateway), ProtecTIER V3.3.6 "},"03-IBM_Storage_System/06-Tape_Storage/12-TS7650G-安装配置.html":{"url":"03-IBM_Storage_System/06-Tape_Storage/12-TS7650G-安装配置.html","title":"TS7650G-安装配置","keywords":"","body":"TS7650G-安装配置   以TS7650G DD5单点虚拟带库配置为例，版本V3.3.7通常。集群包含设备：KVM switch、TSSC(TS3000 System Console)、TS7650G(X3850)、SMC网络交换机、SAN交换机、后端存储设备(IBM存储或其他存储)。安装配置官方参考链接： Installing the hardware for the TS7650G (Gateway), ProtecTIER V3.3.6 Installing the TS7650G (Gateway), ProtecTIER V3.3.6 设备及软件准备 硬件设备 虚拟带库集群相关设备信息如下表： | 设备名称 | 设备型号 | | ---------------- | ------------ | | KVM切换器 | 1754-HC3 | | 网络交换机（SMC） | SMC8126L2 | | SAN光纤交换机 | 2005-B16 | | KVM控制台 | 1723-17X | | TSSC | X3250 M4 | | TS7650G | X3850 X5 | | 存储(示例使用华为) | 5310 V5 | 软件安装包 需要准备的介质名称如下（版本根据需求而定）： LCD7560104_IBM_System_Storage_ProtecTIER_Maintenance_and_Recovery_Disk_for_3958-DD3-DD5and3959-SM1-SM2.iso LCD7664500_IBM_ProtecTIER_Enterprise_Edition_3958-DD5_V3.3.7.iso LCD7665100_IBM_ProtecTIER_Manager_3958-DD3-DD5_and_3959-SM2_V3.3.7.iso ​ 基础配置 设备安装上架   设备安装从上往下顺序建议：KVM、SMC网络交换机、SAN交换机、KVM控制台、TSSC、TS7650G、后端存储设备。尽量在同一个机柜，避免分散，方便进行管理。 集群内部线路连接   此次配置TS7650G DD5为单节点虚拟带库，线路连接根据IBM官方建议，集群设备内部线路连接参考链接： KVM switch, TSSC, and USB modem connections for the stand-alone TS7650G (Gateway), ProtecTIER V3.3.6。 存储及主机线路连接   虚拟带库ProtecTIER Server中Slot1和2，6和7是光纤端口，对于光纤端口使用官方也有相关说明，官方建议Slot1和2用户前端主机连接，Slot6和7用户后端存储连接。官方链接：Connecting Fibre Channel cables for the stand-alone TS7650G (Gateway), ProtecTIER V3.3.6。 管理IP地址配置 根据客户分配的IP地址，在不同设备上配置相应的管理IP，以方便远程管理。配置说明如下： SMC交换机管理口是25和26号口，需要DHCP服务器分配IP，默认用户admin,默认密码admin TS7650G的管理IP配置在配置node时候添加 后端华为存储需要DHCP服务器分配IP后才能登录进行配置指定管理IP 存储配置 使用华为OceanStor 5310 V5，存储直连TS7650G使用。 配置步骤 配置步骤如下： 创建磁盘域。名称默认或者自定义，此次选中了所有磁盘。 创建存储池。名称默认或自定义，RAID根据需求选择，此次RAID选择raid5，8D+1P 创建LUN。LUN划分三种，分配示例如下表： | LUN**名称 | 单个大小 | 创建数量 | 总容量 | 用途 | | --------------- | ------------ | ------------ | ---------- | ----------------------------- | | MD_Quorum | 100G | 1 | 100G | Quorum | | MD_LUN | 4.5T | 10 | 45T | Meta Data配置（数据分析去重） | | UD_LUN** | 5T | 70 | 350T | User Data配置（备份数据存储） | 创建LUN组。LUN组创建两个，一个MD开头LUN，一个是UD开头的LUN 创建主机。单节点的虚拟带库，创建一个主机即可 创建主机组。创建一个主机组即可 创建映射视图（建议在虚拟带库node配置完成后进行创建）。名称自定义，创建两个，分别对应MD和UD开头的LUN 虚拟带库系统安装 安装定制RedHat 安装步骤如下： 放入RedHat安装光盘，此次光盘对应名称为LCD7560104_IBM_System_Storage_ProtecTIER_Maintenance_and_Recovery_Disk_for_3958-DD3-DD5__and__3959-SM1-SM2.iso 开启设备，在出现选择引导模式时，有boot:输入提示，输入linux ks=cdrom，确认后开始安装 会提示安装导致磁盘格式化，选择YES，提示一些协议时候也选择YES 安装完成后会重启设备，此时取出光盘，默认引导到系统 ProtecTIER软件安装 安装步骤如下： 登录系统，用户root，默认密码admin 输入menu命令，进入ProtecTIER软件菜单，选择选项1： +------------------------------------------------------------------------------+ | ProtecTIER slim Menu | +------------------------------------------------------------------------------+ | 1) Install/Update ProtecTIER | | | | E) Exit | +------------------------------------------------------------------------------+ Your choice? 1 根据提示放入ProtecTIER Enterprise Edition安装光盘，此次安装对应名称为：LCD7664500_IBM_ProtecTIER_Enterprise_Edition_3958-DD5_V3.3.7.iso 放入光盘后，按回车，开始安装，直到安装完成(大概需要1小时) 安装完成后会重启，等待重启完成 ProtecTIER Manager客户端安装   在TSSC上更新或安装Linux版本（此次未更新版本），或者在个人笔记本或者专用Windows管理终端上安装均可。版本需要匹配，低版本可能使用不了。此次版本对应安装包名称：LCD7665100_IBM_ProtecTIER_Manager_3958-DD3-DD5_and_3959-SM2_V3.3.7.iso。 虚拟带库配置 node配置 输入menu命令进入ProtecTIER软件菜单： +------------------------------------------------------------------------------+ | ProtecTIER Service Menu | +------------------------------------------------------------------------------+ | 1) ProtecTIER Configuration (...) | | 2) Manage ProtecTIER services (...) | | 3) Health Monitoring (...) | | 4) Problem Alerting (...) | | 5) Version Information (...) | | 6) Generate a service report | | 7) Generate a system view | | 8) Update ProtecTIER code | | 9) ProtecTIER Analysis (...) | | | | E) Exit | +------------------------------------------------------------------------------+ >>> Your choice? 然后选择选项1) Configure ProtecTIER node (...)： +------------------------------------------------------------------------------+ | ProtecTIER Service Menu running on node1 | | ProtecTIER Configuration (...) | +------------------------------------------------------------------------------+ | 1) Configure ProtecTIER node | | 2) Recover Configuration for a replaced server | | 3) Configure machine serial number for a replaced server | | 4) Configure RAS | | 5) Update Time, Date, Timezone and Timeserver(s) | | 6) Scan storage interconnections | | 7) File Systems Management (...) | | 8) Configure replication (...) | | 9) IP Network configuration (...) | | 10) Update Firmware | | 11) Update the System's name | | 12) Validate configuration | | 13) Single Node - code upgrade (For Support Use ONLY) | | | | B) Back | | E) Exit | +------------------------------------------------------------------------------+ Your choice? 1 配置过程中，根据提示输入YES，根据配置需求进行配置。配置过程示例如下： Begin Processing Procedure About to execute: Operation: install Model: TS7650G Application: VTL Continue? (yes|no) yes This will stop the VTFD service, Do you wish to continue? (yes|no) yes Stopping services, please wait Stopping Cluster Services [ Done ] Services stopped Checking Fence Device [ Done ] Checking BOM [ Done ] Checking for existing nodes [ Done ] Checking Application Interfaces [ Done ] Checking repository [ Done ] Checking installed applications [ Done ] Checking local raid [ Done ] Checking conditions done Please provide the following information: ----------------------------------------- NTP server timeserver, IP Address (optional): NTP server secondary_timeserver, IP Address (optional): ApplicationInterface external, IP Address [192.168.10.161]: 10.21.168.168 ApplicationInterface external, Netmask [255.255.255.0]: ApplicationInterface external, Default Gateway [192.168.10.1]: 10.21.168.254 ApplicationInterface external, Hostname [node1]: Please check the following values: ---------------------------------- NTP server timeserver, IP Address: NTP server secondary_timeserver, IP Address: ApplicationInterface external, IP Address: 10.21.168.168 ApplicationInterface external, Netmask: 255.255.255.0 ApplicationInterface external, Default Gateway: 10.21.168.254 ApplicationInterface external, Hostname: node1 Are you sure you want to submit these values? (yes|no|quit) yes Validate Properties File [ Done ] Configuring Hostname [ Done ] Configuring Application Interfaces [ Done ] Stopping cluster [ Done ] Configuring cluster [ Done ] Starting cluster [ Done ] Installing NTP [ Done ] Set interfaces addresses [ Done ] Starting VTFD [ Done ] Starting RAS [ Done ] validation will start in 10 seconds Testing customer network connectivity [ Done ] Testing connectivity to the Default Gateway [ Done ] Getting number of nodes [ Done ] This is a 1 node cluster, will not test fencing validation ended install ended successfully End Processing Procedure Successfully   配置过程中，ApplicationInterface external, IP Address需要输入的IP地址为客户管理IP，即ProtecTIER Server 的5号槽位的1号端口的IP地址。配置完成后，回到ProtecTIER主菜单，选择选项2) Manage ProtecTIER services (...)： +------------------------------------------------------------------------------+ | ProtecTIER Service Menu running on node1 | | Manage ProtecTIER services (...) | +------------------------------------------------------------------------------+ | 1) Display services status | | 2) Start all services | | 3) Stop all services | | 4) Stop ProtecTIER services only (including GFS) | | 5) Stop VTFD service only | | 6) Poweroff This Node | | 7) Reboot This Node | | | | B) Back | | E) Exit | +------------------------------------------------------------------------------+ Your choice? 1 选择选项1) Display services status，查看服务状态是否都是UP： Begin Processing Procedure Service Status ============================== cman UP clvmd UP gfs UP vtfd UP ptrasd UP gmgnt UP End Processing Procedure Successfully 系统磁盘配置   在华为存储上创建映射视图，将磁盘映射给TS7650G的操作系统。登入TS7650G的系统，输入命令fdisk -l查看磁盘，示例： [root@node1 ~]# fdisk -l Disk /dev/sda: 598.9 GB, 598999040000 bytes 255 heads, 63 sectors/track, 72824 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Device Boot Start End Blocks Id System /dev/sda1 * 1 19 152586 83 Linux /dev/sda2 20 2569 20482875 83 Linux /dev/sda3 2570 59138 454390492+ 83 Linux /dev/sda4 59139 72824 109932795 5 Extended /dev/sda5 59139 68185 72669996 83 Linux /dev/sda6 68186 70735 20482843+ 83 Linux /dev/sda7 70736 72824 16779861 82 Linux swap / Solaris Disk /dev/sdb: 107.3 GB, 107374182400 bytes 255 heads, 63 sectors/track, 13054 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Disk /dev/sdb doesn't contain a valid partition table Disk /dev/sdc: 4947.8 GB, 4947802324992 bytes 255 heads, 63 sectors/track, 601536 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Disk /dev/sdc doesn't contain a valid partition table [.........] 然后输入命令mutipath -ll查看多路径，示例： [root@node1 ~]# multipath -ll mpath114 (365c647a100784a811c5d2957000000b9) dm-73 HUAWEI,XSG1 [size=5.0T][features=0][hwhandler=0][rw] \\_ round-robin 0 [prio=1][active] \\_ 3:0:0:74 sdbw 68:160 [active][ready] \\_ round-robin 0 [prio=1][enabled] \\_ 4:0:0:74 sdez 129:176 [active][ready] \\_ round-robin 0 [prio=1][enabled] \\_ 5:0:0:74 sdic 134:192 [active][ready] \\_ round-robin 0 [prio=1][enabled] \\_ 6:0:0:74 sdlf 67:464 [active][ready] mpath55 (365c647a100784a811c5d1e3d0000007e) dm-14 HUAWEI,XSG1 [size=5.0T][features=0][hwhandler=0][rw] \\_ round-robin 0 [prio=1][active] \\_ 3:0:0:15 sdp 8:240 [active][ready] \\_ round-robin 0 [prio=1][enabled] \\_ 4:0:0:15 sdcs 70:0 [active][ready] \\_ round-robin 0 [prio=1][enabled] \\_ 5:0:0:15 sdfv 131:16 [active][ready] \\_ round-robin 0 [prio=1][enabled] \\_ 6:0:0:15 sdiy 8:288 [active][ready] [.........] 输入menu命令进入ProtecTIER软件菜单： +------------------------------------------------------------------------------+ | ProtecTIER Service Menu | +------------------------------------------------------------------------------+ | 1) ProtecTIER Configuration (...) | | 2) Manage ProtecTIER services (...) | | 3) Health Monitoring (...) | | 4) Problem Alerting (...) | | 5) Version Information (...) | | 6) Generate a service report | | 7) Generate a system view | | 8) Update ProtecTIER code | | 9) ProtecTIER Analysis (...) | | | | E) Exit | +------------------------------------------------------------------------------+ >>> Your choice? 1 然后选择选项1) Configure ProtecTIER node (...)： +------------------------------------------------------------------------------+ | ProtecTIER Service Menu running on node1 | | ProtecTIER Configuration (...) | +------------------------------------------------------------------------------+ | 1) Configure ProtecTIER node | | 2) Recover Configuration for a replaced server | | 3) Configure machine serial number for a replaced server | | 4) Configure RAS | | 5) Update Time, Date, Timezone and Timeserver(s) | | 6) Scan storage interconnections | | 7) File Systems Management (...) | | 8) Configure replication (...) | | 9) IP Network configuration (...) | | 10) Update Firmware | | 11) Update the System's name | | 12) Validate configuration | | 13) Single Node - code upgrade (For Support Use ONLY) | | | | B) Back | | E) Exit | +------------------------------------------------------------------------------+ Your choice? 6 选择选项6) Scan storage interconnections，开始扫描磁盘： Your choice? 6 Begin Processing Procedure Scanning of local node storage interconnections Scanning of remote node storage interconnections 81 added mpath device(s) 0 removed mpath device(s) End Processing Procedure Successfully 选择选项7) File Systems Management (...)，进入如下菜单： +------------------------------------------------------------------------------+ | ProtecTIER Service Menu running on node1 | | ProtecTIER Configuration (...) | | File Systems Management (...) | +------------------------------------------------------------------------------+ | 1) Configure file systems on all available devices | | 2) Create file system(s) on a single unused device | | 3) Extend a file system with a new unused device | | 4) Update /etc/fstab | | 5) Display configured devices | | 6) Display unused devices | | 7) Display GFS repository file systems | | 8) Display unused GFS file systems | | 9) Increase capacity completion (applicable for a second cluster node) | | | | B) Back | | E) Exit | +------------------------------------------------------------------------------+ Your choice? 6 选择选项6) Display unused devices查看未配置的磁盘，示例： Begin Processing Procedure Page 1 Device: Size: Status 1. mpath100 5242880.00M Unused 2. mpath101 5242880.00M Unused 3. mpath102 5242880.00M Unused [.........] 22. mpath121 5242880.00M Unused 23. mpath41 102400.00M Unused 24. mpath42 4718592.00M Unused 25. mpath43 4718592.00M Unused [.........] 回到File Systems Management (...)菜单： +------------------------------------------------------------------------------+ | ProtecTIER Service Menu running on node1 | | ProtecTIER Configuration (...) | | File Systems Management (...) | +------------------------------------------------------------------------------+ | 1) Configure file systems on all available devices | | 2) Create file system(s) on a single unused device | | 3) Extend a file system with a new unused device | | 4) Update /etc/fstab | | 5) Display configured devices | | 6) Display unused devices | | 7) Display GFS repository file systems | | 8) Display unused GFS file systems | | 9) Increase capacity completion (applicable for a second cluster node) | | | | B) Back | | E) Exit | +------------------------------------------------------------------------------+ Your choice? 1 选择选项1) Configure file systems on all available devices开始配置： Devices to be configured Device: Size: Status 1. mpath100 5242880.00M Unused [.........] 22. mpath121 5242880.00M Unused 23. mpath41 102400.00M Unused 24. mpath42 4718592.00M Unused ... 33. mpath51 4718592.00M Unused 34. mpath52 5242880.00M Unused [.........] 81. mpath99 5242880.00M Unused Please confirm:? (yes|no) yes Creating physical volume [ Done ] Creating volume group [ Done ] [.........] Creating logical volume [ Done ] Creating File systems [ Done ] Successful capacity upgrade 配置完成后，选择选项5) Display configured devices查看配置的磁盘： Your choice? 5 Begin Processing Procedure Page 1 Device: Partition: VolGroup: LVolume: FileSystem Repository [.........] mpath41 mpath41p1 vgfs0023 lvfs0023 vgfs0023-lvfs0023 No [.........] mpath81 mpath81p1 vgfs0063 lvfs0063 vgfs0063-lvfs0063 No [.........] Next page - [n] Previous page - [b] Exit - [q] Please select :q 输入命令df -h查看文件系统： [root@node1 ~]# df -h Filesystem Size Used Avail Use% Mounted on /dev/sda2 19G 11G 7.5G 59% / /dev/sda3 420G 258M 398G 1% /pt_work /dev/sda6 19G 173M 18G 1% /image /dev/sda5 68G 180M 64G 1% /dump /dev/sda1 145M 20M 118M 15% /boot tmpfs 29G 0 29G 0% /dev/shm /dev/mapper/vgfs0001-lvfs0001 5.0T 988K 5.0T 1% /mnt/vgfs0001-lvfs0001 /dev/mapper/vgfs0002-lvfs0002 5.0T 988K 5.0T 1% /mnt/vgfs0002-lvfs0002 /dev/mapper/vgfs0003-lvfs0003 5.0T 988K 5.0T 1% /mnt/vgfs0003-lvfs0003 /dev/mapper/vgfs0004-lvfs0004 5.0T 988K 5.0T 1% /mnt/vgfs0004-lvfs0004 /dev/mapper/vgfs0005-lvfs0005 [.........] 创建Repository 创建Repository步骤如下： 通过ProtecTIER Manager客户端连接到系统，默认用户和密码都是ptadmin 软件主菜单上点击Repository，然后点击选项Create Repository 开始创建向导流程： Welcome：点击Next下一步， Name：输入自定义名称，然后点击Next Repository size：输入Repository容量等信息（此次配置的UD容量为350T），后端华为存储时7.2k转速的STAT磁盘，故选择了STAT-7.2K 8+8，在此配置下，disk size只能设置成1000，不然会报错。点击Next， Storage：根据之前的规划，将磁盘进行分类，MD或UD文件系统,分好后点击OK,然后现实分配的总览，无误就点击Next Report：现实配置概览，确认信息是否有误，无误点击Finish 开始配置，提示会offline系统，选择YES 开始配置流程，可以点击Run in background后台运行 配置说明： 需要耗费大量时间，磁盘大小不同时间不同，此次大概耗费二十多小时 可以登录操作系统看进度，UD类型磁盘文件系统Use%到99%表示快完成或者完成了 配置完成后可以输入命令/opt/dtc/install/ptconfig -validate进行验证 创建Library 创建Library步骤如下： 通过ProtecTIER Manager客户端连接到系统，默认用户和密码都是ptadmin 软件主菜单上点击VT，然后点击选项VT_Library，然后点击选项Create new Library 开始创建向导流程： Welcome：点击Next下一步， Library details：输入自定义名称，然后点击Next Library type：选择虚拟的带库类型，此次选择IBM TS3500 Tape model：选择tape drive类型，只支持ULT3580-TD3 Tape drives：输入在配置的node中drives数量，根据需求定义 Assignment：每个端口上访问虚拟drives的数量，此次是平均分配 Cartridges：设置Cartridges的数量及大小，根据需求进行自定义。此次配置设置Cartridges数量为5000个，每个大小970.2G。条码编号也可以自定义，此次使用的默认配置 Slots：设置Slots的数量，根据需求自定义。此次配置slots设置为5000个，import/export slots数量设置为50 Report： 配置的预览，检查是否有误。确认无误点击Finish 提示会offline系统，选择YES 开始配置流程，可以点击Run in background后台运行 配置大概需要十多分钟，完成后检查各项配置 Host配置 连接光纤线   TS7650G DD5设备中，机器后面的Slot1和Slot2是用来用户连接主机的，每个端口速率2Gb，建议通过SAN交换机进行连接，方便调整。 zone配置   如果通过SAN交换机连接到主机，在SAN交换机上配置相应的zone，建议点对点，不建议把TS7650G上端口都绑在一起。 配置Host映射 配置Host映射步骤如下： 使用ptadmin用户登录ProtecTIER Manager 在主菜单VT菜单中点击Host initiator management 对发现的主机端口进行自定义命名，确认后点击保存 在主菜单VT菜单中点击Confiture LUN masking groups 添加左下角Add添加一个Group 首先输入Group的名称 在Selected Host Initiator中点击Add添加主机WWN 在Library Mappings中点击Add添加带库的端口 确认后进行保存 "},"03-IBM_Storage_System/07-NAS_Storage/":{"url":"03-IBM_Storage_System/07-NAS_Storage/","title":"NAS_Storage","keywords":"","body":"NAS_Storage 简介   IBM NAS存储产品接触过的就Nseries和V7000U，Nseries一些型号是OEM NetAPP的产品，IBM早已淘汰停产，但是还是有极少数客户在使用中。V7000U是近些年的产品，底层硬件是一台X3650服务器，接触也不多。 V7000U官方资料：V7000U knowledgecenter 内容 Nseries-常用命令和操作 "},"03-IBM_Storage_System/07-NAS_Storage/01-Nseries-常用命令和操作.html":{"url":"03-IBM_Storage_System/07-NAS_Storage/01-Nseries-常用命令和操作.html","title":"Nseries-常用命令和操作","keywords":"","body":"Nseries-基本操作 目前就接触过N3400和N6040，维护不多，操作不难但是长时间不用就忘了，记下来。 信息查看和收集 基本检查 命令 用途 rdfile /etc/messages 查看日志 environment status 查看系统环境状态 sysconfig -r 查看磁盘相关配置 sysconfig -a 查看所有配置 sysconfig -v 查看硬件状态 ifconfig -a 查看IP状态 vif status 查看VIF端口 aggr status 查看aggr状态 vol status 查看vol状态 lun status 查看lun状态 disk show -v 查看硬盘状态 cf status 查看cluster状态 收集日志 确认autosupport状态是enable： N3400b> options autosupport.enable autosupport.enable on 触发最新autosupport信息 N3400b> options autosupport.doit 同时收集/etc/messages*和/etc/log/auditlog文件。 硬盘更换 查看硬盘状态： N3400b> disk show -v DISK OWNER POOL SERIAL NUMBER 0b.38 N3400B (84230013) Pool0 ZAKUBKBH 0b.34 N3400A (84228001) Pool0 ZBGU7DUH 0b.35 N3400B (84228013) FAILED ZBG6H8NF 查看所在槽位，可以看到位于1号柜子7号槽位： aggr status -r RAID Disk Device HA SHELF BAY CHAN Pool Type RPM Used (MB/blks) Phys (MB/blks) failed 0b.35 0b 1 3 FC:A - ATA 7200 423111/866531584 423889/868126304 拔出故障硬盘，换上新的硬盘，输入命令查看状态： N3400b> disk show -v DISK OWNER POOL SERIAL NUMBER 0b.38 N3400B (84230013) Pool0 ZAKUBKBH 0b.34 N3400A (84228001) Pool0 ZBGU7DUH 0b.35 Not Owned NONE ZBBF08JG 磁盘属于哪个控制器就在那个控制器下执行： N3400b> disk assign 0b.35 N3400b> disk show -v DISK OWNER POOL SERIAL NUMBER 0b.38 N3400B (84230013) Pool0 ZAKUBKBH 0b.34 N3400A (84228001) Pool0 ZBGU7DUH 0b.35 N3400B (84230013) Pool0 ZBBF08JG 查看磁盘使用状态，可以看到是个spare备用盘： N3400b> aggr status -r 更换完成。 "},"03-IBM_Storage_System/08-Cloud_Object_Storage/":{"url":"03-IBM_Storage_System/08-Cloud_Object_Storage/","title":"Cloud_Object_Storage","keywords":"","body":""},"03-IBM_Storage_System/09-SAN_Switch/":{"url":"03-IBM_Storage_System/09-SAN_Switch/","title":"SAN_Switch","keywords":"","body":"SAN_Switch 简介 SAN全称Storage Area Networks，SAN Switch通俗点讲就是连接接存储和主机的光纤交换机。 IBM SAN Switch有两个系列： SAN b 系列：OEM博科 SAN c 系列：OEM思科 官方网站：https://www.ibm.com/cn-zh/it-infrastructure/storage/san IBM支持 7*24小时呼叫中心：400-810-6678 IBM 用户支持中心：产品下载和更新、打开和查看案例、产品通知以及支持指南，官方连接： IBM 支持团队 内容 Switch-收集数据 Switch-常用命令 Switch-常见问题 "},"03-IBM_Storage_System/09-SAN_Switch/01-Switch-收集数据.html":{"url":"03-IBM_Storage_System/09-SAN_Switch/01-Switch-收集数据.html","title":"Switch-收集数据","keywords":"","body":"Switch-收集数据 交换机硬件架构相对比较简单，故障也相对也少。大多数故障是SFP模块故障，有时候也有一些内部微码问题，当然也有一些外部问题需要通过交换机日志来进行排查。 SAN B-type 数据收集 IBM SAN B-type系列交换机是OEM博科的，但是从交换机图形界面（EZSwitchSetup)收集的日志IBM support的工具解析不了。 一般收集IBM B-type系列交换机日志有两种： 一般硬件故障时候：supportshow 较复杂的问题：supportsave supportshow收集 就是收集命令supportshow的输出 以Xsehll为例，登录到交换机后，在输入命令前依次点击Xsehll选项：文件-日志-启动 在交换机上运行命令： supportshow 运行完成后依次点击Xsehll选项：文件-日志-停止 将Xsehll输出的文件重命名保存即可。 supportsave收集 收集条件： 远程ftp服务器，文件提取到本地方便 服务器上指定目录有写权限 目录建议新建个空目录，因为内容较多 收集步骤如下： 运行命令：supportsave 提示\"OK to proceed?\"时输入：yes 提示\"Host IP or Host Name\"时输入ftp服务器ip 根据提示输入ftp访问用户名和密码 提示\"Protocol\"时输入：ftp 提示\"Remote Directory\"时输入ftp服务器上的指定目录 等待收集完成 完成后在ftp服务器上指定目录下的所有文件压缩打包 建议压缩打包成zip格式，IBM support远程工具不能解析rar格式。 SAN C-type 数据收集 暂未接触到此产品 "},"03-IBM_Storage_System/09-SAN_Switch/02-Switch-常用命令.html":{"url":"03-IBM_Storage_System/09-SAN_Switch/02-Switch-常用命令.html","title":"Switch-常用命令","keywords":"","body":"Switch-常用命令 交换机管理常用命令 SAN B-type 常用命令 IBM SAN B-type系列交换机是OEM博科的，命令和博科交换机基本一致。 示例： configshow -pattern \"fabric.ops\" 基本信息查看   对于高端B384这种交换机，有些命令不是index，而是slot加port，例如index是84，solt号是2，port号是5，那么就是2/5。常用命令如下： 命令 用途 chassisshow 查看交换机chassis信息 switchshow 查看交换机配置信息 ipaddrshow 查看交换机ip地址 switchStatusshow 查看交换机健康状态 portshow 查看某个端口状态，NPIV的虚拟WWN查看 slotshow 查看交换机slot状态 sfpshow 查看某个sfp状态 porterrshow 查看端口数据和数据类型错误统计信息 pshow 查看交换机电源状态 fanhow 查看交换机风扇状态 licenseshow 查看交换机license信息 firmwareshow 查看交换机微码信息 hashow 查看交换机ha状态 tempshow 查看交换机环境温度 islshow 查看thunk连接状态 errdump 查看交换机日志 supportshow 查看交换机诊断信息 fabricShow 显示fabric信息及级联信息 nsshow 查看当前交换机设备信息 nsallshow 查看fabric中的所有设备信息 zone配置相关 创建一个zone的基本步骤： 创建alias：aliCreate 创建zone：zoneCreate 创建cfg或者将zone添加到现有cfg：cfgCreate or cfgAdd 保存配置：cfgSave 激活配置：cfgEnable zone配置相关常用命令如下： 命令 用途 aliCreate 创建别名 aliAdd 在别名中添加成员 aliRemove 删除别名成员 aliDelete 删除别名 aliShow 查看别名信息 zoneCreate 创建zone zoneAdd zone中添加成员 zoneMove zone中删除成员 zoneDelete 删除zone zoneShow 查看zone配置 cgfCreate 创建zone配置文件 cfgAdd 指定zone配置文件中添加zone cfgRemove 指定zone配置文件中删除zone cfgDelete 删除zone配置文件 cfgShow 查看所有zone配置信息 cfgSave 保存zone配置信息 cfgTransAbort 撤销所有上一次cfgSave之后未保存的更改 cfgEnable 激活配置 cfgDisable disable zone配置 configUpload 备份配置 configDownload 恢复配置 以wwnzone为示例,使用格式如下： aliCreate \"DE4000H_A_port2\",\"20:22:d0:39:ea:1a:de:71\" aliCreate \"DE4000H_B_port2\",\"20:22:d0:39:ea:1a:9d:61\" aliCreate \"vios1_fcs1\",\"10:00:00:10:9b:66:ac:1e\" aliCreate \"vios2_fcs1\",\"10:00:00:10:9b:66:da:b7\" zoneCreate \"DE4000H_vios1\",\"DE4000H_A_port2;DE4000H_B_port2;vios1_fcs1;vios2_fcs1\" zoneCreate \"DE4000H_vios2\",\"DE4000H_A_port2;DE4000H_B_port2;vios1_fcs1;vios2_fcs1\" cfgAdd \"cfg_A\",\"DE4000H_vios1;DE4000H_vios2\" cfgEnable \"cfg_A\" cfgSave 注意：  建议先cfgEnable然后cfgSave。先cfgSave的话，会有提示defind和effective的配置会不一致，并且在错误日志里面有warning：defind and effective zone configurations are inconsistent。 修改配置 常用对交换机配置修改命令如下： 命令 用途 portdisable disable一个端口 portenable enable一个端口 portstatsclear 清除交换机指定端口状态 statsclear 清除端口诊断统计信息 chassisdisable disable chassis上所有端口 chassidenable enbale chassis上所有端口 swichdisable disable 交换机 switchenable enbale 交换机 passwd 修改用户密码 errclear 清除错误日志 hafailover 切换HA ipaddrset IP地址配置 configuration 配置菜单，例如配置Domain ID SAN C-type 常用命令 暂未接触 "},"03-IBM_Storage_System/09-SAN_Switch/03-Switch-常见问题.html":{"url":"03-IBM_Storage_System/09-SAN_Switch/03-Switch-常见问题.html","title":"Switch-常见问题","keywords":"","body":""},"03-IBM_Storage_System/09-SAN_Switch/04-Switch-常用脚本.html":{"url":"03-IBM_Storage_System/09-SAN_Switch/04-Switch-常用脚本.html","title":"Switch-常用脚本","keywords":"","body":"Switch-常用脚本 交换机管理或配置梳理常用小脚本。 SAN B-type 查询wwpn是否在此交换机上配置   有时候有一批需要查询一个主机端口不知道具体连的那些交换机，特别是NPIV的，通过switch不能直观看到，如果比较多也很难找。脚本具体说明： 交换机上直接操作不方便，把配置用cfgshow命令取下来，例如文件名叫cfgshow 把需要查询的WWN放在一个单列列表中，例如文件名叫wwnlist 在AIX或者Linux系统下运行即可 输出第一列是需要，第二列是zone名字，第三列是查询的WWN 可以将输出重定向到csv文件用excel打开编辑 脚本如下： count=0 for wwn in `cat wwnlist` do result=`cat cfgshow |grep -i $wwn|awk 'NR==1'` if [ -z \"$result\"] then count=$((count+1)) echo \"$count,$result,$wwn\" fi done 待补充 "},"03-IBM_Storage_System/10-SAN_Volume_Controller/":{"url":"03-IBM_Storage_System/10-SAN_Volume_Controller/","title":"SAN_Volume_Controller","keywords":"","body":"SAN_Volume_Controller 简介   IBM SAN Volume Controller(SVC)是一款企业级存储系统，采用IBM Spectrum Storage™产品家族成员IBM Spectrum Virtualize™软件构建而成，通过支持对于成功至关重要的大规模全新工作负载，可帮助企业实现更为出色的数据经济效益。SVC系统可以处理移动应用和社交应用产生的海量数据，支持灵活的混合云部署，并提供从最新分析技术中获取洞察所需的性能和可扩展性。 IBM官方网站：IBM SAN Volume Controller IBM官方文档：IBM SAN Volume Controller(2145 and 2147)documentation IBM支持 7*24小时呼叫中心：400-810-6678 IBM 用户支持中心：产品下载和更新、打开和查看案例、产品通知以及支持指南，官方连接： IBM 支持团队 内容 SVC-数据收集 SVC-远程拷贝 SVC-常用命令 SVC-Quorum磁盘 SVC-固件升级 "},"03-IBM_Storage_System/10-SAN_Volume_Controller/01-SVC-数据收集.html":{"url":"03-IBM_Storage_System/10-SAN_Volume_Controller/01-SVC-数据收集.html","title":"SVC-数据收集","keywords":"","body":"SVC-数据收集 SVC是IBM Spectrum Storage™产品家族成员，IBM Storwize Storage系列及IBM FlashSystem系列和SVC管理界面基本一致，收集数据方法也基本一致。 收集数据方式 在SVC中，收集故障诊断日志有四种方式： management GUI interface：用户管理界面 service assistant interface：一般是IBM工程师用 command-line interface (CLI)：很少用 service command-line interface (CLI) ：IBM专家用 USB flash drive interface：极少数情况下IBM工程师用 本文主要介绍用Management GUI数据收集方法，详解各种数据适合的不同故障场景，可以让客户及时准确收集对应的数据，以便IBM快速准确的判断故障。 Management GUI数据收集 整理摘自IBM官方支持中心，链接：https://www.ibm.com/support/pages/node/690179 收集方法 在Management GUI中，选择Settings--> Support--> Download Support Package-->选择日志类型然后点击 \"Download\"。四种方式收集日志描述及大小估算： Option Description Size(1Group,30vol) Size(4Groups,250Vol) 1 Standard logs 10 MB 340 MB 2 Standard logs plus one existing statesave 50 MB 520 MB 3 Standard logs plus most recent statesave from each node 90 MB 790 MB 4 Standard logs plus new statesaves 90 MB 790 MB 四种选项解析 Option1：Standard logs大多数问题都可以通过此日志去诊断，例如简单硬件故障，包含内容如下： SVC/Storwize事件日志 SVC/Storwize审核日志 Linux日志，包括/var/log/messages Option2：Standard logs plus one existing statesave此选项包含选项1以及系统中的当前配置节点最新statesave。在某些微码版本中，此选项实际上从当前配置节点收集最新的转储。 Option3：Standard logs plus most recent statesave from each node此选项包含选项1以及系统中每个节点最新statesave。 Option4：Standard logs plus new statesaves此选项生成livedump。livedump在系统中的每个节点或节点容器上生成，并且此时包含许多有关系统的详细日志记录信息，此详细的日志记录信息对于分析某些问题是必需的。收集此日志注意事项： livedump生成可能需要10到30分钟 进行livedump收集会对系统性能产生暂时的小影响 根据故障类型选择日志 对于与主机或存储之间有关的问题，选择Option4 对于关键性能问题，先收集Option1，然后收集Option4 对于一般性能问题，收集Option4 对于2030、1196或1195错误，收集Option3，不要收集Option4 对于与压缩卷有关的问题，收集Option4 对于存储子系统的问题，收集Option4 对于与Metro或Global Mirror有关的问题，包括1920错误，从两个系统中收集Option4 对于所有其他问题，包括一般硬件问题，收集Option1 Service Assistant Interface收集 客户很少用到，不作详述，一般是IBM工程师用的，在发生宕机故障时候，收集宕机时刻生成的dump日志。 USB flash drive interface收集 节点启动不了时候收集，一般是IBM工程师用，IBM工程师也很少用到，不作详述。 其它信息收集 VPD信息收集 收集方法如下： 登录到Management GUI中 选择\"Monitoring\"，然后选择\"System\" 选中对应的节点，然后右键 选择\"Actions\"菜单里面的\"download VPD\" "},"03-IBM_Storage_System/10-SAN_Volume_Controller/02-SVC-远程拷贝.html":{"url":"03-IBM_Storage_System/10-SAN_Volume_Controller/02-SVC-远程拷贝.html","title":"SVC-远程拷贝","keywords":"","body":"SVC-远程拷贝 SVC远程拷贝(Remote Copy)功能是SVC一项重要功能，可用于数据冗余、数据备份、数据迁移及容灾数据同步等。 拷贝模式 SVC提供了三种一致性拷贝模式： 高速镜像：采用数据实时同步方式 全局镜像：此模式是异步模式，在写操作应用到主卷后再将其应用到辅助卷，这需要两个站点直接的高带宽链接，以防止在发生故障时丢失数据 具有变更卷的全局镜像：此方式也是异步模式。在使用此方式时候，将跟踪变更，并将变更拷贝到中间变更卷，变更将定期传输至辅助站点以降低带宽需求（时间可以设置从60s至86400s） 在SVC Management GUI中，根据图标就可以看出同步采用的是哪种类型，如图所示： 高速镜像修改成全局镜像（异步） 例如一个一致性组test，状态是一致同步状态，采用高速镜像（同步）模式，修改成全局镜像（异步）步骤如下： 选择一致性组test，右键点击“停止”选项 对话框提示是否允许辅助卷的读写访问，不勾选“允许辅助读/写访问”（看配置需求） 然后点击“停止一致性组”，可以看到同步关系是“一致停止” 选择一致性组test，右键点击“编辑一致性组”选项 对话框“编辑一致性组”中类型选择“全局镜像”，循环方式“无”，循环周期默认“300秒” 点击确认下一个对话框会提示：该关系中的卷是否已同步，选择“否，卷未同步” 选择一致性组test，右键点击“启动”选项 状态为“不一致拷贝”，可以任务列表里面查看拷贝进度 高速镜像修改成具有变更卷的全局镜像（异步） 例如一个一致性组test，状态是一致同步状态，采用高速镜像（同步）模式，修改具有变更卷的全局镜像（异步）步骤如下： 前面步骤同上1-4步骤； 对话框“编辑一致性组”中类型选择“全局镜像”，循环方式选择“多个”，循环周期默认“300秒”，循环周期根据需求定义在60s至86400s之间 在修改完成后，启动一致性组，是无法启动的，提示没有主变更卷 不需要删除一致性关系，选中需要一致性组中的一致性关系，右键选择“全局镜像变更卷” 可以选择创建新的或者添加新的卷（此卷必须与关系中的其它卷在同一个I/O组，并且具有相同的容量，无法将改卷映射给主机，或者在其它拷贝服务中使用）。 同样在辅助SVC端也要创建同样的辅助全局变更卷，才可以启动一致性组。 一致性组相关命令 有时候需要用到一些命令去查看或者编辑一致性组关系，用的很少，简单记录几个。 查看一致性组 查看所有及指定某一个查看的命令，不知道ID先查看所有： lsrcconsistgrp -delim : lsrcconsistgrp -delim : rc_consist_group_id 说明：rc_consist_group_id是一致性组的ID 创建一致性组 创建一致性组及往一致性组里面添加关系： mkrcconsistgrp -name new_name -cluster cluster_id chrcrelationship -consistgrp consist_group_name rc_rel_id 说明： new_name是新一致性组的名称，cluster_id是新一致性组 的远程集群的ID 如果 未指定-cluster，则仅在本地群集上创建一致性组- 新的一致性组不包含任何关系，并且处于空状态。 consolid_group_name是要为其分配关系的新一致性组的名称，而rc_rel_id是该关系的ID 启动及停止一致性组 启动及停止一致性组以及用-access参数启用辅助卷的写访问： startrcconsistgrp rc_consist_group_id stoprcconsistgrp rc_consist_group_id stoprcconsistgrp rc_consist_group_id -access 说明：rc_consist_group_id是一致性组的ID 删除一致性组 删除一致性组（里面没有一致性关系），以及强制删除（不为空，里面还有一致性关系）： rmrcconsistgrp rc_consist_group_id rmrcconsistgrp -force rc_consist_group_id 说明：rc_consist_group_id是一致性组的ID 更改一致性组 全局镜像更改为高速镜像： chrcconsistgrp -metro rc_consist_group_name 高速镜像更改为全局镜像： chrcconsistgrp -global -cyclingmode none rc_consist_group_name 高速镜像更改为具有变更卷的全局镜像： chrcconsistgrp -global -cyclingmode multi -cycleperiodseconds period rc_consist_group_name 说明： rc_consist_group_name是要更改的一致性组的名称 更改后所有新设置都适用于一致性组内的所有关系 "},"03-IBM_Storage_System/10-SAN_Volume_Controller/03-SVC-常用命令.html":{"url":"03-IBM_Storage_System/10-SAN_Volume_Controller/03-SVC-常用命令.html","title":"SVC-常用命令","keywords":"","body":"SVC-常用命令   SVC命令使用比较少，偶尔也会用到。SVC在7.8及以前版本中，没有awk命令，没有grep命令，有sed命令，但是在更老的7.2版本中，sed命令也没有。V8版本及以后版本目前还没尝试有没有这些命令。SVC命令Knowledge Center：Command-line interface Volume命令 lsvdisk 显示系统可以识别的卷的简要列表或详细视图，Syntax如下： >>- lsvdisk -- --+--------------------------------+-- ----------> '- -filtervalue -- attrib=value -' >--+----------+-- --+----------+-- -----------------------------> '- -nohdr -' '- -bytes -' >--+-----------------------+-- -- --+-----------------+---------> '- -delim -- delimiter -' '- -filtervalue? -' >--+---------------+------------------------------------------->使用示例如下： IBM_2145:SVC_Cluster:superuser>lsvdisk -delim : 0 id:0 name:E850C_LP1 IO_group_id:0 IO_group_name:io_grp0 status:online mdisk_grp_id:1 mdisk_grp_name:Pool1 capacity:200.00GB ... tier_capacity:55.78GB compressed_copy:no uncompressed_used_capacity:59.77GB parent_mdisk_grp_id:1 parent_mdisk_grp_name:Pool1 encrypt:no IBM_2145:SVC_Cluster:superuser>lsvdisk -delim : id:name:IO_group_id:IO_group_name:status:mdisk_grp_id:mdisk_grp_name:capacity:type:FC_id:FC_name:RC_id:RC_name:vdisk_UID:fc_map_count:copy_count:fast_write_state:se_copy_count:RC_change:compressed_copy_count:parent_mdisk_grp_id:parent_mdisk_grp_name:formatting:encrypt:volume_id:volume_name:function 0:E850C_LP1:0:io_grp0:online:1:Pool1:200.00GB:striped:::::60050768018186A3000000000000001D:0:1:not_empty:1:no:0:1:Pool1:no:no:0:E850C_LP1: 1:E850C_LP2:0:io_grp0:online:1:Pool1:200.00GB:striped:::::60050768018186A3000000000000001E:0:1:not_empty:1:no:0:1:Pool1:no:no:1:E850C_LP2: 2:E850C_LP3:0:io_grp0:online:1:Pool1:200.00GB:striped:::::60050768018186A30000000000000006:0:1:not_empty:1:no:0:1:Pool1:no:no:2:E850C_LP3: ... 一个卷的信息非常多，如果只需取部分数据，可以使用脚本： for i in {0..5};do lsvdisk -delim : $i | sed -n '/^id:\\|^name:\\|^capacity:\\|^real_capacity:/p'; done | sed '/^id/{x;p;x;}'| sed '/^id/{N;s/\\n/ /}'| sed '/^id/{N;s/\\n/ /}'| sed '/^id/{N;s/\\n/ /}'| sed '/^id/{N;s/\\n/ /}' 上面脚本运行后示例： id:0 name:E850C_LP1 capacity:200.00GB real_capacity:63.78GB id:1 name:E850C_LP2 capacity:200.00GB real_capacity:29.30GB id:2 name:E850C_LP3 capacity:200.00GB real_capacity:22.70GB id:3 name:E850C_LP4 capacity:200.00GB real_capacity:30.16GB id:4 name:E850C_LP5 capacity:200.00GB real_capacity:10.91GB id:5 name:E850C_LP6 capacity:200.00GB real_capacity:15.31GB 上面脚本把同一卷结果输出在一行，按照原有的格式可以用如下脚本： for i in {0..3}; do lsvdisk -delim : $i | sed -n '/^id:\\|^name:\\|^capacity:\\|^real_capacity:/p'; done | sed '/^id/{x;p;x;}' 上面脚本运行后示例： id:0 name:E850C_LP1 capacity:200.00GB real_capacity:63.78GB id:1 name:E850C_LP2 capacity:200.00GB real_capacity:29.30GB id:2 name:E850C_LP3 capacity:200.00GB real_capacity:22.70GB id:3 name:E850C_LP4 capacity:200.00GB real_capacity:30.16GB 官方参考链接：lsvdisk lsvdisksyncprogress 显示卷拷贝同步的进度，示例如下： IBM_2145:SVC_Cluster1:superuser>lsvdisksyncprogress 0 vdisk_id vdisk_name copy_id progress estimated_completion_time 0 vdisk0 0 100 0 vdisk0 1 100 官方参考链接：lsvdisksyncprogress lshostvdiskmap 显示映射到主机的卷的列表，Syntax如下： >>- lshostvdiskmap -- --+----------+-- -------------------------> '- -nohdr -' >--+-----------------------+-- --+-------------+--------------->示例如下： IBM_2145:SVC_Cluster1:superuser>lshostvdiskmap 0 id name SCSI_id vdisk_id vdisk_name vdisk_UID IO_group_id IO_group_name 0 TSTDB 0 0 tstheart 600507680180863E5000000000000000 0 io_grp0 0 TSTDB 1 1 tstdata1 600507680180863E5000000000000001 0 io_grp0 0 TSTDB 2 2 tstdata2 600507680180863E5000000000000002 0 io_grp0 0 TSTDB 3 247 tstdata3 600507680180863E5000000000000146 0 io_grp0 0 TSTDB 4 248 tstdata4 600507680180863E5000000000000147 0 io_grp0 官方参考链接：lshostvdiskmap Host命令 lshost 生成一个包含有关系统可见的所有主机的简要信息以及有关单个主机的详细信息的列表，Syntax如下： >>- lshost-- --+-----------------------------------+-- ---------> '- -filtervalue -- attribute=value -' >--+----------+-- --+-----------------------+-- -- -------------> '- -nohdr -' '- -delim -- delimiter -' >--+-----------------+--+---------------+---------------------->使用示例： IBM_2145:SVC_Cluster1:superuser>lshost id name port_count iogrp_count status 0 HOST1 4 4 offline 1 host22 4 4 offline 2 host33 4 4 offline 3 host 4 4 online 显示所有offline的主机： IBM_2145:SVC_Cluster1:superuser>lshost -filtervalue status=offline id name port_count iogrp_count status 0 HOST1 4 4 offline 1 host22 4 4 offline 2 host33 4 4 offline 官方参考链接：lshost IO Group命令 lsiogrp 显示对系统可视的输入/输出 (I/O) 组的简明列表或详细视图，示例如下： IBM_2145:SVC_Cluster1:superuser>lsiogrp id name node_count vdisk_count host_count 0 io_grp0 2 804 244 1 io_grp1 0 0 244 2 io_grp2 0 0 244 3 io_grp3 0 0 244 4 recovery_io_grp 0 0 0 IBM_2145:SVC_Cluster1:superuser>lsiogrp 0 id 0 name io_grp0 node_count 2 vdisk_count 804 host_count 244 flash_copy_total_memory 20.0MB flash_copy_free_memory 20.0MB remote_copy_total_memory 50.0MB remote_copy_free_memory 19.7MB mirroring_total_memory 62.0MB mirroring_free_memory 0.0MB raid_total_memory 40.0MB raid_free_memory 40.0MB maintenance no compression_active no accessible_vdisk_count 804 compression_supported yes 官方参考链接：lsiogrp 待补充 "},"03-IBM_Storage_System/10-SAN_Volume_Controller/04-SVC-Quorum磁盘.html":{"url":"03-IBM_Storage_System/10-SAN_Volume_Controller/04-SVC-Quorum磁盘.html","title":"SVC-Quorum磁盘","keywords":"","body":"SVC-Quorum磁盘 定额磁盘是MDisk或受管驱动器，包含专门用于系统管理的保留区域，系统自动分配候选定额磁盘。 定额磁盘介绍 概念   定额磁盘是MDisk或受管驱动器，包含专门用于系统管理的保留区域（如记录镜像卷的同步状态），系统自动分配候选定额磁盘。 用途   定额磁盘用于在一组表决节点不同意系统的当前状态时进行仲裁。系统使用定额磁盘来管理将系统均匀一分为二的 SAN 故障。 一半系统继续运行，另一半系统停止，直至SAN连接恢复。 仲裁机制   可将系统分为两组，每组均包含系统中原来一半数量的节点。定额设备确定哪组节点停止运行并停止处理I/O请求。在这种仲裁情况下，访问定额设备的第一组节点会标记为定额设备的所有者，因而可以继续作为系统运行，并处理所有I/O请求。如果另一组节点无法访问定额设备，或者发现定额设备由另一组节点所拥有，那么该组节点将停止作为系统运行，并且不会处理I/O请求。 选定条件   在定额磁盘发现期间，系统评估每个逻辑单元 (LU) 以确定其是否可能用作定额磁盘。 系统从一组合格的LU中指定三个候选定额磁盘。LU 必须满足以下条件，才能被视为候选定额磁盘： 必须处于受管方式 必须对系统中的所有节点都可视 必须由作为定额磁盘的认可主机的存储系统提供 在iSCSI连接的存储系统上无法找到定额磁盘 必须具有足够的空闲数据块来保存系统状态和配置元数据   每个系统只能拥有一个在仲裁情况下使用的活动定额设备。但是，系统最多使用三个定额设备来记录在发生灾难时要使用的系统配置数据的备份。 注意事项   如果没有可用的定额磁盘，那么镜像卷可能会变为脱机状态。 在定额磁盘上记录镜像卷的同步状态；  为了避免在单次故障中失去所有定额设备的可能性，请在多个存储系统上分配候选定额磁盘或者在多个服务器上运行IP定额应用程序。 配置建议 单节点配置   在未将系统配置为延伸或HyperSwap系统时，正常配置使用受管驱动器或MDisk作为定额设备。系统自动分配候选定额磁盘。但是，向系统添加新存储器或除去现有存储器时，最好是查看定额磁盘分配情况。（可选）可将 IP 定额设备配置为使用定额磁盘的替代方法或者提供额外的冗余。 其他情况配置 参考后面的官方链接。 查看及修改定额磁盘 查看方法 使用命令lsquorum可以查看当前系统定额磁盘配置，active状态为yes的是活动的定额磁盘。 修改条件 更改已分配为候选定额磁盘的受管磁盘时，请遵循以下一般准则： 如果可能，尽量使每个MDisk均由一个不同的存储系统来提供 在更改候选定额磁盘之前，请确保要分配为候选定额磁盘的受管磁盘的状态报告为online 请确保要分配为候选定额磁盘的受管磁盘具有512MB或更多容量 使用更小容量的MDisk，或将驱动器用作定额设备，以显著减少在必要时运行系统恢复过程（也称为第3层或T3恢复）需要的时间量 修改方法 使用命令chquorum修改当前系统定额磁盘配置，步骤如下： 首先使用lsquorum查看当前定额磁盘配置 系统默认三个，记录下需要修改旧定额磁盘的quorum_index列的编号，例如为1 查看确认新定额磁盘的id，在SVC上，在按池划分的mdisk中，找到需要作为新定额磁盘的mdisk，查看属性，记录（标识）id，例如为6 使用如下命令修改仲裁盘：chquorum -mdisk 6 1 其中“6”是新定额磁盘的id，“1”是旧定额磁盘的quorum_index 运行完成后无输出，lsquorum查看状态，可以看到已经修改成功了 参考链接 关于定额磁盘官方相关描述和命令及HyperSwap配置或基于IP的光纤通道用法参考链接： 配置定额 定额磁盘配置 定额磁盘创建和数据块分配 使用 CLI 设置定额磁盘 chquorum lsquorum 镜像卷 "},"03-IBM_Storage_System/10-SAN_Volume_Controller/05-SVC-固件升级.html":{"url":"03-IBM_Storage_System/10-SAN_Volume_Controller/05-SVC-固件升级.html","title":"SVC-固件升级","keywords":"","body":"SVC-固件升级 SVC的微码版本升级，官方参考文档： Software Upgrade Test Utility Updating the software automatically using the CLI Concurrent Compatibility and Code Cross Reference for Spectrum Virtualize 升级前准备 准备工作主要是健康健康、配置备份即升级测试。 健康检查 检查内容： 检查是否有需要维护的事件 检查外部存储器、mdisk和vdisk是否都正常，是否有脱机或降级的卷 如果有脱机的卷，fast_write_state如果为空，则卷可以处于脱机状态，在更新期间不会导致错误 检查主机访问都是否正常，远程复制等是否正常 检查管理IP及各节点服务IP是否正常访问 检查光纤端口是否都正常 检查电池是否online或charged 检查SVC性能是否正常 检查每个节点是否有依赖的卷 配置备份 首先收集一份系统日志备用，使用WEB界面收集即可。 可以通过以下命令进行备份当前配置： IBM_2145:SVC_Cluster:superuser>svcconfig backup 通过SCP将备份文件到自己电脑： ### (Using Linux)### scp superuser@cluster_ip:/dumps/svc.config.backup.* . ### (Using Windows)### pscp -unsafe superuser@cluster_ip:/dumps/svc.config.backup.* . 升级测试   通过GUI测试很简单，不作过多记录，各版本界面操作方式有所不同，具体参考Software Upgrade Test Utility。使用CLI方式简单记录下。 先使用scp将文件拷贝到SVC上，示例如下： # scp IBM2145_INSTALL_upgradetest_31.23 superuser@192.168.1.100:/upgrade/ superuser@10.8.254.60's password: IBM2145_INSTALL_upgradetest_31.23 100% 332KB 28.1MB/s 00:00 然后安装测试包： IBM_2145:SVC_Cluster:superuser>svctask applysoftware -file IBM2145_INSTALL_upgradetest_31.23 CMMVC6227I The package installed successfully. 运行测试示例（后面版本是升级测试目标版本）： IBM_2145:SVC_Cluster1:superuser>svcupgradetest -v 7.4.0.11 svcupgradetest version 31.23 Please wait, the test may take several minutes to complete. ******************* Warning found ******************* This upgrade introduces a new cache architecture. For the duration of the upgrade the cache will be disabled for the entire system, which may affect performance. Once this upgrade has completed the cache will be automatically re-enabled. This system-wide cache disable is only required when installing the new cache architecture for the first time. Subsequent upgrades will not disable the cache on the entire system. ... ******************* Warning found ******************* This system is exposed to APAR HU02213, which can cause warmstarts in a remote system during upgrade. Please see the following web page for details before continuing: https://www.ibm.com/support/pages/node/6356439 Results of running svcupgradetest: ================================== The tool has found 0 errors and 4 warnings. None of these issues will prevent the software upgrade from being started. Please review any warnings and errors to make sure it is safe to upgrade. 示例说明： 此次示例中发现0 errors，如果没有errors表示升级可以进行 此次示例中发现4 warnings，需要注意查看warnings说明，例如第一个就说会有新的缓存体系，升级会影响性能 SVC一般没有内置硬盘，如果有或者是V7000等设备有内置硬盘，硬盘微码版本过低或者有bug也会在此提示，先升级硬盘微码方可继续 升级操作 使用WEB GUI升级   GUI升级很简单，不作过多记录，各版本界面操作方式有所不同，具体参考Updating the software automatically using the CLI。使用CLI方式简单记录下。 使用自动更新 首先通过scp或pscp微码文件拷贝到系统中： # scp IBM2145_INSTALL_7.4.0.11 superuser@192.168.1.100:/upgrade/ 在之前的测试步骤通过后，运行命令执行升级： IBM_2145:SVC_Cluster:superuser>applysoftware -file IBM2145_INSTALL_7.4.0.11 如果是7.4.0之前的版本更新，使用如下CLI命令检查更新过程的状态： svcinfo lssoftwareupgradestatus 说明： 该命令显示inactive，表示更新完成 如果状态为stalled_non_redundant，继续进行其余的节点更新集可能会导致脱机卷 如果是7.4.0或更高版本进行更新，使用如下CLI命令以检查更新过程的状态： lsupdate 说明： 该命令显示success表示更新完成 如果状态为stalled_non_redundant，继续进行其余的节点更新集可能会导致脱机卷   如果从7.4.0之前的版本进行更新，则会收到状态消息system_completion_required。要完成更新过程，执行命令applysoftware -complete。运行该命令后，可以运行lsupdate来查看更新完成的进度。 验证是否成功   要验证更新是否成功完成，可以在GUI中查看，或者在系统中的每个节点执行lsnodevpdCLI命令。代码版本字段显示新的代码级别表示更新成功。 手动更新系统 个版本有所不一样，7.8版本官方参考文档：Updating the system manually 注意事项 注意事项说明如下： 注意根据官方Code Cross Reference来制定升级方案，版本跨度大可能需要中间版本作为跳板 升级前检查中如果有脱机的卷，并且fast_write_state为空，则卷可以处于脱机状态，在更新期间不会导致错误 在更新过程中任何节点遇到内存DIMM故障，立即停止并按照更新系统中的说明进行操作 部分版本升级会引入了新的缓存体系结构，集群缓存功能会被关闭，升级过程中可能会影响性能 节点更新之间有30分钟的延迟，延迟使主机多路径软件有时间重新发现到更新节点的路径 每个节点可能需要30多分钟进行系统自动更新 "},"03-IBM_Storage_System/10-SAN_Volume_Controller/06-SVC-系统性能.html":{"url":"03-IBM_Storage_System/10-SAN_Volume_Controller/06-SVC-系统性能.html","title":"SVC-系统性能","keywords":"","body":"SVC-系统性能 SVC性能   SVC性能相关统计文件，可以在收集日志中进行查看，也可以从配置节点上的/dumps/iostats目录中进行检索，拷贝示例如下： scp superuser@cluster_name:/dumps/iostats/* /tmp 性能相关命令参考： SVC 8.3.x startstats SVC 8.3.x lssystemstats SVC 8.3.x lsnodestats SVC性能相关字段 lsnodestats字段说明 命令lsnodestats输出部分字段说明： 字段值 描述 cpu_pc 显示用于系统的已分配CPU容量的百分比 fc_mb 显示系统上光纤通道流量每秒传输的总兆字节数。此值包括主机I/O和用于系统内通信的任何带宽 fc_io 显示系统上光纤通道流量每秒传输的总输入/输出(I/O)操作。此值包括主机I/O和用于系统内通信的任何带宽 write_cache_pc 显示节点的写入缓存使用百分比 total_cache_pc 显示节点的写入和读取缓存使用的总百分比 vdisk_mb 显示采样期间对卷的读取和写入操作每秒传输的平均兆字节数 vdisk_io 显示在采样期间每秒为卷读取和写入操作传输的平均I/O操作数 vdisk_ms 显示系统在采样期间响应对卷的读取和写入请求所需的平均时间量（以毫秒为单位） mdisk_mb 显示采样期间对MDisk的读取和写入操作每秒传输的平均兆字节数 mdisk_io 显示在采样期间每秒传输到MDisk的读取和写入操作的平均I/O操作数 mdisk_ms 显示系统在采样期间响应对MDisk的读取和写入请求所用的平均时间量（以毫秒为单位） vdisk_w_mb 显示采样期间对卷的读取和写入操作每秒传输的平均兆字节数 vdisk_w_io 显示在采样期间为写入卷的每秒传输的平均I/O操作数 vdisk_w_ms 显示系统在采样期间响应对卷的写入请求所需的平均时间量（以毫秒为单位） mdisk_w_mb 显示采样期间对MDisk的写操作每秒传输的平均兆字节数 mdisk_w_io 显示在采样期间为写入MDisk的操作每秒传输的平均I/O操作数 mdisk_w_ms 显示系统在采样期间响应对MDisk的写入请求所用的平均时间量（以毫秒为单位） vdisk_r_mb 显示采样期间对卷的读取操作每秒传输的平均兆字节数 vdisk_r_io 显示在采样期间每秒传输到卷的读取操作的平均I/O操作数 vdisk_r_ms 显示系统在采样期间响应对卷的读取请求所用的平均时间量（以毫秒为单位 mdisk_r_mb 显示在采样期间对MDisk的读取操作每秒传输的平均兆字节数 mdisk_r_io 显示在采样期间每秒传输到MDisk的读取操作的平均I/O操作数 mdisk_r_ms 显示系统在采样期间响应对MDisk的读取请求所用的平均时间量（以毫秒为单位） dumps/iostats文件中字段 节点的统计信息字段说明： 统计名称 描述 cluster_id 表示集群的名称 cluster 表示集群的名称 cpu busy- 表示自节点重置以来的总CPU平均核心繁忙毫秒数。该统计数据报告了处理器轮询、等待工作与做工作的时间量。该统计数据从零开始累积 comp- 表示自重置节点以来压缩进程核心的总CPU平均核心繁忙毫秒数 system- 表示自节点重置以来的总CPU平均核心繁忙毫秒数。该统计数据报告了处理器轮询、等待工作与做工作的时间量。该统计数据从零开始累积。该统计信息与该cpu busy统计信息提供的信息相同，并最终取代该cpu busy统计信息 cpu_core id- 表示CPU内核ID comp- 表示自节点重置以来压缩进程核心的每个核心 CPU 平均核心繁忙毫秒数 system- 表示自节点重置以来系统进程核心的每个核心 CPU 平均核心繁忙毫秒数 ID 表示节点的名称 node_id 指示节点的唯一标识符 rb 表示接收的字节数 re 表示累计接收延迟，不包括入站队列时间。此统计数据是节点通信层从I/O排队缓存到缓存为其完成所经历的延迟 ro 表示接收到的消息或批量数据的数量 rq 表示累计接收延迟，包括入站队列时间。这个统计数据是从命令到达节点通信层到缓存完成命令的延迟 wb 表示发送的字节数 we 表示累计发送延迟，不包括出站队列时间。该统计数据是从节点通信层向光纤通道发出消息到节点通信层收到消息到达通知的时间 wo 指示发送的消息或批量数据的数量 wq 表示累计发送延迟，包括出站队列时间。此统计数据包括发送数据的整个时间。该时间包括节点通信层收到消息并等待资源的时间，向远程节点发送消息的时间，以及远程节点响应的时间 各个节点的MDisk的统计信息部分字段说明： 统计名称 描述 ID 指示应用统计信息的MDisk的名称 idx 指示应用统计信息的MDisk的标识符 pre 指示每个MDisk的读取外部响应时间的峰值（以毫秒为单位）。磁盘读取的外部响应时间是通过在发出 SCSI 读取命令时启动计时器并在命令成功完成时停止来计算的 pro 指示每个MDisk的读取排队响应时间的峰值（以毫秒为单位）。该值表示读取命令从它们加入队列开始所花费的峰值经过时间 pwe 指示每个MDisk的写入外部响应时间峰值（以毫秒为单位）。磁盘写入的外部响应时间是通过在发出 SCSI 写入命令时启动计时器并在命令成功完成时停止来计算的 pwo 指示每个MDisk的写入队列响应时间的峰值（以毫秒为单位）。该值表示写入命令从它们加入队列开始所花费的峰值经过时间 rb 表示读取的数据块的累积数量（自节点开始运行以来） re 指示每个MDisk的累积读取外部响应时间（以毫秒为单位）。磁盘读取的累积响应时间是通过在发出SCSI读取命令时启动计时器并在命令成功完成时停止来计算的。经过时间被添加到累积计数器中 ro 指示已处理的MDisk读取操作的累积数量（因为节点正在运行） rq 指示每个MDisk的累积读取排队响应时间（以毫秒为单位）。此响应是从要发送到MDisk的命令队列上方测量的，因为队列深度已满。此计算包括读取命令从它们加入队列开始所用的时间 ure 指示每个MDisk的累积读取外部响应时间（以微秒为单位）。磁盘读取的累积响应时间是通过在发出 SCSI 读取命令时启动计时器并在命令成功完成时停止来计算的。经过时间被添加到累积计数器中 urq 指示每个MDisk的累积读取排队响应时间（以微秒为单位）。此响应是从要发送到MDisk的命令队列上方测量的，因为队列深度已满。此计算包括读取命令从它们加入队列开始所用的时间 uwe 指示每个MDisk的累积写入外部响应时间（以微秒为单位）。磁盘写入的累积响应时间是通过在发出 SCSI 写入命令时启动计时器并在命令成功完成时停止来计算的。经过时间被添加到累积计数器中 uwq 指示每个MDisk的累积写入排队响应时间（以微秒为单位）。此时间是从要发送到MDisk的命令队列上方测量的，因为队列深度已满。此计算包括写入命令从它们加入队列开始所用的时间 wb 表示写入的数据块的累积数量（自节点运行以来） we 指示每个MDisk的累积写入外部响应时间（以毫秒为单位）。磁盘写入的累积响应时间是通过在发出SCSI写入命令时启动计时器并在命令成功完成时停止来计算的。经过时间被添加到累积计数器中 wo 指示已处理的MDisk写入操作的累积数量（因为节点正在运行） wq 指示每个MDisk的累积写入排队响应时间（以毫秒为单位）。此时间是从要发送到MDisk的命令队列上方测量的，因为队列深度已满。此计算包括写入命令从它们加入队列开始所用的时间 单个节点的卷的统计信息部分字段说明： 字段值 描述 idx 应用统计信息的卷 rb 读取的数据块的累积数量(自节点运行以来) rl 每个卷的累积读取响应时间(单位ms)。卷读取的累积响应时间是通过在收到 SCSI 读取命令时启动计时器并在命令成功完成时停止来计算的，经过时间被添加到累积计数器中 rlw 自上次收集统计信息以来每个卷的最差读取响应时间(单位µs)。在每个统计收集样本之后，此值重置为零 ro 已处理的卷读取操作的累积数量(自节点开始运行以来) rxl 自上次重置节点以来每个卷的累积读取数据传输响应时间(单位ms)。此统计数据的高值表明延迟可能是由结构和/或主机提交的读取命令多于其处理能力引起的 ub 表示未映射的数据块的累积数量(因为节点正在运行) ul 每个卷的累积取消映射响应时间(单位ms)。卷取消映射的累积响应时间是通过在收到 SCSI 取消映射命令时启动计时器并在命令成功完成时停止来计算的。经过时间被添加到累积计数器中。 ulw 每个卷的最差取消映射响应时间(单位µs)。卷取消映射的最差响应时间是通过在收到 SCSI 取消映射命令时启动计时器并在命令成功完成时停止来计算的 uo 已处理的卷取消映射操作的累积数量(自节点开始运行以来) uou 未在8 K边界上对齐的卷取消映射操作的累积数量 wb 写入的数据块的累积数量(自节点运行以来) wl 每个卷的累积写入响应时间(以毫秒为单位)。卷写入的累积响应时间是通过在收到 SCSI 写入命令时启动计时器并在命令成功完成时停止来计算的。经过时间被添加到累积计数器中 wlw 自上次收集统计信息以来每个卷的最差写入响应时间(单位µs)。在每个统计收集样本之后，此值重置为零 wo 已处理的卷写入操作的累积数量(因为节点正在运行) wou 未在 4 K 边界上对齐的卷写入操作的累积数量。 wxl 自上次重置节点以来每个卷的累积写入数据传输响应时间(单位ms)。此统计数据的高值表示延迟可能是由于节点请求数据写入卷时结构和/或主机响应缓慢造成的。 xl 自上次重置节点以来每个卷的累积读取和写入数据传输响应时间(单位ms) 每个节点的卷缓存的统计部分字段说明： 字段值 描述 cm 缓存中保存的已修改或脏数据的扇区数 ctd 由于卷缓存刷新或降级操作而被启动写入、提交给其他组件的缓存降级总数 ctds 为cache-initiated的磁道写入而写入的扇区总数 ctp 由cache-initiated的前置读取的磁道阶段数 ctps 缓存启动的暂存扇区的总数 ctrh 对前置或非前置数据的总磁道读取缓存命中数。例如，跨越两个磁道的单个读取，其中只有一个磁道获得了总缓存命中，计为一个磁道读取缓存命中 ctrhp 从其他组件接收到的磁道读取数，这些数据被视为对任何预留数据的缓存命中 ctrhps 为从其他组件接收到的读取而读取的扇区总数，这些组件在任何预留数据上获得缓存命中。 ctrhs 为从其他组件接收到的读取而读取的扇区总数，这些组件在前置或非前置数据上获得了总缓存命中 ctr 接收到的磁道读取总数。例如，如果单次读取跨越两个磁道，则将其计为两次总磁道读取 crts 为接收到的读取而读取的扇区总数 ctwft 从其他组件接收并以flush-through写入模式刷新处理的磁道写入数 ctwfts 从其他组件接收并以fflush-through写入模式刷新的写入而写入的扇区总数 ctwfw 从其他组件接收并在fast-write模式下处理的磁道写入数 ctwfwsh 由于内存不足，以write-through模式写入的磁道以fast-write模式写入 ctwfwshs 由于内存不足，直接写入的磁道以fast-write模式写入 ctwfws 从其他组件接收并以fast-write模式处理的写入而写入的扇区总数 ctwh 从其他组件接收到的磁道写入次数，其中磁道中的每个扇区都对缓存中的已脏数据进行了写命中。要将写入计为总缓存命中，整个磁道写入数据必须已在写入缓存中标记为脏 ctwhs 从其他组件接收到的扇区总数，其中磁道中的每个扇区都对缓存中的已脏数据进行了写入命中 ctw 接收到的磁道写入总数。例如，如果一次写入跨越两个磁道，则将其计为两次总磁道写入 ctws 从组件接收到的写入而写入的扇区总数 ctwwt 从其他组件接收并在write-through模式下处理的磁道写入数 ctwwts 为从其他组件接收并在write-through模式下处理的写入而写入的扇区总数 cv 表示缓存中保存的读写缓存数据的扇区数 卷和卷副本的缓存统计信息部分字段说明： 字段值 描述 ri 读ios，累积数据 wi 写ios，累积数据 r 读未命中的扇区，累积数据 rh 读命中的扇区，累积数据 ft flush_through 写入的扇区，累积数据 fw fast_write写入的扇区，累积数据 wt write_through写入的扇区，累积数据 wh 写命中的扇区，累积数据 m 修改数据的扇区，快照非累积数据 v 读和写缓存数据，快照非累积数据 d destages dav destage延迟平均值，单位µs，非累积值 dcn destage计数，累积数据 sav stage延迟平均值，单位µs，非累积值 scn stage计数，累积数据 pp 固定百分比 tav 数据传输延迟平均值，单位µs，非累积值 teav 跟踪锁定延迟(不包括)平均值，单位µs，非累积值 tsav 跟踪锁定延迟(共享)平均值，单位µs，非累积值 各个节点的高速镜像和全局镜像关系中的卷的统计信息字段说明： 统计名称 描述 gwl 主VDisk：此统计数据累积主写入延迟，即主全局镜像写入完成后，直到在辅助集群中接收和硬化数据并且通知已发送回主集群并由主集群接收所用的时间. 一个操作的平均值可以通过除以gwl（gws采样周期内的全局镜像写入次数）得到。运行时，gwl/的值gws大约是恢复点目标 (RPO)。当关系停止时，此计算不起作用。 辅助VDisk：此统计数据累积辅助写入延迟，即辅助集群上收到写入后提交写入磁盘所用的时间。 一个操作的平均值可以通过除以gwl（gws采样周期内的全局镜像写入次数）得到 gwo 指示重叠卷写入的总数。重叠写入是指写入请求的逻辑块地址 (LBA) 范围与对同一 LBA 范围的另一个未完成的请求发生冲突，并且该写入请求对于辅助站点仍然未完成 gwot 指示固定或不固定重叠写入的总数。当所有集群中的所有节点都处于系统版本 4.3.1 时，此统计信息记录了主节点上全局镜像功能接收到的写入 I/O 请求的总数重叠。当任一集群中的任何节点运行早于 4.3.1 的系统版本时，此值不会增加 gws 指示向辅助站点发出的写入请求总数 节点端口的统计信息部分字段说明： 统计名称 描述 bbcz 指示缓冲区信用计数器为零的总时间（以微秒为单位）。该统计信息仅由 8 Gbps 光纤通道端口报告。对于其他端口类型，此统计数据为0 cbr 表示从控制器接收的字节 cbt 指示传输到磁盘控制器的字节数 cer 指示从磁盘控制器接收的命令。注意：cer指标始终为 0 cet 指示向磁盘控制器发起的命令 dtdc 指示经历过数据传输延迟的传输次数 dtdm 表示已测量其数据传输延迟的传输次数 dtdt 指示数据传输过度延迟的总时间（以微秒为单位） har 指示在数据传输过程中中止主机读取操作的计数。此计数包括主机中止的I/O操作，以及系统内部中止的操作 haw 指示在数据传输过程中中止主机写入操作的计数。此计数包括主机中止的I/O操作，以及系统内部中止的操作 hbr 表示从主机接收的字节数 hbt 指示传输到主机的字节数 her 表示从主机接收的命令 het 指示向主机发起的命令。注意：het指标始终为0 hsr 指示对于主机读取操作而言被认为较慢的数据传输计数 hsw 指示对于主机写入操作而言被认为较慢的数据传输计数 icrc 表示无效的CRC数 id 指示节点的端口标识符 itw 表示无效的传输字数 lf 指示链路故障计数 lnbr 指示接收到同一集群中其他节点的字节数 lnbt 表示传输到同一集群中其他节点的字节数 lner 表示从同一个集群中的其他节点接收到的命令 lnet 表示向同一个集群中的其他节点发起的命令 lsi 指示信号丢失计数 lsy 指示同步丢失计数 pspe 表示原始序列协议错误计数 rmbr 指示接收到其他集群中其他节点的字节数 rmbt 指示传输到其他集群中其他节点的字节数 rmer 表示从其他集群中的其他节点接收到的命令 rmet 指示向其他集群中的其他节点发起的命令 wwpn 指示节点的全局端口名称 更多性能统计名称参考官方文档：SVC Starting statistics collection 池性能 池性能注意事项 Pool performance注意事项： 不要在一个池中混用same-tier或具有不同性能特征的MDisk。这种技术是确保从池中创建的卷具有一致的性能特征的唯一方法 允许在一个池中使用不同层的阵列，因为它们的性能差异将通过使用Easy Tier功能变得有利 如果需要将特定工作负载隔离到单独的存储中，请创建多个存储池 确保针对选定的池类型和功能集完成了性能调整 池和缓存的关系   系统使用缓存分区来限制性能不佳的存储控制器可能对集群系统产生的潜在负面影响。缓存分区分配大小基于配置的存储池的数量。此设计可防止单个过载的后端存储系统填充系统写入缓存并降低其他存储池的性能。下表是单个存储池可以使用的write-cache数据限制： 存储池数量 上限 1 100% 2 66% 3 40% 4 30% 5或更多 25% 性能影响： 只有针对受影响存储池的写入受到限制。对受限制池的读取I/O请求继续正常处理。但是由于系统后端存储可以维持的最大速率卸载缓存数据，因此预计读取响应时间会受到影响 发往其他（非限制）存储池的所有I/O将照常继续 "},"03-IBM_Storage_System/10-SAN_Volume_Controller/07-SVC-池_mdisk_卷.html":{"url":"03-IBM_Storage_System/10-SAN_Volume_Controller/07-SVC-池_mdisk_卷.html","title":"SVC-池mdisk卷","keywords":"","body":"SVC-池mdisk卷 Pool Mdisk Volume Image mode volumes   Image mode volumes映像方式卷是与一个MDisk有直接关系的特殊卷。Image模式通过使用虚拟化提供从MDisk到卷的直接逐块转换。最常见的用例是将数据从旧的（通常是非虚拟化的）存储迁移到基于SVC的虚拟化基础架构。此模式是为了满足以下主要使用场景: 映像模式支持对已包含直接写入而非通过SVC写入的数据的MDisk进行虚拟化。相反，它是由直接连接的主机创建的 此模式使客户端能够以最短的停机时间将SVC插入现有存储卷或LUN的数据路径 映像模式使由SVC管理的卷能够与底层RAID控制器提供的本机复制服务功能一起使用。为避免在以这种方式使用 SVC时丢失数据完整性，禁用卷的 SVC缓存非常重要 SVC提供迁移到映像模式的能力，这使SVC能够导出卷并直接从路径中没有SVC的主机访问它们 官方参考链接：SVC Image mode volumes 待补充 "},"03-IBM_Storage_System/10-SAN_Volume_Controller/20-SVC-简单脚本.html":{"url":"03-IBM_Storage_System/10-SAN_Volume_Controller/20-SVC-简单脚本.html","title":"SVC-简单脚本","keywords":"","body":"SVC-简单脚本 记录一些简单实用的脚本。 host相关 找出node logged in count为单数的host   SVC中可能会有很多hosts，并且如果是PowerVC自动化部署的hosts，状态都会在SVC上显示降级，如果hosts非常多，就很难找出哪些hosts的node_logged_in_count为单数，通过图形界面需要一个个查看属性，命令行中7.8微码版本也没找到比较直观列出来的命令。 脚本说明： 测试SVC版本是V7.8版本，此版本中没有awk或gawk命令，主要通过sed实现 直接把脚本贴在命令行运行即可，输出的内容复制到一个csv文件，然后通过excel格式优化即可 脚本只用到了lshost命令，不需要superuser等高权限用户，命令参考：V7000 7.8 lshost 脚本中第一列是host name，第二列是WWPN，第三列是此WWPN的node_logged_in_count，后面是第二列第三列的循环，根据自己的一个host WWPN多少去自定义多少，或者手动在csv里面加入也行 脚本中过滤掉了node_logged_in_count为0的WWPN，只列出了单数的，例如1，3，只要有单数的，host就会被列出来，具体哪个WWPN是单数也很直观看出来 脚本内容： echo 'Host Name,WWPN,node_logged_in_count,WWPN,node_logged_in_count,\\ WWPN,node_logged_in_count,WWPN,node_logged_in_count,' for id in `lshost -nohdr -delim : -filtervalue status=degraded |\\ sed 's/:.*//g'` do for count in `lshost $id |\\ sed -n 's/node_logged_in_count //p' |sed -n '/0/!p'|uniq` do if [ $(($count%2)) -ne 0 ] then lshost -delim , $id |\\ sed -n '/^name\\|^WWPN\\|^node_/p'|\\ sed '/^WWPN/{N;s/\\n/,/}'|\\ sed -n '/node_logged_in_count,0/!p'|\\ sed 's/name,//;s/WWPN,//;s/node_logged_in_count,//'|\\ tr '\\n' ',' echo fi done done 输出示例： Host Name,WWPN,node_logged_in_count,WWPN,node_logged_in_count,WWPN,node_logged_in_count,WWPN,node_logged_in_count, DB-c99d1-63771951,C050760872FB00CD,1,C050760871FC00AC,1,C050760872EC00DA,1,C050760872FA00A1,1, DB-6350d-18064883,C0507608CDF4002A,1,C0507608CDE4001B,1,C0507608CDB1008A,1,C0507608CDD10076,1, 卷相关 vdisk中镜像在同一个池的卷   如果vdisk的镜像分布在同一个池，那么意义就不大，一般建议在不同的池，池的外部存储器也不是同一个。 脚本说明： 测试SVC版本是V7.8版本，此版本中没有awk或gawk命令，主要通过sed实现 直接把脚本贴在命令行运行即可，输出的内容复制到一个csv文件，然后通过excel格式优化即可 脚本只用到了lsvdisk命令，不需要superuser等高权限用户 首选筛选了copy_count为2的卷ID: lsvdisk -nohdr -delim : -filtervalue copy_count=2 lsvdisk -nohdr -delim : -filtervalue copy_count=2 |sed 's/:.*//g' 通过查找匹配，如果去重后删除第一行为空，说明镜像在同一个池： lsvdisk -delim , 2 |sed -n '/^mdisk_grp_id/p' lsvdisk -delim , 2 |sed -n '/^mdisk_grp_id/p'|sed '1d' lsvdisk -delim , 2 |sed -n '/^mdisk_grp_id/p'|sed '1d'|uniq lsvdisk -delim , 2 |sed -n '/^mdisk_grp_id/p'|sed '1d'|uniq|sed '1d' 判断卷name是否一致的脚本： for id in `lsvdisk -nohdr -delim : -filtervalue copy_count=2 |\\ sed 's/:.*//g'` do result=`lsvdisk -delim , $id |sed -n '/^mdisk_grp_id/p'|\\ sed '1d'|uniq|sed '1d'` if [ -z $result ] then lsvdisk -delim , $id|\\ sed -n '/^name\\|^capacity\\|^mdisk_grp_name/p' fi done 或者判断mdisk_grp_name,many这项的值是不是many： for id in `lsvdisk -nohdr -delim : -filtervalue copy_count=2 |\\ sed 's/:.*//g'` do result=`lsvdisk -delim , $id |\\ sed -n '/^mdisk_grp_name,many/p'` if [ -z $result ] then lsvdisk -delim , $id|\\ sed -n '/^name\\|^capacity\\|^mdisk_grp_name/p' fi done 查找未映射给主机的卷 首先列所有的卷ID: lsvdisk -nohdr -delim :|sed 's/:.*//g' 判断条件看下面命令是否有输出： result=`lsvdiskhostmap 2` 脚本如下： for id in `lsvdisk -nohdr -delim :|sed 's/:.*//g'` do result=`lsvdiskhostmap $id` if [ -z \"$result\" ] then lsvdisk -nohdr -delim , -filtervalue volume_id=$id fi done 待补充 "},"04-IBM_Virtualization/":{"url":"04-IBM_Virtualization/","title":"IBM_Virtualization","keywords":"","body":"IBM_Virtualization 简介   虚拟化（Virtualization）技术最早出现在20世纪60年代的IBM大型机系统，在70年代的System370系列中逐渐流行起来。随着近年多核系统、集群、网格甚至云计算的广泛部署，虚拟化技术在商业应用上的优势日益体现，不仅降低了 IT 成本，而且还增强了系统安全性和可靠性，虚拟化的概念也逐渐深入到人们日常的工作与生活中。 IBM支持 7*24小时呼叫中心：400-810-1818转5004 IBM 用户支持中心：产品下载和更新、打开和查看案例、产品通知以及支持指南，官方连接： IBM 支持团队 在线支持指南： 高效快速获得IBM售后技术支持 内容 PowerVC PowerVM "},"04-IBM_Virtualization/01-PowerVC/":{"url":"04-IBM_Virtualization/01-PowerVC/","title":"PowerVC","keywords":"","body":"PowerVC 简介   IBM® PowerVC™ Virtualization Center 是一款高级虚拟化和云管理解决方案。该产品基于 OpenStack 构建而成，可针对运行在 IBM Power Systems™ 上面的 IBM AIX®、IBM i 及 Linux 虚拟机 (VM) 提供简单的虚拟化管理和云部署支持。该产品旨在提高管理员的工作效率，简化云管理，支持快速在 Power Systems 服务器上部署虚拟机。PowerVC 为 Power Systems 可扩展的云管理奠定了基础，包括集成到基于 OpenStack 技术的更高级的云编排平台上。 官方介绍网站：IBM PowerVC官网 内容 PowerVC-安装 "},"04-IBM_Virtualization/01-PowerVC/01-PowerVC-安装.html":{"url":"04-IBM_Virtualization/01-PowerVC/01-PowerVC-安装.html","title":"PowerVC-安装","keywords":"","body":"PowerVC-安装 PowerVC支持得系统不多，主要是RedHat和SUSE。但是当前还不支持RHEL 8。RHEL 7.6 ALT支持PowerVC SDI版本1.4.4和1.4.4.1。 RedHat安装PowerVC 系统环境：Red Hat Enterprise Linux 7.8 64 位 安装包准备 需要准备得安装包如下： 系统安装包：rhel-server-7.8-x86_64-dvd.iso PowerVM安装包：powervc-install-x86-rhel-1.4.4.0.tgz 如果系统中没有Python3，需要准备Python3安装包 Python依赖包，打包名字：redhat_relevant for PowerVC.tar 检查系统环境 查看yum： [root@redhat ~]# rpm -qa |grep yum yum-rhn-plugin-2.0.1-10.el7.noarch yum-metadata-parser-1.1.4-10.el7.x86_64 yum-3.4.3-167.el7.noarch 查看yum源： [root@redhat PowerVC]# yum repolist Loaded plugins: product-id, search-disabled-repos, subscription-manager This system is not registered with an entitlement server. You can use subscription-manager to register. repolist: 0 提示没有注册，并且没有，后面进行配置。 检查是否安装Python [root@redhat ~]# python Python 2.7.5 (default, Sep 26 2019, 13:23:47) [GCC 4.8.5 20150623 (Red Hat 4.8.5-39)] on linux2 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> 系统配置 网络配置 PowerVC使用默认的网络接口：eth0。要使用其他网络接口HOST_INTERFACE，请在运行安装脚本之前设置环境变量。例如： export HOST_INTERFACE=eth1。 我得虚拟机是ens160，修改查看如下： [root@redhat ~]# export HOST_INTERFACE=ens160 [root@redhat ~]# env 查看hostname，并且在/etc/hosts中添加目前IP和hostname： [root@redhat PowerVC]# cat /etc/hostname redhat [root@redhat PowerVC]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.18.130 redhat 配置本地yum源 对于RedHat Enterprise Linux 7，安装PowerVC的一些先决条件已从OS介质移至使用RHN连接访问的Optional Software通道。所以我们配置个本地yum源。 #创建镜像挂载点 [root@redhat PowerVC]# mkdir -p /mnt/cdrom #挂载镜像 [root@redhat PowerVC]# mount /dev/cdrom /mnt/cdrom mount: /dev/sr0 is write-protected, mounting read-only #在/etc/yum.repos.d目录下建一个文件redhat7.repo [root@redhat yum.repos.d]# touch /etc/yum.repos.d/redhat7.repo [root@redhat yum.repos.d]# ls redhat7.repo redhat.repo redhat7.repo中写入如下内容： [local] name=Red Hat Enterprise Linux 6.8 baseurl=file:///mnt/cdrom enabled=1 gpgcheck=1 gpgkey=file:///mnt//cdrom/RPM-GPG-KEY-redhat-release 再次运行yum repolist进行验证： [root@redhat yum.repos.d]# yum repolist Loaded plugins: product-id, search-disabled-repos, subscription-manager This system is not registered with an entitlement server. You can use subscription-manager to register. local | 2.8 kB 00:00:00 (1/2): local/group_gz | 95 kB 00:00:00 (2/2): local/primary | 2.1 MB 00:00:00 local 5231/5231 repo id repo name status local Red Hat Enterprise Linux 6.8 5,231 repolist: 5,231 安装net.tool 我这个版本必须安装，输入如下命令安装： [root@redhat powervc-1.4.4.0]# yum install net-tools 安装依赖包 此依赖包官方统称：Red Hat Enterprise Linux packages relevant to PowerVC 共包含：python-zope-interface；python-jinja2；python-pyasn1-modules；python-webob；python-webtest；python-libguestfs；SOAPpy；pyserial；python-fpconst；python-twisted-core；python-twisted-web 看名字和Python有关，进入到存放依赖包的目录，文件名：redhat_relevant for PowerVC.tar [root@redhat PowerVC]# tar -xvf 'redhat_relevant for PowerVC.tar' 解压后进入生成的目录，安装所有的包，运行脚本开始安装： [root@redhat redhat_relevant_for_PowerVC]# ./install.sh 安装PowerVC 进入到存放PowerVC安装包的目录，我直接传过来文件是tar文件：powervc-install-x86-rhel-1.4.4.0.tar 将文件进行解压 [root@redhat PowerVC]# tar -xvf powervc-install-x86-rhel-1.4.4.0.tar 解压后生成目录：powervc-1.4.4.0，进入到此目录进行安装： [root@redhat powervc-1.4.4.0]# ls cloud install lib locale RPM-GPG-KEY-PowerVC gpfs lap license packages version.properties [root@redhat powervc-1.4.4.0]# ./install ################################################################################ Starting the IBM PowerVC 1.4.4.0 installation on: 2020-07-18T21:20:13-04:00 ################################################################################ Select the edition to install: 1 - IBM PowerVC Standard 2 - IBM Cloud PowerVC Manager 9 - Exit 根据安装需求选择安装类型，中途提示license的回复1同意即可，防火墙提示根据需求选择。 等待安装大约十几分钟，报错了，因为内存不够进程被killed了，官方最低要求是10G的交换空间，看来笔记本的虚拟机扛不住，不过方法应该没错。 ./install: line 929: 29414 Killed /usr/sbin/semanage permissive -d $domai nFailed to restore security context. See install log for details. "},"04-IBM_Virtualization/02-PowerVM/":{"url":"04-IBM_Virtualization/02-PowerVM/","title":"PowerVM","keywords":"","body":"IBM_PowerVM 简介   PowerVM 依托 Power Systems™ 平台的高级 RAS 功能和领先性能，能够为 AIX、IBM i 及 Linux 应用提供安全的、可扩展的服务器虚拟化环境。 PowerVM架构下主要有Virtual I/O Server和Virtual I/O Client。 Virtual I/O Server简称VIOS，即I/O虚拟服务分区，底层是AIX系统；Virtual I/O Client简称VIOC，即虚拟分区，可以是AIX、IBM i 及 Linux。 官方网站：IBM PowerVM 内容 PowerVM-数据收集 PowerVM-VIOS常用命令 PowerVM-常见问题 "},"04-IBM_Virtualization/02-PowerVM/01-PowerVM-数据收集.html":{"url":"04-IBM_Virtualization/02-PowerVM/01-PowerVM-数据收集.html","title":"PowerVM-数据收集","keywords":"","body":"PowerVM-数据收集 硬件故障 PowerVM是Power小型机平台上产品，VIOS也是一个系统，出现硬件故障就是Power小型机硬件故障，在非操作系统层面需要收集的日志可以参照：Power-小型机数据收集 PowerVM问题 如果虚拟I/O的问题，一般是PowerVM配置或者设备参数问题，需要结合VIOS和VIOC来判断问题。 VIOS上收集 收集snap 用padmin用户登录VIOS，输入命令snap收集snap，不需要加参数，在/home/padmin目录下生成的snap.pax.Z文件，拷贝出来即可。 收集映射关系 收集vscsi、NPIV和网络映射关系，依次运行如下命令，通过终端日志功能记录下来： $lsmap -all $lsmap -all -npiv $lsmap -all -net 将终端记录的日志拷贝下来。 VIOC上收集 用root用户登录到VIOC，依次运行： snap -r snap -ac 在/tmp/ibmsupr目录下生成的snap.pax.Z文件，拷贝出来即可。 HMC上收集 在HMC上同样也可以收集vscsi、NPIV和网络映射关系，用hscroot用户登录到HMC，依次运行如下命令，通过终端日志功能记录下来： # lshwres -r virtualio -m --rsubtype scsi --level lpar # lshwres -r virtualio -m --rsubtype fc --level lpar # lshwres -r virtualio -m --rsubtype eth --level lpar "},"04-IBM_Virtualization/02-PowerVM/02-PowerVM-VIOS常用命令.html":{"url":"04-IBM_Virtualization/02-PowerVM/02-PowerVM-VIOS常用命令.html","title":"PowerVM-VIOS常用命令","keywords":"","body":"PowerVM-VIOS常用命令 VIOS系统中常用的命令。 AIX命令   可以VIOS底层是AIX系统，VIOS 2版本使用的是AIX6.1，VIOS 3版本开始使用的是AIX7.2，各版本命令基本一致。用padmin用户登录到VIOS后，可以使用命令：oem_setup_env切换到AIX root用户，o开头的命令使用的很少，个人一般使用r o进行切换，切换不了就输入完整命令，AIX层面的命令可以参考:AIX-常用命令 VIOS命令   默认使用padmin用户登录，VIOS相关命令只能在padmin用户下执行，有一些命令在AIX环境下可以执行的在VIOS里面也可以执行，有一些不行，不行就切换一下。下面介绍命令都是只在VIOS中的（有些一样但是输出不一样，例如lspath），记下来方便查阅。 基础查看类 命令 用途 ioslevel 查看vios版本 shutdown -restart 重启VIOS license -accept 同意license oem_setup_env 切换到AIX root cfgdev 扫描识别新设备 errlog 查看报错信息 lspath 查看磁盘路径 lsrep 查看镜像对应的vtopt lsvopt 查看vtopt对应的镜像 lsvg -pv rootvg 查看rootvg pv情况 lsvg -lv rootvg 查看rootvg lv情况 lsmap -all 查看vscsi映射关系 lsmap -all -npiv 查看npiv映射关系 lsmap -all -net 查看网络关系 lsmap ‑vadapter 查看某个vhost映射 lsdev ‑dev 查看设备(hdisk,vhost) lsdev ‑dev ‑attr 查看设备指定属性 entstat -all |grep Active 查看SEA状态 属性修改 有些命令有点长，换个方式，命令加示例结合。 修改设备属性，例如修改hdisk的queue_depth： $ chdev ‑dev hdisk2 ‑attr queue_depth=20 永久修改设备属性，例如hdisk2的reserve_policy属性： $ chdev -dev hdisk2 -attr reserve_policy=no_reserve -perm vtopt操作 创建VMLibrary，例如在rootvg下创建一个10G的： $ mkrep -sp rootvg -size 10G 查看VMLibrary： $ lsrep 删除VMLibrary： $ rmrep -f 创建vtopt，例如在vhost0上创建： $ mkvdev -fbo -vadapter vhost0 将镜像加载到vtopt,例如AIX7231.iso加载到vtopt0： $ loadopt -disk AIX7231.iso -vtd vtopt0 将镜像从vtopt上卸载,例如卸载vtopt0上的镜像： $ unloadopt -vtd vtopt0 基础配置 创建vscsi映射关系： $ mkvdev -vdev -vadapter -dev 创建NPIV映射关系： $ vfcmap -vadapter -fcp 创建SEA: $ mkvdev -sea -vadapter -default -defaultid -attr ha_mode=auto ctl_chan= 取消NPIV映射关系： $ vfcmap -vadapter -fcp 取消vscsi映射关系： $ rmvdev -vtd SEA切换命令 有时候由于一些原因需要手动切换SEA。手动切换一种方式就是更改SEA网卡属性，先在每个vios上查看状态： $ entstat -all |grep Active 在Active状态值为True的vios中输入如下命令进行切换： $ chdev -dev -attr ha_mode=standby 当维护结束需要恢复时候的时候修改属性回auto： $ chdev -dev -attr ha_mode=auto 系统升级 $ updateios -accept -install -dev 配置备份viosbr命令   可以在root权限下使用mksysb或者克隆操作进行备份整个系统，也可以使用viosbr命令，用途：对Virtual I/O Server (VIOS)执行备份虚拟和逻辑配置、列出配置以及复原配置等操作。 viosbr命令示例 viosbr命令使用示例示例： $ viosbr -backup -file /tmp/vios_backup_190101 会在/tmp目录下生成名为vios_backup_190101.tar.gz的备份文件。 查看备份文中的所有内容： $ viosbr -view -file /tmp/vios_backup_190101 仅查看物理磁盘信息： $ viosbr -view -file /tmp/vios_backup_190101 -type pv 复原所有可能的设备并显示关于已部署和未部署设备的摘要： $ viosbr -restore -file /tmp/vios_backup_190101 要每天备份VIOS中的所有设备属性和虚拟设备映射，并保留最后5个备份文件： $ viosbr -backup -file mybackup -frequency daily -numfiles 5 生成的备份文件位于home/padmin/cfgbackups下 其它说明 官方文档链接：viosbr 命令 说明： viosbr 命令不会备份适配器或驱动程序的父设备、设备驱动程序、虚拟串行适配器、虚拟终端设备、内核扩展、因特网网络扩展 (inet0)、虚拟 I/O 总线、处理器、内存或高速缓存 其它命令 更多命令可参考官方文档：Virtual I/O Server and Integrated Virtualization Manager commands listed alphabetically "},"04-IBM_Virtualization/02-PowerVM/03-PowerVM-常见问题.html":{"url":"04-IBM_Virtualization/02-PowerVM/03-PowerVM-常见问题.html","title":"PowerVM-常见问题","keywords":"","body":"PowerVM-常见问题 VIOS系统中常见问题。 HMC连接问题 HMC查看虚拟网络报错 报错示例一 报错示例： \"Error occurred while querying for SharedEthernetAdapter from VIOS with ID - Unable to connect to Database.\" 官方描述：HMC Enhanced GUI-\"Error occurred while querying for SharedEthernetAdapter... Unable to connect to Database\" 报错示例二 报错示例： Error occurred while querying for SharedEthernetAdapter from VIOS with ID in System - The system is currently too busy to complete the specified request. Please retry the operation at a later time. If the operation continues to fail, check the error log to see if the filesystem is full. 官方说明：HMC Enhanced GUI - \"Error occurred while querying for SharedEthernetAdapter...The system is currently too busy to complete the specified request.\" 查看存储池报错 报错示例： \"Cannot connect to one or more Virtual I/O Servers. Virtual I/O Server Error Details Error occurred while querying for VirtualMediaRepository from VIOS with ID - Unable to connect to Database.\" 官方描述：HMC Enhanced GUI - \"Error occurred while querying for VirtualMediaRepository from VIOS... Unable to connect to Database.\" 解决方法 官方针对以上问题的解决方案：When Using HMC GUI you see message \"Unable to connect to the Database Error occurred \" VIOS升级问题 root用户被删 通过updateios命令进行VIOS升级失败，出现类似以下错误： sysck: 3001-037 The name root is not a known user for file /usr/bin/rm_mlcache_file. sysck: 3001-003 A value must be specified for owner for entry /usr/bin/rm_mlcache_file.   原因是root用户被删除了，可以尝试手动重新创建root用户，并确保所有用户属性都与运行中的VIOS的root用户相匹配。 或者从备份系统进行恢复。 官方说明：updateios errors \"sysck: 3001-037 The name root is not a known user for file\" ntp.conf can not be a link   更新VIOS时出现“ sysck：3001-017”错误，可能是由于文件ntp.conf是“链接”而不是“文件”引起的。 updateios和alt_root_vg都将报告错误。 报错示例如下： sysck: 3001-017 Errors were detected validating the files for package ios.cli.rte. 0503-464 installp: The installation has FAILED for the \"usr\" part of the following filesets: ios.cli.rte 6.1.x.yyy ios.cli.rte 6.1.x.yyy USR APPLY FAILED ios.cli.rte 6.1.x.yyy USR CLEANUP SUCCESS 确认方式： $ ls -ld /home/padmin/config/ntp.conf lrwxrwxrwx 1 root system 13 Nov 17 2014 /home/padmin/config/ntp.conf -> /etc/ntp.conf 解决方法：创建\"/home/padmin/config/ntp.conf\"文件作为\"file\"而不是动态\"link\". # mv /home/padmin/config/ntp.conf /home/padmin/config/ntp.conf_link 或者 # rm /home/padmin/config/ntp.conf # cp /etc/ntp.conf /home/padmin/config/ntp.conf # chmod 760 /home/padmin/config/ntp.conf # chown root:staff /home/padmin/config/ntp.conf 查看： $ ls -ld /home/padmin/config/ntp.conf -rwxrw---- 1 root staff 630 mmm dd yyyy /home/padmin/config/ntp.conf 升级或克隆方法： $ updateios -dev -accept -install $ alt_root_vg -bundle update_all -location -target 官方说明：VIO updateios reports sysck 3001-017. File ntp.conf can not be a link. 待补充 "},"05-IBM_Operating_System/":{"url":"05-IBM_Operating_System/","title":"IBM_Operating_System","keywords":"","body":"IBM_Operating_System 简介   IBM 操作系统运根据硬件架构运行在不通的设备上，Linux for Power（如RedHat和SUSE）、AIX和AS/400可以运行在IBM Power系列小型机上，z/OS运行在IBM Z系列大型机上。 关于Power上操作系统介绍官网：IBM 操作系统 IBM系统支持 7*24小时呼叫中心：400-810-1818转5004 IBM 用户支持中心：产品下载和更新、打开和查看案例、产品通知以及支持指南，官方连接： IBM 支持团队 在线支持指南： 高效快速获得IBM售后技术支持 内容 AIX AS400 RedHat "},"05-IBM_Operating_System/01-AIX/":{"url":"05-IBM_Operating_System/01-AIX/","title":"AIX","keywords":"","body":"AIX 简介 IBM 为 IBM Power 体系架构开发的一种基于开放标准的 UNIX 操作系统，具备安全性、可扩展性和稳健性。 AIX官方主页：https://www.ibm.com/cn-zh/it-infrastructure/power/os/aix AIX产品文档：https://www.ibm.com/support/knowledgecenter/ssw_aix 内容 AIX-数据收集 AIX-常用命令 AIX-用户策略 AIX-HA常用操作 AIX-NIMserver AIX-TCPIP-配置IPv6 AIX-磁盘多路径 AIX-网络与通信 AIX-系统管理 "},"05-IBM_Operating_System/01-AIX/01-AIX-数据收集及分析.html":{"url":"05-IBM_Operating_System/01-AIX/01-AIX-数据收集及分析.html","title":"AIX-数据收集及分析","keywords":"","body":"AIX-数据收集及查看 硬件类   gawk自定义变量可以是任意数目的字母、数字和下划线，但是不能以数字开头，并且区分大小写。 AIX系统安装在Power系列小型机上，硬件故障大多数也会记录在操作系统日志里面，一般情况下运行snap -gc收集可以了。如果没有HMC管理，AIX系统日志可以进行硬件故障判断，有些情况下需要二者结合。 硬件类型日志收集具体可以参考：Power-小型机数据收集 系统日志收集 命令snap是AIX系统中收集系统信息和配置最常用的命令。 最常用的就是snap -gc，其中参数-c是打包压缩成.Z文件， 收集需要条件： 需要root用户执行 需要ftp服务器传输出日志 确保文件系统/tmp有足够的空间（snap -ac可能会很大，dump经常几个G） 收集方法以snap -gc为例如下： root用户登录到系统 运行snap -r清除之前收集的日志 运行snap -gc进行收集 在/tmp/ibmsupt目录下将snap.pax.Z文件拷贝出来 常用其它收集参数如下： -a：收集全部信息并压缩打包（包括dump，但是不包括PowerHA信息） -D：收集DUMP信息 -f：收集文件系统信息 -e：收集PowerHA信息 -k：收集内核信息 -n：收集NFS信息 -L：收集LVM信息 -t：收集网络相关信息 命令snap更多用法可以参照官方介绍：AIX snap命令介绍 多路径软件数据收集 连接外接存储并且使用多路径，当出现路径问题时候，需要收集多路径软件相关信息。 收集命令输出即可，常用AIX多路径软件有SDDPCM、SDD、MPIO和PowerPath。 SDD收集命令 datapath query device datapath query adapter lsvpcfg MPIO收集命令 lspath mpio_get_config -Av SDDPCM收集命令 pcmpath query device pcmpath query adapter lspcmcfg PowerPath（EMC存储）收集命令 powermt version powermt display dev=all 日志查看 系统错误日志查看命令： errpt errpt -d H errpt -d S errpt -aj 系统错误日志目录：/var/adm/ras/errlog 系统启动日志查看目录： /var/adm/ras/bootlog /var/adm/ras/bosinstlog /var/adm/ras/conslog alog命令 alog用于创建并维护创建字标准输入的固定大小的日志文件。常用参数介绍： -C:更改指定LogType的属性 -f :指定日志文件的名称 -o:列出日志文件的内容 -t :指定LogType -H:显示alog命令的用法 -s:指定日志文件的大小限制（字节） 常用用法示例： 命令 功能 alog -t boot -o 查看系统启动日志 alog -t lvmcfg -o 查看LVM相关日志 alog -t boot -o |grep data 查看系统最后重启时间 alog -f -o 列出日志文件的内容 date | alog -f 记录日志文件中的当前日期和时间 alog -C -t boot -s 8192 修改boot日志大小为8192字节 更多用法介绍参考官方文档：alog Command 升级相关日志 install_all_updates: Log file is /var/adm/ras/install_all_updates.log 日志分析 core dump分析 使用命令snap -ac收集dump，解压文件： # ls snap.pax.Z # uncompress snap.pax.Z # ls snap.pax # pax -r -f snap.pax pax: Ready for volume 2 pax: Type \"go\" when ready to proceed (or \"quit\" to abort): go pax: [offset 345m+441k+321]: Continuing ... pax: Type \"go\" when ready to proceed (or \"quit\" to abort): go pax: [offset 2g+24m+599k+902]: Continuing pax: snap.pax : 0511-626 An invalid file header has been read. pax: snap.pax : Skipping to the next file...ls 解压报错了，并且没一会虚拟AIX把我电脑搞蓝屏，以后再示例。 待补充 "},"05-IBM_Operating_System/01-AIX/02-AIX-常用命令.html":{"url":"05-IBM_Operating_System/01-AIX/02-AIX-常用命令.html","title":"AIX-常用命令","keywords":"","body":"AIX-常用命令和操作 硬件类 slibclean 除去内科和库中任何当前不用的模块 netstat -ni 查看网络配置 autoconf6 配置IPv6 netstat -rn 查看路由 netstat -a netstat -v entstat -d ent0 |grep -i vlan tcpdump -lni en7 |grep -i echo entstat -d device 诊断IEEE 802.3ad etherchannel问题 entstat entX svmon -G svmon -P netstat -in chdev -l enX -a mtu_bypass=on refresh -s clcomdES stopsrc -s clcomdES;startsrc -s clcomdES AIX常用命令 du -sg ssh -v #   有个需求，给网卡配置一个IP,但是不想启用，启用就会IP冲突，如果直接配置在START Now里选择No的话IP也会自动生效，配置方法： 首先配置一个无效的IP在此网卡上 然后修改网卡属性： smit tcpip Further Configuration Network Interfaces Network Interface Selection Change / Show Characteristics of a Network Interface 选择需要修改的网口 在Change / Show a Standard Ethernet Interface界面中： INTERNET ADDRESS (dotted decimal)中填入需求的正确IP Current STATE选项里面选择detach 回车确认 需要启用ip时使用命令ifconfig en1 up即可 强制删除非空目录 rm -rf wkhtmltopdf scp /tmp/aix7236.iso tmpusr@10.8.222.11:/tmp 目录： scp -r /tmp/aix tmpusr@10.8.222.11:/tmp ‌ oslevel -s 7200-03-05-2016 ‌ oslevel -rl 7200-04 Fileset Actual Level Recommended ML powerscStd.vtpm.rte 1.1.4.2 1.1.4.3 sysmgt.cfgassist 7.2.3.16 7.2.4.0 ‌ lppchk -vm3 ‌ instfix -i |grep ML All filesets for 7.2.0.0_AIX_ML were found. All filesets for 7200-00_AIX_ML were found. All filesets for 7200-01_AIX_ML were found. All filesets for 7200-02_AIX_ML were found. All filesets for 7200-03_AIX_ML were found. Not all filesets for 7200-04_AIX_ML were found. After you download the TL, locally : cd /media directory installp -acFXYd . powerscStd.vtpm installp -acXYd . sysmgt.cfgassist cd installp -aXYgd . -e /tmp/install.log sysmgt.cfgassist installp -c all and run and send me output of below commands: lppchk -v oslevel -s installp -aXYgd . -e /tmp/install_sysmgt.log sysmgt.cfgassist Additional info, Please download the following files from below link: https://developer.ibm.com/javasdk/support/aix-download-service/ Java8_64.jre.tar.gz (140255885) Java8_64.sdk.tar.gz (14418713) Thank you. 02:36 am 07/25 Good day Junaid, Thank you for raising Case# TS002515360 with IBM Software Support. I am Arlina from AIX software support and I will be working with you on the case. You may download Java8 from below link. Before you can download code, you need an IBM Registration ID. https://developer.ibm.com/javasdk/support/aix-download-service/ For more reference: IBM Java for AIX HowTo: Install or upgrade IBM Java to a specific release https://www-01.ibm.com/support/docview.wss?uid=isg3T1022693 Resolution summary:He can download the latest version of the Java fileset from : https://www-01.ibm.com/support/docview.wss?uid=isg3T1022644 After you download them for each of the filesets: gzip tar -xvf .tar cd inutoc . installp -acXYd . "},"05-IBM_Operating_System/01-AIX/03-AIX-用户策略.html":{"url":"05-IBM_Operating_System/01-AIX/03-AIX-用户策略.html","title":"AIX-用户策略","keywords":"","body":"AIX-用户策略 用户属性文件 AIX中每个用户都有相关属性，与用户属性相关的文件： 用户基本属性：/etc/passwd 用户环境属性：/etc/security/environ 定义用户的资源定额和限制：/etc/security/limits 用户的扩展属性：/etc/security/user 用户的管理角色属性：/etc/security/user.roles 审计配置信息：/etc/security/audit/config 组的基本属性：/etc/group 组的扩展属性：/etc/security/group 用户最后登录属性：/etc/security/lastlog 常用命令 常用用户操作命令如下： 命令 用途 lsuser -f root 以节格式查看用户属性 lsgroup -f system 以节格式查看用户组属性 mkgroup -a tmpg 新建名为tmpg的组管理账户 mkuser -a test 新建名为test的管理账户 rmgroup tmpg 删除用户组tmpg rmuser -p test 删除用户test及所有属性 pwdadm test 为test设置密码 passwd 修改当前用户密码 chuser 修改用户属性 用户属性修改 创建修改用户都可以使用smit菜单，参数一目了然，推荐用此方法；不推荐直接修改配置文件，后果可能会很严重，用命令也要注意。 修改配置文件 修改/etc/security/user文件注意事项： 修改default的配置会影响所有用户，如果用户指定了相应的配置，以用户指定的配置为准 有些default的配置对root无效，例如maxexpired 修改expires参数要注意格式，此参数是设置用户到期时间，如果不慎修改了default里面的值，并且格式不对，例如expires = 120，那么所有未单独指定此值的用户（一般都是采用default）都将很快过期 修改maxage注意，如果修改的是default里面的值，会应用到所有未配置此值的用户，例如设为4，4周内没改过密码，那么此用户将在下一次登录提示更改密码 修改密码策略例如密码长度，需要字符数量等，会在下一次修改密码提示，目前的密码不受影响 在修改user文件后，用户间配置需要空一行，否则会出现问题 修改用户示例 修改用户test的到期日期为2020年12月31日12点： chusr expires=1231120020 test 使用户test能够远程访问此系统： chusr rlogin=true test 用户基本属性 以下是控制登录并且与密码质量无关的用户属性： 属性名称|属性说明 :---|:--- account_locked|如果明确地需要锁定账户，那么该属性可以设置为True；缺省值为False admin|如果设置为True，那么该用户无法更改密码。只有管理员可以更改它。 admgroups|列出子用户具有管理权限的组。对于这些组，该用户可以添加或删除成员。 auth1 |用于授权用户访问的认证方式。不推荐使用 auth2|按auth1指定的无论上面对用户进行认证后的方法。它无法阻止对系统的访问。一般为None daemon |此布尔参数指定是否允许用户使用startsrc命令启动守护程序或子系统， login|指定是否运行该用户登录。 logintimes|限制用户何时可以登录。 registry|指定用户注册表。 rlogin|指定所指定用户能否使用rlogin或telnet命令登录 su|指定其它用户是否可以使用su命令切换至此标识。 sugroups|指定运行哪个组结合至此用户标识 ttys|限制某些账户进入物理安全区域 expires |定义用户账号过期时间，用于管理学生或访客账户；也可以用于临时关闭账户 loginretries |指定用户标识被系统锁定之前连续的可以尝试登录失败的最大次数。 umask |指定用户的初始umask rcmds|指定所指定用户能否使用rsh抿了或rexec命令运行各个命令。 hostallowedlogin|指定许可用户登录的主机。 hostdeniedlogin|指定不许可用户登录的主机 maxulogs|指定每个用户的最大登录数。 用户登录策略 建议用户首先使用自己的普通用户登录，然后允许su命令去登录到root，不建议以root用户的身份登录。下表是摘自IBM官方登录策略推荐： 操作名称|描述|推荐设置 :---|:---|:--- Interval between unsuccessful logins|用于为/etc/security/login.cfg中的logininterval属性设置相应的值，该参数的作用是指定一段时间间隔（以秒计），在该时间内，如果尝试进行了若干次登陆后仍无法成功登录，那么将禁用该端口。例如，如果logininterval设为60，logindisable设为4，那么如果在1分钟内发生4此尝试登录失败后就将禁用该账户|高安全性：300;中安全性：600;低安全性：无效;AIX标准设置：无限制 Number of login attempts before locking the account|用于为/etc/security/login.cfg中的loginrteries属性设置相应的值，该属性的作用是指定每个账户上可连接进行的登录尝试次数，如果经过在达到该次数后仍无法登录，那么将禁用相应的账户。不要对root账户设置该属性|高安全性：3;中安全性：4;低安全性：5;AIX标准设置：无限制 Remote root login|用于更改/etc/security/user中的rlogin属性设置相应的值，该属性的作用是指定系统上是否允许以root账户远程登录| 高安全性：False;中安全性：False;低安全性：无效;AIX标准设置：True Re-enable login after locking|用于为/etc/security/login.cfg中的loginreenable属性设置相应的值，该属性的作用是指定一段时间间隔（以秒计），当端口被logindisable禁用后，经过此指定的时间间隔后将解锁端口|高安全性：360;中安全性：30;低安全性：无效;AIX标准设置：无限制 Disable login after unsuccessful login attempts |用于为/etc/security/login.cfg中的logindisabel属性设置相应的值，该属性的作用是指定端口锁定前可进行的登录尝试次数|高安全性：10;中安全性：10;低安全性：无效;AIX标准设置：无限制 Login timeout|用于为/etc/security/login.cfg中的ligintimeout属性设置相应的值，该属性的作用是指定输入密码时允许的时间间隔|高安全性：30;中安全性：60;低安全性：60;AIX标准设置：60 Delay between unsuccessful logins|用于为/etc/security/login.cfg中的logindelay属性设置相应的值，该属性的作用是指定两次失败登录之间的延迟时间（以秒计）。每次登录失败后将附加一段延迟时间。例如，设置为5，在第一次登录失败后，终端将等待5秒，然后再发出下一次登录请求，第二次失败后，终端将等待10秒（2*5）|高安全性：10;中安全性：4;低安全性：5;AIX标准设置：无限制 Local login |用于更改/etc/security/user中的login属性设置相应的值，该属性的作用是指定系统上是否允许以root账户登录控制台|高安全性：False;中安全性：无效;低安全性：无效;AIX标准设置：True 用户密码策略 良好的密码是抵御未授权进入系统的第一道有效防线。 符合以下条件的密码有效： 大小写字母的混合 字母、数字或标点符号的组合 未写在任何地方 如果使用/etc/security/passwd文件，那么长度最少未7个字符最大PW_PASSLEN个字符 不是在字典中可以查到的真实单词 不是键盘上的字母的排列模式，例如qwerty 不是真实单词或已知排列模式的反向拼写 不包含任何与您自己、家庭或朋友有关的个人信息 不与从前一个密码的模式相同 可以较快输入，这样便是的人就不能确定您的密码 除了这些机制外，还可以通过对密码进行限制，使其不得包含可能被猜到的标准UNIX单词，从而实施更严格的规则。 下表是摘自IBM官方密码策略规则推荐： 操作名称|描述|推荐设置 :---|:---|:--- Minimum number of characters|用于为/etc/security/user中的mindiff属性设置相应的值，该属性的作用是指定组成新密码必须的最少字符|高安全性：4；中安全性：3；低安全性：无效；AIX标准设置：无限制 Minimum age of characters|用于为/etc/security/user中的minage属性设置相应的值，该属性的作用是指密码可更改前必须经过的最小周数| 高安全性：1；中安全性：4；低安全性：无效；AIX标准设置：无限制 Maximum age of characters|用于为/etc/security/user中的maxage属性设置相应的值，该属性的作用是指密码可更改前必须经过的最大周数| 高安全性：13；中安全性：13；低安全性：52；AIX标准设置：无限制 Minimum length for password|用于为/etc/security/user中的minlen属性设置相应的值，该属性的作用是指定密码的最小长度| 高安全性：8；中安全性：8；低安全性：8；AIX标准设置：无限制 Minimum number of alphabetic characters |用于为/etc/security/user中的minalpha属性设置相应的值，该值指定密码中包含的字母字符的最小数目|高安全性：2；中安全性：2；低安全性：2；AIX标准设置：无限制 Password reset time|用于为/etc/security/user中的histexpire属性设置相应的值，该属性的作用是指定密码可以重置前必须经过的周数。| 高安全性：13；中安全性：13；低安全性：26；AIX标准设置：无限制 Maximum times a char can appear in a password|用于为/etc/security/user中的maxrepeats属性设置相应的值，该属性的作用是指定密码中同样字符运行出现的最大次数|高安全性：2；中安全性：无效；低安全性：无效；AIX标准设置：8 Password reuse time |用于为/etc/security/user中的histsize属性设置相应的值，该属性的作用是指定用户不能符用的旧密码个数|高安全性：20；中安全性：4；低安全性：4；AIX标准设置：无限制 Time to change pass-word after the expire-tion|用于为/etc/security/user中的maxexpired属性设置相应的值，该属性的作用是指定maxage后用户可更改到期密码的最长周期 |高安全性：2；中安全性：4；低安全性：8；AIX标准设置：-1 Minimum number of non-alphabetic char-acters|用于为/etc/security/user中的minother属性设置相应的值，该属性的作用是指定密码中非字母字符的最少个数|高安全性：2；中安全性：2；低安全性：2；AIX标准设置：无限制 Password expiration warning time|用于为/etc/security/user中的pwdwarntime属性设置相应的值，该属性的作用是指定系统发出需要更改密码的警告前等待的天数|高安全性：5；中安全性：14；低安全性：5；AIX标准设置：无限制 修改root用户注意事项 修改/etc/security/user文件注意   最近改了一些系统root用户的参数，都是直接修改/etc/security/user文件，主要是root用户过期时间，即参数maxage = 15，表示15周过期。过一段时间发现登录root提示：Your account has expired。找了几个测试分区，都是很久没改过，修改maxage = 15后，有的提示： [compat]: 3004-332 Your password has expired. 有的分区提示： 3004-302 Your account has expired; please see the system administrator. 提示用户过期的改了密码是也是一样的提示。继续进行了一些测试： 修改近期改过密码分区的root用户maxage = 15后（和下一个用户条目没有空行），登录root用户过期，删掉此行（删掉后和下一个用户条目间没有空行），重新试一样提示用户过期登录不了 修改近期改过密码分区的root用户maxage = 15后（和下一个用户条目有空行）,用户可以正常登录，密码也没过期；删掉空行，提示用户过期；加上空行，用户可以正常登录 修改长时间没改过root密码分区的root用户maxage = 15后（和下一个用户条目没有空行），会提示用户过期，无法进行登录 修改长时间没改过root密码分区的root用户maxage = 15后（和下一个用户条目有空行），会提示密码过期，也会提示输入新密码进行修改   注意，在修改过程中，保持一个root用户会话的连接，因为提示root用户过期后，没有其它系统配置免密登录的是无法再用root进入到系统的，只能通过光盘引导进入维护模式修改user文件，在维护模式下vi很不好用，加空行可以使用下面命令： sed '/daemon:/{x;p;x;}' user > user.bak mv user.bak user   建议在操作user前建议备份一份，因为我第一次在使用命令sed '/daemon:/{x;p;x;}' user > user直接重定向到user文件后，user文件内容清空了，还好有备份。维护模式下vi虽然很不好用，但是依然可以vi文件然后i进行插入文本。 待补充 "},"05-IBM_Operating_System/01-AIX/04-AIX-HA常用操作.html":{"url":"05-IBM_Operating_System/01-AIX/04-AIX-HA常用操作.html","title":"AIX-HA常用操作","keywords":"","body":"AIX-HA常用操作 PowerHA是AIX系统中常用的高可用软件。 日志查看和收集 日志查看 大多数HA日志存放在/var/hacmp目录下，常用的有： 命令errpt -e输出：系统日志，会有HA集群事件，也可以查看/var/adm/ras/errlog文件 /var/hacmp/adm/cluster.log：包含由PowerHA SystemMirror脚本和守护程序生成的带时间戳的格式化消息，诊断集群问题时候首先检查此文件 /var/hacmp/log/hacmp.out，包含脚本执行的每个命令的逐行记录，包括每个命令的所有参数的值 /var/hacmp/clverify/clverify.log：集群验证详细输出 /var/hacmp/log/autoverify.log：在自动集群验证运行期间发生的任何警告或错误 /var/hacmp/log/clutils.log：包含有关日期，时间，结果以及哪个节点执行了自动集群配置验证的信息 /var/adm/ras/syslog.caa:CAA日志，CAA即Cluster-Aware AIX 在检查启动问题时候，启动HA的时候，跟踪hacmp.out输出查看日志，执行命令：tail -f hacmp.out。在PowerVM环境，通常要检查netmon.cf配置，路径：/usr/es/sbin/cluster/netmon.cf。 日志收集 smit收集cluster log方法： 执行命令 ：smit hacmp 选择选项：\"Problem Determination Tools\" 选择选项：\"PowerHA SystemMirror Log Viewing and Management\" 选择选项：\"Collect Log Files for Problem Reporting\" 各参数说明如下： Log Destination Directory：默认/tmp目录 Collection Pass Number：默认为2，1是计算所需空间 Nodes to Collect Data from：默认选择all Debug ：默认是No，除非IBM 专家建议 Collect RSCT Log Files：默认Yes 命令收集方法： 执行命令snap -ec即可，收集数据存放在/tmp/ibmsupt下面，文件名snap.pax.Z。 常用命令 PowerHA一般用smit菜单操作，失误率小，偶尔用命令。在AIX系统中，PowerHA命令路径：/usr/es/sbin/cluster。常用命令如下： 命令 功能 clstop 停止集群，注意参数 lscluster -m 查看集群状态 lssrc -g caa 查看caa/rsct/cluster等服务 lssrc -ls cthags 检查组服务子系统 no -a | grep routerevalidate 查看routerevalidate no -po routerevalidate=1 修改routerevalidate ls -al /dev/datavg 查看vg信息，主要是看major号 lvlstmajor 查看可用的 major号 chdev -l fscsi0 -a fc_err_recov=fast_fail -P 修改光纤口属性 chdev -l -a queue_depth=40 -P 修改磁盘属性示例 /usr/sbin/rsct/bin/dhb_read -p -r 心跳盘测试(主) /usr/sbin/rsct/bin/dhb_read -p -t 心跳盘测试(备) clctrl -tune -L 查看HA一些参数配置 clctrl -tune -L network_fdt 查看Network network_fdt配置 说明： AIX操作系统缓存路由，需要设置routerevalidate选项：routerevalidate=1。 启停HA命令日常不推荐用，特别是停止，需要加参数指定停止选项。 参数配置说明 资源组策略说明 \"Startup\"启动说明： Online On Home Node Only:资源组启动期间，仅在其主节点（最高优先级）上启动 Online On First Available Node:资源组在第一个可用的参与节点上启动 Online On All Available Nodes:资源组在所有节点上启动 Online Using Distribution Policy:每个节点上只有一个资源组启动 \"Fallover\"故障转移： Fallover To Next Priority Node in the list:资源组遵循在节点列表中指定的默认节点优先级顺序 Fallover Using Dynamic Node Priority:节点失败时动态选择迁移节点，一般三节点情况下 Bring Offline(On Error Node Only:当节点发生error时候，使资源组脱机 \"Fallback\"退回方式： Fallback To Higher Priority Node in the list:当优先级较高的节点加入群集时，资源组将回退 Never Fallback:资源组加入群集时不会回退到较高优先级的节点 资源组节点优先级 对于资源组，节点优先级定义在资源组属性参数\"Participating node list\"中，说明如下： 列表定义了可以承载特定资源组的节点列表，可以是部分节点，也可以是全部 默认节点优先级由节点在特定资源组的节点列表中的位置来标识 节点列表中的第一个节点具有最高的节点优先级。该节点也称为资源组的主节点。在另一个节点之前列出的节点具有比当前节点更高的节点优先级 HA停止策略 在停止HA时候，菜单\"Stop Cluster Services\"中选项\"Select an Action on resource groups\" Bring resource groups Offline:停止正在停止的节点上当前在线的所有受管资源,资源组不会切换到任何节点上 Move resource groups:停止正在停止的节点上当前在线的所有受管资源,资源组会切换到可用节点上 Unmanage resource groups:群集服务将立即停止,节点上资源不会停止,应用程序继续运行,PowerHA SystemMirror继续运行，并且RSCT保持运行状态 常用操作 network_fdt参数   network_fdt即Network Failure Detection Time,在老版本的AIX系统中可能没这个参数，在IV76622中引入了此参数。查看network_fdt参数命令(单位是毫秒)： clctrl -tune -L network_fdt 修改network_fdt参数命令(单位是秒，范围5-590)： clmgr modify cluster NETWORK_FAILURE_DETECTION_TIME= smit查看及修改方法： smit hacmp Custom Cluster Configurations CLuster Nodes and Networks Manage the Cluster Cluster heartbeat settings Press Enter 官方说明：PowerHA SystemMirror use of Cluster Aware AIX 常见问题 同步问题 问题一：  同步时候报error时间戳问题，在同步时候选项中第二个选项选择yes可以自动修复这个问题（在HA停止状态下才有此选项）， Force synchronization if verification fails? [No] to Force synchronization if verification fails? [Yes] 问题二：  A是主节点在运行资源组，B是备节点未启动，A可以同步到B（可能有warring说配置不一致），B也可以启动，但是启动后查看状态B看到A是down，A看到B是down，如果尝试从A向B切换，会发现选择不了B节点的，建议步骤：停掉B备节点，然后检查两个节点的rhost文件： HA6:etc/es/sbin/cluster/rhosts HA7:/etc/cluster/rhosts 切换问题 问题一：  在切换HA过程中很慢，看日志是发现HA脚本出现问题过不去，执行选项 Recover From PowerHA SystemMirror Script Failure即可，然后去检查修复脚本的问题。问题二:  A是主节点在运行资源组，B是备节点HA也在运行，状态看都正常，但是从A向B切换后发现部分文件系统挂载，然后又自动卸载，查看状态节点资源组是error状态，如果排除脚本的问题，那可能是文件系统配置问题，建议检查/etc/filesystems是否一致，还有就是检查文件系统，是否有在B机单独在HA的文件系统中加过文件或者目录或者软链接等。问题三:  A往B切换过程中出现问题，A变成error状态，资源组两边都没有，执行选项 Recover From PowerHA SystemMirror Script Failure后HA状态看起来正常，但是B机的NAS文件系统未挂载（在HA脚本中有写挂载），手动挂载后，发现A机df -g命令有报错，并且不会自动返回到shell。检查解决步骤： 检查rc.local和inittab都没有异常的选项 检查A机HA停止脚本中有无效的NFS文件系统umonut选项，注释或者删除 检查A机HA停止脚本中有漏掉的NFS文件系统umonut选项，添加上去 手动执行umonut漏掉的NFS文件系统 执行后发现有操作系统的文件系统umount了，手动mount或者重启即可 节点通信问题   通常情况下，节点通信问题原因可能有：网络问题，配置问题等等，配置例如host表，rhost文件，IP配置，wlan配置问题等等，但是有时候问题不是很明显，最近遇到过一个HA配置无问题，网络看起来也是正常的，但是HA同步就同步不了。例如：A节点HA未启动，B节点HA启动了，资源组正在运行，AB节点都是PowerVM环境的VIOC。从B往A同步执行等半天后，发现报错如下： ERROR:Comm error found on node:   在B节点Show Cluster Services菜单中，执行后很慢出结果，等待结果出来后发现A节点Cluster-Aware AIX status是down的状态，在A节点上检查服务状态： # lssrc -a |grep inetd inetd tcpip 2490704 active # lssrc -a |grep cthags cthags cthags inoperative # lssrc -a |grep clcomd clcomd caa 6750706 active # lssrc -a |grep clconfd clconfd caa 12911042 active # lssrc -ls inetd Subsystem Group PID Status inetd tcpip 2490704 active Debug Not active Signal Purpose SIGALRM Establishes socket connections for failed services. SIGHUP Rereads the configuration database and reconfigures services. SIGCHLD Restarts the service in case the service ends abnormally. Service Command Description Status caa_cfg /usr/sbin/clusterconf clusterconf active ftp /usr/sbin/ftpd ftpd active 从B向A或A向B ping都看起来正常： $ ping -S nodea nodeb PING nodeb: (1.1.253.130): 56 data bytes 64 bytes from 1.1.253.130: icmp_seq=0 ttl=255 time=0 ms 64 bytes from 1.1.253.130: icmp_seq=1 ttl=255 time=0 ms 64 bytes from 1.1.253.130: icmp_seq=2 ttl=255 time=0 ms 使用lscluster -m命令去查看集群状态，可以看到A节点下有如下显示： Points of contact for node :0 在A节点的HA Show Repository Disks菜单中执行后获取不到心跳盘的部分信息，并会有报错（时有时无）： ERROR:unable to communicate with \"nodeb\"(nodeb,ip) ERROR:\"Repository Disks PVID\" was not found in data that you requested. 在B节点的HA Show Repository Disks菜单可以获取到心跳盘信息，有时也会有： Communication error, see logfile 以上菜单都执行比较慢，但是使用dhb_read命令去测试两个节点间心跳磁盘，测试是正常的。 lspv查看caavg_private VG的状态是active，检查caa日志，会发现如下报错： tcpsock_ndd_add2_sendq: Overflow, Dropping packet. Could not send lock request message. rc=127 cluster_utils.c get_cluster_lock...Could not get lock....   可能是在节点A上启用了jumbo frames,而B节点无法接收jumbo frames，可以分别在两个node上执行如下命令，如果Jumbo frame启用了，那么MTU size = 9000： # netstat -i Name Mtu Network Address Ipkts Ierrs Opkts Oerrs Coll en1 1500 link#2 ee.37.5f.fc.eb.3 281954049 0 33827048 0 0 en1 1500 10.8.253 npospdb2-cv 281954049 0 33827048 0 0 en0 1500 link#3 ee.37.5f.fc.eb.2 901593154 0 586172871 0 0 en0 1500 192.168.3 node_svc 901593154 0 586172871 0 0 en0 1500 1.1.253 nodeb 901593154 0 586172871 0 0   此次没有启动jumbo frames，但也是是网络通信问题，检查HA boot ip所在网卡的属性，如果largesend是开启的，在这种情况下，VIOS上的相应适配器也应启用largesend和large_receive，以避免在管理程序中出现碎片。可以使用命令clrsh测试节点连接： # clrsh nodea date Communication error, see logfile # clrsh nodeb date Thu Feb 18 11:07:15 CST 2021 # hostname nodea # clrsh nodea date Thu Feb 18 11:08:24 CST 2021 # clrsh nodeb date Thu Feb 18 11:08:34 CST 2021 # clrsh nodea date Thu Feb 18 11:08:46 CST 2021 # clrsh nodeb date Communication error, see logfile 可以看到有时候通信异常，有时候能出现命令输出也比较慢。 解决方法可以禁用mtu_bypass： # chdev -l enX -a mtu_bypass = off 或在VEA或中继VEA上禁用PLSO： # chdev -l entX -a platform_lso = no IBM相关问题描述链接： IJ25390: SLOW TCP PERFORMANCE WITH VIRTUAL ETHERNET ADAPTER AND LARGESENDAPPLIES TO AIX 7200-04 VIOS (Doc Number=6667): High Impact / Highly Pervasive APAR IJ25390 磁盘问题 PVID问题   有时候由于某些异常原因导致某一节点的数据磁盘的PVID丢失或者不一致，例如备节点test1磁盘PVID异常，同步时候报错如下： ERROR: A disk with PVID 000baf2b911918a40000000000000000 is a part of the volume group datavg participating in resource group test_rg on node test2. Node test1 is also part of this resource group, but it does not have this PVID defined as a part of this volume group. The list of PVIDs per volume group should be consistent for all nodes that can require access to this volume group. Starting Corrective Action: cl_resource_update_vg_definitions. Do you want to change volume group definitions for the volume group: datavg participating in resource group test_rg on node: test1 [Yes / No]: Updating volume group definitions of shared VG: datavg participating in resource group test_rg so that it will be consistent across all the nodes from this resource group: FAIL 如果磁盘reserve_policy属性是single_path则改成no_reserve： 如果PVID不一致，修改PVID为一致，如果磁盘reserve_policy属性是single_path则改成no_reserve, 然后同步，备机test1的VG信息恢复，HA启动正常 如果test1的disk PVID为NONE，使用命令odmdelete -o CuDv -q \"name=hdisk3\"删除ODM信息，然后重启操作系统，磁盘PVID和VG信息应该会恢复 修改PVID方法(每两位从十六进制转换成八进制)，示例： echo \"\\0000\\0013\\0257\\0053\\0231\\0030\\0030\\0244\\c\" > /tmp/myPVID cat /tmp/myPVID |dd of=/dev/hdisk3 bs=1 seek=128 lquerypv -h /dev/hdisk3 80 rmdev -dl hdisk3 cfgmgr lspv 或者使用写的Python脚本修改：Python-AIX配置修改-自动修改hdisk的PVID 磁盘异常丢失   模拟磁盘丢失，断掉备机test1分区的hdisk3磁盘映射，双vios都断开，磁盘开始报路径丢失和磁盘操作错误，但是VG状态不变，磁盘状态看起来正常，主机端test2没有errpt： test1:/#lspv hdisk0 00f939e23e8ab01a rootvg active hdisk1 000baf2b911815a4 datavg concurrent hdisk2 000baf2b9118164a caavg_private active hdisk3 000baf2b9e10273d datavg concurrent 在主机test2新建文件系统，备机test1的datavg状态从concurrent变空，并且主机test2报错： test2:/#errpt IDENTIFIER TIMESTAMP T C RESOURCE_NAME DESCRIPTION F7DDA124 1209160521 U H LVDD PHYSICAL VOLUME DECLARED MISSING 备机test1报错： IDENTIFIER TIMESTAMP T C RESOURCE_NAME DESCRIPTION AEA055D0 1209160521 I S livedump Live dump complete CAD234BE 1209160521 U H LVDD QUORUM LOST, VOLUME GROUP CLOSING 52715FA5 1209160521 U H LVDD FAILED TO WRITE VOLUME GROUP STATUS AREA F7DDA124 1209160521 U H LVDD PHYSICAL VOLUME DECLARED MISSING E86653C3 1209160521 P H LVDD I/O ERROR DETECTED BY LVM B6267342 1209160521 P H hdisk3 DISK OPERATION ERROR 命令rmdev -Rdl hdisk3删除不了磁盘，直接odmdelete -o CuDv -q \"name=hdisk3\"删除ODM库，可以删除。然后VIOS重新映射磁盘，报错： \"hdisk7\" is already being used as a backing device. Specify the -f flag to force this device to be used anyway. 强制映射： mkvdev -vdev hdisk7 -vadapter vhost3 -dev vtscsi8 -f   磁盘使用命令cfgmgr扫描不回来，停掉备机test1的HA，重启系统，重启后hdisk3恢复，并且vg信息也有。再次用命令rmdev -Rdl hdisk3删掉磁盘，cfgmgr扫描回来后依然正常。 宕机问题 宕机原因参考链接： TWT-如何处理hacmp中dms的问题 Toolbox-LPAR AIX Rebooted Auto DB2-Diagnosing a host reboot with a restart light GPFS filesystem outage with a kernel panic IBM Spectrum Scale filesystem outage with a kernel panic IV87544: SHUTDOWN -F ON POWERHA MAY PANIC INSTEAD OF HALT IV69760: NODE DOWN IN CAA CLUSTER DUE TO CONFIGRM MEMORY LEAK PowerHA集群与宕机相关原理等： RSCT3.2-Action 9: investigate an AIX node crash Adjusting Dead Man Switch Timeout for CLUSTER (DMS) 待补充 "},"05-IBM_Operating_System/01-AIX/05-AIX-NIMserver.html":{"url":"05-IBM_Operating_System/01-AIX/05-AIX-NIMserver.html","title":"AIX-NIMserver","keywords":"","body":"AIX-NIMserver NIMserver功能很强大，目前用的比较多的就是mksys备份恢复系统及升级系统等。 AIX系统备份 常规备份注意 mksysb的前提条件： 备份的目录有足够的空间 备份时确保系统活动减少到最低限度   如果需要排除某个文件系统或目录，编辑/etc/exclude.rootvg文件。例如，要排除名为temp的目录的所有内容，格式示例： /temp/ 要排除名为/tmp的目录的内容，并避免排除路径名中带有/tmp的任何其他目录，格式示例： ^./tmp/ ^./backup/ 排除exclude.rootvg文件中目录的备份操作（其它默认）： smit mksysb Enter backup device or file Change \"EXCLUDE files?\" form \"no\" to \"yes\" 对应上面操作的命令是： mksysb -e -i -A /tmp/mksysb0312.sysb 参数解释： 参数-e：在备份时排除/etc/exclude.rootvg文件中列示的文件 参数-i：调用生产/image.data文件的mkszfile命令 参数-A: 备份DMAPI文件系统文件 不带镜像的备份   在AIX系统中，对rootvg进行备份使用mksysb时候，默认会在根目录下创建image.data文件，mksysb会根据此文件生成对应的镜像。如果原系统有镜像两块磁盘，直接做mksyb，恢复分区只有一块磁盘，在恢复时候会报错，提示空间不够，有几种解决方法： 解除原分区的镜像，做mksyb后再重新做镜像（对一些高要求系统来说存在风险） 搞一块新的临时硬盘到新分区（也许配置会比较麻烦，后续可能会删掉概率也大） 修改image.data文件，在做mksysb的时候不创建新的image.data，使用修改的image.data IBM 官方介绍：Creating and Restoring a Mksysb Without Preserving Mirrors 近期写了一个脚本修改image.data文件，参考链接：Shell-mksysb相关脚本 新建image.data文件： mkszfile 文件示例： lv_data: VOLUME_GROUP= rootvg LV_SOURCE_DISK_LIST= hdisk0 LV_IDENTIFIER= 00cb4d6e00004c0000000168788002ed.1 LOGICAL_VOLUME= hd5 VG_STAT= active/complete TYPE= boot MAX_LPS= 512 COPIES= 1 LPs= 1 STALE_PPs= 0 INTER_POLICY= minimum INTRA_POLICY= edge MOUNT_POINT= MIRROR_WRITE_CONSISTENCY= on/ACTIVE LV_SEPARATE_PV= yes PERMISSION= read/write LV_STATE= closed/syncd WRITE_VERIFY= off PP_SIZE= 128 SCHED_POLICY= parallel PP= 1 BB_POLICY= non-relocatable RELOCATABLE= no UPPER_BOUND= 32 LABEL= primary_bootlv MAPFILE= LV_MIN_LPS= 1 STRIPE_WIDTH= STRIPE_SIZE= SERIALIZE_IO= no FS_TAG= DEV_SUBTYP= 需要修改的项目： LV_SOURCE_DISK_LIST= hdisk0:如果两块盘互为镜像这里会显示两个盘符，不需要镜像保留一个即可 COPIES= 1：不需要镜像就改成1 PP= 20：根据LV的情况来判断，和LPs的值保持一致 使用vi修改命令示例： :%s/COPIES= 2/COPIES= 1/g AIX系统恢复   AIX系统从mksysb恢复通常使用NIMserver比较多，也可以把mksysb做成一个启动CD，刻录出来或者通过虚拟光驱去安装。恢复过程中注意事项： 如果对端分区没开起来，NIM分发系统时候会报网络问题：code78，可以忽略 在分发过程中好像不能再开个shell再次分发，但是在分发完成后系统安装过程中可以再分发系统 确保/etc/hosts表里面IP和hostname都是一一对应关系，如果一个IP对应不同hostname，系统安装完成后hostname可能不是预期的 系统迁移通过mksysb恢复的系统需要注意事项： hostname名不能变，可能导致数据库启动不了 /etc/hosts表必须一致 心跳vg的磁盘的hdiskX编号必须一致，网卡的编号可以不一致 HA 6.1 /usr/es/sbin/cluster/etc/rhosts 需配置 HA 7.1 etc/rhosts需配置一致 PowerVM 环境下/usr/es/sbin/cluster/netmon.cf需配置 数据库裸设备可能需要更改权限 AIX 7.1心跳vg需要重新配置 NIM相关操作 resetmachine 有时候删除定义machine时候需要先reset一下： smit nim Perfom NIM Administration Tasks Manage Machines Perform Operations on Machines 选择需要reset的machines进行reset 在reset the NIM State of a machie菜单回车即可reset 如果是想删除machines定义，在reset the NIM State of a machie菜单中将两个选项都改成yes。 mksysb资源定义并分发 AIX安装镜像定义并分发 常见问题 host表IP冲突   当host表里面有一个IPA对应hostA,如果在定义一个host，IPA对应hostB，定义B名字的machine后，分发系统会报错，即使后期删掉了IPA对应主机名A的关系，一样会报错。提示： rc=0 exportfs: hostA:unkonwn host warning:warning:0042-006 m_bos_inst:(From_Master) connnetc Connection timed out NIM恢复系统卡在0608   使用NIM恢复AIX系统时候卡在0608代码，终端上显示是在Welcome to AIX,卡很久没反应。部分AIX版本有bug，官方发布了相关补丁,IV09250及IV09316： 官方描述：IV09250: UNABLE TO COMPLETE NIM BOOT, STUCK AT SRC 0608 APPLIES TO AIX 7100-01 官方补丁：Fix pack information for: Unable to complete NIM Boot, stuck at SRC 0608 非上诉版本也会出现此种问题，例如在AIX7.1.5.4版本也遇到过，官方有故障排除说明，参考链接如下： Troubleshooting NIM LED hangs 待补充 "},"05-IBM_Operating_System/01-AIX/06-AIX-TCPIP-配置IPv6.html":{"url":"05-IBM_Operating_System/01-AIX/06-AIX-TCPIP-配置IPv6.html","title":"AIX-TCPIP-配置IPv6","keywords":"","body":"AIX-配置IPv6   有客户近期需要配置IPv6，看了官网配置方案不难，给客户写了一份方案，这里也把方案记录下方便查阅，以后可能经常会用到。分两种情况，一种是已经有IPv4，一种是没有，两种配置差别不大，但是有些细节步骤不一样，还是分开写避免混淆。 从IPv4到IPv6的手动升级 当前系统已经配置了IPv4的情况下采用此方案。 配置IPv6地址 输入命令查看当前配置： bash-5.0# netstat -ni Name Mtu Network Address Ipkts Ierrs Opkts Oerrs Coll en0 1500 link#2 4e.8e.70.0.90.cf 403401863 0 408849341 0 0 en0 1500 9.200.104 9.200.104.23 403401863 0 408849341 0 0 lo0 16896 link#1 151933830 0 151933834 0 0 lo0 16896 127 127.0.0.1 151933830 0 151933834 0 0 lo0 16896 ::1%1 使用root用户权限，输入命令autoconf6来配置IPv6,然后查看配置： bash-5.0# autoconf6 bash-5.0# netstat -ni Name Mtu Network Address Ipkts Ierrs Opkts Oerrs Coll en0 1500 link#2 4e.8e.70.0.90.cf 403917847 0 409372234 0 0 en0 1500 9.200.104 9.200.104.23 403917847 0 409372234 0 0 en0 1500 fe80::4c8e:70ff:fe00:90cf 403917847 0 409372234 0 0 sit0 1480 link#3 9.200.104.23 0 0 0 0 0 sit0 1480 ::9.200.104.23 0 0 0 0 0 lo0 16896 link#1 152128319 0 152128323 0 0 lo0 16896 127 127.0.0.1 152128319 0 152128323 0 0 lo0 16896 ::1%1 输入命令启动ndpd-host守护进程： bash-5.0# startsrc -s ndpd-host 配置开机启用IPv6 重新启动计算机后，新配置的IPv6将被删除。要在每次重新启动时启用IPv6，操作步骤如下： 首先打开文件: /etc/rc.tcpip； 取消注释下列所示的行（对比当前配置）： # Start up autoconf6 process start /usr/sbin/autoconf6 \"\" # Start up ndpd-host daemon start /usr/sbin/ndpd-host \"$src_running\" 在start /usr/sbin/autoconf6 \"\"行中加上 -A参数： start /usr/sbin/autoconf6 \"\" -A 重新启动系统后，配置会自动配置。 配置IPv6路由 使用root用户权限，输入命令netstat -ni查看已配置的IPv4； 然后输入命令autoconf6来配置IPv6, 输入以下命令，在属于两个子网的每个路由器的接口上手动配置全局地址（根据需求）： bash-5.0# ifconfig en0 inet6 3ffe:0:0:aaaa::/64 eui64 alias bash-5.0# ifconfig en1 inet6 3ffe:0:0:bbbb::/64 eui64 alias 要激活IPv6转发，输入如下命令： bash-5.0# no -o ip6forwarding=1 启动ndpd-router守护进程： bash-5.0# startsrc -s ndpd-router 开机启用IPv6路由 首先打开文件: /etc/rc.tcpip；取消注释下面所示行（对比当前配置）： # Start up autoconf6 process start /usr/sbin/autoconf6 \"\" 在上面注释的行后面加上如下内容（根据当前系统需求）： # Configure global addresses for router ifconfig en0 inet6 3ffe:0:0:aaaa::/64 eui64 alias ifconfig en1 inet6 3ffe:0:0:bbbb::/64 eui64 alias 取消注释下面所示行（对比当前配置）： # Start up ndpd-host daemon start /usr/sbin/ndpd-host \"$src_running\" 未配置IPv4的时配置IPv6 配置IPv6地址 使用root用户权限，输入命令autoconf6 -A来配置IPv6; 然后输入命令netstat -ni查看当前配置,输出示例如下： Name Mtu Network Address Ipkts Ierrs Opkts Oerrs Coll en0 1500 link#3 0.4.ac.17.b4.11 7 0 17 0 0 en0 1500 fe80::204:acff:fe17:b411 7 0 17 0 0 lo0 16896 link#1 436 0 481 0 0 lo0 16896 127 127.0.0.1 436 0 481 0 0 lo0 16896 ::1 436 0 481 0 0 输入命令启动ndpd-host守护进程：startsrc -s ndpd-host 配置开机启用IPv6 重新启动计算机后，新配置的IPv6将被删除。要在每次重新启动时启用IPv6，操作步骤如下： 首先打开文件: /etc/rc.tcpip； 取消注释下列所示的行（对比当前配置）： # Start up autoconf6 process start /usr/sbin/autoconf6 \"\" # Start up ndpd-host daemon start /usr/sbin/ndpd-host \"$src_running\" 在start /usr/sbin/autoconf6 \"\"行中加上 -A参数： start /usr/sbin/autoconf6 \"\" -A 重新启动系统后，配置会自动配置。 配置IPv6路由 1） 使用root用户权限，输入命令autoconf6 -A来配置IPv6：输出示例： Name Mtu Network Address Ipkts Ierrs Opkts Oerrs Coll en1 1500 link#2 0.6.29.dc.15.45 0 0 7 0 0 en1 1500 fe80::206:29ff:fedc:1545 0 0 7 0 0 en0 1500 link#3 0.4.ac.17.b4.11 7 0 17 0 0 en0 1500 fe80::204:acff:fe17:b411 7 0 17 0 0 lo0 16896 link#1 436 0 481 0 0 lo0 16896 127 127.0.0.1 436 0 481 0 0 lo0 16896 ::1 436 0 481 0 0 输入以下命令，在属于两个子网的每个路由器的接口上手动配置全局地址（根据需求）： bash-5.0# ifconfig en0 inet6 3ffe:0:0:aaaa::/64 eui64 alias bash-5.0# ifconfig en1 inet6 3ffe:0:0:bbbb::/64 eui64 alias 要激活IPv6转发，输入如下命令： bash-5.0# no -o ip6forwarding=1 启动ndpd-router守护进程： bash-5.0# startsrc -s ndpd-router 开机启用IPv6路由 首先打开文件: /etc/rc.tcpip；取消注释下面所示行（对比当前配置）： # Start up autoconf6 process start /usr/sbin/autoconf6 \"\" 在start /usr/sbin/autoconf6 \"\"行中加上 -A参数： start /usr/sbin/autoconf6 \"\" -A 在上面注释的行后面加上如下内容（根据当前系统需求）： # Configure global addresses for router ifconfig en0 inet6 3ffe:0:0:aaaa::/64 eui64 alias ifconfig en1 inet6 3ffe:0:0:bbbb::/64 eui64 alias 取消注释下面所示行（对比当前配置）： # Start up ndpd-host daemon start /usr/sbin/ndpd-host \"$src_running\" 在引导时启用IP转发，运行如下命令： no -r -o ip6forwarding=1 其它 要调出接口的子集，可以使用命令autoconf6的-i参数。示例显示接口en0和en1： autoconf6 -i en0 en1 "},"05-IBM_Operating_System/01-AIX/07-AIX-磁盘多路径.html":{"url":"05-IBM_Operating_System/01-AIX/07-AIX-磁盘多路径.html","title":"AIX-磁盘多路径","keywords":"","body":"AIX-磁盘多路径 AIXPCM 简介   IBM存储产品对SDDPCM的支持将于2020年6月30日正式终止（EOS）。 AIXPCM全称AIX path control module，是AIX操作系统中替代SDDPCM的默认多路径软件，目前据我了解不需要单独安装，在某个版本后默认在系统里面，如果没有升级到拥有的版本即可。 相关链接 官方相关链接如下： 各版本对应补丁下载：Fix pack information for: AIX PCM RAS Enhancements SDDPCM迁移到AIXPCM说明：How To Migrate SDDPCM to AIXPCM 迁移步骤说明：Migrate to AIXPCM using \"Manage_Disk_Drivers\" Command Spectrum Virtualize存储推荐多路径说明：Spectrum Virtualize Multipathing Support for AIX and Windows Hosts AIX和VIOS系统推荐多路径说明：The Recommended Multi-path Driver to use on IBM AIX and VIOS When Attached to SVC and Storwize storage IBM MPIO多路径说明：IBM AIX multipath I/O (MPIO) resiliency and problem determination lsmpio命令:lsmpio命令 从SDDPCM迁移到AIXPCM 参考官方文档，使用PowerHA环境进行了测试： 操作系统版本：7100-04-05-1720 PowerHA版本：7.2.1.4 外置存储类型：IBM SVC 检查准备 检查AIX PCM 安装包（AIX 7.1）： IV33411 Abstract: AIX PCM RAS Enhancements Fileset devices.common.IBM.mpio.rte:7.1.3.0 is applied on the system. 查看当前使用多路径： # manage_disk_drivers -l |grep -i svc IBMSVC NO_OVERRIDE NO_OVERRIDE,AIX_AAPCM,AIX_non_MPIO # manage_disk_drivers -l |grep -i 2107ds8k 2107DS8K NO_OVERRIDE NO_OVERRIDE,AIX_AAPCM,AIX_non_MPIO 说明： 如果安装了SDDPCM，则值NO_OVERRIDE表示SDDPCM用于配置该系列的设备。如果未安装SDDPCM，则使用AIX默认PCM 对于AIX_AAPCM选项，即使安装了SDDPCM，管理员也可以指示AIX使用AIX默认PCM，修改后重新引导系统即可 修改默认属性： # chdef -a queue_depth=32 -c disk -s fcp -t mpioosdisk queue_depth changed # chdef -a reserve_policy=no_reserve -c disk -s fcp -t mpioosdisk reserve_policy changed # chdef -a algorithm=shortest_queue -c PCM -s friend -t fcpother algorithm changed 对于DS8K: # chdef -a queue_depth=32 -c disk -s fcp -t aixmpiods8k queue_depth changed # chdef -a reserve_policy=no_reserve -c disk -s fcp -t aixmpiods8k reserve_policy changed 说明： 当然也不一定要在修改路径模式前修改，如果本来都是使用的默认值的话 此修改根据需求来定，并不会修改当前磁盘的属性，修改后重新引导系统以修改后的值作为默认值 AIXPCM的默认路径选择算法是fail_over AIXPCM支持shortest_queue算法，该算法类似于SDDPCM的load_balance算法 确认是否使用SDDPCM 如果系统中没有SDDPCM设备，直接删除SDDPCM的安装包即可，查看目前系统有： # pcmpath query device Total Dual Active and Active/Asymmetric Devices : 4 DEV#: 4 DEVICE NAME: hdisk4 TYPE: 2145 ALGORITHM: Load Balance SERIAL: 600507180120262E3000000000000313 ========================================================================== Path# Adapter/Path Name State Mode Select Errors 0* fscsi0/path0 OPEN NORMAL 35 0 1 fscsi0/path1 OPEN NORMAL 2790295 0 2* fscsi1/path2 OPEN NORMAL 35 0 3 fscsi1/path3 OPEN NORMAL 2765410 0 上面命令有输出代表使用了SDDPCM，继续查看： # lsdev -Cc disk hdisk0 Available Virtual SCSI Disk Drive hdisk4 Available 24-T1-01 MPIO FC 2145 修改步骤 在PowerHA备机上进行，首先停掉PowerHA，执行下面命令修改： # manage_disk_drivers -d IBMSVC -o AIX_AAPCM ********************** ATTENTION ************************* For the change to take effect the system must be rebooted 提示需要重启，重新启动系统。 检查确认 系统重新启动后，检查是否还使用SDDPCM： # pcmpath query device No device file found 然后使用lsmpio命令查看： # lsmpio name path_id status path_status parent connection hdisk0 0 Enabled Sel vscsi0 810000000000 hdisk1 0 Enabled Sel vscsi1 810000000000 hdisk4 0 Enabled Clo fscsi0 500507180120c1c4,2000000000000 hdisk4 1 Enabled Clo fscsi0 500507180120c5cb,2000000000000 可以看到NPIV方式过来的存储磁盘没有使用SDDPCM了，继续查看： # manage_disk_drivers -l |grep -i svc IBMSVC AIX_AAPCM NO_OVERRIDE,AIX_AAPCM,AIX_non_MPIO # lsmpio -ar Adapter Driver: fscsi0 -> AIX PCM Adapter WWPN: c0507109681e0006 Link State: Up Paths Paths Paths Paths Remote Ports Enabled Disabled Failed Missing ID 500507180120c1c4 4 0 0 0 0xc95e00 500507180120c5cb 4 0 0 0 0xc95600 Adapter Driver: fscsi1 -> AIX PCM Adapter WWPN: c0507609688e0004 Link State: Up Paths Paths Paths Paths Remote Ports Enabled Disabled Failed Missing ID 500507180110c1c4 4 0 0 0 0xc95400 500507180110c5cb 4 0 0 0 0xc95600 信息对比 以hdisk4为例进行对比前后属性差别，SDDPCM时候VPD信息： # lscfg -vpl hdisk4 hdisk4 U8408.E8E.8490ECW-V2-C24-T1-W500507130110C1A4-L2000000000000 MPIO FC 2145 Manufacturer................IBM Machine Type and Model......2145 ROS Level and ID............0000 Device Specific.(Z0)........0000063268181002 Device Specific.(Z1)........0200602 Serial Number...............600507180110821E3000000000000311 PLATFORM SPECIFIC Name: disk Node: disk Device Type: block 修改后VPD信息： # lscfg -vpl hdisk4 hdisk4 U8408.E8E.8490ECW-V2-C24-T1-W500507110110C1CA4-L2000000000000 MPIO IBM 2145 FC Disk Manufacturer................IBM Machine Type and Model......2145 ROS Level and ID............30303030 Serial Number...............2145 Device Specific.(Z0)........0000063268181002 Device Specific.(Z1)........ Device Specific.(Z2)........ Device Specific.(Z3)........ PLATFORM SPECIFIC Name: disk Node: disk Device Type: block 修改前属性： # lsattr -El hdisk4 PCM PCM/friend/sddpcm PCM True PR_key_value none Reserve Key True algorithm load_balance Algorithm True clr_q no Device CLEARS its Queue on error True dist_err_pcnt 0 Distributed Error Percentage True dist_tw_width 50 Distributed Error Sample Time True flashcpy_tgtvol no Flashcopy Target Lun False hcheck_interval 60 Health Check Interval True hcheck_mode nonactive Health Check Mode True location Location Label True lun_id 0x2000000000000 Logical Unit Number ID False lun_reset_spt yes Support SCSI LUN reset True max_coalesce 0x40000 Maximum COALESCE size True max_transfer 0x40000 Maximum TRANSFER Size True node_name 0x500507110110c1a4 FC Node Name False pvid 00fa90eee3be28e90000000000000000 Physical volume identifier False q_err yes Use QERR bit True q_type simple Queuing TYPE True qfull_dly 2 delay in seconds for SCSI TASK SET FULL True queue_depth 20 Queue DEPTH True recoverDEDpath no Recover DED Failed Path True reserve_policy no_reserve Reserve Policy True retry_timeout 120 Retry Timeout True rw_timeout 60 READ/WRITE time out value True scbsy_dly 20 delay in seconds for SCSI BUSY True scsi_id 0xc95400 SCSI ID False start_timeout 180 START unit time out value True svc_sb_ttl 0 IO Time to Live True timeout_policy fail_path Timeout Policy True unique_id 33213600507110180813E50000000000003F304214503IBMfcp Device Unique Identification False ww_name 0x500507110110c1a4 FC World Wide Name False 修改后属性： # lsattr -El hdisk4 PCM PCM/friend/fcpother Path Control Module False PR_key_value none Persistant Reserve Key Value True+ algorithm shortest_queue Algorithm True+ clr_q no Device CLEARS its Queue on error True dist_err_pcnt 0 Distributed Error Percentage True dist_tw_width 50 Distributed Error Sample Time True hcheck_cmd test_unit_rdy Health Check Command True+ hcheck_interval 60 Health Check Interval True+ hcheck_mode nonactive Health Check Mode True+ location Location Label True+ lun_id 0x2000000000000 Logical Unit Number ID False lun_reset_spt yes LUN Reset Supported True max_coalesce 0x40000 Maximum Coalesce Size True max_retry_delay 60 Maximum Quiesce Time True max_transfer 0x80000 Maximum TRANSFER Size True node_name 0x500507110100c1a4 FC Node Name False pvid 00fa90eee3be28e90000000000000000 Physical volume identifier False q_err yes Use QERR bit True q_type simple Queuing TYPE True queue_depth 20 Queue DEPTH True+ reassign_to 120 REASSIGN time out value True reserve_policy no_reserve Reserve Policy True+ rw_timeout 30 READ/WRITE time out value True scsi_id 0xc95400 SCSI ID False start_timeout 60 START unit time out value True timeout_policy fail_path Timeout Policy True+ unique_id 33213600507110180813E50000000000003F304214503IBMfcp Unique device identifier False ww_name 0x500507110110c1a4 FC World Wide Name False 卸载SDDPCM 使用smit deinstall命令即可： Remove Installed Software Type or select values in entry fields. Press Enter AFTER making all desired changes. [Entry Fields] * SOFTWARE name [devices.fcp.disk.ibm.mpio.rte] + PREVIEW only? (remove operation will NOT occur) yes + REMOVE dependent software? yes + EXTEND file systems if space needed? no + DETAILED output? no + WPAR Management Perform Operation in Global Environment yes + Perform Operation on Detached WPARs no + Detached WPAR Names [_all_wpars] 说明： 卸载devices.fcp.disk.ibm.mpio.rte包即可，REMOVE dependent software?选yes会卸载依赖包 先预览可以看到卸载的三个包，确认后PREVIEW only?选no开始卸载 卸载完成后建议重启下操作系统 卸载结果示例: Installation Summary -------------------- Name Level Part Event Result ------------------------------------------------------------------------------- devices.sddpcm.71.rte 2.6.6.0 ROOT DEINSTALL SUCCESS devices.sddpcm.71.rte 2.6.6.0 USR DEINSTALL SUCCESS devices.fcp.disk.ibm.mpio.r 1.0.0.24 USR DEINSTALL SUCCESS File /etc/inittab has been modified. 验证是否卸载： # lslpp -l |grep sddpcm # pcmpath query device ksh: pcmpath: not found. 后续操作 在PowerHA备节点修改成功及卸载SDDPCM后： 启动备节点PowerHA 从主节点切换资源组到备节点 按照之前步骤修改主节点的多路径方式 总结说明 总结如下： 修改后需要重新启动生效，卸载SDDPCM后也建议重启下操作系统 以上步骤在测试机进行验证，切换正常，没有发现异常，说明对PowerHA没有影响 如果系统中没有SDDPCM设备，直接删除SDDPCM的安装包即可，系统会默认使用AIXPCM MPIO与SDDPCM SDDPCM IBM已经EOS。 简介   AIX系统默认安装了MPIO Disk Path Control Module,SDDPCM(Subsystem Device Driver Path Control Module)是一个可单独安装的软件包，通过AIX MPIO框架为磁盘提供AIX MPIO支持，当支持的设备配置为MPIO-capable设备时，SDDPCM将被加载并成为AIX MPIO FCP（光纤通道协议）/FCoE（以太网光纤通道）设备驱动程序或SAS设备驱动程序的一部分。带有SDDPCM模块的AIX MPIO设备驱动程序或SAS设备驱动程序可增强数据可用性和I/O负载平衡。 MPIO常用命令及示例 查看所有磁盘路径类型（使用了SDDPCM会有所不同）： # lsdev -Cc disk hdisk0 Available 05-08-00-3,0 16 Bit LVD SCSI Disk Drive hdisk1 Available 05-08-00-4,0 16 Bit LVD SCSI Disk Drive hdisk2 Available 05-08-00-5,0 16 Bit LVD SCSI Disk Drive hdisk3 Available 06-08-02 MPIO 2810 XIV Disk hdisk4 Available 06-08-02 MPIO 2810 XIV Disk 查看所有磁盘路径及单个磁盘路径： # lspath # lspath -l hdisk3 Enabled hdisk3 fscsi0 Enabled hdisk3 fscsi1 查看所有磁盘路径（带路径id和及路径连接信息）及单个磁盘路径： # lspath -F \"status name path_id parent connection\" # lspath -F \"status name path_id parent connection\" | grep -w hdisk3 Enabled hdisk3 0 fscsi0 500173800ccd0150,1000000000000 Enabled hdisk3 1 fscsi1 500173800ccd0140,1000000000000 列出所有存储系列及其支持的驱动程序（部分示例）： # manage_disk_drivers -l Device Present Driver Driver Options 2810XIV AIX_AAPCM AIX_AAPCM,AIX_non_MPIO DS4100 AIX_APPCM AIX_APPCM,AIX_fcparray 修改驱动程序，使用AIX_non_MPIO管理2810XIV设备（会有提示需要重启）： manage_disk_drivers -d 2810XIV -o AIX_non_MPIO 查看磁盘路径优先级： # lspath -AHE -l hdisk2 -p vscsi1 attribute value description user_settable priority 1 Priority True 修改磁盘路径优先级,步骤如下： smit mpio MPIO Path Management Change/Show Path Characteristice Change/Show Characteristics for a Device's Path Choose one Devide Name,and then choose one path Change the Priority 命令示例： chpath -l 'hdisk100' -p 'fscsi0' -w '500173800ccd0150,62000000000000' -a priority='1' 禁用及启用vscsi下hdisk2的路径： # chpath -l hdisk2 -p vscsi1 -s disable paths Changed # chpath -l hdisk2 -p vscsi1 -s enable paths Changed 强制删除hdisk2的vscsi0下830000000000路径，然后重新扫描（部分显示）： # rmpath -l hdisk2 -p vscsi0 -w 830000000000 -d path Deleted # cfgmgr -vl vscsi0 ---------------- attempting to configure device 'vscsi0' Time: 0 LEDS: 0x25b3 invoking /usr/lib/methods/cfg_vclient -l vscsi0 Number of running methods: 1 ---------------- Completed method for: vscsi0, Elapsed time = 0 return code = 0 修改磁盘属性示例： # chdev -l hdisk2 -a reserve_policy=no_reserve # chdev -l hdisk2 -a algorithm=load_balance_port # chdev -l hdisk2 -a algorithm=round_robin 路径状态 一共六种状态： Enabled：正常状态 Disabled：手动disable Defined：已定义，ODM库中有信息 Available：包含Enabled和Failed状态 Missing：路径丢失 Failed：路径失败 SDDPCM命令 SDDPCM重要命令及其功能： pcmpath: 显示和管理 SDDPCM 设备。 pcmpath query adapter: 显示适配器配置 pcmpath query version: 显示 SDDPCM 的版本 pcmpath query device: 显示 SDDPCM 设备（pcmpath query device 44 仅显示此设备） pcmpath query essmap: 显示完整概述 pcmpath set device algorithm: 动态更改路径选择算法 pcmpath set device hc_mode: 动态更改路径运行状况检查模式 pcmpath set device hc_interval: 动态更改路径运行状况检查时间间隔 pcmpath set device Mpath N online/offline: 动态启用（联机）或禁用（脱机）路径 pcmpath set adapter N online/offline: 动态启用（联机）或禁用（脱机）适配器（SDDPCM 保留设备的最后一个路径，并且如果该设备正在使用最后一个路径，则会失败） pcmquerypr: 读取并清除暂存的保留和注册密钥 pcmquerypr -vh /dev/hdisk30: 查询并显示暂存的保留（-V 详细模式以及详细信息） pcmquerypr -rh /dev/hdisk30: 释放暂存保留（如果设备被当前主机保留） pcmquerypr -ch /dev/hdisk30: 删除暂存保留并清除所有保留密钥注册 pcmquerypr -ph /dev/hdisk30: 删除暂存保留（如果设备被其他主机保留） pcmgenprkey: 设置或清除所有 SDDPCM 多路径 I/O (MPIO) 设备的 PR_key_value Object Data Manager (ODM) 属性 磁盘重要属性介绍 algorithm（只使用MPIO情况下） algorithm = fail_over：  默认的，某些第三方ODM使用不同的默认值。使用此算法，一次只能将I/O沿一条路径路由；如果用于发送I/O的路径发生故障或被禁用，则会选择列表中的下一个启用的路径，并将I/O路由到该路径。可通过修改每个路径上的path_priority来自定义列表中路径选择的顺序。algorithm = round_robin：  使用此算法，将在磁盘的所有启用路径上分配和激活I/O。可以通过修改path_priority属性来加权沿每个路径路由的I /O百分比；如果路径发生故障或被禁用，则该路径不再用于发送I/O。algorithm = shortest_queue：  该算法的行为与round_robin轻负载时非常相似。当负载增加时，此算法将优先选择活动I/O操作最少的路径。因此，如果一个路径由于存储区域网络（SAN）的拥塞而变慢，则其他较少拥塞的路径将用于更多的I/O操作。该算法将忽略路径优先级值。 algorithm（使用SDDPCM） Failover only (fo 故障转移)：  设备的所有I/O操作都将发送到同一（首选）路径，直到该路径由于I/O错误而failed。发生故障后选择一条备用路径用于后续的I/O操作。Load balancing (lb 负载均衡)：  通过评估每个路径所连接的适配器上的负载来选择用于I/O操作的路径。如果多个路径具有相同的负载，则从这些路径中随机选择一个路径。负载均衡模式还包含故障转移保护。Load balancing sequential (lbs 负载均衡顺序)：  此策略与Load balancing相同，针对I/O顺序进行了优化。负载均衡顺序策略也称为优化顺序策略，这是SDDPCM的默认设置。Round robin (rr 轮循)：  从上一次I/O操作未使用的路径中随机选择用于每个I/O操作的路径。如果设备只有两个路径，那么 SDD 会交替使用这两个路径。Round robin sequential (rrs 轮循顺序)：  该策略与round-robin策略相同，针对顺序 I/O 进行优化。 hcheck_mode（路径运行状况检查模式） hcheck_mode = nonactive：  在此模式下，PCM在没有活动I/O的路径上发送运行状况检查命令，其中包括状态为failed的路径。如果选择的算法是故障转移，那么还将在状态为启用但没有活动I/O的每个路径上发送运行状况检查命令；如果选择的算法为round_robin或shortest_queue，则仅在状态为failed的路径上发送运行状况检查命令；如果磁盘处于空闲状态，则在运行状况检查间隔到期时，会在没有挂起I/O的任何路径上发送运行状况检查命令。 hcheck_mode = enabled：  在此模式下，PCM沿所有启用的路径发送健康检查命令，甚至在健康检查时具有其它活动I/O的路径也是如此。 hcheck_mode = failed：  在此模式下，PCM仅向标记为failed的路径发送路径运行状况检查。 hcheck_interval（路径运行状况检查间隔）   路径运行状况检查间隔是指基于hcheck_mode设置的MPIO路径运行状况检查将探测并检查打开的磁盘的路径可用性的时间间隔（以秒为单位）。当设置hcheck_interval = 0表示禁用MPIO的路径健康检查机制，这意味着任何failed的路径需要人工干预，以恢复或重新启用。  大多数情况下，hcheck_interval为默认最好，设置过小会快速检查路径，以便恢复及尽快启用，但是可能会占用SAN上的大量带宽。  AIX实施紧急最后一次健康检查，以在需要时恢复路径。如果设备只有一条非failed路径，并且在最后一条路径上检测到错误，那么AIX会在重试I/O之前在所有其它failed路径上发送运行状况检查命令，而不管hcheck_interval设置如何。 timeout_policy（超时策略）   此属性指示发生命令超时时PCM应该采取的措施。当I/O操作未能rw_timeout在磁盘上的值内完成时，将发生命令超时。timeout_policy共有三个值（如果在设备上可以设置fail_path，推荐设置为此值）：timeout_policy = retry_path：  在刚刚经历命令超时的同一路径上重试，这可能会导致I/O恢复的延迟，因为该命令可能会在此路径上继续失败，在连续几次失败之后，AIX才会使路径failed并在备用路径上尝试I/O。timeout_policy = fail_path：  假设设备还有至少一条其它路径未处于failed状态，那么单个命令在路径上超时后，将此路径标记为failed，然后强制在其它正常路径上重试I/O，这可以从命令超时中更快地恢复，并且还可以更快地检测到设备的所有路径都failed的情况。系统会通过AIX运行状况检查命令恢复由于超时策略而failed的路径，但是，AIX在恢复后的一段时间内避免将路径用于用户I/O，以确保路径不会出现重复的故障。timeout_policy = disable_path：  此设置会导致路径被禁用。禁用的路径只能通过手动用户干预，使用chpath命令重新启用路径来恢复。 参考链接 IBM官方相关参考链接： MPIO介绍：IBM AIX MPIO SDDPCM介绍与下载：Subsystem Device Driver Path Control Module SDDPCM介绍:Subsystem Device Driver Path Control Module for IBM AIX 其它多路径软件 近期有安装过AIX Host Utilities，但是由于兼容性最后没成功，后期用到了再记录。 "},"05-IBM_Operating_System/01-AIX/08-AIX-网络与通信.html":{"url":"05-IBM_Operating_System/01-AIX/08-AIX-网络与通信.html","title":"AIX-网络与通信","keywords":"","body":"nslookup ssh -v cat /etc/ssh/sshd_config /etc/netsvc.conf hosts mtrace :打印从源到接收方的多点广播路径 traceroute 显示IP信息包至某个网络主机的路由 on remote system: startsrc -s iptrace -a\"-b -d -l 300000000 -a /tmp/iptraceSCPserver.out\" stopsrc -s iptrace ON client system: startsrc -s iptrace -a\"-b -d -l 300000000 -a /tmp/iptraceSCPclient.out\" stopsrc -s iptrace upload iptrace files: FROM CLIENT: /tmp/iptraceSCPclient.out /tmp/iptraceSCPclient.out.old . ...... if exists FROM SERVER: /tmp/iptraceSCPserver.out no -po sb_max=2097152 chdev -l enX -a tcp_recvspace=1048576 -a tcp_sendspace=1048576 no -po sb_max=8388608 chdev -l enX -a tcp_recvspace=4193204 -a tcp_sendspace=4193204 "},"05-IBM_Operating_System/01-AIX/09-AIX-系统管理.html":{"url":"05-IBM_Operating_System/01-AIX/09-AIX-系统管理.html","title":"AIX-系统管理","keywords":"","body":"AIX-系统管理 /etc/inittab文件 作用：控制初始化过程，init命令去调用/etc/inittab文件。 条目格式 在/etc/inittab文件中，条目格式如下: Identifier:RunLevel:Action:Command 冒号既是分隔符也是注释符号，如果要注释掉inittab条目，在条目开头加上冒号： :Identifier:RunLevel:Action:Command 字段简介： Identifier：唯一表示对象的字符串 RunLevel：可以处理该条目的运行级别，运行级别有效地对应于系统中进程的配置，由数字0到9表示 Aciton：告诉init命令如何处理在标识符字段中指定的进程 Command：要执行的shell命令 Action简介： Aciton 描述 respawn 如果进程不存在，启动进程；进程终止后重新启动。如果进程存在，则不执行任何操作，继续扫描/etc/inittab文件 wait 当init命令输入与该条目的运行级别匹配时，启动该进程并等待其终止 once 当init命令输入与该条目的运行级别匹配时，启动该进程，而不等待其终止；当进程终止后，不重启进程 boot 仅在系统启动期间（即init命令在系统启动期间读取/etc/inittab文件时）处理该条目 bootwait 系统启动后，在init命令第一次从单用户状态变为多用户状态时，处理该条目 powerfail 仅当init命令收到电源故障信号（SIGPWR）时，才执行与此条目相关的过程 powerwait 仅当init命令收到电源故障信号（SIGPWR）时，才执行与该条目关联的过程，并等待其终止，然后继续处理/etc/inittab文件 off 如果与此条目关联的进程当前正在运行，发送警告信号（SIGTERM），并等待20秒钟，然后使用kill信号（SIGKILL）终止该进程。如果该进程未在运行，忽略此条目。 ondemand 在功能上与respawn相同，除了此操作适用于a，b或c值，不适用于运行级别 initdefault 仅在最初调用init命令时才扫描具有此操作的条目 sysinit 在init命令尝试访问控制台之前（登录之前），将执行这种类型的条目 条目操作 将记录添加到/etc/inittab文件中格式及示例： mkitab Identifier:Run Level:Action:Command mkitab tty002:2:respawn:/usr/sbin/getty /dev/tty2 更改/etc/inittab文件中记录的格式及示例（改成运行级别在2和3上运行）： chitab Identifier:Run Level:Action:Command chitab tty002:23:respawn:/usr/sbin/getty /dev/tty2 列出/etc/inittab文件中记录： lsitab -a lsltab 删除/etc/inittab文件中记录： rmitab IBM官方介绍：https://www.ibm.com/support/knowledgecenter/ssw_aix_72/filesreference/inittab.html PowerHA中对/etc/inittab文件的操作: https://www.ibm.com/support/knowledgecenter/SSPHQG_7.2/admin/ha_admin_etcinittab.html 待补充 "},"05-IBM_Operating_System/01-AIX/10-AIX-系统性能.html":{"url":"05-IBM_Operating_System/01-AIX/10-AIX-系统性能.html","title":"AIX-系统性能","keywords":"","body":"AIX-系统性能 记录一些常见的AIX系统性能查看分析知识。 CPU性能 官方参考文档 AIX官方性能数据收集脚本：AIX MustGather: System Performance Analysis amepat -N svmon -G iostat -t 1 5 131 lparstat 7274 topas 4130 vmstat IBM AIX: Performance Analysis Using iperf "},"05-IBM_Operating_System/01-AIX/11-AIX-常见问题.html":{"url":"05-IBM_Operating_System/01-AIX/11-AIX-常见问题.html","title":"AIX-常见问题","keywords":"","body":"AIX-常见问题 记录一些常见的AIX系统问题。 系统升级问题 升级时空间报错 升级版本过程中报错： AIX 6.1 Not enough disk space for sni_lv. 问题说明： sni_lv is an lv that is temporarily created during the install but needs 256M of space to be created. Encouraged the customer to reduce the size of a fs to have at least 256 MB free in the rootvg, then retry the installation. 解决方法：保证rootvg里面至少有256M的空余空间，再升级过程中会创建一个临时文件需要需要空间。 升级bosboot报错 升级AIX系统过程中报错： 0503-409 installp: bosboot verification starting... 0503-497 installp: An error occurred during bosboot verification processing. 查看boot信息重建bosboot命令都可以执行： bootlist -m normal -o bootlist -v bosboot -ad /dev/hdisk0 bosboot -ad /dev/hdisk1 bootlist -m normal hdisk0 hdisk1 再次尝试升级还是同样报错，解决方法： 如果hdisk0是引导设备，那么下面命令输出应该是这样的： #ls -l /dev/rhdisk0 /dev/ipldevice crw------- 2 root system 20, 0 Apr 07 2004 /dev/ipldevice crw------- 2 root system 20, 0 Apr 07 2004 /dev/rhdisk0 如果/dev/ipdevice丢失或者不正确, 重建链接即可，示例： #ln -f /dev/rhdisk0 /dev/ipldevice 再次尝试升级成功。 系统升级提示差JAVA包 AIX7232升级到AIX7236最后报了一个包安装不上，提示需要JAVA包： Requisite Failures ------------------ SELECTED FILESETS: The following is a list of filesets that you asked to install. They cannot be installed until all of their requisite filesets are also installed. See subsequent lists for details of requisites. sysmgt.cfgassist 7.2.3.16 # Configuration Assistant MISSING REQUISITES: The following filesets are required by one or more of the selected filesets listed above. They are not currently installed and could not be found on the installation media. Java8_64.sdk # Base Level Fileset 下载Java8_64.jre和Java8_64.sdk后安装，先安装Java8_64.jre，示例： # gunzip Java8_64.jre.tar.gz # tar -xvf Java8_64.jre.tar # inutoc . # smit installp 下载地址：IBM Java for AIX Reference: Service Information and Download Guide 系统升级后SSH用不了 AIX7232升级到AIX7236后，使用ssh或者scp时候都会报错： /etc/ssh/sshd_config line 40: Bad SSH2 cipher spec \\ 'aes128-cbc,aes192-cbc,aes256-cbc,blowfish-cbc,arcfour,\\ aes128-ctr,aes192-ctr,aes256-ctr,arcfour256,arcfour128'. 不止cipher，还有MAC也有此样报错，用下面命令逐一检查cipher和MAC： # sshd -t -o Ciphers=aes128-cbc # sshd -t -o MACs=hmac-ripemd160 有报错提示bad的，从ssh_config文件中完全删除密码行。验证新密码列表： # ssh -Q cipher # ssh -Q MAC 官方说明：IBM AIX: 'Bad SSH2 cipher spec' Error Upon Starting sshd 运行上面命令同时，还会发现如下报错： Deprecated option RhostsAuthentication 启动sshd服务时候也会报，这个是新系统已经废弃选项，在文件sshd_config中注释掉即可。 提示用户组非已知 报错示例如下： sysck: 3001-038 The name mail is not a known group for entry /usr/bin/bellmail. sysck: 3001-003 A value must be specified for group for entry /usr/bin/bellmail. ... sysck: 3001-038 The name printq is not a known group for entry /usr/bin/chquedev. sysck: 3001-003 A value must be specified for group for entry /usr/bin/chquedev. sysck: 3001-017 Errors were detected validating the files for package bos.rte.printers. 0503-464 installp: The installation has FAILED for the \"usr\" part of the following filesets: bos.rte.printers 7.2.3.17 installp: Cleaning up software for: bos.rte.printers 7.2.3.17 创建提示的用户组再执行升级即可： mail用户组：name=mail,id=6,admin=true printq用户组：name=mail,id=6,admin=true,users=lp 命令反应慢 系统资源问题 现象： ping此机器ip会有比较慢，有几毫秒 ssh过去时候等半天才弹出输密码界面 登录进去后敲任何命令都比较慢 系统CPU资源没爆但是使用比较高 rootvg有磁盘使用率100% 原因：有大文件在持续向rootvg里面磁盘写入，并且只是写入其中一块，导致其100%，所以系统慢。 系统资源空闲   系统正常运行，但是登录特别慢，登录成功后输入命令反应也特别慢，系统资源也不是很紧张，文件系统也没爆。刚开始怀疑DNS问题，检查没发现问题，再检查日志有大量以下报错： 3A30359F 1030230010 T S init SOFTWARE PROGRAM ERROR 报错详细内容： Detail Data SOFTWARE ERROR CODE Command is respawning too rapidly. Check for possible errors. COMMAND id: audit \"/usr/sbin/audit start # System Auditing\"   检查/etc/inittab文件，关于此命令的条目Aciton项设置是respawn,此设置表示如果进程不存在，启动进程；进程终止后重新启动。结合报错信息:Command is respawning too rapidly,说明执行过于频繁导致其它命令反应比较慢，检查命令是否有问题。 磁盘问题 rootvg磁盘missing   rootvg有两块磁盘，都是通过vscsi过来的，vios端路径全部丢失，但是已经恢复了，vioc系统中还是现实missing昨天，部分lv处于stale状态。 如果丢失磁盘上有lg_dumplv，需要先修改dump： # sysdumpdev -P -p /dev/sysdumpnull 确认磁盘路径是恢复的，激活一下VG： # varyonvg rootvg 磁盘状态恢复正常，镜像自动同步，等待完成即可，改回dump配置： # sysdumpdev -P -p /dev/lg_dumplv 如果直接修改磁盘状态是不成功的(即使修改了dump配置）： smit chpv Change Characteristics of a Physical Volume Physical volum STATE from not active to active 引导问题 savebase failed 当解除rootvg镜像时候报错： 0516-1734 rmlvcopy:Warning,savebase failed.Please manually run 'savebase' berfore rebooting. 可能原因引导只在一块盘中，而解除镜像的盘正好是引导所在的盘，把引导添加进去即可： # bosboot -ad /dev/hdiskX # bootlist -m normal hdiskX # savebase 删除磁盘报错 当rmdev删除某个磁盘时候报错: rmdev 0514-508 Connot save the base customized infomation on /dev/ipldevice 原因应该也是hd5里面的boot信息没有了，处理方法： # bosboot -ad /dev/hdiskX # bootlist -m normal hdiskX # synclvodm -P -v rootvg hd5丢失 执行某些命令时候可能有报错如下： 0514-508 Cannot save the base customized information on /dev/ipldevice. 0514-609 Unable to save the base customized information on /dev/ipldevice. 检查LV，可能是hd5引导lv被删掉了，重建lv命令： # mklv -y hd5 -t boot -a e rootvg 1 如果创建失败，先删掉odm库信息： # odmdelete -q name=hd5 -o CuDv # odmdelete -q name=hd5 -o CuAt 创建成功后同步lv： # synclvodm -P -v rootvg 然后查看lv信息： # lslv -m hd5 查看引导盘信息： # bootinfo -b 里面会现实hd5所在在盘hdiskX，往里面写入引导信息： # bosboot -ad /dev/hdiskX 如果写入失败，加入lv名称： # bosboot -ad hdiskX -l hd5 如果rootvg是双盘镜像，镜像lv到另外一个块盘，写入引导信息： # bosboot -ad hdiskXX -l hd5 最后添加引导列表信息： # bootlist -m normal hdiskX hdiskXX 删文件报错 rm命令报错 当使用rm命令删除大量文件时候，会有如下报错： # rm testfile* ksh: /usr/bin/rm: 0403-027 The parameter list is too long. 报错说明   此错误表示已达到ARG_MAX值。 ARG_MAX的值为24,576 字节，在/usr/include/sys/limits.h文件中设置。此值无法更改，因为它已编译到列出的命令中。 这是传递给正在运行的命令的字节数，在此实例中表示正在执行的文件的名称。 解决方法一 先查找然后递归方式删除，示例如下： # find . -xdev -exec rm -r {} \\; 解决方法二 或者修改参数： # smitty chgsys ARG/ENV list size in 4K byte blocks [6] change ARG/ENV list size in 6K byte blocks to 1024 或者使用命令： chdev -l sys0 -a ncargs=64 删除完成后，修改回来即可 其它问题 错误代码0403-059 执行某些命令时候会收到0403-059报错，示例如下： /etc/reducevg[436]: Mb_pending:0403-059 There cannot be more than 9 levels of recursion   这不是AIX问题，是如何获取.profile的问题，如果是要到root用户，使用su root而不是使用su - root可以解决问题。官方参考链接：Receive 0403-059 There cannot be more than 9 levels of recursion during Informix Install. 待补充 "},"05-IBM_Operating_System/01-AIX/12-AIX-系统或软件安装.html":{"url":"05-IBM_Operating_System/01-AIX/12-AIX-系统或软件安装.html","title":"AIX-系统或软件安装","keywords":"","body":"AIX-系统或软件安装 记录系统安装及一些常见的软件安装方法。 系统安装 软件安装 安装OpenSSL和OpenSSH 官方参考链接：Downloading and Installing or Upgrading OpenSSL and OpenSSH 下载安装包 需要下的安装包: OpenSSH_8.1.102.2104.tar.Z openssl-1.1.1.1200.tar.Z 下载链接： OpenSSH: https://www.ibm.com/resources/mrs/assets?source=aixbp&S_PKG=openssh OpenSSL: https://www.ibm.com/resources/mrs/assets?source=aixbp&S_PKG=openssl All available packages: https://www.ibm.com/resources/mrs/assets?source=aixbp 升级安装步骤 创建临时目录，上传安装包： # mkdir /tmp/newOpenSSL # mkdir /tmp/newOpenSSH 备份SSH配置文件夹： # cp -pr /etc/ssh /etc/ssh_backup 解压OpenSSL： # cd /tmp/newOpenSSL # uncompress openssl-1.1.1.1200.tar.Z # tar -xvf openssl-1.1.1.1200.tar # cd 安装OpenSSL： smitty install 选择Install and Update Software->Install Software INPUT device / directory for software [.] 输入当前目录. SOFTWARE to install [_all_latest] 按F4、/然后查找ssl匹配项，选中回车 \"ACCEPT new license agreements?\" [yes] (Tab键) 安装完成后的sshd命令位于/usr/sbin目录，配置文件位于/etc/ssh目录 解压OpenSSH： # cd /tmp/newOpenSSH # uncompress OpenSSH_8.1.102.2104.tar.Z # tar -xvf OpenSSH_8.1.102.2104.tar # cd 安装OpenSSH： smitty install 选择Install and Update Software->Install Software INPUT device / directory for software [.] 输入当前目录. SOFTWARE to install [_all_latest] 按F4、/然后查找SSH匹配项，选中回车 \"ACCEPT new license agreements?\" [yes] (Tab键) 检查服务状态： # lssrc -g sshd 备份新的版本配置： # cp -p ssh_config ssh_config.orig_ # cp -p sshd_config sshd_config.orig_ 恢复ssh host keys： # cd /etc/ssh_backup # cp -pr cp ssh_host_*_key* /etc/ssh 重启SSHD服务： # startsrc -s sshd # stopsrc -s sshd 待补充 "},"05-IBM_Operating_System/02-AS400/":{"url":"05-IBM_Operating_System/02-AS400/","title":"AS400","keywords":"","body":"AS/400 简介 IBM i：创新平台 - 由创新者创造，为创新者享有。 AS/400官方主页：https://www.ibm.com/cn-zh/it-infrastructure/power/os/ibm-i 内容 AS400-检查&日志收集 AS400-系统基本知识 AS400-常用命令 AS400-常用操作 AS400-磁盘管理 AS400-系统性能 AS400-作业管理 AS400-子系统管理 AS400-备份与恢复 AS400-网络与通信 AS400-程序开发相关 AS400-DB2 AS400-i_Access AS400-学习笔记 "},"05-IBM_Operating_System/02-AS400/01-AS400-检查&日志收集.html":{"url":"05-IBM_Operating_System/02-AS400/01-AS400-检查&日志收集.html","title":"AS400-检查&日志收集","keywords":"","body":"AS/400-检查&日志收集 记录日常数据收集方法和检查命令。 AS/400-日志收集 HMC和ASMI日志收集   AS/400系统安装在Power系列小型机上，硬件故障会记录在操作系统日志里面，也会记录在HMC和ASMI中。AS/400系统日志可以进行硬件故障判断，有些情况下需要二者结合。 硬件类型非操作系统日志收集具体可以参考：Power-小型机数据收集 操作系统日志   AS/400日志类型也比较多，输入命令WRKPRB可以查看系统Problems。通常需要下载spool file形势下载日志，官方参考下载方法文档：How to download spool files - Small, Medium, Large - and in the correct ASCII format 打印错误日志 收集方法如下： 输入命令：PRTERRLOG，然后按F4 选择log类型，输出方式时间以及格式等，然后回车执行 执行命令：WRKSPLF可以查看收集日志信息 进入IBM i Access 的打印机输出选项中取出来 命令PRTERRLOG官方介绍：PRTERRLOG WRKPRB收集 收集方法如下： 执行命令：WRKPRB 在需要打印的日志条目前面输入6(Print detailes),回车确认 WRKSPLF可以查看及IBM i Access取出来 Job log收集 收集方法如下： 输入命令DSPJOBLOG，然后按F4 选项JOB中内容可以根据需求输入 选项OUTPUT中输入*PRINT WRKSPLF可以查看及IBM i Access取出来 History Log收集 收集方法如下： 输入命令DSPLOG，然后按F4 选项PERIOD中开始时间和结束时间可以根据需求输入 选项OUTPUT中输入*PRINT WRKSPLF可以查看及IBM i Access取出来 高级分析命令输出收集 例如收集命令SMIASPRESOURCES输出： STRSST进入SST 选择选项1. Start a service tool 选择选项4. Display/Alter/Dump 选择选项2. Dump to printer 选择选项2. Licensed Internal Code (LIC) data 选择选项14. Advanced analysis 进入Select Advanced Analysis Command屏幕，在Option第一行中输入1(Select)，然后在后面输入命令SMIASPRESOURCES 回车确认，进入Specify Advanced Analysis Options屏幕，默认设置，回车确认 会生成一个spool file，通过IBM i Access取出来即可 Product Activity Log 收集方法如下： 执行命令:STRSST进入SST 输入SST用户名和密码，密码区分大小写 主菜单命令行输入1选择Start a Service Tool，回车确认 输入1选择Product Activity Log，回车确认 输入1选择Analyze log，回车确认（选项有6种，根据需求选择） Log选项选择1（根据不同需求选择），时间根据需求填入，回车确认 Report type项输入3选择Print options，其它默认，回车确认 同样WRKSPLF可以查看及IBM i Access取出来 AS/400-性能数据收集 如果有idoctor可以直接在idoctor上查看性能数据或者收集。 Collection Services数据收集 CS数据收集： Go Perform Selection 7.Display performance data (or DSPPFRDTAto this menu) 可以看到库文件是QPFRDATA，member是每天的性能数据，记住需要收集member名称 回到主菜单，在临时库下创建一个savf，例如临时库叫IBM：CRTSAVF IBM/PERFDATA0910，或者自己建一个库，savf名字自定义，使用CRTSAVF也行 创建后查看savf：DSPLIB IBM 开始收集性能数据，输入SAVOBJ进入Save Object菜单 按F9显示更多属性 第一行Objects选项输入之前记下的性能数据member名称 第二个选项Library输入member所在的库，也就是QPFRDATA 选项Device项输入*SAVF 选项Save file输入之前定义的savf名称：PERFDATA0910 选项Library输入savf所在的Library：IBM，或自定义的库名称 回车确认，提示保存成功 查看是否成功：DSPSAVF IBM/PERFDATA0910 说明： 如果比较大并且需要上传到指定位置，建议SAVF时候启用压缩 如果需要从SAVF恢复性能数据，Restore选项中Saved library填入名称必须和保存时候一致 可以将数据恢复到其它库，需要在Restore to library中填入指定的LIB AS400 Trace生成并收集 Job Trace 启动Trace（必须有*SERVICE特殊权限）： STRTRC（指定被跟踪的目标作业、跟踪的大小和类型以及在跟踪数据慢时要采取的操作） 选项Session ID里面填入自定义名称，例如MyTrace 选项Jobs填入名称用户等： 选项Job name为需要追踪的名称，例如为：BACKUP 选项User填入对应的用户ID，例如：QSECOFR 选择Number为*all 选项Thread ID to include根据需求填入或空着 选项Job types默认*all 选项Maximun storage to use根据需求填入，例如：10000000，单位为KB 选项Trace full根据需求选择*STOPTRC或*WRAP 选项Trace type根据需求选择或直接*ALL 按F9后还有附加参数 选项Trace type下： 选项Component选择*NONE 选项Trace level根据需求或者空着 选项Trace filter一般*NONE 选项Restart after next IPL一般*NO 选项Watch for message下Message identifier一般*NONE，其它空着 选项Watched message queue下： 选项Message queue填入*SYSOPR 选项Library填入*LIBL 回车确认 说明： 增加最大存储使用量也很重要，对于大多数问题，默认值可能不够大 如果希望在IPL之后重新启动跟踪，附加参数下的选项Restart after next IPL输入*YES 如果希望在找到消息ID时自动结束跟踪，请将其添加到消息标识符参数中。如果在跟踪中遇到消息，它将自动结束。被监视的消息队列允许指定被监视的消息的来源 TRCJOB是过时的Trace命令。在当前版本中，TRCJOB命令将发出STRTRC 结束Trace： ENDTRC（用于关闭或用户打印Trace） 选项Session ID输入之前定义并启动的Trace名称 选项Data option输入*LIB 选项Data Library输入*CURLIB 选项Replace data输入*YES 选项Print trace data输入*NO 说明： 上面示例指定了要结束的Trace名称，并且现在不要选择打印Trace的选项 如果在监视特定消息ID时自动结束Trace，则无需使用此命令 打印Trace： PRTTRC（用于打印Trace，如未在ENDTRC上指定） 选项Data Member输入之前定义并启动的Trace名称，例如Mytrace 选项Data Library输入*CURLIB 选项Select jobs输入*ALL，下面用户和数量可以空着 选项Delete trace输入*YES 选项Sort by输入*THREAD 选项Output输入*PRINT 说明： 如果打印Trace，选择删除Trace将清除Trace成员 打印选项将为用户的当前作业创建一个Spooled File CL命令示例： STRTRC SSNID(MYTRACE) JOB((*ALL/QSECOFR/BACKUP)) MAXSTG(10000000) TRCFULL(*STOPTRC) ENDTRC SSNID(MYTRACE) DTALIB(TRACELIB) PRTTRC DTAMBR(MYTRACE) DTALIB(TRACELIB) 官方参考链接： IBM i 7.2 Job tracing STRTRC - Starting a Job Trace Job TCP/IP trace   使用Trace TCP/IP Application(TRCTCPAPP)命令必须具有具有*SERVICE特殊权限的用户配置文件。输入下面CL命令开始Trace： TRCTCPAPP *DDM 如果要将Trace限制到某个端口，例如SSL的448端口： TRCTCPAPP *DDM *ON RMTNETADR(*INET *N '255.255.255.255' 448) 正在进行的Trace完成后，运行以下命令并查看生成的spooled file： TRCTCPAPP *DDM *OFF 说明： 如果跟踪了多个连接，则需要定位spooled file并将其与每个QRWTSRVR作业匹配 将Trace TCP/IP Application (TRCTCPAPP)命令与*DDM应用程序一起使用时，可以Trace单个发送或接收的消息的最大数据量限制为6000字节 与 *DDM 应用程序一起使用的限制 官方参考链接： TCP/IP communications trace Trace TCP/IP Application (TRCTCPAPP) Communications Trace for TCP/IP Printers (R510 and Above) Communications Trace for TCP/IP Printers Using the STRCMNTRC Command How do I start an AS/400 trace of communications on behalf of DB2 DataPropagator for AS/400? FTP数据传输 可以使用FTP传输savf： ftp 192.168.0.100 BIN quote site namefmt 1(PCD到AS400之间用此，如果是AS400之间用namefmt 1) cd /QSYS.lib/IBM.lib(如果是在IBM这个Library) lcd (PC本地路径或者本地AS400的库位置，例如/QSYS.lib/IBM.lib GET PERFDATA0910.savf(注意后缀) 如果是unix那种Links，示例： 230 QSECOFR logged on. ftp> bin 200 Representation type is binary IMAGE. ftp> get /tmp/E980_SYSSNAP_202105131040.zip 200 PORT subcommand request successful. 150-NAMEFMT set to 1. 150 Retrieving file /tmp/E980_SYSSNAP_202105131040.zip 226 File transfer completed successfully. 如果是iASP，需要设置，示例： QUOTE RCMD SETASPGRP TEMASP 命令官方参考链接：QUOTE (Send a Subcommand to an FTP Server) AS/400-系统检查 日常检查： 查看是否有硬件错误：WRKPRB 查看历史日志内容：DSPLOG，指向条目按F1查看详细 检查硬盘空间:WRKDSKSTS,检查是否超过80% 检查cpu 内存：WRKSYSSTS 检查系统消息：DSPMSG QSYSOPR 检查系统状态：WRKSYSACT 检查share pool：WRKSHRPOOL 检查SST：STRSST 检查PLOG 检查SA LOG 检查VLOG 检查磁盘状态和路径 检查CUP状态：WRKSYSSTS 检查MEMMORY\\DISK状态和使用率：WRKDSKSTS 网络状态检查： IP:NETSTAT *IFC或CFGTCP--1（Work with TCP/IP interfaces）--F11 Route：NETSTAT *RTE 网络端口：NETSTAT *CNN HA检查 WRKCLU -- 6(Work with cluster nodes)确保所有节点均为Active状态 检查IASP状态：DSPASPSTS ASPDEV(IASPNAME) 检查系统补丁状态：go ptf 检查系统软件状态：go licpgm 检查msgq，检查有无高级别信息:DSPMSG QSYSOPR 检查job状态：WRKATCJOB 物理硬件资源检查： 检查CPU内存等资源（数量/位置/FUR/SN)：WRKHDWRSC TYPE(*PRC) 检查网卡等资源：WRKHDWRSC(WRKHDWRSC *CMN) 检查光纤卡等设备：WRKHDWRSC(WRKHDWRSC *STG) 检查Spooled： 检查所有Spool文件：WRKSPLF 检查splf数量：WRKOUTQ 检查ASP状态：WRKDEVD *ASP 检查用户Profile：WRKUSRPRF USRPRF(BONDHUANG) 检查是否开启自动清理：CHGCLNUP AS400系统ASP清理 删除Journal receiver 可以删除处于SAVED和ONLINE状态的Journal receiver，查看日志接收器： DSPOBJD OBJ(*ALL) OBJTYPE(*JRNRCV) 例如我看到有QAUDJR0001和QAUDJR0002比较大。使用下面命令删除： DLTJRNRCV JRNRCV(QSYS/QAUDJR0001) DLTJRNRCV JRNRCV(QSYS/QAUDJR0002)   QAUDJR0001成功删掉，但QAUDJR0002提示删不掉。因为正在使用，并且提示状态attached下无法删除。使用下面命令查看状态： DSPJRNRCVA JRNRCV(QSYS/QAUDJR0002) 在下面命令下进行删除操作也不行： WRKJRNRCV JRNRCV(*ALL/*ALL) 使用如下命令新建一个Journal receiver，自动生成名称为QAUDJR0003： CHGJRN QSYS/QAUDJRN JRNRCV(*GEN)   然后再次查看QAUDJR0002状态为ONLINE，建议使用SAVOBJ命令保存备份（生产环境很有必要），然后再使用删除命令删除： DLTJRNRCV JRNRCV(QSYS/QAUDJR0002) 清理CS性能数据的系统库 首先停掉性能数据收集，ENDPFRTRC命令或者： GO PERFORM 2 Collect performance data 3 Stop collect performance data 如需要性能数据，先备份，然后执行命令清理： CLRLIB LIB(QPFRDATA) 启动CS数据收集，STRPFRTRC命令或者： GO PERFORM 2 Collect performance data 1 Start collect performance data 删除Spooled文件 首先删除无用Spooled文件： 命令WRKSPLF 找到需要删除的Spooled文件，选择4=Delete删除即可   执行命令RCLSPLSTG(Reclaim Spool Storage)命令回收未使用超过用户指定天数的Spooled文件的未使用存储，示例如下： RCLSPLSTG DAYS(30)   此命令回收系统辅助存储池(ASP 1)和所有已定义基本用户ASP(ASP 2-32)中超过30天未使用的假脱机文件的所有未使用存储。 检查自动清理 检查步骤如下： 输入命令CHGCLNUP后按F4 查看参数ALWCLNUP(Allow cleanup)为*YES 查看参数USRMSG(Number of days to keep)下面设置是否合理 QMGTOOLS   QMGTOOLS全称Must Gather Data Collector Tool，是一组工具，可帮助各个团队收集有关其产品问题的数据。官方参考链接： QMGTOOLS: Must Gather Data Collector User's Guide QMGTOOLS: How to check and update QMGTOOLS MustGather: How to obtain and Install QMGTOOLS and keep it current QMGTOOLS SAVF下载地址 QMGTOOLS安装   安装方式很多，可以安装相应的PTF，也可以通过iDoctor进行安装，或者直接手动restore savf。使用最简单方式，下载SAVF后restore，例如下载的是qmgtool740.savf，首先传输到HQLIB库中，restore命令示例如下： RSTLIB SAVLIB(QMGTOOLS) DEV(*SAVF) SAVF(HQLIB/QMGTOOL740)   运行GO QMGTOOLS/MG命令可以进入主菜单，或者先运行命令ADDLIBLE QMGTOOLS后，可以直接输入GO MG进入主菜单。菜单示例如下： MG Must Gather Data Collector (C) COPYRIGHT IBM CORP. 2009, 2012 Select one of the following: 1. System Snapshot 14. External Storage 2. HA (High Availability) 15. Work Management 3. Performance/Misc collection 16. Internals 4. Client/Server 17. Electronic Services 5. Communications menu 18. 6. Database menu 19. Hardware data collection 7. CTA/EWS (JAVA/HTTP/DCM/WAS) 20. HMC menu 8. Save/Restore menu 9. Misc tools 22. QSPTLIB menu 10. FTP data to IBM 23. FTP spoolfile to IBM 11. View FTP to IBM statuses 24. PTF menu 12. Display build date 25. Store FTP2IBMCMD credentials 13. Check IBM for updated QMGTOOLS 26. QMGTOOLS Help MGTOOLS收集数据 参考链接:IBM Support QMGTOOLS: Collect ECS/ESA data 集群数据收集 如果iASP使用的High Availability，收集集群信息步骤： GO MG进入主菜单 选择选项2. HA (High Availability) 选择选项1. Collect/retrieve cluster data from multiple nodes 进入到DMPCLU屏幕，在SYSSNAP选项中输入Y 收集完成后，会提示日志压缩文件zip的路径，下载到本地即可 系统Snapshot收集 收集System Snapshot步骤如下： GO MG进入主菜单 选择选项1. System Snapshot 进入选项屏幕，根据需求 收集完成后，会提示日志压缩文件zip的路径，下载到本地即可 PowerHA日志收集 官方参考链接：MustGather: IBM i High Availability Master Document for Data Collection IBM i PowerHA only 官方参考链接：PowerHA: How To Use QMGTOOLS MustGather Data Capture Tool (for High Availability Only) PowerHA Tools IASP Manager   收集数据以执行PowerHA IASP Manager Toolkit相关问题的调试，收集的数据生成zip文件，收集命令示例： QZRDHASM/DMPINF ENV(*Name of environment) 收集说明： 如果调试FlashCopy问题，最好在FlashCopy源节点和目标节点上运行命令 如果调试Metro Mirror(MMIR)、Global Mirror(GMIR)或LUN Switch(LUN)问题，最好在环境的源节点和目标节点上运行命令 如果不确定，最好在集群中的所有节点上运行命令 官方参考链接：MustGather: High Availability-PowerHA Tools IASP Manager Toolkit PowerHA Tools Full System Manager Toolkit 官方参考链接：MustGather: High Availability-FSFC(Full System Flashcopy) Cross-Reference文件问题 官方收集数据参考链接：MustGather: System Cross-Reference File Problems 待补充 "},"05-IBM_Operating_System/02-AS400/02-AS400-系统基本知识.html":{"url":"05-IBM_Operating_System/02-AS400/02-AS400-系统基本知识.html","title":"AS400-系统基本知识","keywords":"","body":"AS/400-系统基本知识 简单记录AS/400系统基本知识。参考链接： IBM i 词汇表 IBM i 概念 IBM i官方补丁推荐： IBM Support Access to PTF Cover Letters 系统基本概念 基本概念有： Job：作业（JOB) File systems：文件系统 Queue：队列(QUEUE) Subsystem：子系统(SBS) Message：消息(MSG) Objects：对象(OBJ) System Value：系统值(SYSVAL) Description：描述(Description） Security and User Authority：安全性和用户权限 Logs and Journals：记录和日志 Software fixes:软件修订 IBM i commands：IBM i命令 作业（JOB) 基础知识   由操作系统执行的所有工作都称为作业。作业是操作系统组织、跟踪和处理工作的方式。作业通常包括系统完成特定任务所需的全部信息。作业可以分为如下几类： Interactive jobs：交互式作业是在用户登录显示站时开始并在用户注销时结束的作业 Batch jobs：批处理作业是提交给系统的一组预定义的处理操作，在用户和系统之间几乎没有交互或没有交互的情况下执行 Autostart jobs：自启动作业是执行重复性工作、与特定子系统关联的一次性初始化工作、为应用程序初始化功能或为同一子系统中的其他作业提供集中服务功能的批处理作业 Prestart jobs：预启动作业是在收到工作请求之前开始运行的批处理作业 Communication jobs：通信作业是由来自远程系统的程序启动请求启动的批处理作业 Reader and writer jobs：Reader作业是spooled input作业, writer作业是spooled output作业 Server jobs：服务作业在系统后台连续运行的作业 System jobs：系统作业由操作系统创建，用于控制系统资源和执行系统功能 官方参考链接： IBM i 7.3 Job IBM i 7.3 Job types IBM i 7.3 Job description IBM i 7.3 Work with Job (WRKJOB) IBM i 7.3 Managing jobs 常用命令 命令 描述 WRKACTJOB Work with Active Jobs WRKACTJOB SBS(QBATCH) Work with Active Jobs(Subsystem/Job:QBATCH) WRKJOBSCDE Work with Job Schedule Entries SBMJOB submit job File systems文件系统   文件系统是使用户能够访问按逻辑单元组织的存储器的特定段。系统上的这些逻辑单元是文件、目录、库和对象。IBM i 中文件系统分类： “根”(/) 文件系统 开放式系统文件系统(QOpenSys)：QOpenSys文件系统与基于UNIX的开放式系统标准兼容 用户定义的文件系统(UDFS)：用户定义的文件系统(UDFS)位于用户选择的辅助存储池(ASP)或者独立辅助存储池(ASP)中 库文件系统(QSYS.LIB)：QSYS.LIB文件系统支持IBM i库结构 独立ASP QSYS.LIB：独立ASP QSYS.LIB文件系统支持用户创建和定义的独立辅助存储池(ASP)中的IBM i库结构 文档库服务文件系统 (QDLS)：通过此文件系统能够访问文档和文件夹 光盘文件系统(QOPT)：QOPT文件系统能够访问存储在光学介质上的流数据 IBM i NetClient文件系统(QNTC)：QNTC文件系统能够访问存储在正运行Windows NT4.0或更高版本或者Linux操作系统的 Integrated xSeries Server(IXS)上的数据和对象 IBM i 文件服务器文件系统(QFileSvr.400)：QFileSvr.400文件系统对远程 IBM i平台上的其他文件系统提供了透明访问。通过分层目录结构来进行访问。 网络文件系统(NFS)：网络文件系统(NFS)使用户能够访问存储在远程NFS服务器上的数据和对象 官方参考链接：IBM i 7.3 文件系统 库文件系统 (QSYS.LIB)   查看库文件的对象和成员可以使用命令STRPDM,然后选择对应的选项进行搜索即可，在本文档同条目中《程序开发相关》小节中有相关操作。 常用命令： 命令 描述 WRKLIB Work with Libraries DSPLIB Display Libraries DSPLIBL Display Library List 注意事项： QSYS.LIB文件系统不区分对象名称中的大小写字符 无论对象名称中的字符采用大写还是小写，搜索对象名称时将获得相同的结果 官方参考链接： IBM i 7.3 库文件系统 (QSYS.LIB) 队列(QUEUE) 三种基本队列（QUEUE）: 消息队列（Message Queue）-等待显示的信息 作业队列（Job Queue）-等待处理的后台批作业 输出队列（Output Queue）-等待打印的Spooled File 参考链接： IBM i 7.3 管理消息队列 IBM i 7.3 Managing job queues IBM i 7.3 Managing output queues IBM i 7.3 Managing replication queues 消息队列（Message Queue） 可使用的系统队列如下： QSYSOPR：系统操作员消息队列，包含需要操作员回复的系统消息 QSYSMSG：可选消息队列，保存若干错误消息 QHST：历史记录，保存用于跟踪系统活动的消息 打印机队列存储与每个打印机相关联的消息 电子客户支持程序在恢复PTF指令时用于发送消息的消息队列存储电子客户支持发送的所有消息，以便可减少发送至 QSYSOPR 的消息数 每个用户和工作站还具有消息队列，用于保存来自系统操作员、另一用户或另一系统的消息 常用QSYSPOR，系统操作员消息队列相关操作： ## display operators message queue DSPMSG QSYSOPR ## Change Qsysopr Message Queue Modes CHGMSGQ QSYSOPR *break IBM官方参考链接： IBM i 7.3 消息队列类型 IBM i Change Message Queue (CHGMSGQ) 子系统(SBS)   子系统是在系统上处理工作的地方。子系统是一个单一的、预定义的操作环境，系统通过它来协调工作流和资源使用。该系统可以包含多个子系统，所有子系统都彼此独立运行。子系统管理资源。 AS400里面五个基本的子系统：QCTL,QINTER,QBATCH,QSPL,QCMN。IBM官方参考链接： IBM i 7.3 Subsystems IBM i 7.3 Managing subsystems 消息(MSG) 基本概念   消息是从人员、程序或该操作系统发送至消息队列的通信。每个用户概要文件和工作站都具有一个与它关联的消息队列。QSYSOPR 消息队列特别重要，系统会将大量有关作业完成和系统状态的消息发送至QSYSOPR消息队列。三种消息类型：break,notify,hold。 IBM官方参考链接： IBM i 7.3 消息 IBM i 7.3 Scenario: Message monitor 常用命令 命令 描述 DSPMSG Display Messages WRKMSG Display Messages DSPMSG QSYSOPR display operators message queue CHGMSGQ Change Message Queue CHGMSGQ QSYSOPR *break Change Qsysopr Message Queue Modes SNDBRKMSG Send Break Message 对象(OBJ)   系统上可处理的每项内容都被视为一个对象。例如，数据文件、程序、库、队列、用户概要文件和设备描述是所有类型的对象。一库是一种重要的对象类型。库本质是其他对象的容器或组织结构，并且用户可使用库来引用系统上的其他对象。库可包含大量对象，并且可与特定用户概要文件或应用程序关联。唯一可包含其他库的库名为 QSYS，它包含系统上的所有其他库。 对象类型： 对象类型主要有：Files,Programs,Commands,Libraries,Queues,Modules,Service programs 其他不常用对象：User profiles,Job descriptions,Subsystem descriptions,Device descriptions 对象特点： 不同的对象类型具有不同的操作特性，这些差异使每个对象类型都是独一无二的 每个对象都有一个名称，对象名称和对象类型用于标识对象，对象名称由创建对象的用户指定，对象类型由用于创建对象的命令确定 系统通过防止滥用某些功能来保持完整性，具体取决于对象类型。例如命令CALL使程序对象运行，如果用户指定了CALL并命名了一个文件，则该命令将失败，除非碰巧有一个同名的程序 官方参考链接： IBM i 7.3 对象 IBM i objects 内存池Memory pools   内存池是主内存或存储的逻辑分区，保留用于处理作业或作业组。子系统中的多个池可帮助用户控制作业对系统资源的竞争。在一个子系统中拥有多个池的优点是用户可以将完成的工作量和这些作业的响应时间分开。例如，在白天，可能希望交互式作业以良好的响应时间运行，可以使交互式池变大。到了晚上，可能会运行许多批处理作业，因此可以使批处理池变大。 Private memory pools私有内存池: 私有内存池（也称为用户定义的内存池）包含特定数量的主存储，单个子系统可以使用它来运行作业 这些池不能被多个子系统共享，用户可以分配多达62个私有内存池用于活动子系统 Shared memory pools共享内存池： 可以定义的64个共享内存池，其中的63个供创建子系统描述时使用（机器池保留供系统使用） Special Shared Pools (*MACHINEand*BASE) *MACHINE内存池用于highly-shared Machine和操作系统程序: 此内存池的大小在系统值Machine memory pool size(QMCHPOOL)中指定,没有用户作业在此内存池中运行 在WRKSYSSTS命令显示屏幕中，机器内存池显示为系统池标识符1，在IBM Navigator for i中标识为Machine *BASE内存池包含系统上所有未分配的主存储器（其他内存池不需要的所有主存储器）： Base池包含可由许多子系统共享的存储。Base内存池用于批处理工作和其他系统功能。 The Base memory pool minimum size (QBASPOOL) 系统值指定基本内存池的最小大小 此内存池的活动级别在Base memory pool maximum eligible threads (QBASACTLVL) 系统值中指定 在WRKSYSSTS命令显示屏幕中，机器内存池显示为系统池标识符2，在IBM Navigator for i中标识为Base General Shared Pools 通用共享池是多个子系统可以同时使用的主存储池。在字符的界面上，它们的标识如下： *INTERACT是用于交互式作业的交互式存储池 *SPOOL是用于spool写入程序的存储池 *SHRPOOL1到*SHRPOOL60是用户可以自用的存储池 在IBM Navigator for i 中，通用共享池被标识为Interactive、Spool 和Shared 1 - Shared 60 官方参考链接： IBM i 7.3 Memory pools IBM i 7.3 Managing memory pools IBM i 7.3 Types of memory pools Security and user authority 安全和用户权限说明： 操作系统根据用户概要文件中的信息以及为此系统实现的安全策略确定用户可访问哪些资源 安全性是系统操作的关键组成部分。它构建到操作系统内，并且几乎影响系统上的每项功能 安全策略会限制用户可访问的对象。对于具有对象级别安全性的系统，存在若干提供对象访问权限的方式 官方参考链接： IBM i 7.3 安全性和用户权限 IBM i 7.3 安全级别 Logs and Journals 官方参考链接：IBM i 7.3 Logs and journals Logs Logs分为三类，说明如下： Job logs：作业记录。跟踪由系统执行的作业的描述、状态和操作 History logs：历史记录。获取常规系统信息，例如设备更改、操作员消息、作业完成和其他活动 Problem logs：问题记录。检索系统上发生的系统问题的记录 官方参考链接： IBM i 7.3 Job logs IBM i 7.3 History logs IBM i 7.3 Problem logs Journals   Journals是系统对象，包含有关对另一系统对象进行的更改的信息。日志可用来恢复数据库文件、数据区、数据队列和集成文件系统对象。定期进行日志记录会加快管理任务（例如保存操作）的速度。 官方参考链接：IBM i 7.3 Journal management Software fixes 可使用修订来安装和管理软件及软件更新。官方参考链接： IBM i 7.3 Software fixes IBM i 7.3 维护和管理IBM i及相关软件 IBM i 7.3 安装 升级或删除IBM i及相关软件 IBM i commands 命令构成介绍及常用命令见下一篇Markdown。官方参考链接：IBM i commands 待补充 "},"05-IBM_Operating_System/02-AS400/03-AS400-常用命令.html":{"url":"05-IBM_Operating_System/02-AS400/03-AS400-常用命令.html","title":"AS400-常用命令","keywords":"","body":"AS/400-常用命令 记录常用的AS400系统命令。官方相关参考链接： IBM i 命令 IBM i 7.3 CL command finder-Alphabetic list IBM i 7.3 CL command finder IBM i 7.3 CL commands by product IBM i 7.3 CL concepts 系统命令构成 AS400 CL命令由动词、对象以及形容词（可无）组成；例如WRKACTJOB等： 动词 形容词 对象 WRK ACT JOB CHG USR PRF 官方参考链接：IBM i 命令 常用动词 AS400常用动词和示例命令如下表： 命令 描述 示例命令 DSP* Display DSPMSG WRK* Work with WRKACTJOB CFG* Config CFGTCP CHG* Change CHGUSRPRF CRT* Creat CRTMSGQ ADD* Add ADDTCPRTE DLT* Delete DLTJRN RMV* Remove RMVDIR STR* Start STRSST END* End ENDJOB EDT* Edit EDTF SND* Send SNDMSG CPY* Copy CPYTODIR SAV* Save SAVCFG RST* Restore RSTOBJ SBM* Submit SBMJOB DSC* Disconnect DSCJOB INZ* Initialize INZMEDBRM GRT* Grant GRTUSRAUT 常用形容词或对象（单词）缩写 缩写 全拼 示例 ACT Active WRKACTJOB ADM Administration GO TCPADM APP Application TRCTCPAPP AUT Authority GRTOBJAUT BRK Break SNDBRKMSG DSK Disk WRKDSKSTS DEV Device WRKDEVD ERR Error PRTERRLOG GRP Group SETASPGRP HDW Hardware WRKHDWRSC JRN Journal DSPJRN JOB Job WRKACTJOB SBS(QBATCH) LIB Library CRTLIB MSG Message DSPMSG QSYSOPR MED Media WRKMEDBRM OBJ Object WRKOBJ OBJ(*ALL) OPR Operators DSPMSG QSYSOPR PMN Permission GRTUSRPMN PRB Problem WRKPRB PRF Profile WRKUSRPRF RSC Resource WRKHDSRSC SBS Subsystem WRKACTJOB SBS(QBATCH) SCD Schedule WRKJOBSCED STS Status WRKDSKSTS SYS System WRKSYSACT SHR Share WRKSHRP TAP Tape DSPTAP TRC Trace STRTRC USR User CRTURSPRF VAL Values WRKSYSVAL 常用形容词或对象（组合词）缩写 缩写 全拼 示例 ASP Auxiliary Storage Pool DSPASPSTS BRMS Backup Recovery and Media Services GOBRMS CLNUP Clean up CHGCLNUP DEVD Device Descriptions WRKDEVD*ASP JOBD Job Descriptions DSPJOBD LIBL Library List DSPLIBL MLB Media Library WRKMLBSTS MSGQ Message Queue DSPMSGQ PDM Programming Development Manager STRPDM SPLF Spool File WRKSPLF SST System Service Tools STRSST SAVF Save File DSPSAVF SCDE Schedule Entries WRKJOBSCED SRLNBR Serial Number DSPSYSVAL SYSVAL(QSRLNBR) 常用单字母缩写 缩写 全拼 示例 A Attributes CHGSPLFA D Descriptions DSPJOBD E Entry ADDJOBQE F File WRKSPLF I Infomation WRKMEDIBRM L List DSPLIBL Q Queue CHGMSGQ 常用其它单词缩写 缩写 全拼 示例 CMN Communication WRKHDWRSC*CMN PRC Processor WRKHDWRSC*PRC RTE Route NETSTAT*RTE STG Storage WRKHDWRSC*STG 命令查询 命令查询方法一 只知道某个命令的前半部分，输入前半部分后加上星号回车即可查看所有相关命令:例如输入：cfg* 输出示例： Opt Command Library Text CFGACCWEB QSYS Configure Access for Web CFGDEVMLB QSYS Configure Device Media Library CFGPMAGT QSYS Configure PM Agent CFGPM400 QSYS Configure PM Agent CFGRPDS QSYS Configure VM/MVS Bridge 命令查询方法二 不知道命令的前半部分，只知道后面某些部分，可以输入GO CMD*显示命令系列，输入后示例： Opt Menu Library Text CMDCCS QSYS Change Control Server Commands CMDCDE QSYS Code Commands CMDCFG QSYS Configuration Commands 然后输入GO CMDCFG可以查看到所有的Configuration Commands，示例如下： Select one of the following: Commands 1. Add Configuration Entry ADDEMLCFGE 2. Configure Access for Web CFGACCWEB 4. Configure Device ASP CFGDEVASP 同样，输入GO CMDMSG可以查看到所有和Message相关的命令。 注意：一旦选择了命令序号回车后，就表示执行此命令，需慎重。 命令输入   主菜单下有两行输入位置，如果不够用，输入命令CALL QCMD,有四行，如果还不够用，按F11，全屏供输入命令。按F10可以显示之前的命令及详细信息。 常用类型 命令 描述 WRKSYSVAL Work with System Values CHGSYSVAL change system values CHGCLNUP Change Cleanup CRTUSRPRF creat user profile WRKUSRPRF work user profile PRTERRLOG print Error Log DSPLIBL Display Library List WRKSPLF work with all spooled files STRSST Start System Service Tools STRPDM Programming Development Manager(PDM) DSPUSRPRF display user profile WRKSYSSTS Work with System Status WRKDSKSTS Work with Disk Status WRKACTJOB Work with Active Jobs WRKSYSACT Work with System Activity PING Verify TCP/IP Connection (PING) STRQSH QSH Command Entry(UNIX Command) GO快捷菜单 命令 描述 GO ASSIST Operational Assistant (TM) Menu GO BRMS Backup Recovery and Media Services for i5/OS GO DISKTASKS Disk Space Tasks GO MESSAGE messages menu GO MSGF Messages Files GO PTF PTF menu GO PERFORM Performance menu GO POWER Power On and Off Tasks GO SAVE Save menu GO SECBATCH GO TCPADM TCP/IP Administration Message/Message queue Message 命令 描述 DSPMSG Display Messages WRKMSG Display Messages DSPMSG QSYSOPR display operators message queue DLTMSGF Delete Message File SNDBRKMSG Send Break Message SNDMSG Send Message Reply List 命令 描述 ADDRPYLE Add Reply List Entry CHGRPYLE Change Reply List Entry RMVRPYLE Remove Reply List Entry WRKRPYLE Work with Reply List Entries Alerts 命令 描述 ADDALRACNE Add Alert Action Entry ADDALRSLTE Add Alert Selection Entry CHGALRACNE Change Alert Action Entry CHGALRSLTE Change Alert Selection Entry DLTALR Delete Alert WRKALR Work with Alerts Message queue 命令 描述 CRTMSGQ Create Message Queue CHGMSGQ Change Message Queue CHGMSGQ QSYSOPR *break Change Qsysopr Message Queue Modes DLTMSGQ Delete Message Queue Output Queue和Spool File Output Queue 命令 描述 CRTOUTQ Create Output Queue CLROUTQ Clear Output Queue CHGOUTQ Change Output Queue DLTOUTQ Delete Output Queue WRKOUTQ Work with All Output Queues Spool File 命令 描述 CHGSPLFA Change Spooled File Attributes CPYSPLF Copy Spooled File CHGPRTF Change Printer File CRTPRTF Create Printer File DLTEXPSPLF Delete Expired Spooled files OVRPRTF Override with Printer File RCPLSPLSTG Reclaim Spool Storage STRSPLRCL Start Spool Reclaim WRKSPLF Work with All Spooled Files Writer 命令 描述 CHGWTR Change Writer ENDWTR End Writer HLDWTR Hold Writer RLSWTR Release Writer WRKWTR Work with Writers 日志查看和收集 命令 描述 WRKPRB work with problems DSPLOG Display History Log Contents DSPJOBLOG Work with Job Logs STRTRC Start Trace ENDTRC End Trace PRTTRC Print Trace Data TRCTCPAPP Trace TCP/IP Application Journal&Journal receiver Journal 命令 描述 CRTJRN Create Journal CHGJRN Change Journal CHGJRNA Change Journal Attributes CHGJRNOBJ Change Journaled Object DLTJRN Delete Journal Journal receiver 命令 描述 DLTJRNRCV Delete Journal Receiver DSPJRNRCVA Display Journal Receiver Attributes WRKJRNRCV Work with Journal Receivers 用户管理 命令 描述 CHGUSRPRF Change User Profile DLTUSRPRF Delete User Profile DSPUSRPRF Display User Profile DSPWSUSR Display Work Station User WRKUSRJOB Work with User Jobs WRKUSRPRF Work with User Profiles WRKUSRPRF USRPRF(*ALL) work with all user profile Authority 命令 描述 GRTACCAUT Grant Access Code Authority GRTDPRAUT Grant DataPropagator Authority GRTOBJAUT Grant Object Authority GRTUSRAUT Grant User Authority GRTUSRPMN Grant User Permission GRTWSOAUT Grant Workstation Object Authority 系统及硬件管理 系统硬件 命令 描述 WRKHDWRSC TYPE(*PRC) Work with Processor Resources WRKHDWRSC *CMN Work with Communication Resources WRKHDWRSC *STG Work with Storage Resources 系统管理 命令 描述 CHGSYSVAL Change System Value DSPSYSVAL SYSVAL(QSRLNBR) Display System serial number ENDCLNUP End Cleanup RTVCLNUP Retrieve Cleanup STRCLNUP Start Cleanup WRKSYSVAL Work with System Values 系统清理 命令 描述 CHGCLNUP Change Cleanup ENDCLNUP End Cleanup RTVCLNUP Retrieve Cleanup STRCLNUP Start Cleanup IPL 命令 描述 CHGIPLA Change IPL Attributes DSPIPLA Display IPL Attributes Objects管理 命令 描述 CRTDUPOBJ Create a Duplicate Object SAVCHGOBJ Save Changed Objects WRKOBJ Work with Objects WRKOBJ OBJ(*ALL) Work with All Objects WRKOBJ QSYSINC Work with QSYSINC Object WRKOBJPDM Work with Objects using PDM JOB管理 JOB 命令 描述 ADDAJE Add Autostart Job Entry ADDPJE Add Prestart Job Entry ADDWSE Add Work Station Entry ADDJOBQE Add Job Queue Entry ADDJOBSCDE Add Job Schedule Entry BCHJOB Batch Job CHGJOB Change Job CHGAJE Change Autostart Job Entry CHGPJE Change Prestart Job Entry CHGJOBQE Change Job Queue Entry DSPJOB Display Job DSCJOB Disconnect Job ENDJOB End Job RTVJOBA Retrieve Job Attributes SBMJOB Submit Job SBMDBJOB Submit Database Job STRPJ Start Prestart Jobs TFRJOB Transfer Job TFRBCHJOB Transfer Batch Job WRKJOB Work with Job WRKACTJOB Work with Active Jobs WRKACTJOB SBS(QBATCH) Work with Active Jobs(SBS/Job:QBATCH) WRKJOBQ Work with All Job Queues WRKJOBSCDE Work with Job Schedule Entries WRKUSRJOB Work with User Jobs WRKSBMJOB Work with Submitted Jobs WRKSBSJOB Work with Subsystem Jobs Job Description 命令 描述 CRTJOBD Create Job Description CHGJOBD Change Job Description DLTJOBD Delete Job Description DSPJOBD Display Job Description WRKJOBD Work with Job Descriptions Job Tables 命令 描述 DSPJOBTBL Display Job Tables LIB管理 命令 描述 CRTLIB Create Library DSPLIB Display Libraries DSPLIBL Display Library List WRKLIB Work with Libraries WRKLIB TESTLIB Work with TESTLIB Library SAVLIB Save Library RSTLIB Restore Library SBS子系统 命令 描述 CHGSBSD Change Subsystem Description CRTSBSD Create a Subsystem Description DSPSBSD Display Subsystem Description DLTSBSD Delete Subsystem Description ENDSBS End Subsystem WRKSBS Work with Subsystems Memory池 命令 描述 CHGSHRPOOL Change Shared Storage Pool WRKSHRPOOL Work with Shared Storage Pools ASP 命令 描述 DSPASPSTS Display ASP Status SETASPGRP Set ASP Group WRKDEVD *ASP Work with Device Descriptions(type asp) 磁盘管理 命令 描述 GO DISKTASKS Disk Space Tasks PRTDSKINF Print Disk Information RTVDSKINF Retrieve Disk Information WRKDSKSTS Work with Disk Status 程序许可管理 命令 描述 WRKSFWAGR Work with Software Agreements WRKLICINF Work with License Information 备份与恢复 BRMS 命令 描述 GO BRMS Backup Recovery and Media Services for i5/OS GO BRMMEDMOV Move Management ADDMLMBRM Add Media Library Media to BRM ADDMEDBRM Add Media to BRM CHGMEDBRM Change Media using BRM DSPASPBRM Display ASP Information using BRM DSPLOGBRM Display BRM Log Information DUPMEDBRM Duplicate Media using BRM INZBRM Initialize BRMS MOVMEDBRM Move Media using BRM STRBKUBRM Start Backup using BRM STRMNTBRM Start Maintenance for BRM WRKASPBRM Work with ASP Descriptions WRKPCYBRM Work with Policies using BRM WRKMLMBRM Work with Media Library Media WRKMEDBRM Work with Media using BRM WRKMEDIBRM Work with Media Information using BRM WRKMLBBRM The Work with Media Libraries Media或Media Library 命令 描述 ADDMLMBRM Add Media Library Media to BRM CHGMEDBRM Change Media using BRM DSPTAP Display Tape INZMEDBRM) Initialize Media using BRM WRKMEDBRM Work with Media WRKMEDIBRM Work with Media Information WRKMEDBRM TYPE(*EXP) Work with EXP status media WRKMEDBRM TYPE(*ACT) Work with ACT status media WRKMLBSTS Work with Media Library Status WRKMLBBRM Work with Media Libraries WRKMLMBRM Work with Media Library Media 非BRMS 命令 描述 DUPTAP Duplicate Tape Journal Management Local Journal 命令 描述 APYJRNCHG update the restored file from the last saved point to last restore point. CRTJRN Create Journal CRTJRNRCV Create Journal Receiver CHGJRN Switch the journal receiver to a new ones DSPJRNSTS display journal status DSPJRN Display journal DSPJRNRCVA Display Journal Receiver Attributes DLTJRN Delete Journal DLTJRNRCV Delete Journal Receiver RMVJRNCHG Remove journal changes WRKJRN Work with journals WRKJRNA Work with Journal Attributes WRKJRNRCV Work with Journal Receivers Remote Journal 命令 描述 ADDRMTJRN Add Remote Journal CHGRMTJRN Change Remote Journal RMVRMTJRN Remove Remote Journal SAVE Files 命令 描述 示例 CRTSAVF Create Save File CRTSAVF IBM/TESTSAVF DSPSAVF Display Save File DSPSAVF IBM/TESTSAVF Data areas 命令 描述 示例 DISPDTAARA display Data areas DSPDTAARA DTAARA(*LDA) CHGDTAARA change Data areas 时间戳 命令 描述 DSPRCYAP used to get a system estimate of individual access path rebuilds network and communication 命令 描述 GO TCPADM TCP/IP Administration ADDCMNE Add Communications Entry ADDTCPIFC Add TCP/IP Interface ADDTCPRTE Add TCP/IP Route ADDRTGE Add Routing Entries CFGTCP Configure TCP/IP CHGCMNE Change Communications Entry CHGRTGE Change Routing Entry CHGNETA Change Network Attributes CRTLINETH Create Line Desc(Ethernet) DSPLIND Display Line Description NETSTAT Work with TCP/IP Network Status NETSTAT *RTE Display TCP/IP Route Informatio NETSTAT *IFC Work with TCP/IP Interface Status NETSTAT *CNN Work with IPv4 Connection Status NETSTAT *STATUS Display TCP/IP Stack Status STRTCP Start TCP/IP STRTCPSVR Start TCP/IP Server WRKTCPSTS Work with TCP/IP Network Status WRKLIND Work with Line Descriptions Work Station 命令 描述 ADDWSE Add Work Station Entry CHGWSE Change Work Station Entry RMVWSE Remove Work Station Entry FTP 命令 描述 QUOTE Send a Subcommand to an FTP Server RCMD Send a CL Command to an FTP Server System PowerHA 集群节点命令 命令 描述 ADDCADMRE Add Cluster Admin Domain Managed Resource Entry ADDCADNODE Add Cluster Admin Domain Node Entry ADDCLUMON Add Cluster Monitor ADDCLUNODE Add Cluster Node Entry ADDDEVDMNE Add Device Domain Entry CHGCAD Change Cluster Admin Domain CHGCLU Change Cluster CHGCLUVER Change Cluster Version CHGCLURCY Change Cluster Recovery CHGCLUNODE Change Cluster Node Entry CHGCLUMON Change Cluster Monitor CRTCAD Create Cluster Admin Domain CRTCLU Create Cluster DLTCAD Delete Cluster Admin Domain DLTCLU Delete Cluster DMPCLUTRC Dump Cluster Trace DSPCLUINF Display Cluster Information ENDCAD End Cluster Admin Domain ENDCHTSVR End Clustered Hash Table Server ENDCLUNOD End Cluster Node PRTCADMRE Print Cluster Administrative Domain Monitored Resource Entry RMVCADMRE Remove Cluster Admin Domain Monitored Resource Entry RMVCADNODE Remove Admin Domain Node Entry RMVCLUNODE Remove Cluster Node Entry RMVCLUMON Remove Cluster Monitor RMVDEVDMNE Remove Device Domain Entry RTVCLU Retrieve Cluster WRKCLU Work with Cluster STRCAD Start Cluster Admin Domain STRCHTSVR Start Clustered Hash Table Server STRCLUNOD Start Cluster Node WRKCADMRE Work with Cluster Administrative Domain Monitored Resource Entries WRKCLU Work with Cluster 集群资源组CRG命令 命令 描述 ADDCRGDEVE Add CRG Device Entry ADDCRGNODE Add CRG Node Entry CHGCRG Change Cluster Resource Group CHGCRGDEVE Change CRG Device Entry CHGCRGPRI Change CRG Primary CRTCRG Create Cluster Resource Group DSPCRGINF Display CRG Information DLTCRG Delete Cluster Resource Group DLTCRGCLU Delete CRG Cluster ENDCRG End Cluster Resource Group RMVCRGDEVE Remove CRG Device Entry RMVCRGNODE Remove CRG Node Entry RTVCRT Retrieve CRG STRCRG Start Cluster Resource Group 集群数据管理 命令 描述 ADDASPCPYD Add ASP Copy Description ADDSVCCPYD Add SVC ASP Copy Description CHGASPCPYD Change ASP Copy Description CHGASPSSN Change ASP Session CHGSVCCPYD Change SVC Copy Description CHGSVCSSN Change SVC Session DSPASPCPYD Display ASP Copy Description DSPASPSSN Display ASP Session DSPSVCCPYD Display SVC Copy Description DSPSVCSSN Display SVC Session RMVASPCPYD Remove ASP Copy Description RMVSVCCPYD Remove SVC Copy Description RTVASPCPYD Retrieve ASP Copy Description RTVASPSSN Retrieve ASP Session RTVSVCCPYD Retrieve SVC Copy Description RTVSVCSSN Retrieve SVC Session WRKASPCPYD Work with ASP Copy Description ADDHYSSTGD Add HyperSwap Storage Desc CHGHYSSTGD Change HyperSwap Storage Desc CHGHYSSTS Change HyperSwap Status DSPHYSSTGD Display HyperSwap Storage Desc DSPHYSSTS Display HyperSwap Status RMVHYSSTGD Remove HyperSwap Storage Desc WRKHYSSTS Work with HyperSwap Status 集群管理域 命令 描述 DLTCAD Delete Cluster Admin Domain ENDCAD End Cluster Admin Domain WRKCADMRE Work with Monitored Resources Programming Development Manager 命令 描述 STRPDM Programming Development Manager WRKOBJPDM Work with Objects using PDM WRKLIBPDM Work with Libraries using PDM WRKMBRPDM Work with Members using PDM SQL 命令 描述 RUNSQL Run SQL (RUNSQL) STRSQL Start SQL Interactive Session Database Files Physical Files 命令 描述 CHGPF Change Physical File CRTPF Create Physical File CRTSRCPF Create Source Physical File CHGSRCPF Change Source Physical DSPF Display File DSPFD Display File Description DSPPFM Display Physical File Member Security Security Audit 命令 描述 CHGSECAUD Change Security Auditing CHGUSRAUD Change User Auditing CHGOBJAUD Change Object Auditing CHGDLOAUD Change DLO Auditing Level 其他命令 命令 描述 CRTDSPF Create Display File PWRDWNSYS Power Down System SIGNOFF Sign Off wrklnk work with link "},"05-IBM_Operating_System/02-AS400/04-AS400-常用操作.html":{"url":"05-IBM_Operating_System/02-AS400/04-AS400-常用操作.html","title":"AS400-常用操作","keywords":"","body":"AS/400-常用操作 Message Messages Relpy and Remove Messages Relpy and Remove： Enter command \"DSPMSG QSYSOPR\" Choose one message and enter \"5(Display details and reply)\" in opt,click Enter(options 4 is Remove) Relpy choices: C:Cancel the CL program D:Dump the Cl program variables and cancel the CL program I:Ignore the failing command R:Try the failing command again Messages Send Messages Send： Enter command \"SNDMSG\" and click F4 Message text:Enter messages To user profile:*SYSOPR (or other),click F10 click Page Down to check the message Press Enter Enter command \"SNDBRKMSG\" and click F12 Enter command \"DSPMSG QSYSOPR\" SNDMSG MSG(' THIS IS A TEST MESSAGE') TOUSR(*SYSOPR) User Change and display user profile Change and display user profile： Enter command \"WRKUSRPRF\" click F4,and enter \"*ALL\"(or enter \"WRKUSRPRF USRPRF(*ALL)\") Choose one User Profile name and enter \"2(Change)\" in opt(options 5 is Display),click Enter click F9 show All parameters User Group 创建group profile 创建group profile 并添加本地用户到组内，例如创建ACCOUNTS组，添加tmpusr用户： Enter command \"CRTUSRPRF\" and click F4 Enter the User profile name:ACCOUNTS Set \"password to expried filed\" form *NO to *YES If change the \"Status\" to *DISABLE,the user cannot use this profile to sign on to the system Enter description in \"the text description\" Clieck F10 to continue To see wihck special authorities are available you would press F1 or F4,click Page Down Change \"the Group ID number\" from *NONE to *GEN,click Page Down Press Enter Enter command \"WRKUSRPRF *ALL\" and click F4 Find the tmpusr and enter \"2(Change)\" on the \"Opt\" options ,then click Enter Click F10,then click Page Down Enter ACCOUNTS in the Group profile,click Enter to save the change   添加用户到组可以输入命令“WRKUSRPRF *ALL”后选中多个需要添加的用户，输入命令：GRPPRF(ACCOUNTS)，然后回车确认。 系统修改 修改系统名称 使用命令CHGNETA修改，示例： CHGNETA SYSNAME(SYSTEST) ALRSTS(*ON) ALRPRIFP(*YES) ALRLOGSTS(*LOCAL) 示例说明： 此命令更改pending系统名称 当前系统名称在下一个IPL中更改，生成并记录本地警报 修改系统时间 时间修改对应系统值可以修改系统时间。相关系统值： QDATA：系统日期 QDATATIME：系统日期和时间 QDATFMT：日期格式 QDATSEP：日期分隔符 QDAY：日期中的天 QDAYOFWEEK：日期对应的星期 JOB 查看活动作业日志 例如查看备份作业（例如叫BACKUP）的备份日志： WRKACTJOB找到对应的作业BACKUP，或WRKACTJOB SBS(QBATCH)找备份作业快一点，例如 作业前面输入5选择Work with 选择10.Display job log,if active,on job queue,or pending 再按F10显示更多 按F18可以到最后一条记录 DST/SST 创建host spares DST/SST work with disk units work with disk configuration Start host spare Stop host spare System i navigator:Select host spares View VPD view a disk(resource name:DPH002) VPD: hardware service manager Locate resource by resource name Enter the resource name DPH002 Type options 8(Associated packaging resource(s)),and press enter Type options 5(Dislpay detail),and press enter,can see the disk's VPD indentify a disk(resource name:DPH002): Continue from above or Type options 3(Concurrent maintenance),and press enter Type options 2(Toggle indentify indicator state),and press enter Now the disk LED on Type options 2(Toggle indentify indicator state),and press enter,the LED off Library 库对象跨机拷贝 示例将A分区库TESTLIB拷贝到B分区上： 在临时库下创建一个savf，例如临时库叫IBM：CRTSAVF IBM/TESTSAVF，或者自己建一个库，savf名字自定义，使用CRTSAVF也行 创建后查看savf：DSPLIB IBM 输入SAVLIB进入Save Library菜单 按F9显示更多属性 选项Library输入TESTLIB 选项Device项输入*SAVF 选项Save file输入之前定义的savf名称：TESTSAVF 选项Library输入savf所在的Library：IBM，或自定义的库名称 回车确认，提示保存成功 查看是否成功：DSPSAVF IBM/TESTSAVF 使用FTP将savf从A分区传到B分区： ftp 192.168.0.100 BIN namefmt 1(AS400之间用此) cd /QSYS.lib/IBM.lib(如果是在IBM这个Library) lcd /QSYS.lib/IBM.lib(本地AS400的库位置，或其它自定义库) GET TESTSAVF.savf(注意后缀) 退出FTP查看savf：DSPSAVF IBM/TESTSAVF B分区恢复Library： 输入RSTLIB进入Restore Library菜单 按F9显示更多属性 选项Saved Library输入TESTLIB（恢复后Library名称） 选项Device项输入*SAVF 选项Save file输入恢复的savf名称：TESTSAVF 选项Library输入savf所在的Library：IBM，或自定义的库名称 回车确认，提示保存成功 查看是否成功：WRKLIB TESTLIB Authority   示例查看库Acclib中文件Creditpf的当前权限，并向该组帐户授予*USE权限，但将tmpusr排除在使用该文件之外。 Enter command \"WRKOBJ\" and click F4 Enter Object name：CREDITPF Enter Library name：ACCLIB Enter Object type：*FILE opt \"5(Display authority)\",click Enter Press Enter to exit this screen Opt \"2(Edit authority)\",click Enter Press F6 to add new users Enter User：Accounts and with Object Authority：*Use Enter User：tmpusr and with Object Authority：*Exclued Press Enter to exit this screen opt \"5(Display authority)\",click Enter check the chage Journal Management "},"05-IBM_Operating_System/02-AS400/05-AS400-磁盘管理.html":{"url":"05-IBM_Operating_System/02-AS400/05-AS400-磁盘管理.html","title":"AS400-磁盘管理","keywords":"","body":"AS400-磁盘管理 学习磁盘管理知识以及记录简单磁盘管理操作。官方文档主页： IBM i 7.3 磁盘管理 IBM i 7.3 Disk management checklist 磁盘存储器的组件   系统使用一些电子组件来管理将磁盘中的数据传输至主存储器的过程。数据和程序必须在主存储器中才能使用。用于数据传输的主要硬件： 总线：总线是输入和输出数据传输的主要通信信道。系统可以有一条或多条总线。 IOP：IOP连接至总线。IOP用于在主存储器与特定IOA组之间传输信息： 某些IOP专用于特定类型的IOA，例如，存储IOA 其他IOP可连接至多种类型的IOA，例如，通信IOA和存储IOA 某些系统没有IOP IOA：IOA连接至IOP并处理IOP与磁盘单元之间的信息传输 磁盘单元：磁盘单元是包含磁盘机的实际设备。用户是按磁盘机级别订购硬件的，每个磁盘单元都有唯一序列号 查找磁盘存储器组件的逻辑地址   系统通过逻辑地址访问磁盘单元。逻辑地址由系统总线、系统卡、I/O总线、IOP、IOA和设备号组成。IBM Navigator for i查找磁盘存储器组件的逻辑地址步骤： 从 IBM Navigator for i 中选择Configuration and Service 选择Disk Units 右键单击要查找其地址的磁盘单元 选择Properties 官方参考链接：IBM i 7.3 磁盘存储器的组件 规划磁盘管理 官方参考链接：IBM i 7.3 规划磁盘管理 磁盘管理需求 启用和访问磁盘单元 需要设置用户活DST的权限，官方参考链接：Enabling and accessing disk units 设置通信   在IBM Navigator for i中访问磁盘管理功能，必须先配置服务工具系统并且它必须具有DST访问权。还必须配置用户标识。官方链接：Setting up communication 评估当前配置   可通过 IBM Navigator for i的Disk Units list view视图访问的任何功能。如右键单击该表中的任何对象（例如，特定磁盘单元、磁盘池、奇偶性校验集或机架），例如： 可选择对磁盘单元启动或停止压缩、在奇偶性校验集中包括或排除该磁盘单元，或者重命名该磁盘单元 如果已对该磁盘单元执行镜像保护，那么可对该磁盘单元暂挂或恢复镜像 如果右键单击某个空磁盘单元插槽，那么可启动Install Disk Unit向导 从IBM Navigator for i中激活图形视图，步骤如下： 从IBM Navigator for i中选择Configuration and Service 选择Disk Units或Disk Pools 从Actions菜单中选择Graphical View 打印磁盘配置 使用 IBM Navigator for i打印记录的磁盘配置步骤： 从 IBM Navigator for i中选择Configuration and Service 选择Disk Units 从Actions菜单中选择Graphical View 选择Show device positions以使磁盘单元名称与插入它们的设备位置关联 在Disk Units Graphical View对话框中，选择Print Preview按钮 在新的弹出浏览器中，选择File->Print 计算磁盘空间需求   更改系统上的磁盘配置或磁盘保护前，需要计算此更改的空间需求。可使用磁盘空间计算器来确定磁盘池是否包含足够存储空间来执行更改： 要使用此计算器，需要知道磁盘池中现有的可用空间和已用空间 确保您使用的浏览器支持 JavaScript 并且已启用 JavaScript 使用IBM Navigator for i查看磁盘池配置步骤： 在IBM Navigator for i中选择Configuration and Service 选择Disk Pools 右键单击要查看的源磁盘池，然后选择Properties 选择Capacity选项卡。Capacity选项卡显示已用空间、可用空间、总容量、阈值和用于磁盘池的已用磁盘空间百分比 记录Capacity选项卡中的已用空间、可用空间和阈值 在磁盘空间计算器中输入已用空间值和可用空间值 如果要使用阈值，请在此计算器中输入阈值。如果磁盘使用空间超出阈值，那么此计算器会发出警告 官方方案参考：Scenario: Calculating disk space when moving a disk unit 设置磁盘 在新系统上配置磁盘   下面核对步骤显示用于在新系统上配置磁盘的任务序列。是否需要执行所有任务取决于想要对系统进行的磁盘保护： 显示磁盘配置。目前，除装入源磁盘单元以外的所有磁盘单元显示为未配置。参考链接：评估当前配置 使用Add Disk Unit向导以将未配置磁盘添加至正确磁盘池。可选择启动设备奇偶性校验保护或启动压缩（如果磁盘可供执行这些操作）。参考链接：添加磁盘单元或磁盘池 可将设置存储空间阈值。每个磁盘池的缺省存储空间阈值为90%。参考链接：设置磁盘池阈值 如果选择创建受保护磁盘池并包括要镜像的磁盘单元对，那么可能需要重新启动以使其置于专用服务工具 (DST) 方式，同时立即对这些磁盘池启动镜像。 参考链接：启动镜像保护 如果已对系统磁盘池或基本磁盘池启动镜像保护，请等待至系统完全重新启动 验证磁盘配置是否正确。参考链接：评估当前配置 打印磁盘配置以便进行恢复时可用。参考链接：打印磁盘配置 更换磁盘单元   如果必须更换失效磁盘单元或替换磁盘机以避免故障，使用Replace Disk Unit向导进行更换： 要更换或替换的磁盘单元必须正在运行，且带有镜像保护或设备奇偶性校验保护 要更换镜像磁盘单元，必须先暂挂镜像 正在运行且带有设备奇偶性校验保护的磁盘单元只有在失效时才能更换 带有设备奇偶性校验保护的磁盘单元即使失效也不能更换为未配置的磁盘单元 要使用 IBM Navigator for i更换失效磁盘单元或替换暂挂的镜像磁盘单元步骤： 从IBM Navigator for i中选择Configuration and Service 选择Disk Units 右键单击要更换的磁盘单元，然后选择Replace Disk Unit 遵循向导的指示信息以更换失效磁盘单元 重命名磁盘单元   可将缺省磁盘单元名称更改为更有意义的名称。例如，可将Dd001更改为LoadSource。指定的名称不能包含空格。使用IBM Navigator for i重命名磁盘单元步骤： 从IBM Navigator for i中选择Configuration and Service 选择Disk Units 右键单击要重命名的磁盘单元，然后选择Rename 按照所显示的对话框中的指示信息执行操作 格式化磁盘单元   根据磁盘机容量和性能，完成格式化过程可能需要几分钟到超过1个小时，从而潜在影响系统性能。使用IBM Navigator for i格式化磁盘步骤： 从IBM Navigator for i中选择Configuration and Service 选择Disk Units 右键单击要格式化的磁盘单元，然后选择Format 按照所显示的对话框中的指示信息执行操作 扫描磁盘单元   可扫描磁盘以检查磁盘表面并更正带有错误的所有扇区。根据磁盘容量和性能，扫描过程可能需要几分钟到超过1个小时，从而潜在影响系统性能。使用IBM Navigator for i扫描磁盘步骤： 从IBM Navigator for i中选择Configuration and Service 选择Disk Units 右键单击要扫描的磁盘单元，然后选择Scan 按照所显示的对话框中的指示信息执行操作 检索磁盘日志   可收集有关特定磁盘的信息。只有新一代的磁盘才能返回有意义的记录。使用IBM Navigator for i检索磁盘记录步骤如下： 从IBM Navigator for i中选择Configuration and Service 选择Disk Units 右键单击该磁盘单元，然后选择Retrieve Disk Log 如果要分析设备记录，可以将信息打包成Spool File： 输入命令STRSST并登录到System Service Tools 在System Service Tools屏幕上，选择Start a service tool 在Start a Service Tool屏幕上，选择Product activity log 在Product Activity Log屏幕上，选择Analyze log 在Select Subsystem Data屏幕上，在Log字段中选择1以包括所有记录。在From 和 To字段中指定日期和时间信息 在Select Analysis Report Options屏幕上，对Report type字段选择Print options。在Reference codes字段中，指定5505 在Select Options for Printed Report屏幕上，在Report type字段中选择选项4以打印完整报告。在Include hexadecimal data字段中，选择 Y 设备记录信息存储在Spool File中 磁盘保护 官方参考链接： IBM i 7.3 Disk protection IBM i 7.3 比较磁盘保护选项 官方详细参考链接：Comparing disk protection options 磁盘保护相关硬件要求： RAID 5设备奇偶性校验保护要求一个磁盘的容量专用于存储奇偶性校验集中的奇偶性校验数据 RAID 6设备奇偶性校验保护要求两个磁盘的容量专用于存储奇偶性校验集中的奇偶性校验数据 镜像保护要求两倍于没有镜像保护的系统的磁盘容量，因为所有信息存储两次。镜像保护还可能需要更多总线、输入/输出处理器 (IOP) 和 IOA，这取决于需要的保护级别 热备保护需要一个额外磁盘，此磁盘应已准备好并等待另一磁盘失效时开始工作 磁盘保护类型 设备奇偶性校验保护 官方参考链接：IBM i 7.3 Device parity protection 有关 RAID 5、RAID 6 和 RAID 10 官方说明： IBM i 7.3 RAID 5 concepts IBM i 7.3 RAID 6 concepts IBM i 7.3 RAID 10 concepts 启动设备奇偶性校验保护 使用IBM Navigator for i启动奇偶性校验保护： 从IBM Navigator for i中选择Configuration and Service 选择All Tasks > Disk Management > Start Parity 按照所显示的对话框中的指示信息执行操作   启动设备奇偶性校验保护的最佳时间是添加新磁盘或未配置磁盘时。Add a disk unit or disk pool向导包含用于在奇偶性校验集中添加磁盘并启动设备奇偶性校验保护的步骤。注意事项： 奇偶性校验集中的所有磁盘必须为相同容量 对于OS/400 V5.2 之前发布的带有IOA的系统，RAID 5奇偶性校验集的最小磁盘数为 4。奇偶性校验集中的最大磁盘数为10 V5.2 之后发布的带有IOA的系统最少可包含3个磁盘（对于RAID 5奇偶性校验集）。奇偶性校验集中的最大磁盘数为 18 RAID 6奇偶性校验集中的最小磁盘数为 4，奇偶性校验集中的最大磁盘机数为18 启动带有热备的设备奇偶性校验保护 使用IBM Navigator for i启动带有热备的设备奇偶性校验保护步骤： 从IBM Navigator for i中选择Configuration and Service 选择All Tasks > Disk Management > Start Parity 在Hot Spare Protection下拉列表中，选择Yes 使用命令行步骤： 输入命令STRSST并登录到System Service Tools 在System Service Tools屏幕上，选择Work with disk units 在Work with Disk Units屏幕上，选择Work with disk configuration 在Work with disk configuration屏幕上，选择Work with device parity protection 在Work with device parity protection屏幕上，根据所需要的奇偶性校验保护的级别选择： Start device parity protection - RAID 5 with hot spare Start device parity protection - RAID 6 with hot spare Start device parity protection - RAID 10 with hot spare 管理设备奇偶性校验保护 管理内容： 停止设备奇偶性校验保护 停止设备奇偶性校验保护 将磁盘机添加至奇偶性校验集 从奇偶性校验集中排除磁盘 更改设备奇偶性校验保护的奇偶性校验集优化 使用DST菜单确定奇偶性校验集中的磁盘 使用SST菜单确定奇偶性校验集中的磁盘 使用IBM Navigator for i来确定奇偶性校验集中的磁盘 官方参考链接：IBM i 7.3 Managing device parity protection 设备奇偶性校验保护示例 官方示例：IBM i 7.3 设备奇偶性校验保护示例 写缓存和辅助写缓存IOA   写缓存提供更高的数据完整性和更好的性能。系统发送写操作时，数据写至缓存；然后，写完成消息被发送回系统；稍后，数据写至磁盘。此缓存提供更快的写功能并确保数据完整性。以下操作在处理来自系统的写请求期间发生： 数据落实至IOA中非易失性且有电池支持的缓存 系统发送写完成消息。 以下操作在发送写完成消息后发生： 从IOA缓存向磁盘机发送了写操作： 从IOA缓存向磁盘机发送了写操作： 读取原始数据 通过比较新数据和原始数据来计算增量奇偶性校验 写入新数据 针对奇偶性校验数据的写操作： 读取原始奇偶性校验信息 通过比较增量奇偶性校验和原始奇偶性校验来计算新奇偶性校验 写入新奇偶性校验信息。 数据成功写至数据磁盘机和奇偶性校验磁盘机时被标记为已落实数据 官方参考链接：IBM i 7.3 写缓存和辅助写缓存IOA 镜像保护   如果有多总线系统或带有大型单一总线的系统，那么使用镜像保护很有益。磁盘越多，发生故障及增加恢复时间的情况越多： 与跨站点镜像不同，镜像保护仅针对单个系统进行 镜像保护通过将数据的第二个副本保存在镜像磁盘上来阻止系统停运 如果一个磁盘失效，那么系统依赖于镜像磁盘 热备用保护可与镜像保护配合使用。如果系统中有相应的热备用磁盘，并且镜像磁盘机因为磁盘故障而暂挂，那么热备用磁盘将替换失效子设备 官方参考链接：IBM i 7.3 Mirrored protection 设置镜像保护 启动镜像保护 对磁盘池的磁盘启动镜像保护时，存在的限制： 无法镜像受设备奇偶性校验保护的磁盘 磁盘必须镜像至具有完全相同的扇区大小的磁盘 磁盘必须镜像至容量大致相同的磁盘 在装入源磁盘上启动镜像保护时，有一些限制： 两个容量不相等的磁盘配成镜像对时，必须使用容量较小的磁盘作为装入源设备。然后可以将装入源与容量较大的磁盘配对： 例如，如果装入源磁盘为35GB，那么可以将它与36GB磁盘配对 如果装入源为36GB磁盘，那么不能将它与35GB磁盘配对 必须指示系统将装入源磁盘与位于服务处理器无法用来对分区执行IPL的物理位置的磁盘进行配对 在SST中，Work with disk units->Work with disk configuration->Enable remote load source mirroring。Enable remote load source mirroring功能允许使磁盘与装入源磁盘机配对，即使服务处理器无法使用该磁盘所在的物理位置对分区执行IPL 使用IBM Navigator for i启动镜像步骤： 在IBM Navigator for i中选择Configuration and Service 选择Disk Pools 选择要镜像的磁盘池 右键单击要镜像的磁盘池，然后选择Start Mirroring 热备保护   热备磁盘是存储在系统上的备用磁盘，用于在发生磁盘故障时替换失效磁盘。官方参考链接： IBM i 7.3 Hot spare protection 启动热备保护 使用IBM Navigator for i启动热备保护步骤： 在IBM Navigator for i中选择Configuration and Service 选择Disk Units 右键单击要处理的磁盘 选择Start Hot Spare 使用命令行启动热备保护，步骤： 输入命令STRSST并登录到System Service Tools 在System Service Tools屏幕上，选择Work with disk units 在Work with Disk Units屏幕上，选择Work with disk configuration 在Work with disk configuration屏幕上，选择Start hot spare 确定哪些奇偶校验集受热备保护 使用IBM Navigator for i步骤： 从IBM Navigator for i中选择Configuration and Service 选择All Tasks>Disk Management 选择Parity Sets Hot Spare Protected列指示哪个奇偶校验集具有热备保护 使用命令行查看步骤如下： STRSST登录SST 选择选项Work with disk units 选择选项Work with disk configuration 选择选项Work with device parity protection 选择选项Display disk configuration 选项选项Display Device Parity Status Hot Spare Protected列指示哪个奇偶校验集具有热备保护 多路径磁盘   可定义从系统上的多个输入/输出适配器(IOA)至企业磁盘存储器中的单个逻辑单元号(LUN)的多个连接。官方参考链接：IBM i 7.3 Multipath disk units 多路径磁盘注意事项 创建多路径磁盘时有许多注意事项： 从IOA至逻辑单元号(LUN)的多个连接是在V5.3中实现的 最多可定义从系统上的多个IOA至企业磁盘存储器中的单个LUN的8个连接 企业磁盘存储器并行支持基于不同连接协议的不同主机系统 数据存储器是使用Enterprise Disk Storage Specialist（一个基于 Web 的界面）在相连主机系统间分配的 多路径磁盘机的每个连接都独立地工作 某些连接通过允许使用磁盘存储器（即使单个路径失效）来提供可用性 如果使用多个磁盘，那么必须考虑在节点间移动IOA和多路径连接的隐含意义 不得在节点间分隔多路径连接（通过在逻辑分区间移动IOA或在系统间切换扩展设备） 如果两个不同节点同时具有与企业磁盘存储器中同一LUN的连接，那么两个节点都可能会潜在地覆盖另一节点中的数据 在多系统环境中使用多路径磁盘时，系统实施以下规则： 如果将带有多路径连接的IOA移至另一逻辑分区，那么还必须将带有指向同一磁盘机的连接所有其他IOA移至同一逻辑分区 如果将扩展设备置于可切换状态，请确保指向磁盘的所有多路径连接将与扩展设备一起切换 配置可切换独立磁盘池时，请确保多路径磁盘的所有必需IOA将与独立磁盘池一起切换   如果违反辑多路径配置规则，那么系统会发出警告或错误以就此情况向用户发出警报。报告磁盘连接丢失时应注意。避免出现节点可能覆盖属于另一节点的LUN上的数据的情况： 磁盘连接可能因为各种原因（尤其是在违反以上某个规则时）丢失 如果在IPL期间发现系统磁盘池或基本磁盘池中的多路径磁盘的连接丢失，那么系统会向QSYSOPR消息队列发送消息 如果连接丢失，并且确认已移除连接，那么可更新硬件服务管理器(HSM)以移除资源： 硬件服务管理器是一个工具，用于从逻辑角度和打包角度显示和处理系统硬件，可帮助调试IOA、IOP和设备及修正失效的和丢失的硬件 通过选择指示启动服务工具的选项，可在系统服务工具(SST)和专用服务工具(DST)中访问硬件服务管理器 重置多路径   如果指向磁盘机的连接丢失，那么EventEV0D040, Event Code1E, Message IDCPI096E消息将出现在QSYSOPR消息队列中。重置多路径的方法： 使用multipath reset选项来移除丢失的路径。此选项是在专用服务工具(DST)的Hardware Service Manager中提供的 还可使用Start DASD Management Operation（QYASSDMO）API来移除丢失的多路径磁盘 Storage Resource 命令WRKHDWRSC *STG可以进入Work with Storage Resources页面。 查看光纤端口WWPN 通过HMC查看（部分版本或HBA卡版本可以）： HMC中选中需要查看的设备的对应分区 I/O设备列表中找到需要查看光纤卡然后查看属性 一般有“常规”选项，如果有“详细信息”选项，在“详细信息”选项中可以查看到端口的信息，包括WWPN 通过WRKHDWRSC *STG命令查看： 输入WRKHDWRSC *STG命令 选择DC开头的Resource，\"Opt\"中输入7(Display resource detail) 进入\"Display Resource Detail\"页面后翻页即可找到\"World wide port name\" 通过SST查看： 输入STRSST,然后输入用户密码，进入\"System Service Tools (SST)\" 输入1选择\"Start a service tool\" 输入7选择\"Hardware service manager\" 输入1选择\"Packaging hardware resources (systems, frames, cards)\" 输入9选择\"System Expansion unit\" 进入到\"Packaging Hardware Resources\"面板，输入8选择\"Storage IOA\" 在\"Logical Resources Associated with a Packaging Resource\"面板上，输入5选择\"Storage IOA\" 在\"Auxiliary Storage Hardware Resource Detail\"面板上，右边列中的编号为WWPN 官方参考链接：查找运行IBM i的IBM Power Systems主机的WWPN 磁盘多路径 查看磁盘多路径 通过System Service Tools： 输入STRSST,然后输入用户密码，进入\"System Service Tools (SST)\" 选择选项\"3 Work with Disk Units\" 选择选项\"1 Display disk configuration\" 选择选项\"9 Display disk path status\" 通过Dedicated Service Tools： 以Manual方式运行初始程序装入 (IPL) 来启动系统 选择选项\"3 Use Dedicated Service Tools (DST)\" 使用服务工具用户密码登录到DST 选择选项\"1 Work with disk unit\" 选择选项\"1 Work with disk configuration\" 选择选项\"1 Display disk configuration\" 选择选项\"9 Display disk path status\" 通过IBM Navigator for i（端口 2001）： 展开\"Configuration and Service\" 展开\"Hardware\" 展开\"All Hardware\" 用鼠标右键单击磁盘单元，然后选择\"Properties\" 官方使用IBM Navigator for i说明： 展开\"Configuration and Service\" 单击\"Disk Units\" 用鼠标右键单击磁盘单元，然后选择\"Properties\" 单击窗口左侧的\"Connections\" 官方参考链接：显示磁盘多路径信息和状态 AS400与DS8000 IBM i主机配置 运行IBM i操作系统主机的DS8000存储卷容量和型号: 大小 类型 受保护的型号 不受保护的型号 8.0GiB 2107 A01 A81 16.3GiB 2107 A02 A82 32.7GiB 2107 A05 A85 65.7GiB 2107 A04 A84 131.4GiB 2107 A06 A86 262.9GiB 2107 A07 A87 1 GiB-2000GiB 2107 099 050 官方参考链接：Configurations for IBM Power Systems hosts running IBM i 磁盘空间管理 磁盘信息收集   使用命令RTVDSKINF可以检索磁盘信息，命令PRTDSKINF打印磁盘信息，或者直接使用命令GO DISKTASKS进入Disk Space Tasks菜单，示例： DISKTASKS Disk Space Tasks To select one of the following, type its number below and press Enter: 1. Collect disk space information 2. Print disk space information 10. Work with libraries 11. Work with folders 12. Work with objects by owner 选择1. Collect disk space information收集磁盘信息： Collect Disk Space Information Information collected . . . . . . : A job will be submitted to collect disk space information. This job may take several hours to complete, depending on the size of your system. Type choice below, then press Enter. When to collect information . . . 1=Date/time 2=Weekly 3=Monthly   提示可能需要几个小时时间完成，所以选择一个不繁忙时间段进行，并且尽量少进行，一周或者一月进行一次。此次测试选择了立即执行，收集完成后选择2. Print disk space information进行打印： Print Disk Space Information Information collected . . . . . . : 12/31/21 15:06:10 Select one type of report below, then press Enter. 1=Select Opt Type of Report Library Folder Owner Specific object System summary information 此次测试选择了Library，spooled文件中名为QPEZDISK打开查看即可。 收集IASP示例 示例收集用户定义的TESTIASP信息，直接使用命令RTVDSKINF ASPDEV(TESTIASP)会报错： Command RTVDSKINF not allowed in this setting 提交后台任务可以： SBMJOB CMD(RTVDSKINF ASPDEV(CBSIASP)) JOB(RTVDSKINF) JOBQ(QBATCH) 然后打印数据查看即可： PRTDSKINF PRTTYPE(*OBJ) ASPDEV(CBSIASP) OBJ(*ALL) 磁盘清理 系统自动清理   使用命令Cleanup可以查看当前系统相关配置，可以根据自己需求进行设置，也可以使用命令STRCLNUP计划或立即发起清理，通常系统配置如下所示： Change Cleanup (CHGCLNUP) Type choices, press Enter. Allow cleanup . . . . . . . . . *YES *SAME, *YES, *NO Time cleanup starts each day . . '22:00:00' Time, *SAME, *SCDPWROFF... Number of days to keep: User messages . . . . . . . . 7 1-366, *KEEP, *SAME System and workstation msgs . 4 1-366, *KEEP, *SAME Critical system messages . . . *KEEP 1-366, *KEEP, *SAME Job logs and system output . . 7 1-366, *KEEP, *SAME System journals and logs . . . 30 1-366, *KEEP, *SAME Job queue . . . . . . . . . . . QCTL Name, *SAME Library . . . . . . . . . . . *LIBL Name, *LIBL, *CURLIB 日常清理 管理独立磁盘池 一个独立的磁盘池可以从一个分区中移出并附加到单系统环境中的另一个分区。官方参考链接：Attach Independent Disk pool "},"05-IBM_Operating_System/02-AS400/06-AS400-系统性能.html":{"url":"05-IBM_Operating_System/02-AS400/06-AS400-系统性能.html","title":"AS400-系统性能","keywords":"","body":"AS400-系统性能 记录简单的性能查看、分析、数据收集及性能问题处理。官方参考链接： IBM i 7.3 Managing system performance 性能管理工具 主要性能管理工具有： IBM Navigator for i Performance interface: 显示及管理性能数据 Collection Services: 根据用户定义的间隔，定时收集取样数据，供后续进一步分析 IBM Performance Management for Power Systems (PM for Power Systems): 自动化系统性能数据的收集、保存及分析 IBM Performance Tools for i: 收集、分析及维护系统性能信息 IBM Navigator for i Monitors: 图形化观察系统性能，並自动化回应预先定义的事件或状况 IBM i Job Watcher: 收集特定JOB或现场资源信息 IBM i Disk Watcher: 收集磁盘性能数据或详细信息 Performance explorer: 收集关于特定应用程序或系统资源详细信息 相关工具参考链接： IBM Performance Tools for i [IBM i Performance Tools] IBM Navigator for i Performance interface IBM Performance Management for Power Systems(PM for Power Systems)-support for IBM i 性能相关CL命令或操作 官方参考链接：IBM i 7.2 CL commands for performance 基本实时监控 命令 描述 说明 WRKSYSSTS Work with System Status 显示系统上的作业数和存储池利用率信息 WRKDSKSTS Work with Disk Status 显示系统磁盘的性能信息和属性 WRKACTJOB Work with Active Jobs 允许用户查看和更改系统上运行的作业的属性和资源利用率 WRKSYSACT Work with System Activity 允许用户处理系统上的作业和任务 WRKOBJLCK Work with Object Locks 允许用户使用和显示指定对象上的锁，包括等待应用的锁 WRKSHRPOOL Work with Shared Storage Pools 显示共享存储池的利用率信息或更改存储池属性，包括机器和基础池 收集服务CL及相关操作 命令 描述 说明 CRTPFRDTA Create Performance Data 根据存储在管理集合 (*MGTCOL) 对象中的性能信息创建一组数据库文件 CRTPFRSUM Create Performance Summary 创建包含现有收集服务集合的摘要信息的附加数据库文件 CHGMGTCOL Change Management Collection 更改指定管理收集的属性 DLTMGTCOL Delete Management Collection 从系统中删除管理收集 STRPFRCOL Start Performance Collection 通过收集服务启动系统级性能数据收集 ENDPFRCOL End Performance Collection 停止system-level收集 CHKPFRCOL Check Performance Collection 确定收集服务服务器作业(QYPSPFRCOL) 的当前状态 CFGPFRCOL Configure Performance Collection 更改某些收集属性并确定收集服务将如何管理数据收集 相关命令参考链接： Start Performance Collection (STRPFRCOL) Disk观察CL及相关操作 命令 描述 说明 ADDDWDFN Add Disk Watcher Definition 允许用户指定要在磁盘观察程序收集期间收集的性能数据 ENDDW End Disk Watcher 结束磁盘性能数据收集 RMVDWDFN Remove Disk Watcher Definition 从系统中删除一个或多个磁盘观察程序定义 STRDW Start Disk Watcher 开始收集磁盘性能数据 官方操作参考链接： Managing IBM i Disk Watcher Job Watcher CL命令及相关操作 命令 描述 说明 ADDJWDFN Add Job Watcher Definition 允许用户指定要在Job Watcher收集期间收集的性能数据 ENDJW End Job Watcher 结束Job Watcher收集 RMVJWDFN Remove Job Watcher Definition 允许用户删除Job Watcher定义 STRJW Start Job Watcher 启动Job Watcher收集 官方操作参考链接： Managing IBM i Job Watcher 性能资源管理器(PEX)命令及相关操作 命令 描述 说明 ADDPEXFTR Add PEX filter 向系统添加新的性能资源管理器(PEX)过滤器 PRTPEXRPT Print Performance Explorer Report 打印性能资源管理器收集的数据的格式化列表 STRPEX Start Performance Explorer 启动新的性能资源管理器会话或恢复暂停的性能资源管理器会话 ENDPEX End Performance Explorer 停止性能资源管理器会话收集数据 ADDPEXDFN Add Performance Explorer Definition 向系统添加新的性能资源管理器定义 CHGPEXDFN Change Performance Explorer Definition 更改现有的性能资源管理器定义 CRTPEXDTA Create Performance Explorer Data 根据性能资源管理器收集对象中的数据创建性能资源管理器数据库文件 DLTPEXDTA Delete Performance Explorer Data 删除由性能资源管理器工具收集并保存在特定库中的一组物理文件中的数据 RMVPEXDFN Remove Performance Explorer Definition 从系统中删除一个或多个Performance Explorer定义 RMVPEXFTR Remove Performance Explorer Filter 从系统中移除一个或多个Performance Explorer过滤器 WRKPEXDFN Work with Performance Explorer Definitions 显示现有性能资源管理器(PEX)定义的列表。可以添加新定义或显示、删除或更改现有定义 WRKPEXFTR Work with Performance Explorer Filters 显示现有性能资源管理器过滤器的列表。可以添加新过滤器或显示、删除或更改现有过滤器 官方操作参考链接： Performance Explorer IBM Performance Tools的CL命令 命令 描述 说明 ANZPFRDTA Analyze Performance Data 提供recommendations以提高系统性能 DSPPFRDTA Display Performance Data 显示收集服务收集的性能数据 PRTACTRPT Print Activity Report 打印活动报告 PRTCPTRPT Print Component Report 打印组件报告 PRTJOBRPT Print Job Interval Report 打印作业间隔报告 PRTTRCRPT Print Job Trace Report 打印作业trace报告 PRTLCKRPT Print Lock Report 打印lock报告 PRTPOLRPT Print Pool Report 打印pool报告 PRTRSCRPT Print Resource Report 打印资源报告 PRTSYSRPT Print System Report 打印系统报告 PRTTNSRPT Print Transaction Report 打印交易报告 STRPFRT Start Performance Tools 调用性能工具菜单界面 更多性能数据收集命令 命令 描述 说明 ANZCMDPFR Analyze Command Performance 测量单个CL命令或一组CL命令的性能 CFGPMAGT Configure PM Agent 配置PM代理以发送和接收PM代理性能数据 STRPFRTRC Start Performance Trace 开始收集多道程序级别和事务跟踪数据 ENDPFRTRC End Performance Trace 结束多道程序级别和事务跟踪数据的收集 DLTPFRCOL Delete Performance Collection 从系统中删除性能收集 CPYPFRCOL Copy Performance Collection 创建性能收集的副本 CVTPFRCOL Convert Performance Collection 将先前版本的性能数据转换为当前版本处理所需的格式 SAVPFRCOL Save Performance Collection 保存位于同一库中的单个性能数据集或一组性能数据集的副本 RSTPFRCOL Restore Performance Collection 恢复单个库中的一个性能数据集或一组性能数据集 性能数据收集 官方参考链接： IBM i 7.3 Collection Services IBM i 7.3 Performance data collectors Performance Tools数据收集 启动Performance数据收集，STRPFRTRC命令或者： GO PERFORM 2 Collect performance data 1 Start collect performance data   默认存放在QPFRDATA库下面，通过命令DSPPFRDTA可以查看，正在使用的member不可保存为SAVF，可以先停掉保存了到SAVF后再开启。  一天的数据可能比较大，如果只需要具体某一时间点的数据，例如几分钟的，正在使用的或之前的数据都可以进行截取，示例如下： CRTPFRDTA FROMMGTCOL(QPFRDATA/Q306000006) TOLIB(CSLIB) FROMTIME('10/02/20' '13:30:00') TOTIME('10/02/20' '13:40:00') 示例说明： 示例从QPFRDATA/Q306000006中截取了十分钟性能数据，然后保存到CSLIB 需要注意QPFRDATA/Q306000006中性能数据收集的时间段 测试可以截取目前正在使用的性能数据对象 收集的性能数据通过FTP取出SAVF即可（如果比较大建议SAVF时候启用压缩）。 Job Watcher 相关参考链接： Starting Job Watcher Start Job Watcher (STRJW) Stopping Job Watcher End Job Watcher (ENDJW) Adding a Job Watcher definition Add Job Watcher Definition (ADDJWDFN) Configuring and Starting a Job Watcher Collection Instructions on Gathering Job Watcher Monitor Data QMGTOOLS: Job Watcher Monitor Function (Continuous Job Watcher) 启动Job Watcher Navigator for i : 选择Performance All Tasks > Collectors > Job Watcher Click Start Job Watcher 命令WRKACTJOB SBS(QIDRJW)查看job状态，或者ENDJW查看活动的Job Watcher 使用示例一： STRJW DFN(MYDFN) COL(TEST) LIB(MYLIB) ENDCOL(*NBRSEC 120) 说明： 使用名为 MYDFN 的定义启动 Job Watcher 收集 使用ENDCOL(*NBRSEC 120)，数据收集将在120秒后结束，不使用则为默认ENDCOL(*NBRSEC 60)60秒 收集到的数据将写入库MYLIB中成员TEST的Job Watcher数据库文件 Job Watcher数据库文件名都以QAPYJW开头 使用示例二： STRJW DFN (MYDFN) COLITV (5) ENDCOL (* NBRITV 200)) 说明： 使用名为MYDFN的定义启动 Job Watcher收集 数据将以 5 秒的间隔收集，覆盖定义中指定的间隔 数据收集将在收集 200 个间隔后结束 数据将以成员名称写入库QPFRDATA中的 Job Watcher数据库文件，该成员名称将由Job Watcher根据收集开始的日期和时间生成 使用示例三： STRJW DFN(*SELECT) COL(TEST) LIB(MYLIB) ENDCOL((*DASDMB 100)) 说明： 打开一个提示面板，列出系统上当前存在的所有Job Watcher定义，在此面板上选择的定义将用于确定将收集哪些数据 将100MB的数据写入库MYLIB中成员TEST的Job Watcher数据库文件后，数据收集将结束 停止Job Watcher 直接输入命令ENDJW即可列出活动的collections 的列表，选择对应终止即可。示例： ENDJW COL(*SELECT) ENDJW COL(MYMBR) LIB(MYLIB) 说明： 第一条命令显示活动Job Watcher collections的列表，用户可以从中选择要结束的collections 第二条命令将结束Job Watcher collections，该collections将数据写入库MYLIB中的 Job Watcher 数据库文件中的成员MYMBR 使用示例   收集后的数据默认存放库也是QPFRDATA,可能会比较多比较杂，自己建立一个库同样可以。示例自建LIB存放性能数据和SAVF，收集5分钟的Job Watcher： CRTLIB JWLIB STRJW DFN(Q1SECSQL) COL(JW1008) LIB(JWLIB) ENDCOL((*NBRSEC 300)) CRTLIB PFRLIB CRTSAVF PFRLIB/JW1008 SAVLIB LIB(JWLIB) DEV(*SAVF) SAVF(PFRLIB/JW1008) 将SAVF文件拷贝到本地即可（如果比较大建议SAVF时候启用压缩）。 管理系统性能 官方参考链接：Managing system performance 系统性参数 官方参考链接：IBM i 7.3 System values: Performance overview 应用性能管理 官方参考链接：Applications for performance management 性能调优 官方参考链接：IBM i 7.3 Performing basic system tuning 查看性能数据 官方参考链接： Displaying performance data Viewing and analyzing data IBM Navigator for i Performance interface IBM Navigator for i Monitors性能数据中的指标 参考红皮书：IBM iDoctor for iSeries Job Watcher Advanced dvanced Performance Tool参考链接：IBMi.org – Bart's blog Dispatched CPU   线程或任务被dispatched到虚拟处理器的累计时间。Dispatched to a virtual processor意味着线程或任务已被分配一个虚拟处理器，因此它可以开始执行机器指令。  Dispatched CPU不等于通常在WRKJOB、WRKACTJOB等中看到的CPU利用率或CPU使用时间。 它包括由于多线程(SMT/HMT)与其他线程共享虚拟处理器的时间、由于LPAR共享虚拟处理器的时间，以及内存和缓存提取的时间等。Dispatched CPU通常比使用的CPU大得多时间，因为此CPU等待/共享时间包含在Dispatched CPU中。Transferred CPU CPU Queuing Disk page faults   磁盘缺页故障。这些是DASD读取(Page faults)相关的等待。Page faults经常(不完全是)是在主存储池中同时运行太多jobs/threads引起。如果发生故障的对象类型是1AEF(Temporary Process Control Space)，那么可能是此原因。但是还有其他类型的活动，其中页面错误是预期的或normal： 当程序或应用程序首次在jobs/threads中启动时 DB2访问路径(keyed parts of physical files, or Logical Files)，这些往往以高度不可预测的方式被引用，访问路径的“faulting in”页面被认为是“Normal” 访问挂起故障(SRR)是指等待本身并未发出磁盘读取，但正在等待一些正在进行的磁盘读取，这些磁盘读取可能已在此jobs/threads中异步启动，或者在某些其他jobs/threads中同步或异步启动 与此相关联的faults: SFt：MAINSTORE/LOGICAL-DASD-IO: PAGE FAULT SFP：MAINSTORE/LOGICAL-DASD-IO: PAGE FAULT IO PENDING GRf：MAINSTORE/LOGICAL-DASD-IO: ACCESS GROUP READ FOR FAULT SRR：MAINSTORE/LOGICAL-DASD-IO: ACCESS GROUP READ FOR FAULT IO PENDING Disk non fault reads Disk space usage contention Disk writes Disk other Journaling 此类是与DB2 Journaling相关的等待： JBo：Journal bundle所有者等待DASD日志writes完成。不属于DASD Write类型是因为Journal写入方式有特别之处，尽可能高效写入 JBw：Journal bundle等待DASD完成。是在执行DASD写入的线程以外的线程中发生的等待 为了提高效率，多个jobs/threads可以ride along其他jobs/threads执行的日志DASD 写入 EFJ：EPFS，等待操作系统完成请求的Journal更改 Machine level gate serialization 机器级别门序列化： QGa：Qu gate - high performance QTG：Qu retry gate 有一些相关的QGb、QGc、QGd会包含在ABNORMAL CONTENTION中说明。 Seize contention   Seize总是发生在MI对象(DB2 physical file member, Data Queue, Program, Library)。 占用可能是锁冲突，并可能导致锁冲突。有很多种Seize：shared, exclusive, “fair” and “intent-exclusive”。如果争用占Run/Wait签名的很大一部分，则可能需要检查调用堆栈、wait object and holding task/thread以了解导致争用的原因。 Seize捕获通常(不完全是)与数据库对象和操作相关联: 多个作业中的并发活动（例如打开、关闭、日志同步点、访问路径构建等）可能会导致占用等待 在多个作业中的高并发Create/Delete活动期间，可能会遇到占用等待的其他actions/objects包括库和用户配置文件   在Seize说明中提到holding task/thread这个词。Job Watcher具有确定holder的能力，而不仅仅只是抓出Seize等待情况。它可以基于称为“门”的低级序列化原语为锁、数据库记录锁和其他等待枚举执行此操作。它可以为基于称为gate的低级序列化原语为Locks,Data Base Record Locks和其它等待执行此操作。在waiters和holder方面，需要指出的是，waiter正在经历等待的job/thread往往是受害者，而不是罪魁祸首。 Seize类型详细说明： Rex-->Seize: exclusive Rex-->Seize: long running exclusive Rsh-->Seize: shared Rix-->Seize: intent exclusive Ris-->Seize: intent shared Rfa-->Seize: flush all Rdx-->Seize: database exclusive Rii-->Seize: internal intent exclusive Rot-->Seize: other Rlk-->Seize: lock conflict RXX-->Seize/lock impossible Rsp-->Seize: off-line IASP Rra-->Seize: release all Rrs-->Seize: release Rss-->Seize/lock: internal service tools hash class gate Rmf-->Seize: monitored free Rcu-->Seize: cleanup SOo-->COMMON MI OBJECT CHECKER: SEIZE OBJECT SOi-->COMMON MI OBJECT CHECKER: SEIZE FOR IPL NUMBER CHECK Rsl-->Seize: shared inhibit locks Rfl-->Seize: fair lock blocker Database record lock contention Object lock contention Abnormal contention 性能管理API 官方参考链接： Performance Management APIs 其它 升级后性能数据收集官方参考链接：IBM i 7.3 软件安装-性能数据收集 "},"05-IBM_Operating_System/02-AS400/07-AS400-作业管理.html":{"url":"05-IBM_Operating_System/02-AS400/07-AS400-作业管理.html","title":"AS400-作业管理","keywords":"","body":"AS400-作业管理 官方参考链接： IBM i 7.3 Jobs IBM i 7.3 Managing jobs IBM i 7.5 Jobs system values: Maximum jobs 常见的Job任务   用户可以对作业执行的最常见的任务，包括启动、终止、查询等。可以使用IBM Navigator for i或者字符界面菜单及CL命令操作。参考链接：IBM i 7.3 Common job tasks。 启动作业 官方参考链接：IBM i 7.3 Starting a job 启动在作业队列中等待的批处理作业   可以将作业移到不忙的作业队列，首先检查作业所在的作业队列的状态，并确定将作业移至哪个队列最合适，Navigator操作查看步骤： Work Management > All Tasks > Job Queues > Active Job Queues or All Job Queues   或将正在运行的作业搁置，然后优先移动需要启动的作业。使用此方法时要注意，因为挂起的作业仍包含在最大活动作业计数中。更改作业的优先级并指示应何时运行，操作步骤如下： 右键单击该作业，然后单击“Properties”。 在“Job Properties”窗口中，单击“Job Queue”选项卡 将“Priority on job queue”的“Priority”更改为更高的优先级（0 是最高的） 将“When to make job available to run”设置为“Now”或指定日期和时间 单击“OK” 启动预启动作业   Prestart Job通常在子系统启动的同时启动。当预启动作业因错误被系统终止或子系统启动期间由于预启动作业属性 STRJOBS(*NO)为此时，需要手动启动。可以同时处于活动状态的预启动作业的数量受预启动作业属性上的MAXJOBS属性和子系统的MAXJOBS属性的限制。使用示例： STRPJ SBS(SBS1) PGM(PJLIB/PJPGM) 示例说明： 示例为子系统SBS1中的预启动作业条目PJPGM发起启动，PJPGM在库PJLIB中 发出此命令时，子系统SBS1必须处于活动状态 已启动的作业数是在预启动作业条目PJPGM的INLJOBS值中指定的数量 结束作业 官方参考链接：IBM i 7.3 Ending a job 结束作业:controlled   以受控方式结束作业，可以指定延迟时间，如果延迟时间在作业结束前结束，则作业会立即结束。CL命令使用示例： ENDJOB JOB(001234/HQ/JOB1) OPTION(*CNTRLD) DELAY(50) SPLFILE(*NO) 示例说明： 此命令结束名为001234/HQ/JOB1的作业 假脱机输出保存为假脱机写入器的正常处理 作业有50秒的时间来执行清理例程，之后立即结束 可以通过RTVJOBA(Retrieve Job Attributes)CL命令来检索作业的结束状态 结束作业:immediate   立即结束作业时，可能会有意外结果，例如部分更新的应用程序数据。仅当受控结束不成功时才使用立即结束选项。CL命令示例： ENDJOB JOB(*) OPTION(*IMMED) ENDJOB JOB(JOB1) OPTION(*IMMED) SPLFILE(*YES) 示例说明： 第一个示例为立即结束当前作业 第二个示例为立即结束JOB1作业，作业产生的Spool File删除，作业日志保存 当使用立即结束选项时，系统执行最少的作业结束处理，其中可能包括： 关闭数据库文件 将作业日志和Spool File到输出队列 清理操作系统中的内部对象 显示作业结束显示（用于交互式作业） 完成递交的控制处理 查找作业 查找作业常用命令说明： 命令 描述 示例 WRKACTJOB Work with Active Jobs WRKACTJOB SBS(QBATCH) WRKUSRJOB Work with User Jobs WRKUSRJOB USER(BONDHUANG) WRKSBMJOB Work with Submitted Jobs WRKSBMJOB *USER WRKSBSJOB Work with Subsystem Jobs WRKSBSJOB SBS(QBATCH) 查看作业队列中的作业 IBM Navigator for i查看步骤： Work Management > All Tasks > Job Queues > Active Job Queues or All Job Queues   字符界面使用命令WRKJOBQ显示系统上所有可用作业队列的列表。找到需要查看作业队列后，选择选项5=Work with显示作业队列中的所有作业。或使用WRKSBSJOB命令来显示作业队列及其各自的作业: WRKSBSJOB SBS(*JOBQ) 查看作业属性   作业属性包含有关如何处理作业的信息，它们最初是在创建作业时指定的，一些属性来自工作描述。IBM Navigator for i中找到对应作业直接右键即可查看属性。CL命令查看： 命令WRKJOB。当作业处于活动状态时可以查看以下信息：作业运行属性、调用堆栈信息、作业锁定信息、库列表信息、作业日志信息、打开文件信息、文件覆盖信息、提交控制状态、通信状态、激活组信息、互斥信息和线程信息 命令DSPJOB。此命令显示有关作业的以下信息：作业状态属性、作业定义属性、作业运行属性、假脱机文件信息、作业日志信息、调用堆栈信息、作业锁定信息、库列表信息、打开文件信息、文件覆盖信息、承诺控制状态、通信状态、激活组信息、互斥信息、线程信息、媒体库和属性信息 查看调用堆栈   命令WRKJOB或DSPJOB选择选项11. Display call stack, if active。如果查看线程的调用堆栈，选择选项20. Display threads, if active，然后选择选项10=Display call stack。 将作业放入作业队列 以下是使用字符界面将新作业放置在新作业队列中的方法： 提交作业SBMJOB：允许正在运行的作业将另一个作业提交到作业队列，以便稍后作为批处理作业运行。只能将请求数据的一个元素放置在新作业的消息队列中。如果用于作业的路由条目指定了CL命令处理程序，则请求数据可以是CL命令 添加作业计划条目ADDJOBSCDE：系统在作业计划条目中指定的时间和日期自动将作业提交到作业队列 提交数据库作业SBMDBJOB：将作业提交到作业队列，以便它们可以作为批处理作业运行。此命令允许用户指定此数据库文件及其成员的名称、要使用的作业队列的名称，并决定是否可以通过WRKSBMJOB(Work with Submitted Jobs)命令来显示正在提交的作业 启动数据库读取器STRDBRDR：从数据库读取批处理输入流并将一个或多个作业放置在作业队列中 移动作业TFRJOB：将当前作业移动到活动子系统中的另一个作业队列 移动批处理作业TFRBCHJOB：将当前作业移动到另一个作业队列 将作业移动到不同的作业队列   有时由于长时间运行的作业，作业会积压在队列中；或者作业的计划运行时间与具有更高优先级的新作业冲突。解决这种情况的一种方法是将等待的作业移到另一个相对闲的队列中。可以使用CHGJOB命令，例如将作业JOBA移动到作业队列JOBQB： CHGJOB JOB(JOBA) JOBQ(LIBA/JOBQB) 作业队列中调整作业的优先级   作业队列中的所有作业都排队等待处理，队列中作业的处理顺序取决于作业的优先级，以及子系统上可以同时运行的最大作业数。作业队列中作业的优先级有助于确定作业何时进入子系统运行。从0到9的范围（0是最高）决定了作业队列中作业的优先级。  命令CHGJOB中参数JOBPTY是关于优先级的，输入CHGJOB命令后按F4,然后按F9可以看到更多属性选项，命令示例： CHGJOB JOB(PAYROLL) JOBPTY(4) 说明： 该命令将作业PAYROLL的调度优先级更改为4 由于只指定了作业的简单名称，因此系统中只能存在一个名为PAYROLL的作业。如果有多个，默认的DUPJOBOPT(*SELECT)会导致在交互式作业中显示选择面板 设置工作优先级的技巧 官方参考链接：IBM i 7.3 Tips for setting job priorities 提交一次性作业   需要立即或在预定的日期和时间运行一次作业时，可以使用SBMJOB(Submit Job)命令,此方法立即将作业放入作业队列： SBMJOB命令将作业提交到批处理作业队列通过指定作业描述和指定CL命令或请求数据或指定路由数据来运行程序 如果要在批处理作业中运行单个CL命令，在SBMJOB上使用CMD参数，它会进行语法检查并提示   使用示例，例如SBMJOB命令使用作业描述QBATCH将名为WSYS的作业提交到作业队列QBATCH，CMD参数给出将在作业中运行的CL命令: SBMJOB JOBD(QBATCH) JOB(WSYS) JOBQ(QBATCH) CMD(WRKSYSSTS) 查看作业关联信息 使用IBM Navigator for i： Work Management > Active Jobs 选中需要查看的Job，右键选择Properties 在弹出页面上，选择Memory and processor affinity即可查看 使用字符界面输入命令WRKJOB，选择选项Display job run attributes, if active。 管理作业描述   由于作业描述包括了一组特定的作业相关属性，因此多个作业可以使用相同的作业描述，无需为每个作业重复指定相同的参数。用户可以创建作业描述来描述批处理作业或交互式作业，用户还可以为系统的每个用户创建唯一的描述。官方参考链接：IBM i 7.3 Managing job descriptions。 创建作业描述 使用WRKJOBD命令或CRTJOBD命令来创建作业描述，示例如下： CRTJOBD JOBD(BATCH3) USER(*RQD) JOBQ(NIGHTQ) JOBPTY(4) OUTPTY(4) ACGCDE(NIGHTQ012345) RTGDTA(QCMDB) TEXT('Batch #3 JOBD for high priority night work') 示例说明： 示例在用户的当前库中创建名为BATCH3的作业描述 使用此描述的作业放置在作业队列NIGHTQ中 使用此描述的作业的spooled output的优先级为4 QCMDB是与作业运行所在子系统的路由表中的条目进行比较的路由数据 记帐代码NIGHTQ012345用于记录使用此作业描述的作业的记帐统计信息 其它说明： 作业描述中的值通常是BCHJOB和SBMJOB命令中未指定参数时相应参数的默认值 作业描述中的值可以被BCHJOB和SBMJOB命令上指定的值覆盖 更改作业描述 使用WRKJOBD命令或CHGJOBD命令来创建作业描述，示例如下： CHGJOBD JOBD(QGPL/QPGMR) JOBPTY(2) OUTPTY(2) 示例说明： 示例为设置作业运行和输出优先级。在QGPL库中使用IBM提供的作业描述QPGMR的作业和输出优先级调整为2 QPGMR最初将作业运行和输出优先级设置为级别5 其它说明： 更改作业描述后启动的所有使用该作业描述的作业都会受到影响 如果用户将作业参数更改为与作业描述中指定的内容不同的参数，则该参数不受影响 使用作业描述   作业描述的最常见方法是在SBMJOB命令中指定，参数： job description (JOBD)，例如使用指定的工作描述而不覆盖其任何属性： SBMJOB JOB(OEDAILY) JOBD(QBATCH) 使用指定的工作描述但覆盖某些属性（使用BCHJOB或SBMJOB命令）。例如覆盖作业描述QBATCH中的消息日志记录： SBMJOB JOB(OEDAILY) JOBD(QBATCH) LOG(2 20 *SECLVL) 注意，不能覆盖自动启动作业、工作站作业或通信作业的任何作业描述属性。支持作业描述参数的其它命令： Batch Job (BCHJOB)：此命令指示批处理输入流中批处理作业的开始 Add Prestart Job Entry (ADDPJE)： 命令向指定的子系统描述添加预启动作业条目 Add Autostart Job Entry (ADDAJE)：命令向指定的子系统描述添加自动启动作业条目 Add Work Station Entry(ADDWSE)：命令将工作站条目添加到指定的子系统描述中 控制作业属性资源   子系统分配给作业的属性来自五个来源；作业描述、用户的配置文件、系统值、发出提交作业 (SBMJOB) 命令的作业和工作站（仅限交互式作业）。 使用命令CHGJOBD可以要控制作业属性并告诉子系统何时何地从不同系统对象获取作业属性： *JOBD：告诉工作从工作描述中获取其属性 *USRPRF：告诉作业从用户的用户配置文件中获取其属性 *SYSVAL：告诉作业从系统值中获取其属性 *CURRENT：告诉作业从发出提交作业 (SBMJOB) 命令的作业中获取其属性 *WRKSTN：告诉作业从带有作业的工作站获取其属性（仅限交互式作业） 删除作业描述   使用WRKJOBD命令或DTLJOBD命令来删除作业描述（已在进行中的作业不受此命令的影响），示例从库MYLIB里面删除MYJOBD作业描述： DLTJOBD JOBD(MYLIB/MYJOBD) 管理批处理作业   批处理作业是不需要用户交互即可运行处理的作业。通常是低优先级作业，可能需要特殊的系统环境才能运行。官方参考链接：IBM i 7.3 Managing batch jobs。 提交批处理作业   批处理作业通常是需要特殊系统环境才能运行（例如在夜间运行）的低优先级作业，在作业队列中，批处理作业接收运行时间计划和优先级。提交作业到批处理作业队列命令： Submit Job (SBMJOB)：将作业提交到批处理作业队列通过指定作业描述、指定 CL 命令或请求数据，或指定路由数据来运行程序 Submit Database Job (SBMDBJOB)：用于将作业从数据库文件提交到批处理作业队列。对于这些作业，作业描述来自输入流中的BCHJOB语句   SBMJOB 命令使用作业描述QBATCH将名为WSYS的作业提交到作业队列QBATCH，CMD参数给出将在作业中运行的 CL 命令，示例： SBMJOB JOBD(QBATCH) JOB(WSYS) JOBQ(QBATCH) CMD(WRKSYSSTS) 说明： 如果收到作业未提交的消息，可以显示作业日志Spooled文件以查找错误 使用WRKJOB命令，并指定作业，选择选项4. Work with spooled files。显示作业的日志Spooled文件以查找错误 启动在作业队列中等待的批处理作业 参考上面启动作业章节中的启动在作业队列中等待的批处理作业小节。 管理交互式作业 当用户登录系统或转移到secondary或组作业时，交互式作业开始。当用户退出时，交互式作业结束。 控制非活动作业和workstations   通过在系统值QINACTITV(Time-out interval for inactive jobs)中指定时间间隔，用户可以控制在子系统发送消息（called time-out）之前工作站可以保持非活动状态的时间量。 确定workstations处于非活动状态 以下所有条件都满足，则子系统确定工作站处于非活动状态： 作业在计时器间隔期间未处理任何其他事务，事务被定义为任何操作员交互，如滚动、按回车键、按功能键等 作业状态为display wait 作业not disconnected 作业状态没有改变。 运行作业的子系统未处于受限状态（restricted state） 处理非活动作业 使用系统值QINACTMSGQ(Inactive job message queue)确定处理选项来处理非活动作业： 将QINACTMSGQ系统值设置为消息队列名称，用户或程序可以监视消息队列并采取任何需要的操作，例如结束作业 将QINACTMSGQ统值设置为*DSCJOB，系统将断开工作站上的所有作业: 系统发送一条消息，指示工作站上的所有作业都已与QSYSOPR或配置的消息队列断开连接。（配置的消息队列是显示设备描述的MSGQ参数中指定的消息队列，默认为QSYS或QSYSOPR） 如果交互式作业不支持断开作业，则作业结束 对于作业处于非活动状态的每个时间间隔，都会继续发送一条消息 将系统值QINACTMSGQ设置为*ENDJOB，系统将结束工作站上的所有作业： 系统向QSYSOPR或配置的消息队列发送一条消息，指示工作站上的所有作业都已结束 注意事项： 源传递作业、客户端VTM（虚拟终端管理器）作业和3270设备仿真作业被排除在超时之外，它们始终显示为非活动状态 System/36环境MRT作业也被排除在外，因为它们显示为批处理作业 结束交互式作业 结束交互式作业方法： 使用IBM Navigator for i，在Confirm Delete/End窗口中，可以指定以受控方式结束或立即结束交互式作业 使用ENDJOB命令结束交互式作业 在workstation上使用SIGNOFF(Sign Off)命令立即结束交互式作业。在SIGNOFF命令中使用参数ENDCNN通过网络结束连接 要从设备断开所有作业，请使用DSCJOB命令 断开所有作业与设备的连接   命令DSCJOB允许交互式用户断开工作站上的所有交互式作业并返回到登录显示。如果在达到QDSCJOBITV系统值中的断开间隔时，作业将结束并且在作业的spooled输出中不包括作业日志。限制： 断开连接的作业必须是交互式作业，不能断开正在挂起的作业 除非用户使用系统请求功能从直通目标系统返回源系统，否则不能断开直通作业 命令必须从被断开连接的作业中发出，或与被断开的作业的作业用户身份相同的用户配置文件下运行，或命令的发出者必须在具有*JOBCTL特殊权限的用户配置文件中 作业用户标识是用户配置文件的名称 如果PC管理器处于活动状态，则无法断开作业 断开作业注意事项： System Request菜单上的一个选项允许用户断开交互式作业，该选项调用DSCJOB命令 再次连接作业时，将忽略在登录显示屏上为程序、菜单和当前库指定的值 无法断开已激活PC管理器或PC文本辅助功能的作业 如果由于任何原因无法断开作业，则作业将结束 子系统结束时，子系统中所有断开连接的作业也结束。如果子系统即将结束，则无法在子系统中的任何作业中发出DSCJOB命令 系统值QDSCJOBITV(Disconnect Job Interval)可用于指示可以断开作业的时间间隔，如果达到时间间隔，则断开的作业结束 未超过QDSCJOBITV系统值的断开连接的作业将在子系统结束或发生IPL时结束 避免工作站长时间运行的功能 子系统描述QSYS/QBATCH或QSYS/QBASE具有可用于此目的的作业队列QSYS/QBATCH。示例： SBMJOB JOB(SAVELIBX) JOBD(QBATCH) JOBQ(QSYS/QBATCH) CMD(SAVLIB LIBX DEV(DKT01)) Job状态 Job初始线程状态   作业的初始线程状态。每个作业只显示一个状态。空白状态字段表示处于转换中的初始线程。作业初始线程状态值有如下可能： BSCA：作业的初始线程在活动级别，等待在二进制同步设备的I/O操作完成 BSCW：作业的初始线程等待对二进制同步设备的I/O操作完成 CMNA：作业的初始线程在活动级别的等待对通信设备的I/O操作完成 CMNW：作业的初始线程正在等待对通信设备的I/O操作完成 CMTW：作业的初始线程正在等待另一个作业中的save-while-active检查点处理完成。此等待对于防止将部分提交控制事务保存到Media是必要的 CNDW：作业的初始线程正在等待handle-based的条件 CPCW：作业的初始线程正在等待CPI Communications调用的完成 DEQA：作业的初始线程正在等待池活动级别中的出队操作完成 DEQW：作业的初始线程正在等待出队操作的完成。例如，QSYSARB和子系统监视器通常通过等待出队操作来等待工作 DKTA：作业的初始线程在活动级别等待软盘设备I/O操作完成 DKTW：作业的初始线程正在等待对软盘设备的I/O操作完成 DLYW：由于DLYJOB(Delay Job)命令，作业的初始线程在等待时间间隔结束或特定延迟结束时间时被延迟。函数字段显示作业要延迟的秒数(999999)，或作业要恢复运行的具体时间 DSC：作业已与工作站显示断开连接 DSPA：作业的初始线程在活动级别等待工作站显示的输入 DSPW：作业的初始线程正在等待工作站显示的输入 END：作业已使用*IMMED选项结束，或已使用*CNTRLD选项延迟时间结束 EOFA：作业的初始线程在活动级别等待在到达文件结尾后再次尝试对数据库文件执行读取操作 EOFW：作业的初始线程正在等待到达文件结尾后再次尝试对数据库文件执行读取操作 EOJ：作业因ENDJOB(End Job)或ENDSBS(End Subsystem)以外的原因而结束。例如，SIGNOFF或ENDGRPJOB(End Group Job)或未处理的异常 EVTW：作业的初始线程正在等待一个事件。例如，QLUS和SCPF通常通过等待事件来等待工作 GRP：作业因TFRGRPJOB(Transfer to Group Job)命令而暂停 HLD：作业正在held状态 HLDT：作业的初始线程在held状态 ICFA：作业的初始线程在活动级别等待完成对系统间通信功能文件的I/O操作 ICFW：作业的初始线程正在等待对系统间通信函数文件的I/O操作完成 INEL：作业的初始线程不合格，当前不在池活动级别 JVAA：作业的初始线程在池活动级别等待的Java程序操作完成 JVAW：作业的初始线程在等待的Java程序操作完成 LCKW：作业的初始线程正在等待锁 LSPA：作业的初始线程在池活动级别中等待附加的锁定空间 LSPW：作业的初始线程正在等待附加锁空间 MLTA：作业的初始线程在活动级别等待完成对多个文件的I/O操作 MLTW：作业的初始线程正在等待对多个文件的I/O操作完成 MSGW：作业的初始线程正在等待来自消息队列的消息 MTXW：作业的初始线程处于互斥等待状态。互斥锁是一种同步功能，用于允许多个作业或进程序列化它们对共享数据的访问 MXDW：作业的初始线程正在等待对混合设备文件的I/O操作完成 OPTA：作业的初始线程在活动级别等待完成对光学设备的I/O操作 OPTW：作业的初始线程在等待完成对光学设备的I/O操作 OSIW：作业的初始线程正在等待OSI通信子系统OSLISN、OSRACS、OSRACA、OSRCV或OSRCVA操作的完成 PRTA：作业的初始线程在活动级别等待输出到打印机的完成 PRTW：作业的初始线程正在等待完成对打印机的输出 PSRW：作业的初始线程是等待程序启动请求的预启动作业 RUN：作业的初始线程当前正在活动级别运行 SELW：作业的初始线程处于选择等待状态 SEMW：作业的初始线程正在等待信号量。信号量是一种同步功能，用于允许多个作业或线程序列化它们对共享数据的访问 SIGS：作业的初始线程被一个信号停止 SIGW：作业的初始线程正在等待一个信号 SRQ：作业的初始线程是系统请求作业对的暂停的一半 SVFA：作业的初始线程在活动级别中等待Save File操作的完成 SVFW：作业的初始线程在等待Save File操作的完成 TAPA：作业的初始线程在活动级别等待对磁带设备的I/O操作完成 TAPW：作业的初始线程在等待对磁带设备的I/O操作完成 THDW：初始线程正在等待另一个线程完成操作 TIMA：作业的初始线程在活动级别，正在等待一个时间间隔后结束 TIMW：作业的初始线程正在等待一个时间间隔后结束 SMB Job状态   使用WRKJOBSCDE(Work with Submitted Jobs)命令查看SBM作业时，系统中显示的作业状态有如下几种类型： ACTIVE: 作业已经启动 ACTIVE HELD: 作业已经启动，但处于held状态 DSC: 作业已断开连接 DSC HELD: 作业已断开连接并处于held状态 END: 作业因为ENDJOB(End Job)或ENDSBS(End Subsystem)命令正在终止，使用immediate选项或使用controlled选项导致作业在延迟时间到期时结束 EOJ: 作业因为ENDJOB(End Job)或ENDSBS(End Subsystem)以外的命令正在终止(例如，作业正常结束或有未处理的异常) FIN: 作业已经完成 JOBLOG PENDING: 作业已完成，作业日志尚未写入 JOBQ: 该作业位于作业队列中，但不是TFRJOB(Transfer Job)或TFRBCHJOB(Transfer Batch Job)命令的结果 JOBQ HELD: 该作业位于作业队列中并处于held状态，但不是TFRJOB(Transfer Job)或TFRBCHJOB(Transfer Batch Job)命令的结果 MSGW: 作业的初始线程有消息在等待 OUTQ: 作业已完成运行，并且在输出队列上具有Spooled文件 OUTQ HELD: 作业已完成运行，在输出队列上具有Spooled文件。Spooled文件通过命令HLDJOB(Hold Job)处于held状态 SCD: 作业安排在特定日期和时间运行 SYSREQ: 作业因系统请求而暂停 SYSREQ HELD: 作业因系统请求而暂停，作业处于held状态 TFRBCH: 作业由于TFRBCHJOB(Transfer Batch Job)命令在作业队列中 TFRBCH HELD: 作业由于TFRBCHJOB(Transfer Batch Job)命令在作业队列中，作业处于held状态 TFRJOB: 作业由于TFRJOB(Transfer Job)命令在作业队列中 TFRJOB HELD: 作业由于TFRJOB(Transfer Job)命令在作业队列中，作业处于held状态 Job Table 官方参考链接： Job Table Capacity (Recovering from SRCB9003610) Display Job Tables(DSPJOBTBL) DSPJOBTBL命令 命令示例： Display Job Tables PUB400 07/13/22 14:36:10 UTC Permanent job structures: Temporary job structures: Initial . . . . : 1000 Initial . . . . : 500 Additional . . . : 10 Additional . . . : 30 Available . . . : 195675 Available . . . : 161 Total . . . . . : 216783 Storage used . . : 69,67 M Maximum . . . . : 970000 ---------------------Entries---------------------- Table Size Total Available In-use Other 8 16752384 16352 16345 7 0 9 16752384 16352 16335 17 0 Permanent job structures   当作业进入系统时，一个永久的作业结构被分配给一个作业。在没有Spooled输出的情况下作业结束或打印作业的所有Spooled输出之前，永久作业结构不可重复使用。条目说明： Initial：系统值QTOTJOB的当前值。此值是在IPL期间为其分配辅助存储的作业表中的初始条目数 Additional：系统值QADLTOTJ的当前值。该值是当作业表中没有更多可用条目时为其分配辅助存储的额外条目数。尽管此值可以设置为大于500，但一次最多可以添加500个作业表条目 Available：可用于系统上新作业的条目数。如果没有可用条目，系统将在开始新作业时遇到性能下降，因为需要扩展表： 但是，过多的可用条目会降低处理与作业一起使用的表和运行时函数的IPL步骤期间的性能 如果可用条目的数量很大，可以在下一次IPL(initial program load)期间压缩作业表 可以使用CHGILPA(Change IPL Attributes)命令更改压缩作业表的选项 Total：所有作业表中包含的条目总数 Maximum：系统上允许的最大作业数(QMAXJOB系统值) Temporary Job Structures   临时作业结构在其变为活动状态时被分配给作业。当作业结束时，临时作业结构可供下一个将变为活动的作业重用。此存储是在使用系统值QTOTJOB时分配的存储之外的。条目说明： Initial：系统值QACTJOB的当前值。该值是在IPL期间为其分配存储的临时作业结构的初始数量 Additional：系统值QADLACTJ的当前值。当所有可用的临时作业结构都分配给活动作业时，此值是为其分配存储的临时作业结构的附加数量 Available：已创建但尚未分配给活动作业的临时作业结构的数量。当作业变为活动状态时，这些作业结构可供使用 Storage used：用于临时作业结构的存储。这包括活动和可用的作业结构 Entries列说明 DSPJOBTBL命令中，Entries的列表项说明： Table：作业表的编号 Size：作业表的大小，单位为bytes Total：作业表中包含的条目总数 Available：可用于新作业的条目数。如果没有可用条目，系统将在开始新作业时遇到性能下降，因为需要扩展表： 但是，过多的可用条目会降低处理与作业一起使用的表和运行时函数的IPL步骤期间的性能 如果可用条目的数量很大，可以在下一次IPL期间压缩作业表 可以使用CHGILPA(Change IPL Attributes)命令更改压缩作业表的选项 In-use：当前由作业队列上的作业、活动的作业或已完成但在输出队列上仍有Spooled输出的作业当前使用的条目数 Other：不可用且当前未被作业队列上的作业、活动作业或已完成但仍在输出队列上具有Spooled输出的作业使用的条目数： 包括标记为不可用的条目和用于正在转换的作业（例如，正在从作业队列转换到活动状态的作业）的条目 第一个表中的一个条目保留用于错误恢复 In-use Entries In-use Entries表示作业当前使用的条目数，列表项说明： Table：作业表的编号 Active：当前由活动作业使用的条目数 Job queue：作业队列中的作业当前使用的条目数 Output queue：已在输出队列上完成Spooled输出的作业当前正在使用的条目数。这不包括尚未写入作业日志的作业 Joblog Pending：已完成且尚未写入的作业日志的作业当前正在使用的条目数。这些作业可能在输出队列上进行了Spooled输出 Job Table Capacity   系统作业表具有最大容量。如果达到此容量，系统可能会崩溃。系统作业表的相关说明如下： 可以在系统上创建的作业结构的最大数量由系统值QMAXJOB控制 此系统值的系统限制最大值为970000 在7.1及更早版本中，此限制为485000 Sipped value为163520 作业表中的条目（或者叫作业结构）可以分解为活动作业、处于JobQ状态的作业、处于 Job Log Pending状态的作业以及来自处于OutQ状态的作业的Spooled文件 作业表条目包含有关作业的信息，例如运行参数、统计信息、Spooled文件信息等 CPI1468-系统作业表接近承载力   当系统作业表中的条目数接近允许的最大数量（在QMAXJOB中指定）时，系统会发送此消息。 当看到此消息时，应immediately增加QMAXJOB系统值： 没有应该使用的固定数量，但是，应该将其至少增加 50000，以便有时间调查填满作业表的内容 不要将其增加到970000的系统限制。 最好以增量的方式增加它，以便在填满时候有恢复的空间 此外，不要退出当前的交互式会话。只要有权访问活动的交互式作业，就可以在没有IPL的情况下调查原因并采取措施纠正它 一旦QMAXJOB增加并且系统脱离直接危险，请按照Investigating Cause of Increased Job Table Usage部分下方的说明进行操作 从SRCB9003610恢复 待补充 "},"05-IBM_Operating_System/02-AS400/08-AS400-子系统管理.html":{"url":"05-IBM_Operating_System/02-AS400/08-AS400-子系统管理.html","title":"AS400-子系统管理","keywords":"","body":"AS400-子系统管理 官方参考链接： IBM i 7.3 Subsystems IBM i 7.3 Managing subsystems 常用子系统任务 查看子系统属性   可以查看属性有：子系统的名称，包含子系统描述的库，子系统描述，子系统状态，子系统中的激活作业数量，子系统中最大激活作业数，子系同作业的名称用户和数量等。使用IBM Navigator for i查看： Work Management > Subsystems > Active Subsystems 选中需要查看的子系统，单击邮件选择Properties即可查看 使用命令DSPSBSD查看QBATCH的子系统描述： DSPSBSD QBATCH 或者使用WRKSBS命令，选中需要查看的子系统，选择选项5=Display subsystem description。 启动子系统 使用IBM Navigator for i 启动： 展开 Work Management > Active Subsystems. 单击Actions > Start Subsystem 指明要启动的子系统的名称和库，然后单击OK 使用命令STRSBS示例，示例启动批处理子系统，名称为QBATCH： STRSBS SBSD(QBATCH) 示例启动与QGPL库中的TELLER子系统描述相关联的子系统，子系统名称是 TELLER： STRSBS SBSD(QGPL/TELLER) 说明： 命令 STRSBS命令使用命令中指定的子系统描述启动子系统 当子系统启动时，系统会分配子系统描述中指定的必要和可用资源(存储、工作站和作业队列) 停止子系统 方式停止： controlled(推荐)：以受控方式结束子系统，作业也以受控方式结束: 允许正在运行的程序执行清理（作业处理结束） 当正在结束的作业具有异步信号SIGTERM的信号处理过程时，将为该作业生成SIGTERM信号 在作业结束之前，应用程序具有为DELAY参数指定的完成清理的时间量 Immediate：立即结束子系统，作业也立即结束： 当正在结束的作业具有异步信号SIGTERM的信号处理过程时，将为该作业生成SIGTERM信号并且QENDJOBLMT系统值指定时间限制 除了处理SIGTERM信号外，不允许正在运行的程序执行任何清理 说明： 建议尽可能使用受控选项停止子系统，这允许活动作业自行结束 使用controlled可确保作业在子系统结束之前完成，这允许正在运行的程序执行清理（作业结束处理） 指定Immediate可能会导致不良结果 创建子系统描述 官方参考文档：IBM i 7.3 Creating a subsystem description 创建子系统描述方法 复制现有子系统描述： 创建现有子系统描述的重复对象，使用命令CRTDUPOBJ(Create a Duplicate Object)。或者使用使用WRKOBJ(Work with Objects)或WRKOBJPDM(Work with Objects using Programming Development Manager)命令 更改子系统描述的副本，使其按需要的方式运行： 例如，需要删除作业队列条目，因为它标识了原始子系统使用的作业队列。然后您需要创建一个新的作业队列条目，指定新子系统使用的参数 需要查看自动启动作业条目、工作站条目、预启动作业条目和通信条目，并确认两个子系统之间没有冲突。例如，验证workstation条目不会导致两个子系统分配相同的显示设备 创建全新的子系统描述： Create a Subsystem Description(CRTSBSD). Create a Job Description(CRTJOBD). 为Add Prestart Job Entry(ADDPJE)和Add Routing Entry(ADDRTGE)创建一个类：Create a Class(CRTCLS) 将工作条目添加到子系统描述中： Add Workstation Entry(ADDWSE) Add Job Queue Entry(ADDJOBQE) Add Communications Entry(ADDCMNE) Add Autostart Job Entry (ADDAJE) Add Prestart Job Entry (ADDPJE) Add Routing Entries(ADDRTGE)到子系统描述中 添加自启动作业条目   当关联的子系统启动时，自动启动作业会自动启动。这些作业通常执行与特定子系统相关联的初始化工作。自动启动作业还可以执行重复性工作或为同一子系统中的其他作业提供集中服务功能。使用命令ADDAJE添加自启动作业条目，使用示例： ADDAJE SBSD(ACCTLIB/ACCTINT) JOB(ACCTINIT) JOBD(ACCTLIB/INITSBS) 说明： 示例为库ACCTLIB中的作业ACCTINIT子系统描述ACCTINT添加自动启动作业条目 每当子系统ACCTINT启动时，自动启动的作业可能用于执行某些例程 当子系统启动时，ACCTLIB中的作业描述INITSBS用于获取该作业的属性，作业ACCTINIT在子系统中自动启动 要使更改生效，必须结束活动子系统然后重新启动 添加预启动作业条目   预启动作业条目可以在子系统启动或输入STRPJ命令时启动，使用命令ADDPJE来添加与启动作业条目，示例将预启动作业条目添加到子系统描述ABC中： ADDPJE SBSD(USERLIB/ABC) PGM(START) JOBD(USERLIB/STARTPJ) 指定最大预启动作业数： ADDPJE SBSD(QGPL/PJSBS) PGM(QGPL/PGM2) USER(PJUSER) MAXJOBS(100) CLS(QGPL/CLS1 75 QGPL/CLS2 *CALC) MAXUSE(50) 示例说明： 将QGPL库中PGM2程序的预启动作业条目添加到QGPL库中包含的PJSBS子系统描述中 指定该预启动作业在PJUSER用户配置文件下运行 此条目可以同时处于活动状态的最大预启动作业数为100 池中的每个预启动作业在作业结束前可以处理50个请求 如果此条目同时有100个预启动作业处于活动状态，则其中75个将使用QGPL库中的CLS1，其中25个将使用QGPL库中的CLS2 如果该条目的50个预启动作业同时处于活动状态，则所有50个作业都将使用QGPL库中的CLS1 添加作业队列条目   作业队列条目标识作业队列，从中选择作业在子系统中运行，从作业队列启动的作业是批处理作业。可以在作业队列条目中指定以下项目： JQBQ：作业队列名称 MAXACT：作业队列中可同时处于活动状态的最大作业数 SEQNBR：子系统从可以启动的作业中选择作业队列的顺序 MAXPTYn：对于指定的作业队列优先级，可以同时处于活动状态的最大作业数 添加示例： ADDJOBQE SBSD(QGPL/NIGHTSBS) JOBQ(QGPL/NIGHT) MAXACT(3) 说明： 将QGPL库中NIGHT作业队列的作业队列条目添加到QGPL库中NIGHTSBS子系统描述中 指定NIGHT作业队列中最多3个批处理作业可以在子系统中同时处于活动状态 添加通讯条目   每个通信条目描述一个或多个通信设备、设备类型或远程位置，当收到程序启动请求时，子系统将针对这些通信设备启动作业。使用命令ADDCMNE添加： ADDCMNE SBSD(ALIB/SBS1) DEV(COMDEV) 示例说明： 示例中将名为COMDEV和模式*ANY(默认）的APPC设备的通信条目添加到库ALIB中的子系统描述SBS1`中 DFTUSR参数默认为*NONE，除非在程序启动请求中提供了有效的安全信息，否则任何作业都不能通过此条目进入系统 用户必须指定DEV参数或RMTLOCNAME参数，但不能同时指定两者 添加路由条目   每个路由条目指定用于启动作业的路由步骤的参数。路由条目标识要使用的主存储子系统池、要运行的控制程序（通常是系统提供的程序QCMD）和附加运行时信息（存储在类对象中）。使用命令ADDRTGE添加： ADDRTGE SBSD(QGPL/ABLE) SEQNBR(5) CMPVAL(XYZ) PGM(QGPL/REORD) CLS(LIBX/MYCLASS) MAXACT(*NOMAX) 示例说明： 示例将路由条目5添加到QGPL库中的子系统描述ABLE 当XYZ的比较值（从位置1开始）在路由数据中匹配时，库QGPL中的程序REORD被启动并使用LIBX中的类MYCLASS 该程序在ID为1的存储池中运行，并且允许的活动routing steps没有最大值 添加工作站条目   当用户登录或从另一个子系统传输交互式作业时启动作业时，将使用工作站条目。使用命令ADDWSE添加，示例如下： ADDWSE SBSD(LIB7/ORDER) WRKSTN(A12) JOBD(LIB7/ORDER) AT(*ENTER) 示例说明： 示例将工作站A12的工作站作业条目添加到库LIB7中ORDER子系统描述中 与工作站A12关联的交互作业可以通过Transfer Job(TFRJOB)命令进入该子系统 创建登录显示文件   登录显示文件用于在分配给子系统的工作站上显示登录显示。当子系统处于活动状态时，可以更改登录显示文件,在下次启动子系统时才会使用新的登录显示文件。使用命令CRTDSPF(Create Display File)创建，具体参考官方文档。 指定新的登录显示   子系统使用在子系统描述的SGNDSPF参数(默认值QDSIGNON)中指定的登录显示文件在用户工作站上创建登录显示。使用命令CHGSBSD进行指定： CHGSBSD SBSD(QSYS/QBATCH) SGNDSPF(MYSIGNON) 说明： 示例子系统QBATCH的登录显示文件从默认值更改为名为MYSIGNON的新文件 在尝试更改控制子系统之前，使用子系统的测试版本来验证显示是否有效 更改子系统描述 更改子系统描述方法   命令CHGSBSD更改指定子系统描述的操作属性。可以在子系统处于活动状态时更改子系统描述，但不能在POOLS参数上指定 *RMV值，作业可能会暂停。示例更改语言库，将子系统描述SPANISH更改为西班牙语辅助语言： CHGSBSD SBSD(QGPL/SPANISH) SGNDSPF(QSYS2931/QDSIGNON) SYSLIBLE(QSYS2931) 更改条目 和创建差不多： 更改自动启动作业条目：CHGAJE(Change Autostart Job Entry) 更改预启动作业条目：CHGPJE(Change Prestart Job Entry) 更改作业队列条目：CHGJOBQE(Change Job Queue Entry) 更改通信条目：CHGCMNE(Change Communications Entry) 更改路由条目：CHGRTGE(Change Routing Entry) 更改工作站条目：CHGWSE(Change Workstation Entry) 更改登录显示： 创建一个新的登录显示文件 更改子系统描述以使用更改后的显示文件而不是系统默认值 详细参考官方文档：Changing a subsystem description 删除子系统描述   命令DLTSBSD(Delete Subsystem Description)从系统中删除指定的子系统描述（包括添加到其中的任何工作条目或路由条目）。更多说明： 通过ADDJOBQE(Add Job Queue Entry)命令分配给该子系统的作业队列不会被删除 当用户删除子系统描述(SBSD)时，SBSD引用的任何对象都不会被删除。 关联的子系统在删除之前必须处于非活动状态 示例从库LIB11中删除名为BAKTEST的非活动子系统描述： DLTSBSD SBSD(LIB1/BAKTEST) 删除条目 和创建及修改差不多： 删除自动启动作业条目：RMVAJE(Remove Autostart Job Entry) 删除预启动作业条目：RMVPJE(Remove Prestart Job Entry) 删除作业队列条目：RMVJOBQE(Remove Job Queue Entry) 删除通信条目：RMVCMNE(Remove Communications Entry) 删除路由条目：RMVRTGE(Remove Routing Entry) 删除工作站条目：RMVWSE(Remove Workstation Entry) 详细参考官方文档：Deleting a subsystem description 配置交互式子系统   设置一个新的交互式子系统时，应该考虑将有多少设备分配给该子系统。由于子系统执行设备管理功能，例如呈现登录显示和处理设备错误恢复，用户可能需要限制分配给单个子系统的设备数量。 创建步骤 第一步：创建库 示例创建一个库来存储用户的子系统配置对象： CRTLIB SBSLIB TEXT('LIBRARY TO HOLD SUBSYSTEM CONFIGURATION OBJECTS') 第二步：创建类 类定义了交互式子系统的某些性能特征。示例创建与QINTER类相同的类： CRTCLS SBSLIB/INTER1 RUNPTY(20) TIMESLICE(2000) PURGE(*YES) DFTWAIT(30) TEXT('Custom Interactive Subsystem Class') 第三步：创建子系统描述   对于需要定义的每个子系统，重复此步骤以创建子系统描述。示例创建属性与QINTER属性相同的子系统描述： CRTSBSD SBSD(SBSLIB/INTER1) POOLS((1 *BASE) (2 *INTERACT)) SGNDSPF(*QDSIGNON) 第四步：创建作业队列   可以使用与子系统名称相同的名称为子系统创建作业队列，并将作业队列条目添加到子系统描述中： CRTJOBQ JOBQ(SBSLIB/INTER1) ADDJOBQE SBSD(SBSLIB/INTER1) JOBQ(SBSLIB/INTER1) MAXACT(*NOMAX)   如果需要使用TFRJOB(Transfer Job)命令将作业转移到用户自定义子系统中，则需要此步骤。 第五步：创建路由条目   系统提供的用于QINTER的路由条目具有一些附加功能。如果需要这些功能，将这些路由条目添加到自定义子系统描述中： ADDRTGE SBSD(SBSLIB/INTER1) SEQNBR(9999) CMPVAL(*ANY) PGM(QSYS/QCMD) POOLID(2) 第六步：创建工作站条目 将工作站条目添加到子系统描述中是分配哪些设备分配给哪个子系统的关键步骤，示例： ADDWSE SBSD(SBSLIB/PGRM) WRKSTN(PGMR*) AT(*SIGNON) ADDWSE SBSD(SBSLIB/ORDERENT) WRKSTN(ORDERENT*) AT(*SIGNON) ADDWSE SBSD(QGPL/QINTER) WRKSTN(QPADEV*) AT(*SIGNON) 示例说明： 用户需要确定哪些子系统应该分配哪些设备：AT(*SIGNON) 确定用户是否需要允许从一个子系统到另一个子系统使用TFRJOB：AT(*ENTER) 示例中，子系统和设备命名约定基于用户所做的工作类型： 程序员一般以PGMR命名设备并在PGRM子系统中运行 Order entry personnel都以ORDERENT命名设备并在ORDERENT子系统中运行 所有其他用户使用QPADEVxxxx的系统默认命名并在IBM提供的QINTER子系统中运行 第七步：定制QINTER   开始使用自己的子系统集时，可能不需要使用QINTER。如果需要继续使用QINTER，需要确保QINTER设置为不分配用户要在其他子系统下运行的工作站。有两种方法，其中一种方法是从QINTER中删除*ALL工作站条目： 从QINTER中删除*ALL工作站条目，然后添加指示希望QINTER分配哪些设备的特定工作站条目 删除*ALL的工作站类型条目是为了防止QINTER尝试分配所有工作站 添加DSP*的工作站条目，以允许所有twinax-attached的显示设备继续分配给QINTER 示例twinax-attached的显示设备将继续在QINTER中运行，QINTER不会尝试分配任何其他设备： RMVWSE SBSD(QGPL/QINTER) WRKSTNTYPE(*ALL) ADDWSE SBSD(QGPL/QINTER) WRKSTN(DSP*) 第八步：配置控制台   关于QINTER的最后一个但非常重要的考虑因素是控制台的*CONS的工作站类型条目。确保用户不会意外阻止某人在控制台上登录。可以通过不将控制台的任何工作站条目添加到自定义交互子系统来防止这种情况发生。  始终在控制子系统中运行控制台并且不要将控制台作业转移到其他一些交互式子系统中是一种很好的做法。这可以防止控制台上的用户无意中结束他们自己的工作。 第九步：将用户分配给特定的子系统 参考官方文档：Assigning users to a specific subsystem 待补充 "},"05-IBM_Operating_System/02-AS400/09-AS400-内存池管理.html":{"url":"05-IBM_Operating_System/02-AS400/09-AS400-内存池管理.html","title":"AS400-内存池管理","keywords":"","body":"AS400-内存池管理 官方参考链接： IBM i 7.3 Memory pools IBM i 7.3 Managing memory pools IBM i 7.3 MEMORY_POOL_INFO view IBM i 7.3 MEMORY_POOL table function 内存池基本信息 查看基本信息可以使用WRKSHRPOOL命令，命令示例： Work with Shared Pools System: LPAR110 Main storage size (M) . : 65536.00 Type changes (if allowed), press Enter. Defined Max Allocated Pool -Paging Option-- Pool Size (M) Active Size (M) ID Defined Current *MACHINE 2752.64 +++++ 2752.64 1 *FIXED *FIXED *BASE 48006.40 2991 48006.40 2 *FIXED *FIXED *INTERACT 14121.59 1183 14121.59 3 *FIXED *FIXED *SPOOL 655.35 5 655.35 4 *FIXED *FIXED *SHRPOOL1 .00 0 *FIXED *SHRPOOL2 .00 0 *FIXED *SHRPOOL3 .00 0 *FIXED 查看所有可以使用命令： SELECT * FROM QSYS2.MEMORY_POOL_INFO; 内存池类型 在AS400-系统基本知识中有相关笔记记录。 PAGING_OPTION   PAGING_OPTION在系统中列名为PAGE_OPT，此值表示系统是否会动态调整存储池的paging特性以获得最佳性能。详细说明如下： *FIXED：系统不会动态调整paging特性。使用系统默认值或设置的值 *CALC：系统会动态调整存储池的paging特性以获得最佳性能 USRDFN：系统不会动态调整存储池的paging特性，而是使用QWCCHGTNAPI定义的值 查看内存池信息 IBM Navigator for i 查看步骤如下： 展开Work Management > All Tasks > Memory Pools 选择Active Memory Pools或Shared Memory Pools 说明： Active Memory Pools显示活动状态的shared和private池 Shared Memory Pools显示所有共享池，而不管它们的当前状态 在被子系统激活之前，不活动的私有池不存在于池定义，因此，IBM Navigator for i无法查看它们 Character-based interface 使用命令DSPSBSD查看，示例查看QCMN子系统描述： 输入命令DSPSBSD QCMN或DSPSBSD SBSD(QSYS/QCMN)进入Display Subsystem Description面板 然后选择选项2. Pool definitions进入Display Pool Definitions面板 可以看到Status,Pool ID,Storage Size (M)及Activity Level等信息 使用命令WRKSHRPOOL查看： WRKSHRPOOL OUTPUT(*) 确定使用内存池的子系统数量   子系统被分配一定比例的内存来运行作业。在了解有多少子系统正在向池提交作业以及池中正在运行多少作业后，用户可能需要通过调整池的大小和活动级别来减少资源争用。 IBM Navigator for i 查看步骤如下： 展开Work Management > All Tasks > Memory Pools 选择Active Memory Pools或Shared Memory Pools 选中需要查看的内存池，然后右键，选中Subsystems单击 Character-based interface 使用命令WRKSBS显示所有子系统及其相应池的列表，示例如下： Work with Subsystems System: Type options, press Enter. 4=End subsystem 5=Display subsystem description 8=Work with subsystem jobs Total -----------Subsystem Pools----------- Opt Subsystem Storage (M) 1 2 3 4 5 6 7 8 9 1 #SYSLOAD 0,00 2 QBATCH 0,00 2 QCMN 0,00 2 确定内存池中作业数量 IBM Navigator for i中查看步骤： 展开Work Management > All Tasks > Memory Pools 选择Active Memory Pools或Shared Memory Pools 选中需要查看的内存池，然后右键，选中Jobs单击 会弹出一个窗口，显示内存池中的作业列表 确定单个作业在哪个池中运行   如果作业未按预期执行，可能需要检查运行该作业的内存池。例如，如果分页过多，则可能需要更大的内存池，或者是池中有太多其他作业，可能需要将作业移动到其它池。 IBM Navigator for i 查看步骤如下： 展开Work Management，选择Active Jobs或Server Jobs 找到需要查看其内存池的作业 在作业名称上右键，选择并点击Properties 单击Resources选项卡，窗口Job Properties-Resources显示有关作业内存池的特定信息 Character-based interface 使用WRKJOB命令查看，示例查看用户BONDHUANG的TESTBCH作业： 输入命令WRKJOB JOB(BONDHUANG/TESTBCH) 选择选项1. Display job status attributes查看属性 显示选项中Subsystem pool ID属性即是需要查看的信息 使用WRKACTJOB命令查看活动作业的池ID，示例查看QBATCH子系统下作业： 输入命令WRKACTJOB SBS(QBATCH)进入Work with Active Jobs面板 按F11，在列Pool下即是池ID，对应Job查看即可 示例： 2=Change 3=Hold 4=End 5=Work with 6=Release 7=Display message 8=Work with spooled files 13=Disconnect ... --------Elapsed--------- Opt Subsystem/Job Type Pool Pty CPU Int Rsp AuxIO CPU % QBATCH SBS 2 0 3214,0 1 0,3 NFMC BCH 2 99 55,5 0 0,0 TESTBCH BCH 2 99 2,3 0 0,0 管理共享池的可调整参数 IBM Navigator for i 查看步骤如下： 展开Work Management > All Tasks > Memory Pools 选择Active Memory Pools或Shared Memory Pools 右键单击要调整的池，然后单击Properties 单击Tuning选项，进入Shared Properties-Tuning窗口 用户可以手动调整特定值，例如池分配百分比、每秒页面错误和优先级 Character-based interface 使用命令WRKSHRPOOL，选择11-Display tuning data即可。 管理池的配置 要更改池的大小、活动级别或分页选项。 IBM Navigator for i 步骤如下： 展开Work Management > All Tasks > Memory Pools 选择Active Memory Pools或Shared Memory Pools 右键单击要调整的池，然后单击Properties 单击Configuration选项，进入Shared Properties-Configuration窗口 可以手动调整特定值，例如池的大小、活动级别或分页选项 Character-based interface   使用命令WRKSHRPOOL(Work with Shared Storage Pools)可以查看共享池的名称和状态信息，通过使用菜单选项，用户可以更改池大小和最大活动水平的值。 更改内存池大小   内存池的大小直接影响子系统可以处理的工作量。子系统拥有的内存越多，它可能完成的工作就越多。在开始更改内存池的参数之前，仔细监视系统非常重要。说明： 系统调谐器会根据系统正在执行的工作量自动调整共享内存池的大小 手动更改内存池大小之前，需关闭系统调谐器，如果未关闭，收到调整后系统会自动再次调整 通过系统值QPFRADJ(Automatically adjust memory pools and activity levels)更改为0来关闭系统调谐器 注意事项： Base pool是唯一没有定义内存量的内存池，它运行所需的内存量最小，基本池包含未在其他地方分配的所有内存 系统上有1000MB内存，其中250MB分配给Machine pool，250MB分配给Interactive pool，500MB未分配的内存存储在基本池中 将内存从一个池移动到另一个池可以修复一个子系统问题，但可能会导致其他子系统出现问题，进而会降低系统性能 IBM Navigator for i 步骤如下： 展开Work Management > All Tasks > Memory Pools 选择Active Memory Pools或Shared Memory Pools 右键单击要调整的池，然后单击Properties 从Properties窗口的Configuration选项中，可以更改定义的内存量，此值是池可以使用的最大内存量 Character-based interface 使用命令CHGSYSVAL，示例更改Machine pool的大小(WRKSYSTS显示中的池1)： CHGSYSVAL QMCHPOOL 'new-size-in-KB' 更改Base pool的最小大小(WRKSYSTS显示中的池2)： CHGSYSVAL QBASPOOL 'new-minimum-size-in-KB' 更改Shared Storage Pool使用命令CHGSHRPOOL: CHGSHRPOOL POOL(*INTERACT) SIZE(1048576) ACTLVL(*SAME) PAGING(*SAME) 示例说明： 示例将Interactive pool的大小更改为1048576KB，活动级别和分页选项保持不变 如果共享池处于活动状态并且有足够的存储可用，则对共享池的更改会立即生效 创建私有内存池   Private memory pools(用户定义的内存池)可由系统的子系统或用户定义的子系统使用。用户最多可以为一个子系统定义10个内存池定义。用户可以在子系统描述中创建私有内存池： 命令CRTSBSD(Create Subsystem Description)中的POOLS(Storage pools)参数： 参数值有：Pool identifier,Storage size,Activity level及Size unit of measure 命令CHGSBSD(Change Subsystem Description)中的POOLS参数 注意事项： 虽然每个子系统描述可以有多达10个用户定义的内存池，但有一个操作限制，即不能超过64个可以随时处于活动状态的内存池（包括Base pool和Machine pool） 如果在分配子系统的内存池之前已经达到最大分配限制，则Base pool将用于仍然需要内存池任何操作 内存池编号方案 池有两组编号方案，一组在子系统内使用，另一组在系统范围内使用： 子系统使用一组数字来引用子系统使用的池 当创建或更改子系统描述时，用户可以定义一个或多个池并标记为1、2、3 等 这些标记是子系统池的，它们与WRKSYSSTS(Work with System Status)上显示的池编号不对应 命令WRKSBS(Work with Subsystems)显示子系统池标识符，以及列标题与系统池标识符相关联: Work with Subsystems Type options, press Enter. 4=End subsystem 5=Display subsystem description 8=Work with subsystem jobs Total -----------Subsystem Pools------------ Opt Subsystem Storage (M) 1 2 3 4 5 6 7 8 9 10 #SYSLOAD 0,00 2 QBATCH 0,00 2 QCMN 0,00 2 QHTTPSVR 0,00 2 QINTER 0,00 2 3 池的编号方式示例参考官方文档：IBM i 7.3 Pool numbering schemes 内存池分配   启动子系统时，系统会尝试分配已启动子系统的子系统描述中用户定义存储池。如果系统无法分配所有请求的存储空间，它将分配尽可能多的可用存储空间，然后在可用时分配剩余的存储空间。用定义的存储池在分配时会减小Base pool的大小。系统值QBASPOOL(Base memory pool minimum size)确定最小 Base pool大小。  如果有700KB可用，并且如果*SHRPOOL2定义为500KB，则300KB分配给第一个存储池，400KB分配给第二个存储池。示例如下: SBSD指定的池ID 1 2 Storage Requested 300K *SHRPOOL2 System Pool ID 3 4 Storage Allocated 300K 400K Activity Level 1 Pool Type Private Shared 内存池活动级别   内存池的活动级别是内存池中可以同时主动使用CPU的线程数。这允许有效使用系统资源。系统管理活动级别的控制： 通常在线程处理期间，程序等待系统资源或工作站用户的响应。在这样的等待期间，一个线程放弃它对内存池活动级别的使用，以便另一个准备好被处理的线程可以代替它 当启动的线程多于同时运行的线程时，多余的线程必须等待使用处理单元（通常这种等待很短）。内存池活动级别允许用户限制子系统中各种内存池中的主内存争用量 正在运行的线程数（或活动线程数）是指有资格竞争处理器并计入内存池活动级别的线程数。从这个意义上说，活动线程不包括等待输入、等待消息、等待分配设备或等待打开文件的线程。活动线程不包括不合格的线程（准备运行但内存池活动级别处于最大值的线程） 活动级别的工作原理   内存池中可以同时激活多个线程，因为在从辅助存储中检索所需数据时，线程的处理可能会被短暂中断。在这个通常很短的延迟期间，可以运行另一个线程。使用活动级别，机器可以处理内存池中的大量线程，同时将争用级别保持在用户指定的限制： 最高活动水平 达到内存池的最大活动级别后，将需要该内存池的其他线程置于不合格状态，以等待内存池中的活动线程数低于最大活动级别或线程达到它的时间片结束 一旦一个线程放弃了它对内存池的使用，其他不活动的线程就可以按照它们的优先级运行。 例如，如果正在运行的线程正在等待来自工作站的响应，它会放弃其活动级别，并且活动级别不再处于其最大值 定义内存池活动级别 正确定义内存池和活动级别通常取决于内存池的大小、CPU 的数量、磁盘单元的数量以及应用程序的特性 数据内存池 活动级别为零的共享内存池是数据内存池。池中没有线程可以运行，它只能用于数据 官方参考链接：IBM i 7.3 Memory pool activity level。 打印池报告   PRTPOLRPT(Print Pool Report)命令根据收集服务从操作导航器界面收集的性能数据生成面向池的报告，报告将写入打印机文件QPPTITVP： 构成报告的两个部分是存储池的子系统活动和工作负载活动 信息按照间隔顺序呈现 根据各种作业详细信息和间隔时间，作业可以选择性地包含在报告中或从报告中排除 PRTPOLRPT命令示例： Print Pool Report (PRTPOLRPT) Type choices, press Enter. Member . . . . . . . . . . . . . Name Report title . . . . . . . . . . *MBRTXT Time period for report: Starting time . . . . . . . . *FIRST Time, *FIRST, *SELECT Starting date . . . . . . . . *FIRST Date, *FIRST Ending time . . . . . . . . . *LAST Time, *LAST Ending date . . . . . . . . . *LAST Date, *LAST Additional Parameters Library . . . . . . . . . . . . QPFRDATA Name 命令选项说明： MBR(Member)：必要参数。指定使用的性能数据成员。名称应对应于在CRTPFRDTA命令的TOMBR参数上指定的成员名称 TITLE(Report title)：所创建报告的标题。如果输入字符，最多50个字符，用撇号括起来 PERIOD(Time period for report)：指定要报告的时间段。该参数由四个元素组成：开始时间和日期，以及结束时间和日期： 开始时间默认从收集期第一天00:00:00开始的数据记录。自定义使用格式hhmm或hhmmss，其中hh是小时，mm是分钟，ss是秒，时间以 24 小时格式指定，带或不带时间分隔符： 开始日期默认从收集期的第一天开始的数据记录；自定义日期必须以系统值QDATFMT指定的格式输入，如果使用分隔符，则按照系统值QDATSEP指定的格式输入 结束时间默认截至当天 23:59:59 的数据记录，格式同开始时间 结束日期默认报告中包含截至收集期最后一天的数据记录。格式同开始日期 LIB(Library)：指定性能数据所在的库 SLTJOB(Select jobs)：指定要包含在报告中的最多 50个作业的列表。与OMTJOB参数互斥 OMTJOB(Omit jobs)：指定要从报告中忽略的最多 50 个作业的列表。与SLTJOB参数互斥 SLTUSRID(Select users)：指定要包含在报告中的最多50个用户名的列表。与OMTUSRID参数互斥 OMTUSRID(Omit users )：指定要从报告中忽略的最多 50 个用户名的列表。与SLTUSRID参数互斥 SLTPOOLS(Select pools)：指定要包含在报告中的最多64个池的列表。与OMTPOOLS参数互斥 OMTPOOLS(Omit pools)：指定要忽略的最多64个池的列表。在任何指定池中运行的作业都将从报告中排除。与SLTPOOLS参数互斥 SLTSBS(Select subsystems)：指定要选择的最多50个子系统的列表。与OMTSBS参数互斥 OMTSBS(Omit subsystems)：指定要忽略的最多50个子系统的列表。在任何指定子系统中运行的作业都将从报告中排除。与SLTSBS参数互斥 SLTLINE(Select communications lines)：指定要选择的最多50条通信线路的列表。与OMTLINE参数互斥 OMTLINE(Omit communications lines)：指定要忽略的最多50条通信线路的列表。使用通过任何指定通信线路连接的远程设备的作业将从报告中排除。与SLTLINE参数互斥 SLTCTL(Select control units )：指定最多50个可供选择的通信控制器的列表。与OMTCTL参数互斥 OMTCTL(Omit control units)：指定要忽略的最多50个通信控制器的列表。与SLTCTL参数互斥 SLTFCNARA(Select functional areas)：指定要选择的最多50个功能区域的列表。与OMTFCNARA参数互斥 OMTFCNARA(Omit functional areas)：指定要忽略的最多50个功能区域的列表。与SLTFCNARA参数互斥 JOB(Job name)：指定提交作业以进行批处理时要使用的作业名称。如果Job description (JOBD)参数指定了*NONE，则忽略此参数的任何值 JOBD(Job description)：指定用于提交作业以进行批处理的作业描述 官方示例： PRTPOLRPT MBR(DTA071588A) PERIOD((2330)(0130)) 示例说明： 示例提交作业以打印从收集的第一天晚上11:30到收集最后一天凌晨1:30收集的数据的报告 如果数据收集在同一天开始和结束，则会打印一条错误消息，因为指定的结束日期和时间早于指定的开始日期和时间 官方参考链接:Print Pool Report (PRTPOLRPT) 清理内存池   CLRPOOL(Clear Pool)命令从主存储池中清除所有对象。这允许SETOBJACC)(Set Object Access)命令报告池内的存储使用情况。命令示例： Clear Pool (CLRPOOL) Type choices, press Enter. Storage pool: Shared pool or subsystem name Name, *JOB, *SHRPOOL1... Pool identifier . . . . . . . 1-10 命令选项说明： POOL(Storage pool)：指定要清除所有对象的池 JOB：与作业关联的池被清除 SHRPOOLn：清除通用共享池。有效值范围从1到10 subsystem：指定子系统名称 pool-identifier：指定子系统池标识符 示例清除与处理该命令的作业关联的池： CLRPOOL POOL(*JOB) 待补充 "},"05-IBM_Operating_System/02-AS400/10-AS400-网络与通信.html":{"url":"05-IBM_Operating_System/02-AS400/10-AS400-网络与通信.html","title":"AS400-网络与通信","keywords":"","body":"AS400-网络与通信 记录简单网络与通信管理操作。 常用管理命令或菜单 GO TCPADM 使用命令GO TCPADM可以进入\"TCP/IP Administration\"菜单，选项示例: 1. Configure TCP/IP 2. Configure TCP/IP applications 7. Work with TCP/IP network status 8. Verify TCP/IP connection 9. Start TCP/IP FTP session 10. Start TCP/IP TELNET session 11. Send TCP/IP spooled file 20. Work with TCP/IP jobs in QSYSWRK subsystem CFGTCP(Configure TCP/IP) 使用命令CFGTCP可以进入\"Configure TCP/IP\"菜单，选项示例： 1. Work with TCP/IP interfaces 2. Work with TCP/IP routes 3. Change TCP/IP attributes 4. Work with TCP/IP port restrictions 10. Work with TCP/IP host table entries 11. Merge TCP/IP host table 12. Change TCP/IP domain information 20. Configure TCP/IP applications 21. Configure related tables 22. Configure point-to-point TCP/IP 23. Load/Unload IP Filter NETSTAT(Work with TCP/IP Network Status) 使用命令WRKTCPSTS可以进入同样菜单，菜单选项示例： 1. Work with IPv4 interface status (NETSTAT *IFC) 2. Display IPv4 route information (NETSTAT *RTE) 3. Work with IPv4 connection status (NETSTAT *CNN) 4. Work with IPv6 interface status 5. Display IPv6 route information 6. Work with IPv6 connection status 10. Display TCP/IP stack status (NETSTAT *STATUS) IBM官方使用说明： IBM i 导航器:Using Netstat from IBM Navigator for i 字符界面使用：Using Netstat from a character-based interface Work with IPv4 connection status   在WRKTCPSTS命令菜单选择3进入\"Work with IPv4 connection status\"，或者使用命令NETSTAT *CNN，进入后可以查看IPv4端口信息，操作选项： 5=Display details：可以查看基本信息和一些端口数据统计信息 8=Display jobs：可以看到端口对应JOB信息 NETSTAT更多信息获取   通过NETSTAT *CNN可以查看端口的一些统计信息，但只针对端口，并且信息条目不是很多，官方提供了更多获取网络统计信息的方法： 返回有关用户QSECOFR的所有网络连接的信息: SELECT * FROM QSYS2.NETSTAT_INFO WHERE BIND_USER = 'QSECOFR' 官方详细说明链接：NETSTAT_INFO view 返回有关使用虚拟以太网协议的所有接口的信息: SELECT * FROM QSYS2.NETSTAT_INTERFACE_INFO WHERE INTERFACE_LINE_TYPE = 'VETH' 官方详细说明链接：NETSTAT_INTERFACE_INFO view 返回有关使用虚拟以太网协议的所有接口的信息: SELECT * FROM QSYS2.NETSTAT_ROUTE_INFO WHERE ROUTE_STATUS = 'YES' OR ROUTE_STATUS = 'ACTIVE' 官方详细说明链接：NETSTAT_ROUTE_INFO view 返回有关使用 IPv4 网络连接的所有作业的信息: SELECT * FROM QSYS2.NETSTAT_JOB_INFO WHERE CONNECTION_TYPE = 'IPV4' 官方详细说明链接：NETSTAT_JOB_INFO view AS400还有API用来抓取上面的信息： List Network Interfaces (QtocLstNetIfc) API Retrieve Network Connection Data (QtocRtvNetCnnDta) API 网络相关配置 创建线路描述 用户必须创建以太网线路描述作为TCP/IP的通信对象。 创建以太网线路描述 使用命令CRTLINETH来创建，步骤： 输入命令CRTLINETH后按F4,进入Create Line Desc(Ethernet)： Line description(LIND)：输入自定义的名称 Resource name(RSRCNAME)：输入网口资源名称，例如CMN12 Bridge identifier(BRIDGE)：默认*NONE 按回车显示更多参数，默认即可或根据需求配置相关参数 或者使用命令，创建的以太网线路描述名称为HQTEST，资源名称为CMN04: CRTLINETH LIND(HQTEST) RSRCNAME(CMN04) 创建聚合以太网线路描述 同样使用命令CRTLINETH来创建，步骤： 输入命令CRTLINETH后按F4，进入Create Line Desc(Ethernet)： Line description(LIND)：输入自定义的名称 Resource name(RSRCNAME)：输入资源名称：*AGG Bridge identifier(BRIDGE)：默认*NONE 按回车显示更多属性: Aggregate policy(AGGPCY)选项中： Standard：填入*ETHCHL，或其它需求选项 Policy type：填入*DFT，或其它需求选项 Aggregated resource list(AGGRSCL)中填入网口资源，例如CMN04和CMN05 其它参数默认，或者根据需求进行设置 或者使用命令，例如将CMN04和CMN05聚合: CRTLINETH LIND(TESTAGGETH) RSRCNAME(*AGG) AGGPCY(*ETHCHL *DFT) DUPLEX(*FULL) AGGRSCL(CMN04 CMN05) 示例创建使用尽可能多的数据包数据来传播传出流量的静态双端口聚合： CRTLINETH LIND(ETHAGG) RSRCNAME(*AGG) AGGPCY(*ETHCHL *SRCDESTP) AGGRSCL(CMN04 CMN05) Aggregate policy(AGGPCY)参数描述(仅在RSRCNAME参数中指定*AGG配置聚合线路时有效)： Standard： *ETHCHL：使用Etherchannel技术将多个以太网适配器聚合在一起 *LNKAGG：使用IEEE 802.3adLink Aggregation技术将多个以太网适配器聚合在一起 Policy type： *DFT：适配器选择算法使用目标IP地址（对于TCP/IP流量）或MAC地址（对于ARP和其他非IP流量）的最后一个字节。对于具有大量客户端的服务器，此模式通常是最佳的初始选择 *SRCPORT：适配器选择算法使用源TCP/IP或UDP端口值 *DESTPORT：通过使用目标TCP/IP或UDP端口值的算法选择传出适配器路径 *SRCDESTP：通过使用组合的源和目标TCP或 UDP端口值的算法选择传出适配器路径 *RNDRBN：传出流量均匀分布在Etherchannel中的所有适配器端口。这种模式是两个主机直接连接（即没有中间交换机）的典型选择。 Policy类型更多说明： *RNDRBN仅在Standard为*ETHCHL时才能使用，它直接强制每批传出数据包使用下一个可用端口，确保所有端口都以接近相等的方式使用。但是，这会产生数据包可能无序传送的风险，并且TCP连接内的无序传送会导致重传和大延迟。如果不考虑这些风险时候使用此模式。 其余的策略类型都可以称为散列(hash)模式，它们描述了使用数据包中的哪些数据来确定每个传出帧使用哪个以太网端口。所有散列模式都强制特定的TCP连接在特定的以太网端口上保持单线程，以避免无序传递问题。它们的区别在于使用多少数据包数据来决定使用哪个端口。最佳网络使用来自在聚合资源列表AGGRSCL中的端口之间大致平均分配传出流量的配置。随着使用更多的分组数据，系统可以做更多的事情来在端口之间传播不相关的流量。但是，使用更多的数据包数据也会强制对每个传出数据包进行一些额外的处理和缓存使用： *DFThash模式使用数据量最少的，只查看目标IP地址（或非 IP 帧的 MAC）。这种模式使用很少的处理器，但只有当流量同时运行到许多不同的IP地址时才会均匀分布（对于繁忙的服务器） *SRCPORT，*DESTPORT，和*SRCDESTPhash模式也看源和目的地TCP或UDP端口号（如果存在）对于每个输出分组。这种评估会导致更多的每个数据包处理，但能够更好地在多个以太网端口之间拆分不相关的流量，例如到同一远程主机的并行文件传输。如果不知道主机处理器是一个约束条件，*SRCDESTP可能是大多数系统的最佳选择 其它注意事项： IBM i Link Aggregation支持与任何链路伙伴的静态聚合*ETHCHL，并支持与Cisco和IBM Networking交换机的LACP *LNKAGG。 其他支持LACP的链接伙伴可能会工作，但不受官方支持 分区中不能存在超过 255 个Aggregation descriptions 相关官方参考链接： Create Line Desc (Ethernet) (CRTLINETH) Preparing to Create an Aggregate Line Description Create an Aggregate Line Description Managing an Aggregate Line Description 配置TCPIP 在创建Line description之后，就可以配置IP了： 输入命令CFGTCP，选择选项1. Work with TCP/IP interfaces，进入对应页面 可以看到系统已配置的IP，在第一行Internet Address输入要配置的IP(或空)，例如192.168.0.100，操作选择1=ADD 按回车确认，进入Add TCP/IP Interface字符界面 参数Line description(LIND)下： Line description：填入之前创建的Line description Virtual LAN identifier：默认*NONE，或根据需求填入Vlan ID 其它参数默认，或者根据需求进行设置 回车确认，提示配置成功后回到Work with TCP/IP interfaces页面 查看刚配置Interface Status选项，目前应该是inatcive状态 在刚配置IP前选择9=Start进行启动，或者根据需求稍后启动 启动后使用PING命令验证网络连通性 使用ADDTCPIFC命令，例如添加Non-AUTOSTART Interface： ADDTCPIFC INTNETADR('192.168.0.100') LIND(TESTAGGETH) AUTOSTART(*NO) SUBNETMASK('255.255.255.0') 配置路由 配置默认路由步骤： 输入命令CFGTCP，选择选项2. Work with TCP/IP routes，进入对应页面 在第一行操作选择1=ADD，进入Add TCP/IP Route页面 参数Route destination(RTEDEST)输入*DFTROUTE 参数Subnet mask(SUBNETMASK)默认为*NONE 参数Next hop(NEXTHOP)指定路由目标的IPv4地址 其它参数默认，或者根据需求进行设置 回车确认，回到主菜单或输入命令NETSTAT *RTE查看路由配置 说明： 要配置缺省 IPv4 路由，必须为Subnet mask(SUBNETMASK)参数指定*NONE 配置其它静态路由更改参数Route destination(RTEDEST)，以及要指定掩码等 使用ADDTCPRTE命令示例添加默认路由： ADDTCPRTE RTEDEST(*DFTROUTE) SUBNETMASK(*NONE) TOS(*NORMAL) NEXTHOP('192.168.0.254') MTU(576) 使用ADDTCPRTE命令示例添加路由： ADDTCPRTE RTEDEST('192.168.1.0') SUBNETMASK('255.255.255.0') TOS(*MINDELAY) NEXTHOP('192.168.0.254') MTU(*IFC) 示例说明： C类网络地址的路由目的地 通过第三个八位字节进行子网划分 接口的最小延迟服务类型 此路由连接可以通过标识为192.168.0.254的网关到达 最大传输单元(MTU)将根据与此路由的下一hop关联的接口计算 待补充 "},"05-IBM_Operating_System/02-AS400/11-AS400-备份与恢复.html":{"url":"05-IBM_Operating_System/02-AS400/11-AS400-备份与恢复.html","title":"AS400-备份与恢复","keywords":"","body":"AS400-备份与恢复   AS400系统中进行备份恢复通常使用BRMS，全称Backup, Recovery, and Media Services，用于规划和管理IBM i产品上的保存和恢复操作。官方参考链接： Backup, Recovery, and Media Services(BRMS) IBM i 7.3备份与恢复 IBM Backup, Recovery and Media Services for i commands SAVE Files 官方参考链接： IBM i 7.3 Save files Working with save files GO SAVE命令 GO SAVE命令菜单选项示例： Save Data 1. Files 2. Libraries 3. Documents and folders 4. Programs 5. Other objects 6. Changed objects only 7. Licensed programs 8. Security data 10. Configuration 11. Objects in directories Save System and User Data 20. Define save system and user data defaults 21. Entire system 22. System data only 23. All user data Save Document Library Objects 30. All documents, folders, and mail 31. New and changed documents, new folders, all mail 32. Documents and folders 33. Mail only Save Libraries 40. All libraries other than system library 41. All IBM libraries other than system library 42. All user libraries 43. All changed objects in user libraries Save for Different Systems 50. Save in System/36 format Related Commands 70. Related commands 官方参考链接： IBM i 7.3 Overview of the GO SAVE command IBM i 7.3 GO SAVE command menu options Save and Restore LIB Save LIB 使用命令SAVLIB,示例将PFRLIB保存到SAVFSAVFLIB/PFRSAVF： SAVLIB LIB(PFRLIB) DEV(*SAVF) SAVF(SAVFLIB/PFRSAVF) 也可以保存到媒体设备，示例将PFRLIB使用drive TAP01报错： SAVLIB LIB(PFRLIB) DEV(TAP01) 官方参考文档：IBM i Save Library(SAVLIB) Restore LIB   使用命令RSTLIB,如果是SAVF，在恢复前可以使用命令DSPSAVF命令查看SAVF相关信息。示例恢复上面SAVLIB的第一个示例： RSTLIB SAVLIB(PFRLIB) DEV(*SAVF) SAVF(SAVFLIB/PFRSAVF) 示例恢复新的对象： RSTLIB SAVLIB(PFRLIB) DEV(TAP01) OPTION(*NEW) 示例说明： 示例从磁带设备TAP01恢复库PFRLIB的保存版本 库中唯一恢复的对象是新对象（保存时在库中但后来被删除的对象） 官方参考文档：IBM i Restore Library(RSTLIB) Save and Restore OBJ Save OBJ 使用命令SAVOBJ，例如保存CS数据对象为SAVF： SAVOBJ OBJ(Q287102629) LIB(QPFRDATA) DEV(*SAVF) SAVF(PFRLIB/PFR1014) 示例保存保存同名的程序和文件到磁带设备： SAVOBJ OBJ(PETE) LIB(LIBXXX) DEV(TAP01) 示例说明： 示例保存位于LIBXXX库中名为PETE的对象 如果LIBXXX包含一个程序和一个名为PETE的文件，那么这两个对象都会被保存 由于STG参数默认值是(*KEEP)，因此不会释放对象占用的存储空间 官方参考文档：IBM i Save Object(SAVOBJ) Restore OBJ 使用命令RSTOBJ，恢复SAVOBJ中的第一个示例： RSTOBJ OBJ(Q287102629) SAVLIB(QPFRDATA) DEV(*SAVF) SAVF(PFRLIB/PFR1014) 示例恢复最近保存的版本： RSTOBJ OBJ(PAYROLL) SAVLIB(LIBX) DEV(TAP01) OBJTYPE(*PGM) VOL(*SAVVOL) 示例说明： 示例将从LIBX库中保存的名为PAYROLL的程序恢复到LIBX 磁带驱动器TAP01用于恢复最近保存的程序版本 Restore说明： 如果需要从SAVF恢复性能数据，Restore选项中Saved library(SAVLIB)填入名称必须和保存时候一致 可以将数据恢复到其它库，需要在Restore to library中填入指定的LIB 如果不知道保存时候的LIB和OBJ名称，可以通过命令DSPSAVF可以查看 官方参考文档：IBM i Restore Object(RSTOBJ) Save时候压缩选项   使用SAVLIB和SAVOBJ命令时，有压缩参数DTACPR(Data compression)可以对保存的数据进行压缩，特别是性能数据收集时，压缩很有必要，选项有： *DEV：默认选项 *NO：不压缩 *YES ：压缩，测试压缩CS数据可以压到默认的一半 *LOW：低压缩 *MEDIUM：中度压缩 *HIGH：高度压缩，测试压缩CS数据可以到默认的六分之一，和7Z差不多 常见问题 官方参考链接：备份与恢复的常见问题 BRMS IBM官方文档主页： IBM i 7.3 Backup, Recovery, and Media Services(BRMS) 使用GO BRMS命令进入主菜单，示例： BRMS Backup Recovery and Media Services for IBM i Select one of the following: 1. Media management 2. Backup 3. Archive 4. Recovery 5. Migration 10. Scheduling 11. Policy administration 12. Reports 20. Start console monitor Media操作管理 官方参考链接：Setting up your media management operation 移动Media   可以使用BRMS跟踪媒体从一个位置到另一个位置的移动的信息。可以使用移动策略为选定的媒体创建移动模式。然后，用户可以设置与移动相关的命令以发出用户在移动策略中指定的移动模式。BRMS还可以帮助用户验证移动模式是否按计划进行。 输入命令GO BRMMEDMOV，进入Move Management菜单，示例： BRMMEDMOV Move Management System: LPAR170 Select one of the following: 1. Run media movement 2. Verify media to be moved 3. Print media movement report 4. Work with move policies 5. Work with calendars 移动策略   使用移动策略为包含活动Media的卷创建移动模式。每个移动策略都与Media策略相关联，而Media策略又与诸如库或控制组之类的保存项目相关联。可以使用MOVMEDBRM或STRMNTBRM命令来启动移动模式。用户也可以使用作业调度程序自动处理这两个命令。  BRMS自带一个名为OFFSITE的默认移动策略。OFFSITE策略跟踪媒体到VAULT位置的移动，直到到期 *EXP。可以更改OFFSITE移动策略，还可以创建其他移动策略来跟踪各种移动模式。 要创建、更改或删除移动策略，步骤如下： 输入WRKPCYBRM，然后回车。进入Work with Move Policies屏幕 Opt第一行中输入1进行添加，然后输入Policy名称，例如叫PAYROLL： 在Seq字段中，指定希望BRMS将Media移动到此位置的顺序 在Location字段中，指明希望BRMS将媒体移动到的位置的名称 在Duration字段中，指明希望将媒体存储在该位置的时间长度此字段的可能值包括天数、特定日期、*EXP（直到到期）、*PERM（永久）、文件组和*RESET（直到到期或直到另一个保存写入媒体） 在Container Action字段中，可以决定让的容器在到达指定位置时打开、关闭或不执行任何操作。有效值为 *OPEN、*CLOSE和*NONE。仅当Use container字段设置为*YES时，此字段才处于活动状态并可用于输入 根据需要查看并更改其余参数(后面说明)后，按回车确认 然后按Enter应用更改 设置移动模式后，需要注意移动策略的其余参数。Create Move Policy中保留的关键字段的简要摘要： Home location参数指定BRMS在其移动周期完成后返回媒体的位置。通常是用户使用Media库的位置： 此参数的默认值为*SYSPCY，它指示BRMS查看主位置的系统策略。系统策略中的默认主位置是*HOME，用户可以根据需要进行更改 还可以使用专门为移动过程创建的新值*ORIGIN。*ORIGIN指示BRMS将过期卷备份返回到备份发生的位置 在Verify moves字段中，指定希望BRMS验证媒体移动活动还是用户自己执行此任务： 此字段的默认值为*YES，表示用户要自己验证媒体移动 BRMS提供Verify Media Movement屏幕，帮助确定在移动策略中创建的移动计划是否成功完成。 可以从Move Management menu菜单访问Verify Media Moves屏幕 *NO表示BRMS会绕过移动验证并立即更新位置信息。建议使用默认值*YES，尤其是在使用媒体库时 Use the Calendar for working days参数来指定希望使用哪些天数来计算媒体在每个位置停留的时间量 使用Calendar for move days参数指定星期几将媒体从一个位置移动到另一个位置 移动策略配置示例： Create Move Policy LPAR110 Move policy . . . . . . . . . . PAYROLL Home location . . . . . . . . . *SYSPCY Name, *SYSPCY, *ORIGIN, F4 list Use container . . . . . . . . . *NO *YES, *NO Verify moves . . . . . . . . . . *YES *YES, *NO Calendar for working days . . . *ALLDAYS Name, *ALLDAYS, F4 for list Calendar for move days . . . . . *ALLDAYS Name, *ALLDAYS, F4 for list Move marked for duplication . . *NO *NO, *YES Text . . . . . . . . . . . . . . Payroll move policy Type choices, press Enter. Seq Location Duration Container Action 10 COMPROOM 5 20 VAULT *EXP 示例说明： 移动策略指示BRMS将媒体从home location移动到COMPROOM，在那里它存在5天 然后将其移至VAULT，直到过期为止 Media过期后，卷将返回到home location 官方参考链接：IBM i 7.3 Move policies 使用移动管理日历 进入日历方式有两种： 输入命令GO BRMMEDMOV，选择选项5. Work with calendars 在创建或者编辑Move Policy时，选项Calendar for working days或Calendar for move days按F4，然后按F9，可以进入Work with Calendars 使用日历来定义天或日期组，以与移动策略中建立的移动模式一起使用。配置示例： Work with Calendars LPAR110 Position to . . . . . . Starting characters Type options, press Enter. 1=Add 2=Change 3=Copy 4=Remove 5=Display Opt Calendar Text HOLIDAY Holiday calendar WORKING Working day calendar 示例添加日历： Work with Calendars LPAR110 Position to . . . . . . Starting characters Type options, press Enter. 1=Add 2=Change 3=Copy 4=Remove 5=Display Opt Calendar Text 1 MONTHMOVE (No entries found) 回车确认，进入Add Calendar屏幕： Add Calendar LPAR110 Calendar name . . . . . MONTHMOVE Position to . . . . . Reference calendar . . *NONE Name, *NONE, F4 for list Text . . . . . . . . . Type options, press Enter. 1=Add 4=Remove Opt Date Selection 1 3/01 *INC 1/01 *INC 2/01 *INC 回车确认，添加了三个日期，字段说明如下： Date添加日历中的日期： 特定日期，例如`12/25/22（或122522） 通用日期，例如12/25（或1225） 特殊值，例如*MON、*TUE等 字段Selectio： 值为*INC：日期或天包含在日历中 值为*EXC：日期或天排除在日历中 添加完成日历后，可以在创建或者编辑Move Policy中选择： Create Move Policy LPAR170 Move policy . . . . . . . . . . TESPOCY Home location . . . . . . . . . *SYSPCY Name, *SYSPCY, *ORIGIN, F4 list Use container . . . . . . . . . *NO *YES, *NO Verify moves . . . . . . . . . . *YES *YES, *NO Calendar for working days . . . MONTHMOVE Name, *ALLDAYS, F4 for list Calendar for move days . . . . . *ALLDAYS Name, *ALLDAYS, F4 for list Move marked for duplication . . *NO *NO, *YES Text . . . . . . . . . . . . . . Type choices, press Enter. Seq Location Duration Container Action 10 TAPMLB02 *PERM 官方参考链接：Working with the move management calendars 移动磁带   MOVMEDBRM命令处理在移动策略中设置的移动模式。可以将MOVMEDBRM命令放在作业调度程序上以自动处理计划的移动，或者根据需要手动处理命令。命令示例： Move Media using BRM (MOVMEDBRM) Level: 2 Type choices, press Enter. Move policy . . . . . . . . . . MOVPCY *ALL From location . . . . . . . . . LOC *ALL + for more values Container . . . . . . . . . . . CNR *ALL Media class . . . . . . . . . . MEDCLS *ALL System name . . . . . . . . . . SYSNAME *ALL File group . . . . . . . . . . . FILEGRP *ALL File group type . . . . . . . . GRPTYPE *ALL Output . . . . . . . . . . . . . OUTPUT *PRINT 命令选项说明： MOVPCY(Move policy)：用户定义的移动策略名称 LOC(From location)：要移动的卷时要使用的介质位置，最多可以指定10个位置 CNR(Container)：要为Media移动选择的容器，可以指定一个容器或所有容器 MEDCLS(Media class)：要为Media移动选择的Media类，可以选择特定Media类或所有Media类 SYSNAME(System name)：要考虑在其Media清单中移动Media的系统名称 FILEGRP(File group)：选择要移动的卷时要使用的文件组 GRPTYPE(File group type)：要选择移动的文件组的类 OUTPUT(Output)：输出 官方示例： MOVMEDBRM LOC(*HOME) OUTPUT(*OUTFILE) OUTFILE(MYLIB/MOVEMENT) 示例说明： 此命令为位于*HOME位置的所有移动策略选择所有卷以进行Media移动 移动操作的摘要放在MYLIB库中数据库文件MOVEMENT的第一个成员中 官方参考链接： Initiating movement Move Media using BRM (MOVMEDBRM) 初始化磁带 重新初始化   对于在Media Class中使用的磁带，进行初始化可以在Work with Media Class中磁带列表前选择10.Reinitialize进行重新初始化，磁带状态可以是*ERR或*EXP，不能为*ACT。 新磁带初始化   对于刚刚放入Media Library并且还没有加入Media Class的磁带，在Work with Media Library Media的磁带列表中，对需要初始化的磁带前选择选项5=Initialize进行初始化。  示例使用设备TAPMLB02初始化卷000007。 该卷被分配了一个Media类DAILYBK并使用DAILYBK指定的密度进行初始化： INZMEDBRM DEV(TAPMLB02) NEWVOL(000007) MEDCLS(DAILYBK) 命令参考链接：Initialize Media using BRM(INZMEDBRM) 添加到MEDCLS并初始化   在Work with Media Library Media屏幕菜单中，可以选择1.Add MLB media选项对磁带进行初始化并添加到指定Media Class中。示例： Add Media Library Media to BRM (ADDMLMBRM) Type choices, press Enter. Media library . . . . . . . . . > TAPMLB02 Name Volume identifier . . . . . . . > '000007 ' Add volume to BRM . . . . . . . > *YES *YES, *NO Initialize media . . . . . . . . > *YES *NO, *YES Media class . . . . . . . . . . > IBMVTL ALLSYSTEM, ANNUAL, ANNUALVT.. Last moved date . . . . . . . . *NONE Date, *NONE Move policy . . . . . . . . . . *NONE *NONE, ANNUAL, MONTH, OFFSI.. Expiration date . . . . . . . . *NONE Date, *PERM, *NONE Device . . . . . . . . . . . . . *MLB Name, *MLB New owner identifier . . . . . . *BLANK Check for active files . . . . . *YES *YES, *FIRST, *NO Code . . . . . . . . . . . . . . *EBCDIC *EBCDIC, *ASCII Clear . . . . . . . . . . . . . *NO *NO, *YES 对应命令如下： ADDMLMBRM MLB(TAPMLB02) VOL(000007) INZ(*YES) MEDCLS(IBMVTL) 多所有Getegouy为*INSERT的磁带进行操作命令： ADDMLMBRM MLB(TAPMLB02) VOL(*INSERT) INZ(*YES) MEDCLS(IBMVTL) 命令官方参考链接：Add Media Library Media to BRM(ADDMLMBRM) 备份配置示例 官方参考链接：IBM i 7.3Tailoring your BRMS operations 驱动器识别   在将磁带库驱动映射给主机后，可以通过WRKHDWRSC *STG命令查看到，WRKMLBSTS里面也有，可以开始通过BRMS配置备份策略。假设系统中认到的磁带库名称是：TAPMLB08。 初始化BRM   此时通过WRKMLMBRM不能看到磁带信息，需要CRTDEVMLB，如果已经存在，需要初始化一下，初始化后，通过命令WRKMLMBRM可以看到磁带，初始化命令如下： INZBRM OPTION(*RUNPRDINZ) 命令参考链接：Initialize BRMS (INZBRM) 创建Media Class 创建步骤如下： 运行命令GO BRMS 选择选项1. Media management 选择选项1. Work with media classes Opt第一行中输入1进行添加，然后输入Class名称，例如叫VTLTEST 确认后回车，进入配置选项页面，例如Density选项输入磁带类型，例如*ULTRIUM3 建议输入描述文本，其他选项根据需求或者默认即可 完成按Enter确认 添加磁带到Media Class 添加步骤如下： 输入命令WRKMLMBRM,可以看到所有磁带 在没有分类的磁带中，前面输入1选择将要移动的磁带 回车进入Add Media Library Media to BRM页面： Media library输入需求的Media library名称，例如之前创建的TAPMLB08 Add volume to BRM选择*YES Initialize media选择*YES，注意，不初始化可能使用不了 Media class输入需要移动到的Media Class，例如之前创建的VTLTEST 其他选项可以默认，完成按Enter确认 可以使用命令WRKMEDBRM MEDCLS(VTLTEST)命令查看，默认应该是*EXP状态 创建Media policy 创建步骤如下： 运行命令GO BRMS 选择选项11. Policy administration 选择选项7. Work with media policies Opt第一行中输入1进行添加，然后输入Class名称，例如叫VTLTEST： Retain type是设置下面选项的单位，例如按天是2=Days Retain media是media过期时间，根据需求设置 Move policy此次配置未添加，以后再搞 Media class输入这个策略对应的Media class，例如之前创建的VTLTEST 其他选项根据需求进行设置，默认也可以 完成按Enter确认 创建Backup planning 创建步骤如下： 运行命令GO BRMS 选择选项2. Backup 选择选项1. Backup planning 选择选项2. Work with backup control groups： 例如创建Control Group名称为TESTBK 根据需求添加Save Item，为对象或库名称 指定ASP Device Weekly Activity SMTWTFS是备份计划，根据需求指定 Incremental Media Policy指定之前创建的Media Policy，例如叫VTLTEST Full Media Policy依旧是之前创建的，例如叫VTLTEST Retain Object Detail选项选择*YES 完成后按Enter确认 回到Backup planning菜单，选择3. Display backup plan查看配置 复制磁带 使用BRMS复制 使用BRMS复制的限制： 要复制的VOL必须是活动卷，并且是BRMS Media库的成员 如果通过在VOL参数中指定Media集的卷以批处理模式复制Media集，则必须在FROMVOL参数中使用特殊值*SET 不能使用DUPMEDBRM命令复制TSM(ADSM)介质 类别为*APPC或*NET的设备不能使用DUPMEDBRM命令复制数据 必须有两个设备才能使用此命令。如果设备是共享设备，BRMS将会开启设备。如果这些设备不是共享设备，必须将它们手动打开 如果使用设备时optimum block size设置enabled，则输出设备支持的最佳块大小必须大于或等于输入设备的最佳块大小 复制操作将根据FROMDEV和TODEV参数确定是使用tape或optical。BRMS不会在单个DUPMEDBRM命令上复制tape和optical卷 命令示例： DUPMEDBRM VOL(*LIST) FROMDEV(TAPMLB01) TODEV(TAPMLB02) MEDPCY(FMT3570) FROMVOL(VOL001 VOL002 VOL003) 示例说明： 示例复制卷VOL001、VOL002和VOL003，使用Media库TAPMLB01作为源设备 Media库TAPMLB02作为目标设备，使用FMT3570Media策略中的Media类作为目标卷 官方命令参考：IBM i7.5 Duplicate Media using BRM(DUPMEDBRM) 非BRMS复制 使用DUPTAP命令限制： 必须有两个磁带驱动器或一个具有两个磁带资源的磁带媒体库设备才能使用此命令 跨卷的文件必须同时复制两个部分文件： 不允许复制以部分文件结尾的磁带，然后将文件的第二部分附加到磁带的末尾 必须通过在FROMVOL参数上指定多个卷来同时复制文件的两个部分 只有具有*SAVSYS(save system)特殊权限的用户才能使用此命令 将挂载在设备TAP01的磁带复制到挂载在设备TAP02的磁带上： DUPTAP FROMDEV(TAP01) TODEV(TAP02)   将磁带卷VOL001和VOL002中的所有文件复制到设备TAPE02上目标卷VOLABC的末尾，官方示例如下： DUPTAP FROMDEV(TAPE01) TODEV(TAPE02) FROMVOL(VOL001 VOL002) TOVOL(VOLABC) FROMSEQNBR(*ALL) TOSEQNBR(*END) 参数说明： FROMDEV：指定复制磁带的源设备 TODEV：指定复制磁带的目标设备 FROMSEQNBR：指定要复制的数据文件序号： 单一值*ALL：所有文件都复制 元素一：起始文件序号： *FIRST：从第一个文件序号开始的所有文件都被复制 1-16777215：指定要复制的起始文件序号。序号范围内的文件会被复制 元素二：结束文件序号： *LAST：以最后一个文件序号结尾的所有文件都被复制 *ONLY：仅复制起始文件序列中指定的文件 1-16777215：指定要复制的结束文件序号 TOSEQNBR：指定要将数据文件复制到哪个序号： FROMSEQ：与源文件相同的序号 END：数据文件被添加到磁带的逻辑末端。使用下一个有效的序号 1-16777215：指定数据文件将被复制到的序列号。 如果设备没有覆盖能力并且指定的值不是要在逻辑磁带卷末尾使用的下一个逻辑值，则不允许使用此值。 复制从指定的文件开始 FROMVOL：指定要复制的磁带的卷标识符(如果指定的设备是Media库设备或虚拟磁带设备，则指定的卷应该是要挂载和使用的磁带标识符或虚拟磁带卷名称)： 单一值：*MOUNTED，放置在FROMDEV 参数中指定的磁带设备上的任何标记或未标记的卷都会被复制： 对于磁带Media库设备，要使用的卷是SETTAPCGY(Set Tape Category)命令装入的类别中的下一个磁带 对于虚拟磁带设备，要使用的卷是当前挂载的卷，或者如果当前没有挂载的卷，则使用处于加载状态的下一个卷 其他值：character-value，指定被复制的标记磁带卷的标识符，最多300个 TOVOL：指定要将数据复制到的磁带的卷标识符(注意事项同上)： 单一值： *MOUNTED：使用当前放置在设备中的磁带卷(其他说明同上) *FROMVOL：放置在FROMDEV参数指定的设备中的磁带的卷标用于初始化放置在 TODEV参数指定的设备中的磁带。 最多复制八个附加卷标和九个用户卷标。磁带Meida库设备和虚拟磁带设备不支持此值 其他值：character-value，指定要将数据复制到的磁带的卷标识符。在卷时间结束时，可以使用此卷标识符重新初始化磁带。如果卷包含正确的卷标识符但代码或密度错误，则磁带将重新初始化为正确的代码和密度。卷标识符被保存。最多300个 TODENSITY：指定写入复制数据的密度或格式： *DEVTYPE：使用磁带设备支持的最高容量密度或格式 其它更多设置参考官方命令说明 COMPACT：指定是否执行设备数据压缩。如果指定的设备不支持压缩，则忽略此参数： *FROMFILE：如果FROMDEV参数中指定的设备读取的文件是使用设备数据压缩写入的，或者如果FROMDEV参数指定虚拟磁带设备，则执行设备数据压缩 *YES：数据压缩，对TODEV参数中指定的设备的所有文件执行 *NO：数据不执行压缩 FILES：指定是否将过期数据文件从放置在FROMDEV参数指定的设备中的磁带卷复制到放置在TODEV参数指定的设备上的磁带卷： *ALL：复制磁带卷上的所有数据文件，保存所有现有文件序号 *ACTIVE：仅复制过期日期晚于当前系统日期的数据文件 数据文件连续重新编号，从卷上第一个文件的编号开始，并忽略任何已过期的文件 USRLBLPGM：指定处理用户磁带标签的用户程序的名称和库。对于在TODEV参数上指定的设备，用户标签程序发送写入磁带的用户标签。对于在FROMDEV参数中指定的设备，用户标签被发送到用户标签程序 FROMENDOPT：在FROMDEV参数指定的设备上放置的磁带卷是倒带，还是在操作完成后倒带并卸载： *REWIND：仅倒带 *UNLOAD：倒带并卸载 *LEAVE：不到带也不卸载，保留在drive上 TOENDOPT：在TODEV参数指定的设备上放置的磁带卷是倒带，还是在操作完成后倒带并卸载 CHECK：指定是否在覆盖安装在TODEV参数上的卷上的磁带文件之前检查它的活动数据。如果 TODEV上有未标记的卷，则忽略此参数： *YES：检查要覆盖的文件是否有活动数据。仅检查要覆盖的第一个文件的活动数据，不检查任何后续文件。如果找到活动文件，则操作结束并发送错误消息 *NO：磁带复制继续，不检查活动文件 EXPDATE：指定复制文件时分配给所有文件的到期日期。此参数仅适用于标准标签磁带： *FROMFILE：与复制源文件一致 *PERM：所有复制的文件都将被分配一个永久的到期日期 date：自定义日期 官方命令参考：Duplicate Tape(DUPTAP) BRMS更多参考链接 参考链接如下： IBM Support BRMS Messages Moving the BRMS Database from One System to Another II13467 - BRM-USING SHARED VOLUMES IN A BRMS NETWORK WHEN THE OWNING SYSTEM IS DOWN 系统备份 官方参考链接：IBM i7.3 备份系统 磁带备份整个系统   注意，备份需要停到系统大多数子系统，此时系统不能进行业务。准备好磁带，将一盒空磁带挂到对应的TAP上。 停掉用户子系统   运行WRKSBS查看运行的子系统，如果有用户的子系统，手动停掉用户所有的子系统。注意，如果是重要系统，停止前可能需要应用部门确认。 停掉系统   输入ENDSYS命令停掉系统的大多数子系统，系统将处于受限状态。等待若干分钟，只剩下QCTL子系统。 发起备份 步骤如下： 运行命令GO SAVE 选择选项21. Entire system 进入Save the Entire System页面，提示会进行的操作： End all subsystems Save the Licensed Internal Code Save the operating system Save the security data Save the device configuration objects Save all user libraries(including libraries for licensed programs) Save all documents and folders Save all distribution and mail objects Save all directories Start the controlling subsystem 也有不会做的操作：Save the contents of job queues or data queues that exist the system 回车确认后进入Specify Command Defaults页面： 选项Devices输入备份的设备，例如TAPMLB08 其他默认，或者根据需求设置 回车确认后进入End Subsystem页面，根据需求设置 回车确认后进入Save System页面，主要是磁带机配置，根据需求配置 回车后，开始备份，查看状态 备份完成后子系统会启动 磁带备份用户数据 通过BRMS备份   在BRMS章备份策略配置节配置好备份策略后，可以直接通过命令发起备份，或者通过定时任务，或者程序实现计划性备份。假设Control Group名称为TESTBK，命令示例如下： STRBKUBRM CTLGRP(TESTBK) SBMJOB(*NO) JOBQ(QBATCH) ACTIVITY(*CTLGRPATR) 待补充 "},"05-IBM_Operating_System/02-AS400/12-AS400-消息&消息队列.html":{"url":"05-IBM_Operating_System/02-AS400/12-AS400-消息&消息队列.html","title":"AS400-消息&消息队列","keywords":"","body":"AS400-消息&消息队列 官方参考链接： IBM i 7.3 消息 IBM i 7.3 管理消息 IBM i 7.3 消息队列 IBM i 7.3 管理消息队列 IBM i 7.3 Scenario: Message monitor 其它参考链接： OS/400 Messages 消息 消息是从另一用户、从该操作系统或从应用程序发送的通信。 消息的类型   系统包含IBM提供的消息文件（存储在系统库QSYS中）、CPF消息文件QCPFMSG(用于系统消息和机器接口消息)及许可程序消息文件(例如QRPGMSG用于RPG消息)。消息类型： 错误消息可指示与系统、设备或程序相关的简单和复杂错误 警报提供针对硬件或软件资源的分析 官方参考链接：IBM i 7.3 消息的类型 错误消息 各种系统消息可指示从简单输入错误至系统设备或程序问题的各种情况。错误消息可发送至消息队列或程序并在屏幕上显示。消息可能为下列其中之一： 当前屏幕上的错误消息 有关系统问题的消息，此消息已发送至系统操作员消息队列QSYSOPR 有关设备问题的消息，此消息已发送至设备描述中指定的消息队列 有关潜在严重系统问题的消息，此消息发送至QSYSMSG消息队列、QSYSOPR队列及用户指定的其他消息队列 程序未处理的意外错误消息（显示在Display Program Messages屏幕上） 官方参考链接： 使用错误消息及其示例：IBM i 7.3 使用错误消息 队列中的消息：IBM i 7.3 消息队列中的消息 警报   Alerts是一条消息。警报会向操作员通知硬件资源（本地设备或控制器、通信线路或者远程控制器或设备）问题。警报还会向操作员通知系统或应用程序检测到的软件错误。如果系统在通信网络中，那么可创建警报并通过网络发送至管理问题的系统。可使用警报来执行以下管理活动： 监视以无人照管方式操作的系统和设备 管理本地操作员不知道如何处理该问题的情况 维持对系统资源和开销的控制 使用命令WRKALR可以查看Alerts消息，示例： Work with Alerts AS400 Type options, press Enter. 2=Change 4=Delete 5=Display recommended actions 6=Print details 8=Display alert detail Resource Opt Name Type Date Time Alert Description: Probable Cause (No alert entries matching selection criteria) 管理消息 查看消息   可以使用IBM Navigator for i查看或者使用命令DSPMSG或WRKMSG,二者基本一样，WRKMSG命令没有START属性，详细菜单属性如下： Display Messages (DSPMSG) Type choices, press Enter. Message queue . . . . . . . . . MSGQ *WRKUSR Library . . . . . . . . . . . Output . . . . . . . . . . . . . OUTPUT * Additional Parameters Message type . . . . . . . . . . MSGTYPE *ALL Messages to display first . . . START *LAST Severity code filter . . . . . . SEV 0 Assistance level . . . . . . . . ASTLVL *PRV 使用命令DSPMSG QSYSOPR查看QSYSOPR消息队列消息。示例： Display Messages System: AS400 Queue . . . . . : QSYSOPR Program . . . . : *DSPMSG Library . . . : QSYS Library . . . : Severity . . . : 60 Delivery . . . : *HOLD Type reply (if required), press Enter. Cleanup of spooled output and jobs on queues completed. Job message queue for 216670/JOBMANAGER/QSECURITY has been wrapped. ` 常用操作说明： 鼠标指向消息，按F1可以查看消息详细信息 F11=Remove a message操作可以删除消息 F13=Remove all操作可以删除所有消息 F16=Remove all except unanswered操作删除除了未回答的所有消息 F10=Display all查看所有 F22=Display list details显示列表详细星系 F21=Select assistance level选择辅助级别： 1=Basic:如果未设置为Basic辅助级别，那么不能显示消息详细信息 2=Intermediate 补充说明：消息队列QSYSMSG用于处理潜在严重系统消息，这些消息需要即时操作。 发送消息   使用IBM Navigator for i发送或使用SNDMSG命令来发送消息。示例使用命令SNDMSG MSG('TEST MESSAGE') TOUSR(BONDHUANG)发送消息给指定用户，其它属性默认，菜单选项示例如下： Send Message (SNDMSG) Type choices, press Enter. Message text . . . . . . . . . . MSG TEST MESSAGE To user profile . . . . . . . . TOUSR BONGDHUANG Additional Parameters To message queue . . . . . . . . TOMSGQ Library . . . . . . . . . . . *LIBL + for more values *LIBL Message type . . . . . . . . . . MSGTYPE *INFO Message queue to get reply . . . RPYMSGQ *WRKSTN Library . . . . . . . . . . . Coded character set ID . . . . . CCSID *JOB 然后使用DSPMSG命令即可查看收到消息： Display Messages Queue . . . . . : BONDHUANG Program . . . . : *DSPMSG Library . . . : QUSRSYS Library . . . : Severity . . . : 00 Delivery . . . : *BREAK Type reply (if required), press Enter. From . . . : BONDHUANG 11/21/21 10:23:37 TEST MESSAGE 对消息做出响应   使用IBM Navigator for i回应消息或使用DSPMSG及WRKMSG命令来回应消息。输入命令后，需要回复的消息会有reply字段，根据需求输入回复的选项或内容。按F1可以查看消息详细信息，并包含回复选项的详细说明。 对打印机消息做出响应 要显示需要回复的打印机消息，步骤如下： 输入命令WRKWTR ASTLVL(*BASIC)进入Work with Printers屏幕 要显示需要回复的打印机消息，请条目前面选择7=Message 在reply字段中，输入对打印机消息的回复 删除消息   使用IBM Navigator for i删除消息或使用DSPMSG及WRKMSG命令中的操作选项来删除消息。关于消息删除的选项有： F11=Remove a message操作可以删除消息 F13=Remove all操作可以删除所有消息 F16=Remove all except unanswered操作删除除了未回答的所有消息   使用DLTMSGF(Delete Message File)命令删除消息文件。示例删除名为INV的消息文件，存储在INV中的所有消息描述也将被删除： DLTMSGF MSGF(INV) 打印消息   可以通过打印消息队列中的所有消息来跟踪系统问题。要打印消息队列中的特定消息（一次一条），步骤如下： 输入WRKMSG命令，按F4获取提示 在Message queue字段中，输入包含要打印的消息的消息队列名称，按Enter键继续。 如果Assistance level设置为Basic(按F21设置） 选择要打印的消息，在Opt选项列中输入5(5=Display details and reply) 按F6打印该消息 如果Assistance level设置为Intermediate(按F21设置） 光标选择要打印的消息，按F1查看详细信息 按F6打印该消息 消息队列 消息队列提供位置以接收参考消息和查询消息并将其存储在特定库中。 消息队列类型 系统提供若干类型的消息队列来接收消息。可使用的系统队列如下所示： 队列QSYSOPR(system operator message queue)包含需要操作员回复的系统消息 队列QSYSMSG(Optional message queue)保存若干错误消息。用于处理潜在严重系统消息，这些消息需要即时操作 历史记录队列QHST(history log)保存用于跟踪系统活动的消息 打印机队列存储与每个打印机相关联的消息 Electronic Customer Support程序在恢复PTF指令时用于发送消息的消息队列存储电子客户支持发送的所有消息，以便可减少发送至QSYSOPR的消息数 每个用户和工作站还具有消息队列，用于保存来自系统操作员、另一用户或另一系统的消息 QSYSOPR队列   系统操作员消息队列QSYSOPR包含需要操作员回复的系统消息。为处理发送至QSYSOPR消息队列或所配置消息队列的大量消息，有对应以下和控制器描述的消息队列参数(MSGQ)： 线路描述：Distributed data interface, Ethernet, frame-relay, token-ring, X.25 控制器描述：APPC, async, local workstation, remote workstation, SNA host, virtual workstation 管理消息队列 官方参考链接：IBM i 7.3 管理消息队列 创建消息队列 使用命令CRTMSGQ创建，命令参数示例如下： Create Message Queue (CRTMSGQ) Type choices, press Enter. Message queue . . . . . . . . . MSGQ Library . . . . . . . . . . . *CURLIB Text 'description' . . . . . . . TEXT *BLANK Additional Parameters Force to auxiliary storage . . . FORCE *NO Queue size: SIZE Initial storage size . . . . . 3 Increment storage size . . . . 1 Maximum increments . . . . . . *NOMAX Authority . . . . . . . . . . . AUT *LIBCRTAUT Allow alerts . . . . . . . . . . ALWALR *NO Coded character set ID . . . . . CCSID *HEX Message queue full action . . . MSGQFULL *SNDMSG 要创建消息队列，请遵循以下步骤： 主菜单中选择选项3. General system tasks 在General System Tasks屏幕中选择选项4. Messages 在Messages屏幕中选择选项7. Create a message queue 在Message queue字段中，输入新消息队列的名称 可选：要指定其他消息队列特征，按F10可指定以下特征： Force to auxiliary storage：可以将所有消息队列更改放入辅助存储器。这包括对消息队列属性的更改以及由于从队列中发送或删除消息而引起的更改。 Queue size：指定消息队列大小 Authority：指定用户权限 Allow alerts：指定消息队列是否允许系统生成警报 Coded character set ID ：指定编码字符集标识 (CCSID) 为严重消息创建消息队列 QSYSMSG   可创建可选消息队列QSYSMSG以保存需要即时操作的特定严重系统消息。输入如下命令创建该队列： CRTMSGQ QSYS/QSYSMSG TEXT ('OPTIONAL MSGQ TO RECEIVE SPECIFIC SYSTEM MESSAGES') 创建后系统将特定系统消息存储在其中。示例： CPF0907 Serious storage condition might exist. Press HELP 更改消息队列的属性   使用CHGMSGQ命令修改，参数和创建时候一样。示例此命令将TESTMSGQ消息队列的传递方法更改为通知模式。当消息已发送到用户队列时，警示灯和声音警报（如果已安装）会立即通知用户： CHGMSGQ MSGQ(TESTMSGQ) DLVRY(*NOTIFY) 更改打印机的消息队列   可更改用于存储每个打印机的关联消息的消息队列的位置，可将打印消息与系统消息、用户消息或错误消息隔离。更改步骤如下： 命令行上输入WRKDEVD *PRT，然后回车确认 在要更改的打印设备前的Opt列中输入2(2=Change) 在Change Device Desc (Printer)屏幕的Message queue参数后输入要更改的消息队列的名称 打印消息队列中的所有消息 打印消息队列中的消息，步骤如下： 主菜单中选择选项3. General system tasks 在General System Tasks屏幕中选择选项4. Messages 在Messages屏幕中选择选项3. Display messages 在Message queue参数选项中，输入要打印消息的消息队列名称 在Library参数中，输入该消息队列所在的库 在Output字段中，输入值*PRTWRAP 或者直接输入命令，示例打印QSYSOPR队列中所有消息： DSPMSG MSG(QSYSOPR) OUTPUT(*PRTWRAP) 自动回复消息   使用命令WRKRPYLE(Work with Reply List Entries)可以查看当前回复列表条目，并且可以修改及删除等操作，命令示例如下： Work with System Reply List Entries System: TEST400 Type options, press Enter. 2=Change 4=Delete Sequence Message Compare Opt Number ID Reply Compare Value Start 10 CPA0700 D *NONE 20 RPG0000 D *NONE 30 CBE0000 D *NONE 待补充 "},"05-IBM_Operating_System/02-AS400/13-AS400-日志&日志接收器.html":{"url":"05-IBM_Operating_System/02-AS400/13-AS400-日志&日志接收器.html","title":"AS400-日志&日志接收器","keywords":"","body":"AS400-日志&日志接收器   Journals是系统对象，包含对另一系统对象进行的更改的信息。Journal可用来恢复数据库文件、数据区、数据队列和集成文件系统对象。定期进行Journal记录会加快管理任务（例如保存操作）的速度。   Journal管理提供了一种记录系统上对象活动的方法。使用Journal管理时，用户创建了一个称为Journal的对象。Journal以Journal entries的形式记录您指定的对象的活动。Journal将Journal entries写入另一个称为Journal receiver的对象中。官方参考链接： IBM i 7.3 Logs and journals IBM i 7.3 Journal management Local journal管理 官方参考链接：IBM i 7.3 Local journal management Setting up journaling   使用CRTJRN(Create Journal)命令创建Journal，使用CRTJRNRCV(Create Journal Receiver)命令创建Journal接收器。Setting up journaling包括创建日志和日志接收器。创建Journal时，需要以下信息： Journal名称，Journal分配的Library(JRN) 与Journal关联的Journal接收器名称及所在的Library(JRNRCV) 为Journal分配存储空间的磁盘池(ASP) Journal的消息队列及队列所在的Library(MSGQ) 是否使用手动或使用系统Journal接收器管理(MNGRCV) 是否自动删除Journal接收器(DLTRCV) Journal接收器大小选项(RCVSIZOPT) Journal的Journal对象限制(JRNOBJLMT) Journal的权限(AUT) 是否最小化特定于条目的数据(MINENTDTA) 是否使用Journal缓存(JRNCACHE) 是否延迟下一次自动更改Journal接收器的尝试(MNGRCVDLY) 是否延迟下一次自动删除Journal接收器的尝试(DLTRCVDLY) 是否在Journal分录中包含固定长度的数据(FIXLENDTA) CL命令创建示例选项： Create Journal (CRTJRN) Type choices, press Enter. Journal . . . . . . . . . . . . JRN Library . . . . . . . . . . . *CURLIB Journal receiver . . . . . . . . JRNRCV Library . . . . . . . . . . . *LIBL ASP number . . . . . . . . . . . ASP *LIBASP Journal message queue . . . . . MSGQ QSYSOPR Library . . . . . . . . . . . *LIBL Manage receivers . . . . . . . . MNGRCV *SYSTEM Delete receivers . . . . . . . . DLTRCV *NO Receiver size options . . . . . RCVSIZOPT *SYSDFT + for more values Minimize entry specific data . . MINENTDTA *NONE Journal caching . . . . . . . . JRNCACHE *NO Manage receiver delay time . . . MNGRCVDLY 10 Delete receiver delay time . . . DLTRCVDLY 10 Fixed length data . . . . . . . FIXLENDTA *JOBUSRPGM + for more values Journal object limit . . . . . . JRNOBJLMT *MAX250K Text 'description' . . . . . . . TEXT *BLANK Additional Parameters Authority . . . . . . . . . . . AUT *LIBCRTAUT 创建Journal接收器时，需要以下信息： Journal接收者的名字 Journal接收器的磁盘池分配 Journal接收器的存储阈值 Journal接收器的权限 命令CRTJRNRCV示例如下： Journal receiver . . . . . . . . JRNRCV Library . . . . . . . . . . . *CURLIB ASP number . . . . . . . . . . . ASP *LIBASP Journal receiver threshold . . . THRESHOLD 1500000 Text 'description' . . . . . . . TEXT *BLANK Setting up journaling示例官方参考链接：IBM i 7.3 Example: Setting up journaling 开启和结束Journaling以及更改Journaling属性 官方参考链接：Starting and ending journaling and changing journaling attributes 管理Journals 官方参考链接：IBM i 7.3 Managing journals Swapping journal receivers   可以使用IBM Navigator for i或使用CHGJRN命令Swapping日志接收器。如果使用系统日志接收器管理，系统会为用户更改日志接收器： 当Swapping journal receivers时，旧的日志接收器将分离 分离日志接收器时，用户无法将其重新附加到任何日志 用户可以使用分离的日志接收器执行以下操作：保存或恢复、显示条目、检索条目、接收条目、使用它来应用或删除日志更改、用它来比较日志镜像、显示其在接收器链中的状态或位置、删除、用远程日志功能复制   可以在CHGJRN命令上使用JRNRCV(*GEN)来创建与当前连接的接收器具有相同属性且位于同一库中的新接收器。这些属性包括所有者、私有权限、公共权限、对象审计、ASP 标识符、阈值和文本。例如Swapping新的审计日志接收器: CHGJRN QSYS/QAUDJRN JRNRCV(*GEN) 删除日志接收器 删除日志接收器的规则如下： 不能删除附加到本地日志的日志接收器。在删除日志接收器之前，必须执行更改日志操作(CHGJRN)以分离它 必须按照它们附加到日志的相同顺序删除日志接收器。 无论之前的限制如何，用户都可以删除损坏或无法操作的接收器。但是，如果连接的接收器损坏，则必须先detach，然后再删除 如果远程日志的日志状态为活动，则无法删除附加到远程日志的日志接收器。如果尝试删除附加到远程日志的接收器，系统将发送查询消息CPA705E。回复消息的结果与回复消息CPA7025的结果相同。 使用命令DLTJRNRCV删除日志接收器，示例删除审计日志接收器： DLTJRNRCV JRNRCV(QSYS/QAUDJR0002) 命令示例： Delete Journal Receiver (DLTJRNRCV) Type choices, press Enter. Journal receiver . . . . . . . . JRNRCV Library . . . . . . . . . . . *LIBL Option . . . . . . . . . . . . . DLTOPT *NONE + for more values Deleting journals   可以使用IBM Navigator for i或者命令DLTJRN来删除日志。示例从系统中删除库MYLIB中的日志JRNLA： DLTJRN JRN(MYLIB/JRNLA) 命令示例： Delete Journal (DLTJRN) Type choices, press Enter. Journal . . . . . . . . . . . . JRN JRNLA Library . . . . . . . . . . . MYLIB 保存日志及日志接收器 使用SAVCHGOBJ命令保存日志接收器： SAVCHGOBJ OBJ(*ALL) OMITOBJ(MYJRCV0002) LIB(RCVLIB) OBJTYPE(*JRNRCV) DEV(media-device-name) ENDOPT(*LEAVE) 示例说明： 示例中所有日志接收器都位于RCVLIB库中，当前附加的日志接收器是MYJRCV0002 示例保存自整个库已保存以来具有任何新条目的所有日志接收器，但排除了当前附加的日志接收器MYJRCV0002 使用SAVCHGOBJ命令保存日志接收器的一个可能的缺点是用户可能会意外保存当前连接的日志接收器。也就是只会保存部分，这样对于恢复去使用时候很麻烦   使用WRKJRNA命令显示每个日志的接收者目录。接收器目录告诉哪些日志接收器尚未保存。然后使用SAVOBJ命令来保存它们： 优点是每个日志接收器只保存一次。如果需要恢复，将不会遇到重名和部分接收者的问题 缺点是需要手动确定要保存的日志接收器的名称 可以结合使用系统日志接收器管理和控制语言(CL)程序来自动执行大多数日志管理任务： 指定日志接收器的阈值大小 为日志指定MNGRCV(*SYSTEM)、DLTRCV(*NO)和消息队列 使用CL程序来监视日志消息队列中指示系统已成功分离日志接收器的消息(CPF7020) 然后用户的CL程序可以保存已分离的接收器并可选择将其删除   自动保存日志接收器的另一种方法是使用QjoRetrieveJournalInformation(Retrieve Journal Information)API。程序可以使用此API来确定日志接收器目录以及未保存哪些接收器。然后程序可以保存未标记为已保存的日志接收器。用户可以将此程序设置为定期运行或作为正常处理的一部分运行。 恢复日志及日志接收器 为了让系统在不使用延迟日志支持时自动重新建立日志环境，必须按以下顺序恢复对象： Journals Based-on physical files Dependent logical files Other journaled object types Journal receivers 更多说明： 恢复日志后，可以随时恢复日志接收器，不需要在日志对象之后恢复它们。当这些对象在同一个库中时，系统会按正确的顺序恢复它们。当这些对象位于不同的库或目录中时，必须以正确的顺序还原它们，或者必须在还原操作后手动重新建立日志环境 可以按任何顺序恢复日志接收器。恢复它们后，使用WRKJRN(Work with Journal)命令显示中的选项9(Associate receivers with journal)以正确的顺序构建接收器链。如果在日志接收器之后恢复日志，还可以使用选项9来构建接收器链 如果在恢复日志之前恢复journaled的对象，则必须重新开始journaling 日志和日志接收器可以位于不同的库中。如果这是真的，必须确保在恢复日志之前将包含日志接收器的库在系统上。确保这一点还可以确保在所需的库中创建日志接收器，因为在恢复日志时会创建日志接收器。如果不能确保这一点，可能需要在所需的日志接收器库中创建一个日志接收器。然后，必须运行CGJRN命令以将新接收器附加到Journal上 在还原期间推迟对象日志记录的官方参考链接：Deferring object journaling during restore Remote Journal管理 官方参考链接： BM i 7.3 Remote journal management IBM i 7.3 Managing remote journals Scenarios: Remote journal management and recovery Remote Journal概念   Remote Journal管理有助于将日志条目有效地复制到一个或多个系统。用户可以通过应用程序使用远程日志管理来维护数据副本。数据副本是驻留在另一个系统或独立磁盘池上的原始数据的副本，原始数据驻留在主系统上，应用程序在正常操作期间对原始数据进行更改。 官方参考链接：IBM i 7.3 Remote journal concepts 规划Remote Journal 官方参考链接：IBM i 7.3 Planning for remote journals 设置Remote Journal 官方参考链接：IBM i 7.3 Setting up remote journals 准备Remote Journal 在建立Remote Journal环境之前，需要进的步骤： 确定Remote Journal网络或环境的范围。参考：IBM i 7.3 Planning for remote journals 确定将用于Remote Journal和相关日志接收器的库重定向（如果有）。库重定向是允许远程日志和相关日志接收器驻留在目标系统上与相应源日志及其相关日志接收器不同的库中的能力 确保所有选定的库都存在于目标系统上。在添加Remote Journal时，需要考虑是否使用库重定向 如果尚不存在，则创建适当的Local journal 配置并激活用户选择使用的通信协议。配置通信协议后，在使用远程日志功能时它必须处于活动状态： 如果您使用OptiConnect for IBM i总线传输方法，则OptiConnect for IBM i子系统QSOC必须处于活动状态。QSOC必须对源系统和目标系统都处于活动状态，并且必须启用适当的控制器和设备 如果使用SNA通信传输，请在适当的线路、控制器和设备上进行更改，并确保子系统QCMN在两个系统上都处于活动状态 如果使用TCP/IP或套接字IPv6，则必须使用STRTCP(Start TCP/IP)命令启动TCP/IP，包括分布式数据管理(DDM)服务 如果使用数据端口，则必须配置集群，确保集群处于活动状态，并使用STRTCPSVR(Start TCP/IP Server)命令启动Internet Daemon(INETD)服务 如果尚不存在，请创建相应的关系数据库(RDB)目录条目，该条目将用于定义远程日志环境的通信协议。当使用 TCP通信连接到独立磁盘池时，独立磁盘池的关系数据库(RDB)条目必须将关系数据库值设置为目标系统的本地RDB条目，并将关系数据库别名值设置为独立磁盘池的名称 添加Remote Journal 以下是将Remote Journal添加到源日志时必须提供的信息： Remote Journal添加到的源系统上的日志名称和库 要添加的目标系统上的Remote Journal名称和库 关系数据库目录条目，用于标识目标系统和其他必要的通信信息 添加的Remote Journal的类型 （可选）日志或日志接收器库重定向： 如果指定了不同的目标日志库或远程接收器库，则这些库将用于保存目标系统上的Remote Journal和接收器。这就是所谓的库重定向。 （可选）要应用于任何新创建的Remote Journal的日志消息队列、文本、删除接收器和删除接收器延迟属性的值 （可选）要使用的筛选条件 使用IBM Navigator for i添加Remote Journal步骤： 连接到用户要使用的系统 展开Journal Management 选择Set Database/Library to use with Journal Tasks并指定要使用的数据库和库 选择Journals 选择要添加Remote Journal的日志，然后选择Add remote journal操作   或者使用ADDRMTJRN(Add Remote Journal)命令或QjoAddRemoteJournal(Add Remote Journal)API来添加Remote Journal。命令ADDRMTJRN示例如下: Add Remote Journal (ADDRMTJRN) Type choices, press Enter. Relational database . . . . . . RDB Source journal . . . . . . . . . SRCJRN Library . . . . . . . . . . . *LIBL Target journal . . . . . . . . . TGTJRN *SRCJRN Library . . . . . . . . . . . Remote receiver library . . . . RMTRCVLIB *SRCRCVLIB Remote journal type . . . . . . RMTJRNTYPE *TYPE1 Journal message queue . . . . . MSGQ QSYSOPR Library . . . . . . . . . . . QSYS Delete receivers . . . . . . . . DLTRCV *NO Delete receiver delay time . . . DLTRCVDLY 10 Text 'description' . . . . . . . TEXT *BLANK   添加Remote Journal处理完成后，Remote Journal没有附加的日志接收器。此外，Remote Journal的日志状态设置为*INACTIVE，意味着Remote Journal尚未准备好从源系统上的日志接收任何日志条目，在此期间，日志条目可以继续存放或复制到源系统上的日志中。在用户激活该Remote Journal之前，不会将任何条目复制到新添加的远程日志。 删除Remote Journal   删除Remote Journal时，必须了解库重定向是否对远程日志有效。如果它有效，则任何库名处理都将用重定向的库名替换用于目标系统上的操作的库名。： 可以使用IBM Navigator for i、RMVRMTJRN(Remove Remote Journal)命令或QjoRemoveRemoteJournal(Remove Remote Journal)API来删除Remote Journal 必须在源系统上启动删除操作，以标识要删除的远程日志 使用任何删除Remote Journal方法时，当前无法将日志条目复制到要删除的Remote Journal 如果Remote Journal状态为*ACTIVE，则必须停用将日志条目复制到Remote Journal的功能 删除Remote Journal时，不会从目标系统中删除Remote Journal和任何关联的日志接收器，删除Remote Journal不会在目标系统上启动任何处理 从源系统上的日志中删除Remote Journal后，如果需要，用户负责删除Remote Journal和关联的日志接收器 用户可以将此Remote Journal添加回源系统上日志的Remote Journal功能定义中 一旦Remote Journal被删除，日志接收器就不再受到删除保护 以下是在目标系统上删除Remote Journal时必须提供的信息： 要删除Remote Journal的源系统上的日志名称和库 要删除的目标系统上的Remote Journal名称和库 关系数据库目录条目，用于标识目标系统和其他必要的通信信息 使用IBM Navigator for i添加Remote Journal步骤： 连接到用户要使用的系统 展开Journal Management 选择Set Database/Library to use with Journal Tasks并指定要使用的数据库和库 选择Journals 选择要删除Remote Journal的日志，然后选择Remote journals操作 在Remote journals列表中，选择要删除的Remote Journal并选择Remove操作 在Remove remote journal对话框中，单击OK 命令RMVRMTJRN示例如下： Remove Remote Journal (RMVRMTJRN) Type choices, press Enter. Relational database . . . . . . RDB Source journal . . . . . . . . . SRCJRN Library . . . . . . . . . . . *LIBL Target journal . . . . . . . . . TGTJRN *SRCJRN Library . . . . . . . . . . . 激活Remote Journal   激活Remote Journal意味着启动并维护日志条目从Local journal到Remote Journal的复制。始终从源系统激活Remote Journal： 如果是第一次激活Remote Journal，则激活Remote Journal会在目标系统上创建一个或多个日志接收器。激活Remote Journal还会在Local journal和Remote Journal之间建立连接，以便可以开始日志条目复制 如果Remote Journal之前被激活过，系统可能会也可能不会在目标系统上创建额外的接收器。这将在Local journal和Remote Journal之间建立连接之前发生，以便日志条目复制可以恢复 当激活或停用Remote Journal时您必须知道库重定向是否对远程日志有效。如果它有效，则任何库名处理都将用重定向的库名替换用于目标系统上的操作的库名 激活将日志条目复制到Remote Journal 激活日志条目到给定Remote Journal的复制，必须满足以下条件： 希望激活的Remote Journal的状态不得为*ACTIVE。Remote Journal必须处于非活动状态才能激活它。如果只想将交付模式从同步更改为异步，则可以 希望激活的Remote Journal不能像级联配置那样主动将日志条目复制到其他远程日志。在激活Remote Journal之前，必须先停用位于下游的Remote Journal 需要提供以下信息以激活将日志条目复制到目标系统上的Remote Journal： 将复制日志条目的源系统上的日志名称和库 日志条目将复制到的目标系统上的Remote Journal名称和库 关系数据库目录条目，用于标识目标系统和其他必要的通信信息 要使用的传递模式：指定同步或异步传递模式 日志接收器从中开始日志条目复制，它定义了日志条目复制的起点 如果指定了异步传递模式，则还可以指定发送任务的优先级。如果未指定值，系统将选择默认优先级，该优先级高于用户可以为此值指定的优先级。将此值设置得太大可能会导致更大的日志条目延迟或滞后 如果指定了同步传送模式，则可以指定同步发送超时值，系统默认使用60秒 （可选）是否应启用有效性检查 （可选）Remote Journal是否在连接结束时尝试自动重新启动 （可选）用于Remote Journal的Remote Journal过滤标准 使用IBM Navigator for i激活Remote Journal步骤： 连接到用户要使用的系统 展开Journal Management 选择Set Database/Library to use with Journal Tasks并指定要使用的数据库和库 选择Journals 选择要删除Remote Journal的日志，然后选择Remote journals操作 在Remote journals列表中，选择要激活的Remote Journal并选择Activate   还可以使用QjoChangeJournalState(Change Journal State)API及CHGRMTJRN(Change Remote Journal)命令。二者操作都必须从源系统发出。命令CHGRMTJRN示例： Change Remote Journal (CHGRMTJRN) Type choices, press Enter. Relational database . . . . . . RDB Source journal . . . . . . . . . SRCJRN Library . . . . . . . . . . . *LIBL Target journal . . . . . . . . . TGTJRN *SRCJRN Library . . . . . . . . . . . Journal state . . . . . . . . . JRNSTATE *SAME Delivery . . . . . . . . . . . . DELIVERY *SAME Starting journal receiver . . . STRJRNRCV *ATTACHED Library . . . . . . . . . . . Data port services: DTAPORTSRV Node identifier . . . . . . . *SAME Data port IP address . . . . . + for more values Sending task priority . . . . . SNDTSKPTY *SAME Synchronous sending time-out . . SYNCTIMO *SAME Validity checking . . . . . . . VLDCHK *SAME Automatic restart: RESTART Maximum attempts . . . . . . . *SAME Delay time . . . . . . . . . . Filter by object . . . . . . . . FTROBJ *SAME Filter images . . . . . . . . . FTRIMAGES *SAME How to make inactive . . . . . . INACTOPT *CNTRLD Remote Journal的Catch-up阶段   Catch-up是指在Remote Journal被激活之前复制源日志的日志接收器中存在的日志条目的过程。追赶阶段是将日志条目复制到Remote Journal的最有效方法。在此追赶处理完成之前，控制权不会返回给激活Remote Journal的请求者。在确定日志条目复制的起点时，用户需要考虑这一点。发生以下动作后，追赶阶段开始： 已在源系统上发出激活Remote Journal的请求 系统已确定要复制到目标系统的日志接收器和日志条目 追赶阶段处理与运行时同步或异步处理之间存在差异。追赶处理将以下内容复制到目标系统： 源系统上的日志中已存在的那些日志条目 在追赶处理期间存放或复制到源日记的那些日志记录   在追赶阶段，日志交付模式将是异步挂起*ASYNCPEND或同步挂起*SYNCPEND具体取决于指定的传递模式。追赶阶段相关和相关处理高级概述： 确定源系统上日志接收器的起点 如有必要，系统会在目标系统上创建一个接收器并将其附加到Remote Journal 系统将源系统上接收器中包含的所有日志条目复制或完成复制到目标系统上相应的接收器 如果源系统上的接收器是当前连接的接收器，则系统通过转换到同步或异步Remote Journal传递模式来完成追赶处理。追赶阶段完成，控制权返回到Remote Journal激活的请求者 如果源系统上的接收器不是源系统上日志的当前附加接收器，则执行以下步骤之一： 如果源日志的接收器链中有下一个接收器，回到第二步(系统会在目标系统上创建一个接收器并将其附加到Remote Journal)。系统从下一个接收器中的第一个条目开始复制日志条目 如果没有下一个接收器（这表明存在接收器链断裂），则追赶阶段完成。处理不会转换到同步或异步模式，更改日志状态处理结束。发送最终转义消息，指示处理已结束 结果： 在系统将给定的Remote Journal转换为同步或异步Remote Journal传递模式后，系统将继续保持该模式。直到停用Remote Journal功能或者发生故障 将日志条目复制到单个Remote Journal的执行独立于将日志条目复制到任何其他定义的远程日志。如果给定的目标系统出现故障或从特定源系统到目标系统的通信出现故障，这一点很重要 如果发生任何一种情况，Remote Journal功能将结束于那些驻留在目标系统上并从源系统维护的受影响Remote Journal。从源系统维护的所有其他Remote Journal将继续正常运行 例如，一个来源Journal可能在两个不同的系统上有两个Remote Journal。在这种情况下，如果从源日志到第二个Remote Journal的条目复制结束，则从源日志到第一个Remote Journal的条目复制不一定结束。如果给定的Remote Journal存在任何类型的故障，系统将结束Remote Journal功能。适当的消息会发送到任一系统或两个相关系统，但其他Remote Journal的Remote Journal功能不会受到影响 给定异步维护Remote Journal的通信线路速度不会影响另一个使用不同物理传输的异步维护Remote Journal的速度 Remote Journal状态的关系数据库注意事项 注意事项如下： 一旦Remote Journal被激活，只要Remote Journal处于活动状态，Remote Journal功能就会使用由指定的关系数据库(RDB)条目定义的通信配置 信息将在Remote Journal被激活的时间点从RDB中获取。因此，即使Remote Journal的日志状态为*ACTIVE时更改了RDB条目的定义，这些更改也不会立即生效 如果Remote Journal被取消激活，然后再次激活，新的RDB条目定义将生效。查看Remote Journal信息时，显示的RDB条目信息表示上次激活Remote Journal时RDB条目信息的状态 自动重启Remote Journal   为了帮助限制通信中断的影响，Remote Journal具有自动重启功能。激活Remote Journal时会指示此重新启动功能，当使用此功能时，指定要进行的重新启动尝试次数以及每次重新启动尝试之间等待的时间量。 当Remote Journal记录因可恢复错误而结束时，QSYSWRK子系统中将启动一个作业以进行重新启动尝试： 如果第一次尝试重新启动失败，消息CPI7027将发送到QSYSOPR，指示将进行下一次重新启动尝试的时间 如果所有重新启动尝试都失败，或者其中之一因不可恢复的错误而失败，则发送消息CPI7028 消息CPF70D5(Remote journal environment ended for journal)表示将触发自动重启的可恢复错误： 4：通信线路错误或目标系统错误 5：目标系统错误 7：超出系统、用户或组配置文件的存储限制 11：等待目标系统响应超时 12：异步Remote Journal无法跟上 21：源系统无法检测到目标系统 28：通信有效性检查失败 消息CPF70C5(Remote journal environment ended for journal)指示将触发自动重启的可恢复错误： 48：数据端口服务错误 49：节点标识符&11不可用于数据端口服务 50：数据端口服务的连接断开 52：数据端口服务无法访问目标Interne 地址 53：数据端口服务的硬件错误 54：内存不足，无法执行数据端口服务请求 55：客户端关闭数据端口服务 取消将日志条目复制到Remote Journal   建议尽可能从源系统而不是目标系统结束条目复制。只有在源系统出现故障且系统尚未结束Remote Journal功能时，才需要结束从目标系统对Remote Journal的复制。更多说明： 如果正在停用异步维护的Remote Journal，可以请求立即或以受控方式结束Remote Journal功能： 对于立即结束，任何已排队等待复制的日志条目将不会发送到Remote Journal 对于受控结束，任何已经排队等待复制的日志条目将被发送到Remote Journal。当所有排队的条目都发送到目标系统后，系统将消息CPF70D3发送到日志消息队列，表明Remote Journal功能已结束 如果正在停用同步维护的日志，则Remote Journal功能将立即结束，无论请求的是立即结束还是受控结束。如果Remote Journal处于处理的追赶阶段，也是立即结束 使用IBM Navigator for i操作步骤： 连接到用户要使用的系统 展开Journal Management 选择Set Database/Library to use with Journal Tasks并指定要使用的数据库和库 选择Journals 选择要删除Remote Journal的日志，然后选择Remote journals操作 在Remote journals列表中，选择要取消的Remote Journal并选择Deactivate 单击Deactivate对话框上的OK   用户还可以使用QjoChangeJournalStateAPI 和CHGRMTJRN命令来停止将日志条目复制到远程日志。注意事项如下： 可以从源系统或目标系统启动API，CHGRMTJRN命令只能从源系统启动 可以在目标系统上使用CHGJRN(Change Journal)命令来停用Remote Journal 管理Remote Journal 官方参考链接：IBM i 7.3 Managing remote journals 保留Remote Journal网络记录 查看Journal属性并打印： WRKJRNA JRN(library-name/journal-name) OUTPUT(*PRINT)   要仅获取日志的Remote Journal信息，WRKJNA命令中使用参数DETAIL(*RMTJRN)。可以使用QjoRetrieveJournalInformation(Retrieve Journal Information)API检索信息并将其放入文件中。要获取相关的关系数据库信息，使用以下命令： WRKRDBDIRE RDB(*ALL) OUTPUT(*PRINT) 显示Remote Journal功能信息 显示方法： 使用导航器登录源端，找到Remote Journal并查看属性 使用导航器登录目标端，找到Journal查看属性 使用WRKJRNA(Work with Journal Attributes)命令 使用QjoRetrieveJournalInformation(Retrieve Journal Information)API DSPJRNRCVA(Display Journal Receiver Attributes)命令显示有关日志接收器的Remote Journal特征的附加信息。对应API:QjoRtvJrnReceiverInformation(Retrieve Journal Receiver Information) 更多管理 更多管理内容内容参考官方文档： 评估系统更改如何影响Remote Journal Getting information about remote journal entries Journal receiver management with remote journals Swapping journal receiver operations with remote journals 使用Remote Journal进行保存和恢复操作的注意事项 Remote journal considerations when restarting the server Working with remote journal error messages 待补充 "},"05-IBM_Operating_System/02-AS400/14-AS400-输出队列管理.html":{"url":"05-IBM_Operating_System/02-AS400/14-AS400-输出队列管理.html","title":"AS400-输出队列管理","keywords":"","body":"AS400-输出队列管理   输出队列(Output Queue)可帮助用户管理作业结束时创建的打印机输出。打印机输出驻留在输出队列中。输出队列确定打印设备处理打印机输出的顺序。官方参考链接：IBM i 7.3 Managing output queues。 创建输出队列   命令CRTOUTQ(Create Output Queue)为spooled files创建一个新的输出队列。每个spooled files的输出队列中都会放置一个条目。文件写入输出设备的顺序由spooled files的输出优先级和队列中文件顺序提示(SEQ参数)上指定的值决定。 创建输出队列示例 示例创建一个名为DEPTAPRT的输出队列并将其放入当前库中： CRTOUTQ OUTQ(DEPTAPRT) AUT(*EXCLUDE) SEQ(*FIFO) TEXT('SPECIAL PRINTER FILES FOR DEPTA') 示例说明： 示例指定了AUT(*EXCLUDE)并且OPRCTL(*YES)，所以输出队列只能由创建队列的用户和具有作业控制权限或spooled files控制权限的用户使用和控制 示例指定了SEQ(*FIFO)，spooled files按先进先出顺序放置在队列中。如果一个用户被授权使用此输出队列，则必须使用GRTOBJAUT(Grant Object Authority)命令授予他们必要的权限 此队列上的文件中包含的数据只能由拥有文件的用户、队列的所有者、具有作业控制权限的用户或具有spooled files控制权限的用户显示 默认情况下，不会在每个作业的输出开头打印作业分隔符 命令CRTOUTQ示例 示例如下： Create Output Queue (CRTOUTQ) Type choices, press Enter. Output queue . . . . . . . . . . OUTQ Library . . . . . . . . . . . *CURLIB Maximum spooled file size: MAXPAGES Number of pages . . . . . . . *NONE Starting time . . . . . . . . Ending time . . . . . . . . . + for more values Order of files on queue . . . . SEQ *FIFO Remote system . . . . . . . . . RMTSYS *NONE 将输出队列分配给作业或作业描述 在用户可以使用新创建的输出队列之前，用户需要将其分配给作业或作业描述。 IBM Navigator for i 使用导航器步骤如下： 展开Work Management > Active Jobs 右键单击作业，然后单击Printer Output Character-based interface   用户可以通过更改作业描述以使用新的输出队列，修改后所有使用作业描述的作业都使用新的输出队列。使用命令CHGJOBD(Change Job Description)进行更改，示例更改作业描述AMJOBS，以使用输出队列QPRINT： CHGJOBD JOBD(AMJOBS/AMJOBS) OUTQ(*LIBL/QPRINT) 以上示例菜单选项示例： Change Job Description (CHGJOBD) Type choices, press Enter. Job description . . . . . . . . JOBD > AMJOBS Library . . . . . . . . . . . > AMJOBS Job queue . . . . . . . . . . . JOBQ *SAME Library . . . . . . . . . . . Job priority (on JOBQ) . . . . . JOBPTY *SAME Output priority (on OUTQ) . . . OUTPTY *SAME Print device . . . . . . . . . . PRTDEV *SAME Output queue . . . . . . . . . . OUTQ > QPRINT Library . . . . . . . . . . . > *LIBL Text 'description' . . . . . . . TEXT *SAME 访问打印机输出 用户可以选择在作业完成运行后从作业中分离打印机输出（将打印机输出与作业完全分离）。 IBM Navigator for i 通过Basic Operations访问作业的打印机输出： 展开Basic Operations 找到需要查看的作业，然后右键，然后单击Printer Output，然后出现打印机输出窗口 通过Output Queues文件夹访问打印机输出： 展开Work Management > Output Queues 选择要用于显示的输出队列（例如Qprint），右侧窗口出现输出队列中的打印机输出 Character-based interface 使用命令WRKOUTQ(Work with Output Queue)，例如显示输出队列QPRINT： WRKOUTQ QPRINT 示例显示输出队列BONDHUANG的显示结果： Work with Output Queue Queue: BONDHUANG Library: QGPL Status: RLS Type options, press Enter. 1=Send 2=Change 3=Hold 4=Delete 5=Display 6=Release 7=Messages 8=Attributes 9=Work with printing status Opt File User User Data Sts Pages Copies Form Type Pty QSYSPRT BONDHUANG WRKIT RDY 1 1 *STD 5 QPRTSPLQ BONDHUANG RDY 2 1 *STD 5 使用命令WRKSPLF(Work with Spooled Files)，命令示例： WRKSPLF JOB(qualified job name) 或者使用WRKJOB命令，选择选项4. Work with spooled files即可。 清除输出队列   当作业创建打印机输出时，它被发送到要打印的输出队列。很可能没有打印所有创建的打印机输出，清除输出队列可以删除队列中的所有输出。 IBM Navigator for i 使用导航器清除输出队列： 展开Work Management > Output Queues 右键单击要清除的输出队列，然后单击Clear Character-based interface 使用命令CLROUTQ(Clear Output Queue)，示例如下： CLROUTQ OUTQ(QPRINT) 示例命令菜单界面示例： Clear Output Queue (CLROUTQ) Type choices, press Enter. Output queue . . . . . . . . . . OUTQ > QPRINT Library . . . . . . . . . . . *LIBL 示例说明： 示例从输出队列QPRINT中删除所有spooled files的条目，这些条目正在等待打印或被保留 当前正在打印的文件条目和仍在从当前正在运行的程序接收数据的文件不受影响 删除输出队列   用户可以使用基于字符的界面来删除输出队列，导航器上应该无法操作，我查看没有此选项。在删除输出队列之前，必须满足以下要求： 被删除的输出队列不能包含任何条目 每个文件的输出必须打印、删除或移动到不同的输出队列 子系统不能处于活动状态 该队列不能被spooling writer使用 如果队列是由系统为特定打印机创建的，则无法删除该队列 Character-based interface 使用命令DLTOUTQ(Delete Output Queue)，示例从系统中删除输出队列BONDHUANG： DLTOUTQ BONGHUANG DLTOUTQ OUTQ(BONGHUANG) 上述命令菜单界面示例： Delete Output Queue (DLTOUTQ) Type choices, press Enter. Output queue . . . . . . . . . . OUTQ > BONGHUANG Library . . . . . . . . . . . *LIBL 查看系统上的输出队列 输出队列确定将打印机输出发送到打印机设备的顺序。 IBM Navigator for i 在系统上查看output queues，使用导航器方法： 在导航器中展开Work Management 单击或展开Output Queues 在导航器中，可以使用Include窗口定制输出队列列表： 右键单击Output Queues 鼠标指向Customize this view 单击Include即可进入定制窗口 Character-based interface 使用WRKOUTQ即可查看所有输出队列，示例： Work with All Output Queues Type options, press Enter. 2=Change 3=Hold 4=Delete 5=Work with 6=Release 8=Description 9=Work with Writers 14=Clear Opt Queue Library Files Writer Status MYOUT1 NUMERICS2 0 RLS A_GANAPA QGPL 0 RLS AAA QGPL 0 RLS AAAALIB QGPL 0 RLS 待补充 "},"05-IBM_Operating_System/02-AS400/15-AS400-Spooled文件管理.html":{"url":"05-IBM_Operating_System/02-AS400/15-AS400-Spooled文件管理.html","title":"AS400-Spooled文件管理","keywords":"","body":"AS400-Spooled文件管理   Spooled文件管理包括诸如保留Spooled文件、释放Spooled文件和移动Spooled文件等任务。官方相关参考链接如下： IBM i 7.3 Spooled file IBM i 7.3 Managing printing IBM i 7.3 Spooled files and output queues IBM i 7.3 Managing spooled files IBM i 7.3 保存和恢复假脱机文件 Spooled文件概念   假脱机是将数据保存在数据库文件中以供以后处理或打印的系统功能。保存并最终打印的此数据称为假脱机文件（或打印机输出文件）。相关详细说明： Spooled文件是从应用程序、系统程序或通过按打印键创建的，这些文件放在称为输出队列的地方 几乎所有生成打印输出的应用程序都使用IBM i操作系统提供的假脱机支持 打印文件的SPOOL参数上的值SPOOL(*YES)和SPOOL(*NO)确定是否请求Spooled支持 使用Print键捕获显示屏的图像一般会创建假脱机文件(必须在工作站设备描述中指定的打印文件中指定SPOOL =*YES)。当按下Print键时，系统会查看QSYSPRT打印文件中的OUTQ参数，以确定将Spooled文件发送到哪个输出队列 QSYSPRT打印文件中SPOOL属性的默认值为*YES SpoolingSPOOL=*YES比直接输出（打印机文件中的SPOOL=*NO）有几个优点： 用户的显示站仍可用于工作 其他用户无需等待打印机可用即可请求打印工作 如果需要特殊表格，用户可以将Spooled文件发送到特殊输出队列并在打印机不忙时打印 由于磁盘操作比打印机快得多，因此可以有效地使用系统 显示Spooled文件列表 使用IBM Navigator for i显示： 展开左侧Basic Operations菜单 单击选项Printer Output 默认设置是显示与当前用户关联的所有打印机输出，显示其它输出： 右键单击Printer Output 鼠标指向Customize this view 单击Include即可进入定制窗口 使用命令WRKSPLF可以查看当前用户的Printer Output： Work with All Spooled Files Type options, press Enter. 1=Send 2=Change 3=Hold 4=Delete 5=Display 6=Release 7=Messages 8=Attributes 9=Work with printing status Device or Total Cur Opt File User Queue User Data Sts Pages Page Copy QSYSPRT BONDHUANG BONDHUANG WRKIT RDY 1 1 QPJOBLOG BONDHUANG QEZJOBLOG QPAD142931 RDY 12 1 显示Spooled文件内容 使用IBM Navigator for i显示(可以显示ASCII Spooled文件)： 展开左侧Basic Operations菜单 单击选项Printer Output 右键单击要显示的打印机输出文件，点击Open   使用WRKSPLF命令，然后选择选项5=Display即可查看。基于字符的界面具有能够显示*LINE和*IPDSSpooled文件的附加功能。 显示与Spooled文件关联的消息   使用WRKSPLF命令，然后选择选项7=Messages即可查看。使用IBM Navigator for i查看方法步骤： 展开左侧Basic Operations菜单 单击选项Printer Output 右键单击带有消息的Printer Output文件，点击Reply Navigator中Spooled文件管理操作 Navigator中Spooled文件管理选项 使用IBM Navigator for i中右键打印机输出文件相关操作： Open(O)：显示Spooled文件内容 Reply(Y)：如果没有消息是灰色的，有消息可以显示消息并回复 Hold(L)：暂时阻止用户选择打印的Spooled文件（打印机输出） Release(A)：释放hold的Spooled文件（打印机输出） Print Next(I)：打印下一个 Send(N)：将Spooled文件发送给另一个用户或系统： Send via TCP/IP：通过TCP/IP发送 Send via SNA：通过SNA发送 Move(M)：将Spooled文件（打印机输出）从一个输出队列移动到另一个输出队列 Delete(D)：删除Spooled文件（打印机输出） Convert to PDF：将Spooled转换为PDF文件： 存储为打印机输出 存储为流文件 作为电子邮件发送 Export(X)：将Spooled文件（打印机输出）导出到用户PC文件系统 Cut(T))：剪切Spooled文件（打印机输出） Copy(C)：拷贝Spooled文件（打印机输出） Advanced(V)： Restart Printing(R)：重新启动打印(命令官方没有介绍，应该是没有) Manage Output Queue(O)：管理输出队列 Manage Printer(P)：管理打印机 Properties(R)：查看及修改Spooled文件（打印机输出）的属性 启用Spooled文件通知消息   要在Spooled文件(打印机输出)完成打印或被打印机写入程序保留时收到通知，需要启用假脱机文件通知功能。在导航器中开启方法如下(官方没有介绍基于字符界面的方法)： 展开Users and groups，单击Users 右键单击要更改的用户名，然后选择Properties 在General面板中，单击用户设置下的Jobs 选择选项Display Session 勾选Send message to spooled file owner 基于字符界面Spooled文件管理操作 字符界面中Spooled文件管理选项 使用命令WRKSPLF进入Work with All Spooled Files，示例： Work with All Spooled Files Type options, press Enter. 1=Send 2=Change 3=Hold 4=Delete 5=Display 6=Release 7=Messages 8=Attributes 9=Work with printing status Device or Total Cur Opt File User Queue User Data Sts Pages Page Copy QSYSPRT BONDHUANG BONDHUANG WRKIT RDY 1 1 QPRTSPLQ BONDHUANG BONDHUANG RDY 2 1 QPJOBLOG BONDHUANG QEZJOBLOG QZDASOINIT RDY 91 1 选项说明如下： 1=Send：将Spooled文件发送给另一个用户或系统，方式描述同上 2=Change：更改Spooled文件的属性 3=Hold：暂时阻止用户选择打印的Spooled文件 4=Delete：删除Spooled文件（打印机输出） 5=Display：显示Spooled文件内容 6=Release：释放hold的Spooled文件（打印机输出） 7=Messages：查看并回复Spooled文件的消息 8=Attributes：查看Spooled文件（打印机输出）的属性 9=Work with printing status： 2=Change status：更改状态 5=Display detailed description：显示详细描述 将Spooled文件转换为PDF 使用命令CPYSPLF(Copy Spooled File)： CPYSPLF FILE(QPRTSPLQ) TOFILE(*TOSTMF) WSCST(*PDF) 示例说明： 使用TOFILE(*TOSTMF)参数指示用户要将Spooled文件复制到流文件 使用TOSTMF和WSCST参数指定流文件中输出的位置和格式(PDF) 控制Spooled文件数量   作业完成后，会保留Spooled文件和内部作业控制信息，直到打印或取消Spooled文件。系统上的作业数和系统已知的Spooled文件数增加了执行IPL和内部搜索所需的时间，并增加了所需的临时存储量。 控制Spooled文件数量方法   用户可以使用CRTJOBD(Create Job Description)或CHGJOB(Change Job)命令上的LOG和LOGOUTPUT参数： LOG(Message logging)： Level,Severity,Text LOGOUTPUT(Job log output)： *SAME,*SYSVAL,*JOBLOGSVR,*JOBEND及*PND   或使用QLOGOUTPUT(Job log output)系统值来控制生成的作业日志的数量，可以设置的值有：*JOBEND,*JOBLOGSVR及*PND，示例如下： Display System Value System value . . . . . : QLOGOUTPUT Description . . . . . : Job log output Job log output . . . . : *JOBEND *JOBEND, *JOBLOGSVR, *PND   用户还可以通过使用系统清理功能来控制作业日志和其他系统输出在系统上停留的天数。有关详细信息，参考命令Change Cleanup(CHGCLNUP)。示例： CHGCLNUP ALWCLNUP(*YES) USRMSG(*KEEP) STRTIME(0700) 示例说明： 示例更改了清理选项，以便在执行清理时保留用户消息而不将其删除 示例中将清理开始时间设置为上午7:00 删除过期Spooled文件   在CHGPRTF(Change Printer File)、CRTPRTF(Create Printer File)、CHGSPLFA(Change Spooled File Attributes)或OVRPRTF(Override with Printer File)命令上使用EXPDATE或DAYS参数，以使Spooled文件符合命令DLTEXPSPLF(Delete Expired Spooled files)的删除条件。示例如下： ADDJOBSCDE JOB(DLTEXPSPLF) CMD(DLTEXPSPLF ASPDEV(*ALL)) FRQ(*WEEKLY) SCDDATE(*NONE) SCDDAY(*ALL) SCDTIME(010000) JOBQ(QSYS/QSYSNOMAX) TEXT('DELETE EXPIRED SPOOLED FILES SCHEDULE ENTRY') 示例会创建一个作业计划任务条目，改任务会使用DLTEXPSPLF命令每天删除系统上所有过期的Spooled文件。 回收Spooled文件存储   使用RCLSPLSTG(Reclaim Spool Storage)命令或自动清理未使用的打印机输出存储 QRCLSPLSTG(Reclaim spool storage)系统值来回收Spooled文件存储。官方参考链接：IBM i 7.3 Reclaiming spooled file storage。 注意事项：这些是从QSPL或QSPLxxxx库中删除Spooled数据库成员的唯一允许方法，任何其他方式都可能导致严重的问题。 保存及恢复Spooled文件   使用SAVLIB、SAVOBJ、STLIB和RSTOBJCL命令上的SPLFDTA参数来保存和恢复Spooled文件，并且不会丢失Spooled文件的打印保真度、属性或标识。官方参考链接： Saving and restoring spooled files IBM i 7.3 保存和恢复假脱机文件 通过Spooled文件大小控制打印   使用CRTOUTQ(Create Output Queue)或CHGOUTQ(Change Output Queue)命令上的MAXPAGES参数按大小控制Spooled文件的打印。示例： CHGOUTQ OUTQ(MYOUTQ) MAXPAGES((40 0800 1600) (10 1200 1300)) 示例说明： 示例要限制在上午8点到下午4点之间在输出队列MYOUTQ上打印超过40页的Spooled文件 在中午12点和下午1点之间，打印不超过10页的Spooled文件 修复输出队列和Spooled文件   使用命令STRSPLRCL(Start Spool Reclaim)修复在不可恢复状态的输出队列和spooled文件。示例回收输出队列BONDHUANG和驻留在输出队列上的所有Spooled文件： STRSPLRCL OUTQ(QUSRSYS/BONDHUANG)   修复系统和基本用户ASP中的所有输出队列和Spooled文件。示例将回收在系统辅助存储池(ASP1)和所有定义的基本用户ASP(ASP 2-32)中找到的所有库中的所有输出队列，驻留在输出队列上的Spooled文件也将被回收： STRSPLRCL OUTQ(*ALL/*ALL) ASPGRP(*SYSBAS)   修复当前用户的ASP组中的输出队列。示例将回收当前用户的ASP组中所有库中名为PRT01的输出队列。驻留在选定输出队列上的Spooled文件也将被回收： STRSPLRCL OUTQ(*ALL/PRT01) ASPGRP(*CURASPGRP) Spool Performance 可能遇到锁争用的Spool对象 Output queue (OUTQ)   此对象是Spooled文件的存储库。在内部，这个对象被实现为一个独立的索引（类型0E子类型 02）。输出队列上的Spooled文件都表示为Output queue索引上的一个条目： 当前的内部设计不允许在不影响数据完整性的情况下共享对输出队列对象的访问。对于在Spooled文件上执行的每个操作，都会在Spooled文件所在的输出队列上获得一个排他锁 这些操作包括在输出队列上添加(CRTSPLF)、删除(DLTSPLF)、保留(HLDSPLF)、释放(RLSPLF)、更改(CHGSPLFA)或列出(WRKOUTQ)Spooled文件 这意味着使用WRKOUTQ(Work with Output Queue)命令将与创建Spooled文件冲突，与删除Spooled文件等冲突 内部打印队列(PRTQ)   内部打印队列包括：QSPUSRQ、QSPALLQ、QSPDEVQ、QSPFRMQ、QSPUDTQ、QSPASPQ、QSPQJBQ。这些内部对象使用WRKSPLF命令有效地列出Spooled文件： 在内部，这些对象被实现为独立的索引（类型0E子类型C7） 系统上的每个Spooled文件都表示为每个索引上的一个条目 每个索引都有一个不同的键，用于对Spooled文件列表进行子集化。例如： 如果交互式用户执行WRKSPLF USER(QSYS)，将锁定QSPUSRQ索引，该索引与用户名无关。仅列出用户QSYS拥有的那些Spooled文件 如果用户执行WRKSPLF DEV(PRT01)，将锁定QSPDEVQ索引，该索引与设备名称无关。仅列出设备输出队列PRT01上的那些Spooled文件 这样就无需检查系统上的所有Spooled文件以确定它是否与WRKSPLF命令上的过滤条件匹配 与输出队列一样，内部打印队列设计的主要缺点是在系统上添加(CRTSPLF)、删除(DLTSPLF)、保留(HLDSPLF)、释放(RLSPLF)、更改(CHGSPLFA)或读取(WRKSPLF)Spooled文件时需要独占锁 这意味着，WRKSPLF USER(QSYS)命令将与创建Spooled文件冲突，与删除Spooled文件等冲突 Output file control block(OFCB)   OFCB或Spooled数据库成员是为Spooled文件存储数据和属性的位置Spooled文件属性存储在与数据库成员关联的空间中： 在数据库成员上获得一个独占空间位置锁，以同步对Spooled文件属性的访问 此对象上的锁争用通常不是问题，因为多个作业通常不会尝试同时访问同一个Spooled文件 Spool control block(SCB)   系统上的每个作业都存在一个spool control block（类型19子类型C2）。此对象挂在工作控制块表条目之外，主要用于保存作业的Spooled文件数量和某些作业属性的计数器： 在为特定作业添加(CRTSPLF)或删除(DLTSPLF)Spooled文件时，或者如果作业的属性正在更改而影响Spooled文件，则需要在SCB上使用排他锁 从在V5R1M0中将Spooled文件的属性从SCB移到数据库成员中后，该对象就不再是争用的主要来源 但是，由于交换或网络Spooled文件活动(SNDNETSPLF或SNDTCPSPLF)，代表其他用户创建许多Spooled文件的客户会遇到争用问题。通常会在附加到QPRTJOB作业的SCB上看到这一点 Reader writer control block(RWCB)   每个系统上存在一个RWCB对象（类型19子类型C5）。此对象包含系统上每个活动写入器的一个条目。 列出(WRKWTR)、启动(STRPRTWTR)、结束(ENDWTR)或更改(CHGWTR)写入器时，RWCB需要排他锁。在启动或结束所有或多个写入器时，更有可能发生对该对象的争用。 可指示Spooled锁争用的消息 消息如下： MCH5802-对象&1的锁定操作不满足 MCH5804-在指定的时间间隔内不满足锁定空间定位操作 CPF3330-没有必要的资源 CPF4218-&7中的输出队列&6不可用 CPF2528-由于&1，作业日志未写入输出队列 CPF4235-无法打开假脱机文件。原因代码是&6 一般Spool性能建议 建议如下： 减少系统上Spooled文件的数量。 在V5R4M0中添加的过期日期(EXPDATE)Spooled文件属性可用于自动从系统中删除假脱机文件。参考DLTEXPSPLF(Delete Expired Spooled files)命令 将Spooled文件分散到尽可能多的输出队列、用户和作业中 确保系统资源调配正确。对于WRKOUTQ和WRKSPLF之类的操作，分页吞吐量是一个重要的门控因素。增加分配给作业处理Spooled文件列表的内存等资源 使用SAVOBJ/RSTOBJ命令保存Spooled文件数据。保存后，将它们从系统中删除 将作业日志输出系统值QLOGOUTPUT或作业属性LOGOUTPUT更改为*PND以减少在系统上创建的作业日志的数量 对于系统上的每个活动写入器，将至少1兆字节的主存储专用于*SPOOL池 确保QRCLSPLSTG系统值未设置为*NONE。使用*NONE会对创建Spooled文件的性能产生不利影响 在高度活跃的Spooled环境中的高峰活动期间避免以下长时间运行的操作： 使用格式SPLF0100或SPLF0200调用QUSLSPL API以列出系统上的所有Spooled文件 使用格式OSPL0100或OSPL0200调用QUSLSPL API以列出系统上的所有Spooled文件 许多基本辅助级别的Spooled和打印操作 CHGJOB OUTPTY(X)针对具有数百或数千个Spooled文件的作业 CHGJOB SPLFACN(*DETACH)针对具有数百或数千个Spooled文件的作业 HLDJOB SPLFILE(*YES)针对具有数百或数千个Spooled文件的作业 RLSJOB针对以前使用HLDJOB SPLFILE(*YES)保存的具有数百或数千个Spooled文件的作业 运行CLROUTQ 运行CALL PGM(QSYS/QSPFIXUP) WRKSPLF性能注意事项   使用WRKSPLF获取Spooled文件列表时，某些选项可能会对具有高度活跃Spooled环境的系统造成性能影响。建议用户选择特定的用户名、打印设备、表单类型、用户数据或ASP来过滤列表。还建议在此环境中避免使用以下选项： 运行命令WRKSPLF SELECT(*ALL) 使用通用的用户名或用户数据来过滤没有推荐选项之一的列表 使用Spooled文件名、限定的作业名或创建日期和时间来过滤列表，而没有推荐的选项之一 使用基本辅助级别：ASTLVL(*BASIC) Spool锁争用场景 输出队列锁争用 自S/38以来，输出队列锁争用一直是个问题。最近的罪魁祸首是输出队列QEZJOBLOG： 当许多作业同时结束并尝试削减作业日志时，可能会出现瓶颈 如果瓶颈足够严重，则会出现消息CPF2528、CPF4218和MCH5802/CPF3330。输出队列争用不限于QEZJOBLOG 一些客户将全部或大部分Spooled输出集中到一个或几个输出队列。这可能导致比QEZJOBLOG更糟糕的瓶颈 场景一 数千个作业同时结束，并尝试将作业日志切到输出队列QEZJOBLOG。 结果： 在这种类型的环境中，可能会导致QEZJOBLOG出现严重的瓶颈 再加上执行WRKOUTQ OUTQ(QEZJOBLOG)的用户，可能会在输出队列上发生严重争用 WRKOUTQ OUTQ(QEZJOBLOG)将在持有排他锁的同时拍摄输出队列的快照，这可能需要几秒钟或几分钟，具体取决于专用于该作业的资源 症状： 尝试在QEZJOBLOG上创建作业日志或访问Spooled文件的作业将进入LCKW或挂在END状态，直到可以剪切作业的作业日志或执行WRKOUTQ的用户已获得快照 可能会产生消息CPF2528、MCH5802/CPF3330和CPF4218 WRKOBJLCK OBJ(QEZJOBLOG) OBJTYPE(*OUTQ)命令可能会显示等待*EXCL锁的作业。随着瓶颈的消退，锁的持有者将从一个作业转移到下一个作业 建议： 将作业日志输出系统值QLOGOUTPUT或作业属性LOGOUTPUT更改为*PND以减少在系统上创建的作业日志的数量。*PND选项将允许“按需”创建作业日志 如果需要Spooled作业日志，请在作业日志输出系统值QLOGOUTPUT或作业属性LOGOUTPUT上指定 *JOBLOGSVR。这将减少系统上创建作业日志的作业数量 将作业描述的日志记录级别更改为不剪切作业日志或仅在需要时剪切作业日志： 注意：如果作业异常结束，无论作业的日志级别如何，作业日志都将可用 减少QEZJOBLOG上的Spooled文件数将会使WRKOUTQ OUTQ(QEZJOBLOG)命令持有排他锁的时间更短 调用ENDSBS命令时，使用ENDSBSOPT(*NOJOBLOG)参数减少创建的作业日志量 将作业日志Spooled文件分散到多个输出队列中。如何将不同子系统创建的作业日志路由到不同的作业日志输出队列的示例如下： 为系统上定义的每个需要单独的作业日志输出队列的子系统创建一个库 创建QUSRSYS/QEZJOBLOG输出队列的副本，并将副本放入创建的每个库中 创建QSYS/QPJOBLOG打印机文件的副本，并将副本放入创建的每个库中 将每个重复的QPJOBLOG打印机文件的OUTQ属性从QUSRSYS/QEZJOBLOG更改为*LIBL/QEZJOBLOG 为每个子系统创建一个路由条目以调用执行CHGSYSLIBL LIB(x)的单独程序，库列表的系统部分被修改为在QSYS上面的第一步中创建的新库 注意：使用此技术时，请注意不会对这些重复的输出队列进行系统输出的自动清理。结合使用EXPDATESpooled文件属性和DLTEXPSPLF命令来自动清理Spooled文件 确保系统资源调配正确。对于WRKOUTQ和WRKSPLF之类的操作，分页吞吐量是一个重要的门控因素。增加分配给作业处理Spooled文件列表的内存等资源 在不使用输出队列的非高峰时间，将Spooled文件移动到备用输出队列。DLTOLDSPLF之类的应用程序使用CHGSPLFA命令(非DLTSPLF)修改以移动超过X天的Spooled文件 使用OA清理功能GO CLEANUP减少作业日志的保留期 要减少对QEZJOBLOG的争用，使用WRKJOBLOG命令而不是WRKOUTQ来访问作业日志Spooled文件。此命令不会获得QEZJOBLOG输出队列上的锁定 确保QEZJOBLOG仅用于保存作业日志Spooled文件 确保QRCLSPLSTG系统值未设置为*NONE。使用*NONE会对创建Spooled文件的性能产生不利影响 场景二   客户每天创建30000个Spooled文件到输出队列(OUTQA)。客户的Spooled文件保留政策是将Spooled文件在OUTQA中保留7天。输出队列平均有200000-210000个Spooled文件。在高峰操作期间，客户有10个应用程序同时在输出队列上创建和更改Spooled文件。客户在系统上还有25个唯一用户试图访问相同的Spooled文件以显示、更改、保留或释放它们。 结果： 在这种类型的环境中，可能会导致输出队列出现严重的瓶颈 对于OUTQA中的Spooled文件执行的每个操作，都会在输出队列上获得一个排他锁 再加上执行WRKOUTQ OUTQ(OUTQA)的用户，可能会在输出队列上发生严重争用 这可能需要几秒钟或几分钟，具体取决于专用于该作业的资源 随着Spooled文件的数量、创建Spooled文件的应用程序或访问输出队列上的Spooled文件的用户增加，争用也会增加 症状： 尝试在输出队列上创建或访问Spooled文件的作业将进入LCKW，从而导致作业吞吐量降低 可能会产生消息MCH5802/CPF3330和CPF4218 WRKOBJLCK OBJ(OUTQA) OBJTYPE(*OUTQ)命令可能会显示等待*EXCL锁的作业。随着瓶颈的消退，锁的持有者将从一个作业转移到下一个作业 建议： 将Spooled文件分散到尽可能多的输出队列中。减少输出队列上的Spooled文件数将会使WRKOUTQ OUTQ(OUTQA)命令在更短的时间内保持独占锁 使用SAVOBJ/RSTOBJ命令保存Spooled文件数据。保存Spooled文件后，将其从系统中删除 Spooled文件到期日期EXPDATE属性与DLTEXPSPLF命令一起可用于自动从系统中删除Spooled文件 确保系统资源调配正确。对于WRKOUTQ和WRKSPLF之类的操作，分页吞吐量是一个重要的门控因素。增加分配给作业处理Spooled文件列表的内存等资源 验证是否确实需要输出队列上的所有Spooled文件。许多客户应用程序创建临时Spooled文件并立即删除它们的案例。建议尽可能避免使用Spooled文件作为存储临时数据的工具。Spooled文件审计可以帮助确定这是否是一个问题 在不使用输出队列的非高峰时间，将Spooled文件移动到备用输出队列。DLTOLDSPLF之类的应用程序使用CHGSPLFA命令(非DLTSPLF)修改以移动超过X天的Spooled文件 要减少具有数千个Spooled文件的输出队列的争用，使用WRKSPLF或WRKJOB OPTION(*SPLF)来访问Spooled文件，而不是WRKOUTQ 确保将作业日志和系统转储生成到专用输出队列 确保QRCLSPLSTG系统值未设置为*NONE。使用*NONE会对创建Spooled文件的性能产生不利影响 内部打印队列锁争用   内部打印队列对象争用的罪魁祸首是WRKSPLF命令，该命令列出了系统上所有或大部分Spooled文件。更多说明如下： WRKSPLF USER(*ALL)将在持有索引排他锁的同时拍摄QSPALLQ内部打印队列的快照 此索引包含系统上每个Spooled文件的条目，因此生成快照可能需要几秒钟或几分钟 当索引被锁定时，系统上的Spooled文件不能被创建、保留、释放、删除或更改 如果瓶颈足够严重，可能会出现消息CPF4235 RC1和MCH5802/CPF3330 场景一 在高峰运行时间，在具有300000个Spooled文件的系统上，用户执行WRKSPLF USER(*ALL)。 结果： WRKSPLF USER(*ALL)将在持有排他锁的同时拍摄QSPALLQ索引的快照 这可能需要几秒钟或几分钟，具体取决于专用于该作业的资源 在快照完成之前，不能在系统上创建、保留、释放、删除或更改任何Spooled文件 症状： 尝试创建、保留、释放、删除、更改或列出Spooled文件的作业将在LCKW状态下挂起 可能会产生消息MCH5802/CPF3330和CPF4235 RC1 由于这是一个内部对象，因此不能使用WRKOBJLCK命令来确定持有锁的作业 在QSPTLIB库(可通过PTF获得)中提供的DSPLCKSTS命令，可用于确定锁持有者 一旦WRKSPLF USER(*ALL)的用户完成了索引的快照，瓶颈就会消失 建议： 减少系统上Spooled文件的数量。使用SAVOBJ/RSTOBJ命令保存Spooled文件数据。保存后将它们从系统中删除。Spooled文件EXPDATE属性与DLTEXPSPLF命令一起可用于自动从系统中删除Spooled文件 确保系统资源调配正确。对于WRKOUTQ和WRKSPLF之类的操作，分页吞吐量是一个重要的门控因素。增加分配给作业处理Spooled文件列表的内存等资源 使用WRKSPLF USER(*ALL)以外的其他内容来对Spooled文件列表进行子集化。过滤用户、表单类型或用户数据可能更合适。使用WRKJOB OPTION(*SPLF)或WRKOUTQ获取Spooled文件列表 从V5R3M0版本开始添加支持将Spooled文件存储在IASP中。这种新设计用键控数据库逻辑文件替换了内部打印队列对象。这种方法允许共享访问数据库逻辑文件 场景二   在高峰运行时间，系统上有300000个Spooled文件，用户执行WRKSPLF USER(USERX)，但是，USERX拥有290000个Spooled文件。 结果： WRKSPLF USER(USERX)将拍摄QSPUSRQ索引的快照，同时持有一个排他锁 快照将仅包括用户USERX拥有的那些Spooled文件，但是数量较多，与执行WRKSPLF USER(*ALL)一样效果。 这可能需要几秒钟或几分钟，具体取决于专用于该作业的资源 在快照完成之前，不能在系统上创建、保留、释放、删除或更改任何Spooled文件 症状： 尝试创建、保留、释放、删除、更改或列出Spooled文件的作业将在LCKW状态下挂起 可能会产生消息MCH5802/CPF3330和CPF4235 RC1 由于这是一个内部对象，因此不能使用WRKOBJLCK命令来确定持有锁的作业 在QSPTLIB库(可通过PTF获得)中提供的DSPLCKSTS命令，可用于确定锁持有者 一旦WRKSPLF USER(USERX)的用户完成索引的快照，瓶颈就会解决 建议： 将Spooled文件分布在更多用户中 减少系统上Spooled文件的数量。使用SAVOBJ/RSTOBJ命令保存Spooled文件数据。保存后将它们删除。Spooled文件EXPDATE属性与DLTEXPSPLF命令一起可用于自动从系统中删除Spooled文件 确保系统资源调配正确。对于WRKOUTQ和WRKSPLF之类的操作，分页吞吐量是一个重要的门控因素。增加分配给作业处理Spooled文件列表的内存等资源 使用WRKSPLF USER(USERX)以外的其他内容来对Spooled文件列表进行子集化。过滤用户、表单类型或用户数据可能更合适。使用WRKJOB OPTION(*SPLF)或WRKOUTQ获取Spooled文件列表 从V5R3M0版本开始添加支持将Spooled文件存储在IASP中 场景三   在高峰运行时间，系统上有300000个Spooled文件，用户执行WRKSPLF SELECT(*ALL *ALL *STD)，但是，系统上的290,000个Spooled文件的表单类型值为*STD。 结果： WRKSPLF SELECT(*ALL *ALL *STD)将拍摄QSPUSRQ索引的快照，同时持有一个排他锁 快照将仅包含表单类型为*STD的Spooled文件，与执行WRKSPLF USER(*ALL)一样。 这可能需要几秒钟，具体取决于专用于该作业的资源 在快照完成之前，不能在系统上创建、保留、释放、删除或更改任何Spooled文件 症状： 尝试创建、保留、释放、删除、更改或列出Spooled文件的作业将在LCKW状态下挂起 可能会产生消息MCH5802/CPF3330和CPF4235 RC1 由于这是一个内部对象，因此不能使用WRKOBJLCK命令来确定持有锁的作业 在QSPTLIB库(可通过PTF获得)中提供的DSPLCKSTS命令，可用于确定锁持有者 一旦WRKSPLF SELECT(*ALL *ALL *STD)的用户完成索引的快照，瓶颈就会消失 建议： 减少系统上Spooled文件的数量。使用SAVOBJ/RSTOBJ命令保存Spooled文件数据。保存后将它们删除。Spooled文件EXPDATE属性与DLTEXPSPLF命令一起可用于自动从系统中删除Spooled文件 确保系统资源调配正确。对于WRKOUTQ和WRKSPLF之类的操作，分页吞吐量是一个重要的门控因素。增加分配给作业处理Spooled文件列表的内存等资源 使用WRKSPLF SELECT(*ALL *ALL *STD)以外的其他内容来对Spooled文件列表进行子集化。过滤用户、表单类型或用户数据可能更合适。使用WRKJOB OPTION(*SPLF)或WRKOUTQ获取Spooled文件列表 从V5R3M0版本开始添加支持将Spooled文件存储在IASP中 Spool控制块锁定争用   Spool Control Block(SCB)对象争用的主要原因是服务器作业在交换给单个应用程序用户时创建Spooled文件。这可能会导致QPRTJOB作业的SCB争用。如果瓶颈足够严重，可能会出现消息MCH5802/CPF3330。 场景一   在系统高峰运行时间，数百个服务作业被提交给创建、更改和删除Spooled文件的同一用户。 结果： 在这种情况下，所有Spooled文件都将在与服务器作业交换到的用户关联的同一QPRTJOB作业下创建。这可能会导致附加到QPRTJOB的SCB对象发生争用 症状： 尝试为该QPRTJOB创建、删除或更改Spooled文件的作业可能会进入LCKW 可能会产生消息MCH5802/CPF3330 由于这是一个内部对象，因此不能使用WRKOBJLCK命令来确定持有锁的作业 在QSPTLIB库(可通过PTF获得)中提供的DSPLCKSTS命令，可用于确定锁持有者 建议： 减少交换给该特定用户的服务作业的数量 如果可能，增加服务作业要交换到的用户数 确保系统资源调配正确。增加分配给访问QPRTJOB作业的Spooled文件的作业的资源，例如内存 待补充 "},"05-IBM_Operating_System/02-AS400/16-AS400-程序开发相关.html":{"url":"05-IBM_Operating_System/02-AS400/16-AS400-程序开发相关.html","title":"AS400-程序开发相关","keywords":"","body":"AS400-程序开发相关 并非AS/400程序开发笔记，记录系统中跟程序开发相关的知识。 Programming Development Manager (PDM) PDM说明   在AS/400中，源语句是使用程序开发管理器PDM输入的，PDM提供了一种输入程序源语句然后将语句编译成可执行程序的方法，PDM使用\"Source Entry Utility (SEU)\"作为编辑器。使用STRPDM命令进入，菜单示例： 1. Work with libraries 2. Work with objects 3. Work with members 9. Work with user-defined options 相关资料链接： 开发工具介绍链接：Development tools IBM官方应用开发命令介绍：Application development commands AS/400输入源语句：Entering Source Statements as400i.com网站资料：Program Development Manager (PDM) 百度文库资料：Program Development Manager Overview PDM使用 查看QSYSINC Library 示例查看QSYSINC Library中SYS文件下的stocked成员： Enter command \"STRPDM\" Selection \"3. Work with members\" \"File\" option input \"SYS\" \"Library\" option input \"QSYSINC\" \"Type\" and \"Name\" option default(*ALL) Enter to \"Work with Members Using PDM\" page Choose \"STOCKED\" and \"Opt\" enter \"5(Display)\" 示例查看SYS文件权限： Enter command \"STRPDM\" Selection \"2. Work with objects\" \"Library\" option input \"QSYSINC\" Enter to \"Work with Objects Using PDM\" page Choose \"SYS\" and \"Opt\" enter \"5(Display)\" Pagedown to find the \"Allow write operation\" item or other Programming程序设计 Application promramming interfaces(API) System include (QSYSINC) library   Include files是一个文本文件，其中包含一组函数、程序或用户使用的声明，System include (QSYSINC) library为IBM i 操作系统中包含的API提供所有source include files。 在ILE C++中使用QSYSINC header files： #include 例如include QSYSINC/SYS/SOCKET使用： #include IBM官方参考链接： Including QSYSINC Header Files Include files and the QSYSINC library ILE C/C++ Include Files Edit include files   Include files一般都没有写权限，不能MODIFY或MOVE，但是也可以使用一些方法去修改，例如可以将Include files复制到自己的源文件并编辑副本，官方相关说明： Include files and the QSYSINC library How to Edit Source Members in Library QSYSINC listen()-Invite Incoming Connections Requests 函数listen()是用来表示愿意接受传入的连接请求，如果listen()没有完成，传入的连接将被静默丢弃。使用方法： #include int listen(int socket_descriptor, int back_log) Service Program Name: QSOSRV1 Default Public Authority: *USE Threadsafe: Yes 参数说明： socket_descriptor(Input) ：准备接收传入连接请求的套接字的描述符 back_log(Input) ：在系统开始拒绝传入请求之前可以排队的最大连接请求数。可以排队的最大连接请求数由SOMAXCONN（在QSYSINC/SYS/SOCKET中）定义 其它说明： 如果back_log参数指定的值大于SOMAXCONN允许的最大值，则指定的值将被忽略并使用SOMAXCONN值。如果back_log参数指定一个负值，指定的值将被忽略并使用零 官方详细链接：listen()--Invite Incoming Connections Requests 待补充 "},"05-IBM_Operating_System/02-AS400/17-AS400-PowerHA高可用.html":{"url":"05-IBM_Operating_System/02-AS400/17-AS400-PowerHA高可用.html","title":"AS400-PowerHA高可用","keywords":"","body":"AS400-PowerHA SystemMirror 官方参考链接： IBM PowerHA SystemMirror for i 概述 IBM PowerHA SystemMirror for i interfaces PowerHA data replication technologies IBM i 7.3 管理PowerHA IBM i 7.3 实现高可用性 IBM i 7.3 Comparison of PowerHA data resiliency technologies 常用命令 集群节点命令 命令 描述 ENDCLUNOD End Cluster Node RMVCLUNODE Remove Cluster Node Entry RMVDEVDMNE Remove Device Domain Entry WRKCLU Work with Cluster 集群资源组CRG命令 命令 描述 ADDCRGNODE Add CRG Node Entry CHGCRG Change Cluster Resource Group DSPCRGINF Display CRG Information DLTCRG Delete Cluster Resource Group DLTCRGCLU Delete CRG Cluster ENDCRG End Cluster Resource Group RMVCRGNODE Remove CRG Node Entry 命令WRKCLU示例： Work with Cluster Cluster . . . . . . . . . . . . . . . . : TESTCLU Select one of the following: 1. Display cluster information 2. Display cluster configuration information 6. Work with cluster nodes 7. Work with device domains 8. Work with administrative domains 9. Work with cluster resource groups 10. Work with ASP copy descriptions 20. Dump cluster trace 配置PowerHA 配置节点 官方参考链接：IBM i 7.3 配置节点 管理集群 官方参考链接：IBM i 7.3 管理集群 监视集群状态   可以使用IBM Navigator for i或CL命令，示例使用命令DSPCLUINF(Display Cluster Information)打印集群MYCLUSTER的详细信息： DSPCLUINF CLUSTER(MYCLUSTER) OUTPUT(*PRINT) 打印集群MYCLUSTER中定义的所有集群资源组的基本配置信息： DSPCRGINF CLUSTER(MYCLUSTER) CRG(*LIST) OUTPUT(*PRINT) 或者使用WRKCLU命令。官方参考链接：IBM i 7.3 监视集群状态 显示集群配置   可以使用IBM Navigator for i或CL命令DSPCLUINF(Display Cluster Information)或命令WRKCLU(Work with Cluster)。官方参考链接：IBM i 7.3 显示集群配置 管理节点 官方参考链接：IBM i 7.3 管理节点 显示节点属性   可以使用IBM Navigator for i或CL命令WRKCLU(Work with Cluster)，示例显示集群中所有节点的列表以及有关每个节点的详细信息： WRKCLU OPTION(*NODE) 显示集群资源组的列表，包含用于获取集群资源组更多信息的选项： WRKCLU OPTION(*CRG) 官方参考链接： IBM i 7.3 显示节点属性 Work with Cluster (WRKCLU) 停止节点   可以使用IBM Navigator for i或CL命令ENDCLUNOD(End Cluster Node)，示例立即结束节点NODE01上集群MYCLUSTER的集群资源服务： ENDCLUNOD CLUSTER(MYCLUSTER) NODE(NODE01) OPTION(*IMMED) 官方参考链接： IBM i 7.3 停止节点 End Cluster Node(ENDCLUNOD) 移除节点   可以使用IBM Navigator for i或CL命令RMVCLUNODE(Remove Cluster Node Entry)，示例从集群MYCLUSTER集群中删除节点NODE01,群集资源服务在节点NODE01上结束： RMVCLUNODE CLUSTER(MYCLUSTER) NODE(NODE01) 官方参考链接： IBM i 7.3 移除节点 Remove Cluster Node Entry(RMVCLUNODE) 从设备域中除去节点   设备域是集群中的一小部分节点，它们共享设备资源。从设备域中除去节点时，务必十分谨慎。如果从设备域中除去节点，并且该节点是任何独立磁盘池的当前主访问点，该设备域中的其他节点不再能够访问那些独立磁盘池。  从设备域中除去节点后，如果一个或多个现有集群节点仍属于该设备域，那么无法将该节点添加回到该设备域。如需添加回来必须执行下列操作： 删除正在添加至设备域的节点当前拥有的独立磁盘池 通过对该节点执行IPL，重新启动系统 将节点添加至设备域 重新创建已在步骤1中删除的独立磁盘池   可以使用IBM Navigator for i或CL命令RMVDEVDMNE(Remove Device Domain Entry)，示例从集群MYCLUSTER集群中的设备域MYDOMAIN中删除节点NODE01： RMVDEVDMNE CLUSTER(MYCLUSTER) DEVDMN(MYDOMAIN) NODE(NODE01) 官方参考链接： IBM i 7.3 从设备域中除去节点 Remove Device Domain Entry(RMVDEVDMNE) 管理集群资源组(CRG) 官方参考链接：管理集群资源组（CRG） 显示CRG状态   可以使用IBM Navigator for i或CL命令DSPCRGINF(Display CRG Information)，示例打印集群MYCLUSTER中定义的所有CGR的基本配置信息： DSPCRGINF CLUSTER(MYCLUSTER) CRG(*LIST) OUTPUT(*PRINT) 或者使用命令WRKCLU，选择选项9，或下面示例显示集群当前已知的CRG列表： WRKCLU OPTION(*CRG) 官方参考链接： IBM i 7.3 显示CRG状态 Display CRG Information(DSPCRGINF) CRG类型 CRG类型如下： *APP：应用程序集群资源组 *DATA：数据集群资源组 *DEV：设备集群资源组 *PEER：对等集群资源组 CRG状态 CRG状态及描述如下： Active：集群资源组管理的资源当前是resilient状态 Inactive：集群资源组管理的资源目前是非resilient状态 Indoubt：集群资源组对象中包含的信息可能不准确： 当使用Undo操作代码调用退出程序但未能成功完成时，会出现此状态 Restored：集群资源组对象已在此节点上恢复，并且尚未复制到恢复域中的其他节点： 在此节点上启动集群资源服务时，集群资源组将与恢复域中的其他节点同步，并将其状态设置为Inactive Add Pending：Add Node Pending，新节点正在添加到集群资源组的恢复域中： 如果退出程序成功，则状态将重置为其调用命令时的值 如果退出程序失败且无法恢复原始状态，则状态设置为Indoubt Delete Pending：集群资源组对象正在被删除： 当退出程序完成时，集群资源组将从恢复域中的所有节点中删除 Change Pending：正在更改群集资源组： 如果退出程序成功，则状态将重置为调用命令时的值 如果退出程序失败并且无法恢复原始状态，则将状态设置为Indoubt End Pending：集群资源组的Resilience正在结束： 如果退出程序成功，则状态设置为Inactive 如果退出程序失败且无法恢复原始状态，则状态设置为Indoubt Initialize Pending：正在创建集群资源组，并且正在初始化： 如果退出程序成功，则状态设置为Inactive 如果退出程序失败，集群资源组将从所有节点中删除 Remove Pending：Remove Node Pending。一个节点正在从集群资源组的恢复域中删除： 如果退出程序成功，则状态将重置为调用命令时的值 如果退出程序失败且无法恢复原始状态，则状态设置为Indoubt Start Pending：Resilience正在为集群资源组启动 如果退出程序成功，则状态设置为Active 如果退出程序失败且无法恢复原始状态，则状态设置为Indoubt Switchover Pending：CHGCRGPRI(Change Cluster Resource Group Primary)命令调用，出现集群资源组故障或节点故障，导致切换或故障开始，第一备用节点正在成为主节点： 如果退出程序成功，则状态设置为Active 如果退出程序失败且无法恢复原始状态，则状态设置为Indoubt Delete Pending：Delete Cmd Pending。DLTCRG(Delete Cluster Resource Group)命令正在删除集群资源组对象。集群资源组对象仅从运行该命令的节点中删除： 这不是分布式请求。命令完成后，集群资源组将从节点中删除 Add Device Pending：Add Device Entry Pending。正在将设备条目添加到群集资源组： 如果退出程序成功，则状态将重置为其调用命令时的值 如果退出程序失败并且无法恢复原始状态，则将状态设置为Indoubt Remove Device Pending：Remove Device Entry Pending。正在将设备条目从群集资源组中移除： 如果退出程序成功，则状态将重置为其调用命令时的值 如果退出程序失败并且无法恢复原始状态，则将状态设置为Indoubt Change Device Pending：Change Device Entry Pending。正在更改群集资源组中的设备条目： 如果退出程序成功，则状态将重置为其调用命令时的值 如果退出程序失败并且无法恢复原始状态，则将状态设置为Indoubt Change Status Pending：Change Node Status Pending。正在更改群集资源组的当前恢复域中节点的状态： 如果更改成功，则状态将重置为其调用CHGCLUNODE(Change Cluster Node Entry)命令时的值 退出程序失败会导致集群资源组的状态设置为Indoubt 如果备份节点被重新分配为Resilience设备集群资源组的主节点，并且设备的所有权无法转移到新的主节点，则状态设置为Indoubt 停止CRG   可以使用IBM Navigator for i或CL命令ENDCRG(End Cluster Resource Group)。示例结束MYCLUSTER集群中MYCRG集群资源组(当集群资源组退出程序被调用时，会向其传递恢复域中所有活动节点的退出程序数据“important information”)： ENDCRG CLUSTER(MYCLUSTER) CRG(MYCRG) EXITPGMDTA('important information') 官方参考链接： IBM i 7.3 停止CRG End Cluster Resource Group(ENDCRG) 删除CRG   可以使用IBM Navigator for i或CL命令DLTCRGCLU(Delete CRG Cluster)。示例删除MYCLUSTER集群中MYCRG集群资源组： DLTCRGCLU CLUSTER(MYCLUSTER) CRG(MYCRG)   或使用命令DLTCRG(Delete Cluster Resource Group)进行删除，示例从本地系统中删除CRGTEST集群资源组： DLTCRG CRG(CRGTEST) 官方参考链接： IBM i 7.3 删除CRG Delete Cluster Resource Group(DLTCRG) Delete CRG Cluster(DLTCRGCLU) 更改CRG的恢复域   在导航器的Recovery Domain页面上可添加和除去节点、更改节点角色、更改站点名称以及更改数据端口IP地址。或者使用CL命令操作。示例使用命令ADDCRGNODE(Add CRG Node Entry)将备份节点添加到CRG恢复域： ADDCRGNODE CLUSTER(MYCLUSTER) CRG(MYCRG) RCYDMN(NODE1 *BACKUP 3) 示例说明： 示例将节点NODE1添加到MYCLUSTER集群中的集群资源组MYCRG的恢复域 该节点被添加为第三个备份节点，任何现有的备份节点将按顺序重新编号   示例使用命令CHGCRG(Change Cluster Resource Group)对CRT的恢复域进行更改，更改了文本描述和数据端口IP： CHGCRG CLUSTER(MYCLUSTER) CRG(MYCRG) CRGTYPE(*DEV) EXITPGMFMT(*SAME) TEXT('CRG FOR CROSS SITE MIRRORING') RCYDMNACN(*CHGCUR) RCYDMN((NODE1 *SAME *SAME *SAME *ADD ('1.1.1.1'))) 示例说明： 示例更改MYCLUSTER集群中MYCRG集群资源组，集群资源组对象的文本描述更改为指定的值 为节点NODE1添加数据端口IP地址   示例使用命令RMVCRGNODE(Remove CRG Node Entry)从集群MYCLUSTER中的集群资源组MYCRG的恢复域中删除节点NODE03： RMVCRGNODE CLUSTER(MYCLUSTER) CRG(MYCRG) NODE(NODE03) 官方参考链接： IBM i 7.3 更改CRG的恢复域 Add CRG Node Entry(ADDCRGNODE) Change Cluster Resource Group(CHGCRG) Remove CRG Node Entry(RMVCRGNODE) 管理集群管理域 参考链接：IBM i 7.3 管理集群管理域 显示集群管理域 使用WRKCADMRE命令：IBM i 7.3 Work with Monitored Resources Monitored Resources Global Status   在Work with Monitored Resources显示受监视资源中的Global Status项显示的状态详细说明如下： Added：受监控资源条目及其属性已添加到集群管理域中的受监控资源目录中，但尚未同步，因为该域未处于活动状态 Consistent：系统监视的所有资源属性的值在活动集群管理域中是相同的 Failed：该资源不再受集群管理域的监视，应删除受监视的资源条目 Inconsistent：受监视资源条目的一个或多个受监视属性未设置为域中一个或多个节点上的集群管理域已知的值 Pending：受监视属性的值正在跨集群管理域同步 Unknown：无法确定受监视资源条目的状态 Monitored Resources Local Status   在Display Monitored Resource Details显示Node中的Local Status项显示本地节点上资源的状态详细说明如下： Current：此节点上的受监视资源没有挂起的更新 Delete fail：集群中的某个节点上的资源已被删除，管理员需要完成该过程 Delete pending：已在集群中的某个节点上删除了受监视的资源，但该过程尚未在所有节点完全完成 Move fail：资源已在集群中的某个节点上移动，管理员需要完成该过程 Move pending：受监控的资源已在集群中的某个节点上移动，但所有节点的进程尚未完全完成 Rename fail：资源已在集群中的某个节点上重命名，管理员需要完成该过程 Rename pending：受监控的资源已在集群中的某个节点上重命名，但所有节点的进程尚未完全完成 Restore fail：资源已在集群中的某个节点上恢复，管理员需要完成该过程 Restore pending：受监控的资源已在集群中的某个节点上恢复，所有节点的进程尚未完全完成 Update fail：此节点上的资源更新失败 Update pending：此节点上的受监视资源有挂起的更新 Unknown：无法确定受监视资源条目的状态 iASP数据复制 从集群系统到独立分区   Attach IASP操作(通常称为ASP assigner process)是从连接到独立分区的IASP中定位磁盘单元，并更新分区以将IASP接受到配置中. 然后可以改变IASP，允许程序访问IASP中的数据。附加IASP操作强制执行以下限制： 分区必须在单一系统环境中。这意味着分区不能是设备域中的节点 该分区不能有任何IASP，这些独立的辅助存储池是在执行附加IASP操作时配置的 除非是磁盘池组，否则不能将多个IASP附加到分区。磁盘池组是单个主磁盘池以及与主磁盘池关联的所有辅助磁盘池 将独立辅助存储池(IASP)从集群节点复制到非集群节点的步骤： 接收IASP副本的独立分区正常运行，且当前没有将IASP副本的磁盘映射到此独立分区 通过外部存储操作，对IASP中的所有磁盘单元执行复制操作。例如FlashCopy、全局复制、克隆、快照等 在接收IASP副本的独立分区上，如果存在IASP，使用命令CFGDEVASP将其删除，示例：CFGDEVASP ASPDEV(IASPNAME) ACTION(*DELETE) 然后运行CFGDEVASP ASPDEV(*ALL) ACTION(*PREPARE)命令为连接包​​含IASP副本的磁盘单元准备系统配置。说明及注意事项： 此命令删除并清理当前配置的所有IASP 此时不应将存储LUN映射到接收IASP的目标独立分区 IPL独立复制目标系统完成准备工作 将复制的磁盘单元分配给独立复制目标系统（将卷从存储映射到主机） 从专用服务工具(DST) 或系统服务工具 (SST) 运行Attach IASP操作： 运行命令STRSST 选择选项3. Work with disk units 选择选项3. Work with disk unit recovery 选择选项8. Detect attached IASP disk units 进入Confirm attach IASP disk units屏幕，显示独立磁盘池和磁盘池中的单元，如果显示的磁盘池和单元正确，回车确认运行配置 运行高级分析命令MULTIPATHRESETTER(尝试过没成功，官网提到需要做)： STRSST进入SST 选择选项1. Start a service tool 选择选项4. Display/Alter/Dump 选择选项·. Display/Alter storage 选择选项2. Licensed Internal Code (LIC) data 选择选项14. Advanced analysis 进入Select Advanced Analysis Command屏幕，在Option第一行中输入1(Select)，然后在后面输入命令MULTIPATHRESETTER 回车确认，进入Specify Advanced Analysis Options屏幕，Option中-RESETMP -ALL，回车确认 阅读并按照屏幕上显示的说明确认应重置路径（这一步和官方描述有点不一样） Vary-on IASP。如果IASP设备描述不存在，先使用CRTDEVASP命令创建它 验证IASP中的数据，是否能够运行使用独立磁盘池中的数据的作业 官方参考链接：PowerHA: How to Copy an Independent Auxiliary Storage Pool From a Cluster Node to a Non-Cluster Node PowerHA数据复制技术   PowerHA提供了几种不同的数据复制技术。这些技术可以单独使用，有时也可以组合使用，以提供更高级别的中断保护： Geographic mirroring是一种IBM复制技术，可用于任何存储。数据在独立ASP的两个副本之间复制，同时支持同步和异步复制。Geographic mirroring可以防止服务器和存储中断 对于具有外部存储的客户，有多种技术可用： Switched logical units允许将数据的一个副本从一个系统切换到另一个系统，并防止服务器中断 Metro Mirror和 Global Mirror是用于外部存储的同步和异步复制技术，通过将数据从 IASP 的主副本复制到备份副本来防止服务器和存储中断。 HyperSwap是一种DS8000技术，可在存储中断的情况下提供近乎零的中断 FlashCopy是一种时间点复制机制，它可以与任何技术结合使用，用于备份和其他用途 官方参考链接：PowerHA data replication technologies Geographic mirroring   Geographic mirroring使用IBM i集群技术提供高可用性解决方案，其中存储在生产系统独立磁盘池中的一致数据副本在镜像副本上维护。Geographic mirroring通过使用内部或外部存储来维护独立磁盘池的一致备份副本： 如果生产站点发生中断，生产将切换到备份站点，其中包含数据的镜像副本，通常位于另一个位置： 在同步交付模式下，数据在生产系统上完成写入操作之前被镜像，通常用于在发生故障时不会遭受任何数据丢失的应用程序 在异步交付模式下，数据仍会在写入操作完成之前发送到镜像副本，但是，在镜像写入实际到达镜像副本之前，控制权会返回给应用程序 使用现有同步交付模式的一个很好的原因是，如果应用程序想要确保生产端所有已完成的写入都已到达镜像副本端 使用异步交付模式，应用程序响应时间不会像同步交付模式那样受到影响。大量延迟可能会导致异步交付模式所需的额外主存储和 CPU 资源 Geographic mirroring通过使用数据端口服务在独立磁盘池之间提供逻辑页面级镜像。数据端口服务管理多个 IP 地址的连接，从而在Geographic mirroring环境中提供冗余和更大的带宽 Geographic mirroring允许生产副本和镜像副本在Geographic上分开，这样可以在发生站点范围的中断时提供保护： 在规划Geographic mirroring解决方案时，生产和镜像独立磁盘池之间的距离可能会影响应用程序响应时间 生产副本和镜像副本之间的距离越远，可能会导致响应时间越长 在实施使用Geographic mirroring的高可用性解决方案之前，必须了解用户的距离要求以及对应用程序的相关性能影响 具有异步交付模式的Geographic mirroring仅适用于 PowerHA 2.0 及更高版本 官方参考链接： IBM i 7.3 Geographic mirroring Planning geographic mirroring Configuring geographic mirroring Managing geographic mirroring Scenario: Geographic mirroring Metro Mirror   Metro Mirror在两个IBM System Storage外部存储单元之间维护一致的数据副本，卷的目标副本不断更新以匹配对源卷所做的更改；Metro Mirror与集群技术一起使用时，可提供高可用性和灾难恢复解决方案。 与Geographic mirroring一样，也可以镜像存储在独立磁盘池中的数据，但是对于Metro Mirror，磁盘位于IBM System Storage的外部存储单元上 镜像从通常位于生产站点的源外部存储单元到通常位于备份站点的一组目标存储单元发生 数据在外部存储单元之间复制，为计划内和计划外中断提供可用性 它通常用于在发生故障时不会遭受任何数据丢失的应用程序 源卷和目标卷可以位于同一外部存储单元上，也可以位于单独的外部存储单元上 在独立单元的情况下，目标存储单元可以位于最远300公里（186 英里）以外的另一个站点但是，在此距离上使用同步通信时可能会对性能产生影响，考虑使用更短的同步通信以最大限度地减少性能影响可能更实际 官方参考链接： IBM i 7.3 Metro Mirror Planning Metro Mirror Configuring Metro Mirror Managing Metro Mirror Scenario: Metro Mirror PowerHA supported storage servers Global Mirror   Global Mirror在两个IBM System Storage外部存储单元之间维护一致的数据副本。Global Mirror在两个外部存储单元之间提供磁盘 I/O 子系统级别的镜像： 这种异步解决方案通过允许目标站点落后于源站点几秒钟，在无限距离上提供更好的性能，将数据中心分开更远的距离有助于防止区域中断 Global Mirror使用异步技术提供跨两个站点的远程远程复制。通过高速光纤通道通信链路运行，旨在以几乎无限的距离异步维护完整且一致的远程数据镜像，对应用程序响应时间几乎没有影响 使用Global Mirror，复制到备份站点的数据在几秒钟内就可以与生产站点保持同步 官方参考链接： IBM i 7.3 Global Mirror Planning Global Mirror Configuring Global Mirror Managing Global Mirror Scenario: Global Mirror Switched logical units   Switched logical units是一个独立的磁盘池。当交换逻辑单元与IBM i集群技术相结合时，可以为计划内和一些计划外中断创建简单且经济高效的高可用性解决方案： 设备集群资源组(CRG)控制独立磁盘池，可以在计划外中断的情况下自动切换，也可以通过切换手动切换 集群中的一组系统可以利用切换功能将对切换逻辑单元池的访问从一个系统转移到另一个系统 可切换逻辑单元必须位于通过存储区域网络连接的IBM System Storage中 当切换独立磁盘池时，IBM System Storage单元内的逻辑单元会从一个系统重新分配到另一个系统 官方参考链接： IBM i 7.3 Switched logical units Planning switched logical units (LUNs) Configuring switched logical units (LUNs) Managing switched logical units (LUNs) PowerHA supported storage servers FlashCopy   在使用IBM System Storage外部存储单元的IBM i 高可用性环境中，可以使用FlashCopy。FlashCopy为外部存储上的独立磁盘池提供几乎即时的时间点副本，这可以减少完成日常备份所需的时间： 时间点复制功能可让用户即时复制或查看原始数据在特定时间点的样子 目标副本完全独立于与源无关的磁盘池，并且在FlashCopy命令被处理后即可进行读写访问 配置示例 系统中查看FlashCopy描述示例： Display ASP Copy Description E980PRD 05/21/21 14:56:21 ASP copy description . . . . . . . . . : E980PRD Device description . . . . . . . . . . : CBSIASP Cluster resource group . . . . . . . . : *NONE Cluster resource group site . . . . . : *NONE Location . . . . . . . . . . . . . . . : E980PRD Sessions . . . . . . . . . . . . . . . : IASPFC1 IBM System Storage device . . . . . . : IBM.2107-75HBT61 User . . . . . . . . . . . . . . . . : qlpar Internet address . . . . . . . . . . : 10.22.168.66 Alternate internet address . . . . . : 10.22.168.67 对应的I/O资源查看示例： Display ASP I/O Resources E980PRD 05/21/21 14:56:32 LUN ranges Storage Consistency Identifier Range group range IBM.2107-75HAT61 1100-12A4 3100-32A4 1100-13A4 3100-33A4 官方参考链接： IBM i 7.3 FlashCopy Planning FlashCopy Configuring a FlashCopy session Managing the FlashCopy technology Scenario: Performing a FlashCopy function DS8000 Full System HyperSwap   在 IBM i 高可用性环境中，使用HyperSwap作为一种方法来帮助减少或消除由于存储和SAN相关的中断而导致的中断： Full System HyperSwap是一个单系统IBM i 存储硬件高可用性解决方案，它使用IBM Systems Storage DS8000 设备上的Metro Mirror来维护两个IBM Systems Storage外部存储单元之间的一致数据副本 Full System HyperSwap允许进行计划内或计划外的IBM Systems Storage外部存储设备切换，而无需使应用程序脱机以进行切换 Full System HyperSwap仅支持全系统 (SYSBAS) 复制，不支持独立磁盘池复制 Full System HyperSwap 具有与传统 Metro Mirror 跨站点镜像解决方案相同的距离限制 源卷和目标卷可以位于同一个外部存储单元上，也可以位于不同的外部存储单元上 在独立单元的情况下，目标存储单元可以位于最远300公里（186 英里）以外的另一个站点。但是，在此距离上使用同步通信时可能会对性能产生影响，考虑使用更短的同步通信以最大限度地减少性能影响可能更实际 使用Full System HyperSwap必须在系统上安装IBM PowerHA for i Express Edition 使用Full System HyperSwap不需要集群，也不使用集群技术 官方参考链接： DS8000 Full System HyperSwap Planning for DS8000 Full System HyperSwap Configuring DS8000 Full System HyperSwap Managing DS8000 Full System HyperSwap DS8000 HyperSwap with IASPs   在 IBM i高可用性环境中，使用HyperSwap作为一种方法来帮助减少或消除由于存储和SAN相关的中断而导致的中断。HyperSwap是一种存储高可用性解决方案，允许在两个IBM System Storage DS8000单元之间镜像的逻辑单元以接近零的中断时间进行切换： 当HyperSwap在IASP级别实施时，可以与其他PowerHA技术相结合，为计划内和计划外存储中断提供最短停机时间解决方案，并为服务器计划内和计划外中断提供最短停机时间解决方案 要使用HyperSwap，必须在系统上安装IBM PowerHA for i Enterprise Edition 要将DS8000 HyperSwap与IASP一起使用，需要一个集群并且确实使用了PowerHA技术 官方参考链接： DS8000 HyperSwap with independent auxiliary storage pools (IASPs) Planning DS8000 HyperSwap with independent auxiliary storage pools (IASPs) Configuring DS8000 HyperSwap with independent auxiliary storage pools (IASPs) Managing DS8000 HyperSwap with independent auxiliary storage pools (IASPs) 待补充 "},"05-IBM_Operating_System/02-AS400/18-AS400-Power虚拟化分区.html":{"url":"05-IBM_Operating_System/02-AS400/18-AS400-Power虚拟化分区.html","title":"AS400-Power虚拟化分区","keywords":"","body":"AS400-Power虚拟化分区 IBM i虚拟化主要有iHost和PowerVM。 PowerVM 主机相关链接： IBM Power9 Virtual I/O Server Partitioning with a IBM i IBM i 7.3 Virtual Partition Manager IBM i 7.3 Miscellaneous limits IBM i 客户机分区注意事项 在集成虚拟化管理器(IVM)受管服务器上的Virtual I/O Server(VIOS)中配置高级节点故障检测 存储相关链接： IBM FlashSystem 9x00 Environments for IBM i hosts IBM FlashSystem 9x00 Configuring the IBM i operating system FlashSystem 9x00 IBM Power Systems with Virtual I/O Server FlashSystem 9x00 Known IBM i issues and limitations FlashSystem 9x00 Attachment requirements for IBM i hosts DS8900 Configurations for IBM Power Systems hosts running IBM i 配置限制条件 主机上虚拟化相关限制条件 如下表(IBM i7.3)：限制条件|说明 :---|:--- VSCSI光驱的最大数量|16 VSCSI磁带设备的最大数量|4 VSCSI磁盘设备的最大数量|32 每个NPIV的最大活动存储卷路径数|7.3TR7或更高版本为127，其它64 虚拟媒体设备的最大大小|1000000MB 虚拟磁带资源的最大数量|35 最大虚拟光资源|35 存储上相关限制 最小磁盘资源限制： DS8000或使用VIOS作为服务器的虚拟磁盘：520字节扇区需要35GB SVC、Storwize、使用VIOS VSCSI或IBM i作为服务器的虚拟磁盘：40 GB（35GB可用空间） 本机连接的SAS/SCSI（520字节或4160字节扇区）：70 GB 最大磁盘资源限制： 512/520 block disk: 2TB减去1 block 4096 block disk: 2TB减去1 block 4196 block disk: 4TB减去1 block 待补充 "},"05-IBM_Operating_System/02-AS400/19-AS400-系统用户管理.html":{"url":"05-IBM_Operating_System/02-AS400/19-AS400-系统用户管理.html","title":"AS400-系统用户管理","keywords":"","body":"AS400-系统用户管理 相关官方参考链接：IBM i 7.3 User profiles 用户安全 用户相关系统值 用户密码相关系统值如下： 参数 默认值 描述 QPWDLMTCHR *NONE Limit characters in password QPWDLMTREP 0 Limit repeating characters in password QPWDLVL 0 Passwed level QPWDMAXLEN 8 Maximun password length QPWDMINLEN 6 Minimun password length QPWDPOSDIF 0 Limit password character positions QPWDRQDDGT 0 Require digit in password QPWDRQDDIF 0 Duplicat password control QPWDRULES *PWDSYSVAL Password rules QPWDVLDGM *NONE Password validation program QPWRDWNLMT 900 Maximun time for PWRDWNSYS *IMMED QPWRRSTIPL 0 Automatic IPL after power restored "},"05-IBM_Operating_System/02-AS400/20-AS400-系统Security.html":{"url":"05-IBM_Operating_System/02-AS400/20-AS400-系统Security.html","title":"AS400-系统Security","keywords":"","body":"AS400-系统Security 官方参考链接：IBM i 7.3 Security Auditing security 官方参考链接：Auditing security on IBM i 使用Security Audit Journal 官方参考链接：Using the security audit journal CHGSECAUD设置安全审计   使用CHGSECAUD命令来激活系统安全审计(如果它不存在，将创建日志和日志接收器)、将QAUDCTL系统值设置为*AUDLVL并将QAUDLVL系统值设置为默认值。默认设置包括*AUTFAIL、*CREATE、*DELETE、*SECURITY 和 *SAVRST： CHGSECAUD QAUDCTL(*AUDLVL) QAUDLVL(*DFTSET) 设置安全审计 要设置安全审计步骤如下(需要*AUDIT特殊权限)： 使用命令CRTJRNRCV在选择的库(示例使用JRNLIB)中创建日志接收器： CRTJRNRCV JRNRCV(JRNLIB/AUDRCV0001) THRESHOLD(100000) AUT(*EXCLUDE) TEXT('Auditing Journal Receiver') 将日志接收器放在定期保存的库中。不要放在库QSYS中，即使它是日志所在的位置 选择可用于后续方便命名的名称，例如AUDRCV0001。当更改日志接收器以继续命名时，可使用*GEN选项。择让系统管理更改用户的日志接收器时，使用这种类型的命名约定非常有帮助 指定适合用户的系统大小和活动的接收器阈值。选择的大小应基于系统上的事务数和用户选择审核的操作数。如果使用系统change-journal management支持，日志接收器阈值必须至少为100000KB。更多信息可以参考Journal management 在AUT参数上指定*EXCLUDE以限制对存储在日志中的信息的访问 使用CRTJRN命令创建QSYS/QAUDJRN日志： CRTJRN JRN(QSYS/QAUDJRN) + JRNRCV(JRNLIB/AUDRCV0001) + MNGRCV(*SYSTEM) DLTRCV(*NO) + AUT(*EXCLUDE) TEXT('Auditing Journal') JRN必须使用名称QSYS/QAUDJRN，JRNRCV指定在上一步中创建的日志接收器的名称 在AUT参数上指定*EXCLUDE以限制对存储在日志中的信息的访问。必须有权将对象添加到QSYS 使用MNGRCV(Manage receiver)参数让系统更改日志接收器并在附加的接收器超过创建日志接收器时指定的阈值时附加一个新接收器。如果选择此选项，则无需使用CHGJRN命令来分离接收器并手动创建和附加新接收器 指定DLTRCV(*NO)(默认值）表示不要让系统删除分离的接收器。QAUDJRN接收器是用户的安全审计跟踪，在从系统中删除它们之前，确保它们被充分保存 使用WRKSYSVAL命令设置QAUDLVL(audit level)系统值或QAUDLVL2(audit level extension)系统值。此两个值确定将哪些操作记录到系统上所有用户的审计日志中 如有必要，使用CHGUSRAUD命令为单个用户设置操作审计，或为特定用户设置对象审计 如有必要，使用CHGOBJAUD、CHGAUD和CHGDLOAUD命令为特定对象设置对象审计 设置QAUDENDACN系统值以控制系统无法访问审计日志时发生的情况 设置QAUDFRCLVL系统值以控制审计记录写入辅助存储的频率。参考防止丢失审计信息：Preventing loss of auditing information 通过将QAUDCTL系统值设置为*NONE以外的值来开始审计： QSYS/QAUDJRN日志必须存在，然后才能将QAUDCTL系统值更改为*NONE以外的值 当开始审计时，系统会尝试将记录写入审计日志。如果尝试不成功，会收到一条消息并且审核不会启动 管理审计日志和日志接收器   审计日志QSYS/QAUDJRN仅用于安全审计。不应将对象记录到审计日志中，例如使用SNDJRNE(Send Journal Entry)命令或QJOSJRNE(Send Journal Entry)API将用户条目发送到此日志。系统使用特殊的锁定保护来确保它可以将审计条目写入审计日志： 当审计处于活动状态时（QAUDCTL系统值不是*NONE），系统仲裁器作业QSYSARB会锁定QSYS/QAUDJRN日志 当审计处于活动状态时，不能对审计日志执行某些操作，例如：DLTJRN和WRKJRN命令，移动日志，恢复日志 审计日志中的所有安全条目都有一个日志代码T 除了安全条目之外，系统条目也出现在日志QAUDJRN中。这些是日志代码为J的条目，它们与初始程序加载 IPL和在日志接收器上执行的一般操作（例如，保存接收器）有关 如果日志或其当前接收器发生损坏，从而无法记录审计条目，则QAUDENDACN系统值将确定系统采取的操作 系统管理日志接收器的相关详细说明: 创建QAUDJRN日志时指定MNGRCV(*SYSTEM)，或修改为该值，系统会在达到阈值大小时自动分离接收器并创建及附加新的日志接收器，此功能叫做system change-journal management QAUDJRN中指定MNGRCV(*USER)，那么当日志接收器达到存储阈值时，消息将发送到为日志指定的消息队列。需使用CHGJRN命令分离接收器并附加一个新的日志接收器 日志的默认消息队列是QSYSOPR。也可以将不同的消息队列（例如 AUDMSG）: 可以使用消息处理程序来监视AUDMSG消息队列。当收到日志阈值警告CPF7099)时，可以自动附加新的接收器 如果您使用system change-journal management，那么当系统更改日志完成时，消息CPF7020将发送到日志消息队列，可以监视此消息，以便知道何时保存分离的日志接收器 使用Operational Assistant菜单时提供的自动清理功能不会清理QAUDJRN接收器。为避免磁盘空间问题，请定期分离、保存和删除QAUDJRN接收器 如果QAUDJRN日志不存在并且QAUDCTL系统值设置为非*NONE，则在IPL期间进行创建。这仅发生在异常情况之后，例如更换磁盘设备或清除辅助存储池 保存和删除审计日志接收器 附加一个新的审计日志接收器，保存并删除旧接收器： CHGJRN QSYS/QAUDJRN JRNRCV(*GEN) SAVOBJ (保存旧接收器) DLTJRNRCV (删除旧的接收器) 建议选择系统不忙的时间，并且应定期分离当前的审计日志接收器并附加一个新的接收器，原因： 如果每个日志接收器都包含特定、可管理时间段的条目，则分析日志条目会更容易 大型日志接收器会影响系统性能并占用辅助存储池上的宝贵空间 系统管理的日志接收器   如果系统管理接收器，保存所有分离的QAUDJRN接收器并删除它们的步骤(使用日志消息队列和CPF7020消息的监视下述过程，CPF7020消息指示系统更改日志已成功完成)： 输入WRKJRNA QAUDJRN，显示当前连接的接收器，不要保存或删除此接收器 按F15到work with the receiver directory，显示与日志相关联的所有接收器及其相应的状态 使用SAVOBJ命令保存每个接收器，不要保存当前attached的接收器 使用DLTJRNRCV命令删除每个已经保存了的接收器 用户管理的日志接收器 如果选择手动管理日志接收器，分离、保存和删除日志接收器过程： 输入CHGJRN JRN(QAUDJRN) JRNRCV(*GEN)命令，命令作业： 分离当前连接的接收器 使用下一个序列号创建一个新的接收器 将新的接收器附加到日志 使用WRKJRNA命令显示当前连接了哪个接收器：WRKJRNA QAUDJRN 使用SAVOBJ命令保存分离的日志接收器，指定对象类型*JRRNCV 使用DLTJRNRCV命令删除接收器。如果删除没有保存的接收器，将收到一条警告消息 Object Authority Object Authority for User   在对象属性中有用户对对象的权限。可以为用户分配几个不同的系统定义的对象权限级别，这些级别有如下几种： *ALL：允许对对象的所有操作，但仅限于所有者或受授权列表管理权限控制的操作除外 *CHANGE：允许对对象的所有操作，但仅限于所有者或受对象存在权限、对象更改权限、对象引用权限和对象管理权限控制的操作 *EXCLUDE：禁止对对象的所有操作 *USE：允许访问对象属性和使用对象，但用户不能更改对象 USER DEF：当特定对象权限和数据权限与上述任何预定义的对象权限级别不匹配时由系统显示。可以使用display detail功能键(F11)查看具体权限 在定义公共权限时*AUTL值也有效。表示该对象使用的授权列表中的公共权限规范 具体的对象权限有： Opr：对象操作权限提供查看对象属性和使用由用户对对象具有的数据权限指定的对象的权限 Mgt：对象管理权限提供指定安全性、移动或重命名对象以及在对象是数据库文件时添加成员的权限 Exist：对象存在权限提供控制对象存在和所有权的权限 Alter：对象更改权限提供更改对象属性的权限，例如添加或删除触发器以及为数据库文件添加成员 Ref：对象引用权限提供将对象指定为引用约束中的第一级的权限 具体的数据权限有： Read：读取权限提供访问对象内容的权限 Add：添加权限提供向对象添加条目的权限 Update：更新权限提供更改对象中现有条目内容的权限 Delete：删除权限提供从对象中删除条目的权限 Execute：执行权限提供运行程序或搜索库或目录的权限 待补充 "},"05-IBM_Operating_System/02-AS400/21-AS400-系统Services.html":{"url":"05-IBM_Operating_System/02-AS400/21-AS400-系统Services.html","title":"AS400-系统Services","keywords":"","body":"AS400-系统Services 官方文档链接：IBM i 7.5 IBM i Services Performance Services 返回收集服务配置属性： SELECT * FROM QSYS2.COLLECTION_SERVICES_INFO   COLLECTION_SERVICES_INFO视图返回收集服务的配置属性。视图中的列返回的值与CFGPFRCOL(Configure Perf Collection)命令和QypsRtvColSrvAttributes(Retrieve Collection Services Attributes)API返回的值密切相关。调用者必须对QSYS/QYPSCOLL服务程序有*USE权限或通过QPMCCFCN授权列表获得授权。 待补充 "},"05-IBM_Operating_System/02-AS400/22-AS400-系统值.html":{"url":"05-IBM_Operating_System/02-AS400/22-AS400-系统值.html","title":"AS400-系统值","keywords":"","body":"AS400-系统值 官方参考链接： IBM i 7.5 System values IBM i 7.5 System value categories IBM i 7.5 System value finder 系统值分类 Auditing 关于审计值说明如下： 要查看审计系统值，必须具有所有对象*ALLOBJ或审计*AUDIT特殊权限。如果没有所需的权限，则系统值的审核类别不可用 在IBM Navigator for i中，不显示审计类别 在基于字符的界面中，审核系统值显示不可用*NOTAVL值，但QAUDFRCLVL显示-1除外 需要审核*AUDIT权限才能更改审核系统值 字符界面名称 导航器中名称 描述 QAUDCTL,QAUDLVL,QAUDLVL2 Activate action auditing 设置操作审计并为特定功能指定审计级别 QAUDCTL(*NOQTEMP) Do not audit objects in QTEMP 当激活对象级或用户级审计时，使用此系统值排除QTEMP库中的对象 QAUDCTL(*OBJAUD) Activate object auditing 每次用户访问被审计的对象时，使用此系统值让系统将记录写入审计日志 QAUDENDACN Audit journal error action 指定当由于发送日记帐分录时发生错误而无法将审计记录发送到审计日记帐时系统要采取的操作 QAUDFRCLVL Maximum journal entries before writing to auxiliary storage 设置在日记帐分录数据移动到辅助存储之前写入审计日记帐的日记帐分录数 QCRTOBJAUD Default auditing for newly created objects 设置将对象创建到库中时使用的默认对象审计值 Date and time 日期和时间系统值如下表所示： 字符界面名称 导航器中名称 描述 QDATETIME,QCENTURY,QDAYOFWEEK,QDATE,QDAY,QMONTH,QYEAR System date 此系统值设置系统的日期 QDATETIME,QTIME,QHOUR,QMINUTE,QSECOND Time of day 此系统值指定一天中的时间 QLEAPADJ Leap-year adjustment 此系统值指定闰年调整 QTIMADJ Time adjustment 此系统值标识用于时间维护的应用程序 QTIMZON Time zone 此系统值指定系统的时区 QUTCOFFSET Offset from Coordinated Universal Time(UTC) 表示协调世界时(UTC)与当前系统时间之间的小时和分钟差异 Jobs 作业相关系统之如下表所示： 字符界面名称 导航器中名称 描述 QACTJOB,QTOTJOB Allocate storage at restart 指定重新启动时用于活动作业和总作业的存储空间 QADLACTJ,QADLTOTJ Allocate additional storage as needed 指定为活动作业和总作业分配的额外存储空间 QALWJOBITP Allow jobs to be interrupted to run user-defined exit programs 指定系统如何响应用户发起的中断作业以在该作业中运行用户定义的出口程序的请求 QDSCJOBITV Time-out interval for disconnected jobs 此系统值指定断开作业的超时间隔 QENDJOBLMT Maximum time for immediate end 指定作业立即结束期间应用程序清理的最长时间 QINACTITV Time-out interval for inactive jobs 指定非活动作业的超时间隔 QINACTMSGQ When a job reaches time-out 指定当非活动作业超时时要采取的操作 QJOBMSGQFL When maximum size is reached 指定达到最大作业日志大小时要执行的操作 QJOBMSGQMX Maximum job log size 指定最大作业日志大小 QJOBSPLA Initial printer output block size 控制SCB(spooling control block)的初始大小 QLOGOUTPUT Produce printer output for job log 指定作业完成时如何生成作业日志 QMAXJOB Maximum jobs 指定最大作业数 QMAXSPLF Maximum printer output files 指定作业允许的最大打印机输出文件数 QMLTTHDACN When a function in a multithreaded job is not threadsafe 指定当函数不是线程安全时要执行的操作 QSPLFACN Detach printer output after jobs have ended 此系统值指定Spooled文件是与作业一起保留还是与作业分离 待补充 "},"05-IBM_Operating_System/02-AS400/23-AS400-监控系统活动.html":{"url":"05-IBM_Operating_System/02-AS400/23-AS400-监控系统活动.html","title":"AS400-监控系统活动","keywords":"","body":"AS400-监控系统活动 官方参考链接： IBM i 7.5 Monitoring system activity IBM i 7.5 Viewing overall system status WRKSYSSTS命令 检查内存池使用情况 使用IBM Navigator for i检查内存使用情况步骤： 展开Work Management>Memory Pools 右键单击要使用的内存池（例如Interactive），然后单击Properties 单击Configuration选项卡。 位于Size组中的Current字段显示池当前拥有的内存量 Temporary Addresses   每次创建临时对象时，都会使用唯一的临时地址，系统具有非常大但数量有限的可用地址，临时地址的百分比表示使用的这些地址的百分比。  许多系统通常使用的临时地址比例很低。但可能会发生临时地址的快速使用，这通常表明应用程序以异常高的速率创建临时对象，大量本地数据库文件打开： 使用堆空间的程序可以为同一线程中的每16MB堆使用一个地址 每个线程或激活组使用一个新地址 查询可以使用临时地址进行连接和排序的内部处理 一些API调用可以创建临时空间，该空间将使用一个或多个临时地址 减少使用的临时地址数量的最佳做法是更改正在使用它们的应用程序： 也许可以重写应用程序，让一个作业或一组作业处理多个请求，而不是为每个请求启动一个新作业 应用程序可以通过清除和加载新数据而不是删除和创建新数据来重新使用相同的临时空间 查找导致临时地址快速增长的原因方法： 使用WRKSYSACT命令，按F11直到显示分配的存储空间，然后使用F19自动刷新并观察分配存储的作业，按分配的存储量排序可能会提示导致问题的作业或应用程序 或者打开对象审计并在审计日志接收器中查询已创建的对象。这还可以帮助识别导致创建所有临时对象的作业或应用程序 官方参考链接： IBM i Temporary Addresses Database file opens consuming temporary addresses 待补充 "},"05-IBM_Operating_System/02-AS400/24-AS400-HA_Tools_IASP_Manager.html":{"url":"05-IBM_Operating_System/02-AS400/24-AS400-HA_Tools_IASP_Manager.html","title":"AS400-HA_Tools_IASP_Manager","keywords":"","body":"PowerHA Tools for IBM i - IASP Manager   PowerHA Tools IASP Manager是IBM Lab Services编写的高可用性产品。它专为使用IBM存储和/或将PowerHA与独立辅助存储池(IASP)解决方案结合使用的IBM i客户而设计。官方参考链接：PowerHA Tools for IBM i - IASP Manager。 常用命令 常用命令如下： 命令|描述 :---|:--- CHKFLASH|Check FlashCopy CHKPPRC|Check PPRC CHGPPRC|Change PPRC DSPCSEDTA|Display Copy Services Environment exit data ENDFLASH|End a FlashCopy Backup STRFLASH|Start a FlashCopy Backup SWPPRC|Switch PPRC WRKCSE|Work with Copy Services Environments Multi-Target Copy简介   Multi-Target Copy需要DS8000和IBM Copy Services Manager (CSM)。支持使用多达四个站点的多目标解决方案，包括： Metro Mirror - Metro Mirror(MM/MM)：来自同一生产（源）节点的两个Metro Mirror目标 Metro Mirror - Global Mirror(MM/GM)：来自同一生产（源）节点的一个Metro Mirror目标和一个Global Mirror目标 Metro Mirror - Global Mirror + GCP(MM/GM)：来自同一源的一个Metro Mirror目标，一个Global Mirror目标 ，加一个从Global Mirror节点级联的Global Copy目标 PowerHA Tools IASP Manager为Multi-Target环境提供完全自动化，包括： 检查环境是否准备好切换 在切换期间关闭生产中的IASP Metro Mirror或Global Mirror环境的计划内或计划外切换的自动化 切换到拥有生产副本的新节点后将IASP进行Vary on Flash Copy CHKFLASH命令   CHKFLASH(Check FlashCopy)命令检查CSE CRG、节点和硬件资源的状态，以确定可以启动 FlashCopy(STRFLASH)。在CHKFLASH期间发现的所有错误都记录在qzrdhasm.log文件中，该文件位于运行命令分区上的/qibm/qzrdhasm目录中。 STRFLASH命令   执行必要的步骤，将当前生产分区IASP快速复制到FlashCopy(备份)分区IASP，并使FlashCopy(备份)分区 IASP可用： 此命令可以在cluster/recovery中的任何节点上运行，以执行使指定IASP的第二个副本可用所需的步骤 副本将从指定的源节点获取，该源节点也可能参与Metro Mirror或Global Mirror关系，无论复制方向如何 对于冷FlashCopy，生产分区IASP将自动关闭，FlashCopy数据将是生产数据的精确副本 对于热FlashCopy，生产分区IASP保持开启，因此FlashCopy可能会丢失一些尚未刷新到生产分区磁盘的数据 STRFLASH命令属性描述： Environment name：要使用的FLASH CSE环境的名称 Flash Target Node Name：FlashCopy目标节点的名称，*LOCAL或FC node Vary on after flash：是否在FlashCopy node上Vary on，*YES或*NO Quiesce Action：*ENV或下面一种： *QUIESCE：将内存刷新到磁盘并在闪存期间暂时挂起PPRC *FRCWRT：将内存刷新到磁盘，但不在闪存期间暂停PPRC *NONE：在启动闪存之前不要将内存刷新到磁盘 Cluster Resource Group： *ENV CRG name：如果与环境名称不同 Preflashed： *NO *YES：如果FlashCopy已经完成 Connect hosts：*ENV或下面一种： *CURRENT：假设当前连接正确 *REQUIRED：需要修改主机连接。如果未分配卷组，请继续并在适当时运行添加脚本。如果已分配卷组，请验证它们是否适用于此环境。如果没有，终止STRFLASH *ATTEMPT：与*REQUIRED相同，但如果分配了不正确的卷组，则不要Vary on IASP *NO：对主机连接不执行任何操作，但仍将环境标记为*FLASHED Wait for completion：*ENV, *YES或*NO。由于IASP的Vary on现在是异步完成的，因此必须等待Vary on完成才能开始保存 Completion timeout：1-600,*ENV。在向QSYSOPR发送失败消息之前等待改变完成的分钟数 Vary on Source：*YES或*NO。用于生产节点上的IASP Exit program and library： *ENV ：IASP为AVAILABLE时要提交的程序名称 FlashCopy过程 FlashCopy处理过程如下： 对集群、设备域、与DS的连接等进行基本检查 激活FlashCopy节点上的退出程序以执行其他检查： IASP是否varied off 是否正确安装了DSCLI 发现主机连接 确认Metro Mirror还是Golbal Mirror的源或目标。如果是，检查FlashCopy继续进行的情况下复制是否会处于正确状态 如果在命令或环境中请求，STRFLASH程序会向生产节点发出quiesce/frcwrt/vary off STRFLASH程序向FlashCopy节点提交作业以执行以下任务： 将Flash状态设置为20以允许在不同节点上运行的STRFLASH命令知道Flash作业已成功提交。如果作业在60秒内未启动，则STRFLASH命令将出错 根据IBM i的级别执行mkflash脚本或启动ASP会话 将Flash状态设置为90以允许在不同节点上运行的STRFLASH命令在需要时继续处理生产系统的恢复并成功结束，如果等待完成是*NO 如果需要，将IASP进行Vary on(包括相关资源的释放、重置和多路径重置) 将Flash状态设置为100(*FLASHED)，如果等待完成为*YES，则允许STRFLASH成功结束 当FlashCopy状态变为90时，STRFLASH程序继续： 如果生产节点被停顿或varied off，则提交退出程序以恢复或vary on. 如果Wait for completion设置为*YES，则STRFLASH程序将保持活动状态，直到FlashCopy完成，并且状态更改为100 如果Wait for completion设置为*NO，则STRFLASH程序成功结束FlashCopy过程中注意事项 FlashCopy过程中注意事项如下： 如果使用所有默认值，则有效进程将与ACS 2.1 FlashCopy进程(wait for completion = *YES并且connect hosts=*CURRENT)相同 该进程的日志现在分布在最多三个系统中，问题确定需要查看所有相关系统的日志 FlashCopy程序与FlashCopy进程分开运行。应对其进行监控以确保其正常运行 成功的STRFLASH命令并不意味着IASP已成功连接并varied on。必须在FlashCopy过程结束时检查 IASP状态 ENDFLASH命令 命令ENDFLASH说明： 执行从分区中删除所有FlashCopy IASP所需的步骤，并使它们为将来任何 IASP环境的FlashCopy操作做好准备 ENDFLASH命令不会结束ACS 3.0或IASP Manager 4.0中的多个FlashCopie。只有在集群中只配置了一个 FlashCopy环境时，才能使用默认值*ONLY end flash执行的步骤是： 属性*YES强制Vary off所有FlashCopy IASPs 如果不使用增量FlashCopy，移除DS8000上的flash 修改CSEDTA以指示没有Flash Active：如果使用增量，表示准备好进行下一次闪存 注意事项： FlashCopy Status字段必须为*FLASHED才能使用此命令 Metro Mirror Metro Mirror概述   Metro Mirror是一个复杂的灾难恢复环境，包括两组独立的卷：Preferred source volumes和preferred target volumes： 生成节点上的数据副本在HA/DR节点上保持同步 生产节点在继续之前等待来自HA/DR节点的更新确认 性能考虑要求两组卷彼此非常接近，以便最小化等待 Metro Mirror切换 CHKPPRC命令 格式如下： CHKPPRC ENV() TYPE(*) CHKPPRC命令在绿屏底部显示状态消息以显示进度，此命令完成的步骤： 状态信息：获取集群信息 检查CSE CRG中指示的PPRC状态 识别当前的HA/DR节点 识别当前的Production(生产)节点 状态信息：检查集群节点 检查集群节点是否处于活动状态 检查所有节点是否都在设备域中 状态消息：检查HA/DR节点硬件分配 执行DSCLI中的lspprc脚本以确保PPRC处于Full Duplex状态 如果配置正确：CHKPPRC报告A PPRC check for IASP CRG completed successfully. 更多信息及注意事项参考CHKPPRC命令详细说明。 SWPPRC命令使用*SCHEDULED选项   Switch type使用SCHEDULED用于生产和HA/DR节点以及存储设备都在运行但它们的角色需要切换时使用。执行以下步骤： 向生产节点上的QSYSOPR发送*INQ消息：IAS0021 “Perform SWPPRC command for IASP device ? (G C)，回复G继续，C取消 在当前生产节点上使用*YES强制关闭IASP 使用DSCLI为IASP设备运行PPRC Failover任务 Release/ResetHA/DR分区上的IOP/IOA资源，并使磁盘正确注册为IASP 如果需要，在当前HA/DR节点（将成为生产的节点）上将IASP进行vary on。默认值为*YES SWPPRC命令使用*UNSCHEDULED选项   当生成节点发生故障，HA/DR节点需要承担生成角色时，Switch type使用*UNSCHEDULED： Unscheduled切换时，Auto replicate默认为*NO 当TYPE设置为*MMIR时，多个附加选项Switch paused MMIR： 默认值为*NO，如果CHKPRC发现PPRC已挂起，则*NO的默认值会阻止执行切换 *YES将允许继续进行，即使PPRC被暂停   此命令尝试完成为计划切换列出的所有步骤，但即使检测到以下错误，也会允许切换发生： Production node(生产节点)故障 生产存储设备故障(即failbackpprc任务无法运行)   如果交互式运行，第一步会显示Unscheduled PPRC Switch Warning面板；如果批量运行，*INQ消息IAS0727将发送到HA/DR节点上的QSYSOPR。   由于故障，计划外的切换很可能是不完整的切换。纠正故障后，必须运行 SWPPRC *COMPLETE命令以完成PPRC故障转移过程。 SWPPRC命令使用*COMPLETE选项 Switch type使用*COMPLETE用于当错误阻止所有正常切换任务完成时，在计划外切换之后使用。此命令应在当前HA/DR节点上运行，以完成PPRC故障转移过程。 Global Mirror Global Mirror概述 Global Mirror是一个复杂的灾难恢复环境，最多可以包含六组独立的卷： 生产节点上的数据副本异步复制到HA/DR节点；生产节点在继续之前不会等待来自HA/DR节点的更新确认 以配置的时间间隔，在源端存储服务器上创建一致性组(CG)。然后，源端存储服务器在确保该一致性组中的所有更改都已发送到目标存储系统后，在目标存储服务器上启动Flashcopy。然后可以在故障转移期间使用此Flashcopy将目标卷返回到上一个已知的良好一致性副本的状态 全局镜像可以设置为仅在单个方向或任一方向（对称）上运行 IASP Manager对六个卷集使用以下术语： Source volumes(A)：这些是Production node生产节点(Preferred Source首选源)上的应用程序通常使用的卷 Preferred Source CG Flash volumes(E)：当Global Mirror以相反的方向，即Preferred Target到Preferred Source(仅对称symmetrical only)运行时，Global Mirror全局镜像使用这些卷在存储服务器上存储一致性信息(CGs)，跟踪自上次形成一致性组以来对Preferred Source卷所做的更改 Target volumes(B)：这些卷通常在HA/DR节点(Preferred Target)上使用，以维护来自生产节点的数据副本。由于PPRC在全局镜像中异步运行，因此数据更新滞后于源卷的内容 Preferred Target CG Flash volumes(C)：当Global Mirror以正常方向(Preferred Source到Preferred Target)运行时，Global Mirror使用这些卷来存储一致性信息(CGs)。目标存储服务器使用这些卷来跟踪自上次形成一致性组以来对Preferred Target卷所做的更改 Global Mirror target FlashCopy (DCcopy) volumes(D和F)：这些卷用于在当前作为Global Mirror目标的存储服务器上制作可用数据的副本。此副本可以更改以用于测试或保存目的 Global Mirror环境 Global Mirror基础环境(non-symmetrical) 卷集：A、B和C。说明： 此环境在正常方向运行时提供灾难/恢复保护，通过使用C卷来保持一致副本，但在切换时，它无法在相反方向创建一致副本 如果在手动切换回客户首选的生产节点之前被迫切换，客户通常会在B卷上运行尽可能短的时间 Global Mirror对称环境(symmetrical) 卷集：A,B,C和E。说明： 对称环境允许Global Mirror在正常或反向方向上一致地运行 此环境与大多数HA实现类似，只是在发生故障转移时，总会有一些数据不属于一致映像，此数据不可检索。但是，计划的切换具有零数据丢失。 Practice Failover–(Global Mirror目标FlashCopy(DCopy)) 卷集：D和F(可以添加到任何GM环境)，说明： Practice Failover是暂停Global Mirror，目标卷保持一致(pprc故障转移和快速恢复)，并为一组卷创建新的 Flashcopy的过程，而不是用Global Mirror一致性的卷，然后重新启动Global Mirror 此过程创建可用于测试或保存的卷 使用Global Mirror进行切换和故障转移的限制   Global Mirror可以选择在正常操作期间将某些Flashcopy卷用于多种用途。但可能会造成在释放卷以供全局镜像使用之前可能无法完成switchover/failover(切换/故障转移)的情况。 进行Practice Failover(Target-side flash)时阻止switchover或failover 说明如下： 在正常方向进行Practice Failover(Target-side flash)时，B卷建立了多个FlashCopy关系。为了最大限度地减少这些多重关系处于活动状态的时间，IASP Manager仅支持将DCopy(D)作为完整的磁盘副本 计划外切换过程的一部分是执行从C卷到B卷的快速恢复。如果存在现有的B卷与D卷的关系，这将失败，因为这将是不受支持的cascading(级联)FlashCopy 如果D卷存在于配置中，IASP Manager将始终对它们执行检查，如果DCopy(D)未完成，则在切换时检查失败。这时候可以等待DCopy完成，也可以使用WRKCSE运行rmflash_GM_Dcopy_PT.script，然后再次运行SWPPRC命令 Practice Failover时使用多增量FlashCopy   IASP Manager现在支持任何闪存环境的Multiple incremental(多增量)FlashCopy，包括全局镜像的D-Copy。通过应用以下规则增强了对此的支持： 如果Multiple incremental标志打开，则DS故障的SWPPRC将首先列出D-Copy环境 如果D-Copy的不同步扇区为零，即后台增量复制已完成，则flash将自动移除，并且计划外的切换将继续。 注意： 删除FlashCopy关系不会影响磁盘上的数据，FlashCopy节点上的备份可以继续 在返回正常完成后，仍应运行end flash 如果D-Copy仍有未完成的扇区要复制，则SWPPRC将失败。客户可以选择手动移除Flash并重试，或等待后台复制完成 生产节点上使用的Flash Volumes阻止对称切换或故障切换   在symmetrical(对称)环境中运行时，通常使用生产节点CG FlashCopy卷(C或E卷)进行日常备份到磁带。但是，用于保存的FlashCopy的参数和功能与全局镜像的FlashCopy不同。因此，如果请求对称switchover/failover，IASP Manager将确保preferred source的CG FlashCopy卷没有FlashCopy处于活动状态。如果FlashCopy处于活动状态，则CHKPPRC切换将失败，并且必须等到他们使用完卷或在其HA/DR节点上运行ENDFLASH命令以删除FlashCopy关系。然后再次运行SWPPRC命令。 切换Global Mirror CHKPPRC命令   CHKPPRC命令检查CSE CRG、节点和硬件资源的状态，以确定是否可以成功执行SWPPRC(Switch PPRC)命令进行切换： 此命令不对Global Mirror复制采取任何纠正措施，它只是检查事物的状态 在CHKPPRC期间发现的所有错误都记录在qzrdhasm.log文件中，该文件位于/qibm/qzrdhasm目录中 命令示例： CHKPPRC ENV() TYPE(*) CHKPPRC命令在绿屏底部显示状态消息以显示进度，此命令完成的步骤： 状态信息：获取集群信息 检查CSE CRG中指示的PPRC状态 识别当前的HA/DR节点 识别当前的Production(生产)节点 状态信息：检查集群节点 检查集群节点是否处于活动状态 检查所有节点是否都在设备域中 状态消息：检查HA/DR节点硬件分配 执行DSCLI中的lspprc脚本以确保PPRC处于Copy Pending状态 如果配置正确：CHKPPRC报告A PPRC check for IASP CRG completed successfully. 更多信息及注意事项参考SWPPRC命令详细说明。 SWPPRC命令使用*SCHEDULED选项   Switch type使用SCHEDULED用于生产和HA/DR节点以及存储设备都在运行但它们的角色需要切换时使用。执行以下步骤： 向生产节点上的QSYSOPR发送*INQ消息：IAS0021 “Perform SWPPRC command for IASP device ? (G C)，回复G继续，C取消 在当前生产节点上使用*YES强制关闭IASP 使用DSCLI为IASP设备运行PPRC Failover任务 Release/ResetHA/DR分区上的IOP/IOA资源，并使磁盘正确注册为IASP 如果需要，在当前HA/DR节点（将成为生产的节点）上将IASP进行vary on。默认值为*YES SWPPRC命令使用*UNSCHEDULED选项   当只有HA/DR节点及其存储设备可操作时，Switch type使用*UNSCHEDULED。由于当前生产节点不可用，因此无法完成*SCHEDULD切换期间执行的某些步骤。执行以下步骤： 如果以交互方式运行，则在HA/DR节点上显示Unscheduled PPRC Switch Warning 如果批量方式运行，将*INQ消息IAS0727发送到HA/DR节点上的QSYSOPR： IAS0727：\"An Unscheduled SWPPRC command was issued for IASP device ? (G C)\"，回复G继续，C取消 使用DSCLI为IASP设备运行PPRC Failover任务 Release/ResetHA/DR分区上的IOP/IOA资源，并使磁盘正确注册为IASP 如果需要，在当前HA/DR节点（将成为生产节点）上将IASP进行vary on。默认值为*YES GMIR复制关系属性 GMIR重要属性选项D-Copy Flash：D-Copy Flash normal和D-Copy Flash reversed： 指定同名的单独FlashCopy环境可用于此首选目标或此首选源节点的目标节点 当GMIR方向为正常或反向时，两个此类FlashCopy环境允许D-Copy Flash在当前目标上运行 Multi-target解决方案   IASP Manager不再支持Metro-Global Mirror，取而代之的是multi-target支持。需要使用单独的许可程序Copy Services Manager(CSM)。multi-target解决方案支持来自生产节点的两个目标： 对于 MMIR： H1->H2PPRC对被命名为MMIR H1->H3PPRC对被命名为 MMIR2 H2->H3PPRC对被命名为MMIR3 对于GMIR： H1->H2PPRC对也称为MMIR H1->H3 PPRC对称为GMIR H2->H3 PPRC对称为GMIR2 Metro Mirror-Metro Mirror概述   三个节点中的任何一个都可以作为两个高速镜像关系的源。两个Metro Mirror目标之间还创建了隐式关系，这称为Multi Target Incremental Resync(MTIR)关系。关系表如下： 源 活动目标 PPRC方向 *MTIR对 H1 H2, H3 Both Normal H2->H3(MMIR3) H2 H1, H3 H2->H1(MMIR)Reversed;H2->H3(MMIR3)Normal H1->H3(MMIR2) H3 H1, H2 H3->H1(MMIR2)Reversed;H3->H2(MMIR3)Reversed H1->H2(MMIR) SWPPRC(Switch PPRC)命令可以在任何活动目标上运行。 Metro Mirror-Global Mirror概述   Metro Mirror-Global Mirror结合了Metro Mirror的同步可用性和Global Mirror的远距离可用性。需要三个系统或分区：Metro Mirror Source, Metro Mirror Target和Global Mirror Target。关系如下表： 源 活动目标/PPRC方向 未激活PPRC对/状态 H1 H2(MMIR)/Normal;H3(GMIR)/Normal H2->H3(GMIR2 *MTIR) H2 H1(MMIR)/Reversed;H3(GMIR2)/Normal H1->H2(GMIR *MTIR) H3(GMIR Reversed) H1 H3->H2(GMIR2 INELIGIBLE);H1->H2(MMIR GCP *NORMAL) H3(GMIR2 Reversed) H2 H3->H1(GMIR *INELIGIBLE) H2->H1(MMIR GCP REVERSED) 说明及注意事项： 同样SWPPRC(Switch PPRC)命令可以在任何活动目标上运行 当H3是源（GMIR或GMIR2 *REVERSED）时，MMIR PPRC对正在执行全局复制 *GCP功能。扇区更改正在发送到MMIR目标，但没有一致性。这意味着此节点无法切换到作为Global Copy目标 Metro Mirror-Global Mirror(MG)其他注意事项 注意事项： CHKPPRC应针对以下两种环境执行：MMIR和GMIR Metro Mirror-Global Mirror中的GMIR部分允许命令SWPPRC中使用SCHEDULED和*UNSCHEDULED 如果GMIR(或GMIR2)是对称的，则支持SWPPRC返回正常方向。否则，需要手动执行步骤 从对称环境的故障转移中恢复   如果由于站点丢失或生产DS丢失而在对称环境中发生故障转移，则在DS恢复运行后，应使用 SWPPRC *complete重新启动复制。 在GMIR切换到反向后将非对称MG恢复到生产   如果MM/GM环境中的GMIR对被切换并且没有为反向配置的一致性组卷，则切换回GMIR源的唯一方法是执行计划切换。不允许计划外的切换，因为目标上的数据将不一致。 常用命令 CHGPPRC命令 命令示例： Change PPRC (CHGPPRC) Type choices, press Enter. Environment name . . . . . . . . Name Type . . . . . . . . . . . . . . *GMIR, *GMIR2, *MMIR... Option . . . . . . . . . . . . . *DETACH, *REATTACH... Auto Vary On . . . . . . . . . . *YES *YES, *NO 命令选项说明： Environment name：指定要更改的环境的名称。也指Independent ASP CRG名称 Type：Copy Service环境的类型。 此可选参数可用于指定要更改的PPRC环境的类型： *GMIR ：具有此环境名称的PPRC Global Mirroring环境将被更改 *GMIR2：作为多目标复制的一部分，具有此环境名称的PPRC Global Mirroring环境将被更改 *MMIR：具有此环境名称的PPRC Metro Mirroring环境将被更改 *MMIR2：作为多目标复制的一部分，具有此环境名称的PPRC Metro Mirroring环境将被更改 *MMIR3：作为多目标复制的一部分，具有此环境名称的PPRC Metro Mirroring环境将被更改 *ALL：该选项将在环境中活动复制对上执行。此值仅对OPTION(*SUSPEND)或 OPTION(*RESUME)有效 Option：要执行的更改类型： *SUSPEND：暂停复制。 仅当两个节点之间的复制由CSM(TPC)服务器管理时，此选项才有效 *RESUME：暂停的复制将恢复。 仅当两个节点之间的复制由CSM(TPC)服务器管理时，此选项才有效 *DETACH：复制将暂停，备份节点将获得对LUN的read/write访问权限。仅当复制由CSM (TPC) 服务器管理时，此选项才对MMIR复制有效 *REATTACH：对磁盘的Read/write访问将被重置，复制将再次开始。仅当复制由CSM (TPC) 服务器管理时，此选项才对MMIR复制有效 Vary：此可选参数可用于控制在DETACH操作成功完成后是否要将*ASP设备描述改为varied on： *YES ：*ASP设备将varied on *NO：*ASP设备将不会varied on SWPPRC命令 SWPPRC(Switch PPRC)命令用于切换PPRC。 命令示例 例如计划性切换*GMIR，运行SWPPRC命令执行切换，按F4选择参数： Environment name：指定要切换的环境的名称。此名称也指Independent ASP CRG名称 Switch type选项为*SCHEDULED Type选项为*GMIR Auto Vary on选项默认为*YES Auto replicate选项默认为*DFT Switch paused MMIR选项默认为*NO 命令选项说明 PPRC生产系统是否可用？Switch type可能的值有： *SCHEDULED：Independent ASP切换是计划中的。生产系统可用 *UNSCHEDULED：Independent ASP切换是非计划性的。生产系统不可用 *COMPLETE：当先前的生产系统（当前使用备份系统）不可用时，此IASP切换用于从不完整的非计划切换中恢复。此选项仅在当前备份系统上运行有效，即不是运行SWPPRC *UNSCHEDULED的节点，而是另一个节点   Type表示IBM i Copy Services环境的类型。此可选参数可用于指定要切换的PRC环境的类型。具体选项说明如下： *：默认选项。具体类型(GMIR、GMIR2、LUN、MMIR、MMIR2或MMIR3)将由命令处理程序解析。如果环境只有一种类型，则允许使用*，当有两个或更多时，必须指定 *GMIR：将切换具有此环境名称的PPRC全局镜像环境。此环境可以是单个镜像环境，也可以是具有GMIR2和MMIR环境的多目标复制配置的一部分 *GMIR2：将切换具有此环境名称的多目标PPRC全局镜像环境。此环境必须是具有GMIR和MMIR环境的多目标复制配置的一部分 *LUN：将切换具有此环境名称的LUN级别连接切换环境 *MMIR：将切换具有此环境名称的PPRC Metro Mirroring环境： 此环境可以是单个镜像环境，也可以是多目标复制配置的一部分 如果它用于多目标复制，则必须同时存在GMIR和GMIR2环境，或者同时存在MMIR2和MMIR3环境 *MMIR2：将切换具有此环境名称的多目标PPRC Metro Mirroring环境。此环境必须是具有MMIR和 MMIR3环境的多目标复制环境的一部分 *MMIR3：将切换具有此环境名称的多目标PPRC Metro Mirroring环境。此环境必须是具有MMIR和 MMIR2环境的多目标复制环境的一部分   Auto Vary On此可选参数提供了在PPRC切换完成后使IASP在备份节点上脱机的方法。可选的值： *YES：将自动为备份节点上的此IASP发出VRYCFG *ON命令 *NO：IASP配置不会varied on   Auto replicate此可选参数提供了一种方法来覆盖在使用CHGCSEDTA命令时为某些类型和切换配置的自动复制设置。可选的值有： *DFT：使用特定切换类型的默认设置： 对于计划的切换，使用CHGCSEDTA命令配置的设置 对于计划外切换，此默认值为*NO *YES：使用TPC-R的MMIR切换和GMIR切换将自动复制 *NO：使用TPC-R的MMIR切换和GMIR切换将不会自动复制 Switch paused MMIR参数说明   该可选参数提供了一种在PPRC暂停后切换MMIR的方法。仅适用于计划外切换。可以设置参数说明如下： *NO：PPRC按预期运行以完成切换 *YES：PPRC可能会暂停以完成切换 补充说明 补充说明： 如果使用双CSM服务器，如果CHKPPRC和SWPPRC无法与主服务器通信，它们将自动执行对备份CSM服务器的接管 TPC和TPC-R被Spectrum Control或独立的IBM Copy Services Manager(CSM)取代 CHKPPRC命令 命令格式： CHKPPRC ENV() TYPE(*) 命令示例及说明 例如检查*GMIR，输入CHKPPRC命令，按F4在参选选项中选择需求参数： Environment name：指定要切换的环境的名称。此名称也指Independent ASP CRG名称 Type选择*GMIR 运行完成后确认返回结果chkpprc complete successfully   还有两个附加选项是跟Message相关的。Environment name和Type选项的内容说明同SWPPRC命令，参考SWPPRC命令说明即可。 命令注意事项 命令注意事项： 如果环境只有一种类型，则允许使用TYPE(*)，当有两个或更多时，必须指定 如果使用双CSM服务器，如果CHKPPRC和SWPPRC无法与主服务器通信，它们将自动执行对备份CSM服务器的接管 如果执行了CSM服务器接管，并且发现旧的主CSM服务器处于活动状态，CHKPPRC和SWPPRC将自动以HA模式重新启动CSM，但旧的主服务器现在将成为备份服务器 如果CHKPPRC要在生产节点和HA/DR节点上运行，它们不能同时运行，因为当两者都尝试同时访问集群资源时会发生冲突 对于CSM环境，如果CSM服务器丢失，CHKPPRC会发出转义消息IAS00AE： 这是一条警告消息，表明配置可运行，但需要采取措施才能实现完全冗余 监视CHKPPRC功能时，CL程序应区分IAS0070(failed)和IAS00AE 待补充 "},"05-IBM_Operating_System/02-AS400/25-AS400-文档查看及编辑.html":{"url":"05-IBM_Operating_System/02-AS400/25-AS400-文档查看及编辑.html","title":"AS400-文档查看及编辑","keywords":"","body":"AS400-文档查看及编辑 文档查看 DSPF命令 命令官方链接：IBM i 7.5 Display File (DSPF) 显示流文件 示例显示根目录下mydir目录中的文件myfile.txt： DSPF STMF('/mydir/myfile.txt') 显示数据库文件成员 示例显示库MYLIB中文件MYFILE的成员MYMBR1： DSPF FILE(MYLIB/MYFILE) MBR(MYMBR1) 对显示文档操作 DSPF命令相关说明： DSPF命令为顶部、底部、查找/更改和打印功能提供了快捷方式 DSPF命令是自由格式命令 命令参数要么是必需的，要么是位置的，要么是可选的，可以按任何顺序输入 命令不区分大小写，但参数区分大小写 有些命令有缩写：例如，可以输入F或Find、T或TOP、B或BOT 可以输入以下DSPF命令： F或FIND字符串： 要查找字符串，在Control行上输入F string，然后按Enter 字符串可以用空格、引号或双引号分隔 T或TOP： 转到文件顶部，在Control行上输入T，然后按Enter B或BOT: 转到文件底部，在Control行上输入B，然后按Enter PRINT： 打印将从当前行开始打印文件并打印文件的其余部分 SEU编辑器 SEU全称Source Entry Utility，相关参考链接： IBM i 7.3 Using the Source Entry Utility (SEU) IBM i 7.3 Starting SEU AS400-SEU-1 待补充 "},"05-IBM_Operating_System/02-AS400/26-AS400-Auxiliary_Storage_Pool.html":{"url":"05-IBM_Operating_System/02-AS400/26-AS400-Auxiliary_Storage_Pool.html","title":"AS400-Auxiliary_Storage_Pool","keywords":"","body":"AS400 Auxiliary_Storage_Pool   AS400磁盘管理内容中也有涉及此方面的，需要学习和了解的知识也比较多，磁盘池单独列出来。磁盘池在基于字符的界面中也称为Auxiliary Storage Pool(ASP)，是系统上一组磁盘单元的软件定义。相关官方参考链接： IBM i 7.5 Disk pools Managing auxiliary storage pools Adding disk units to an existing auxiliary storage pool Deleting an auxiliary storage pool Working with ASP trace and ASP balance Attach Independent Disk pool IASP IASP vary on 官方参考链接： Display ASP Status(DSPASPSTS) IASP: Example Output Providing Steps From Vary On and Vary Off of IASP IBM Support iASP Vary-On Time Variables Jobs Using IASP and Impact during Vary On/Off -IBM Support EDTRBDAP for IASP During Vary On IBM Support IASP Varyon Time IASP vary on步骤 IASP vary on涉及的步骤： 0 Cluster vary job submission 1 Waiting for devices - none are present 2 Waiting for devices - not all are present 3 DASD checker 4 Storage management recovery 5 Synchronization of mirrored data 6 Synchronization of mirrored data - 2 7 Scanning DASD pages 8 Directory recovery - permanent directory 9 Authority recovery 10 Context rebuild 11 Journal recovery 12 Database recovery 13 Journal synchronization 14 Commit recovery 15 Database initialization 16 Database recovery 17 Commit initialization 18 User profile creation 19 UID/GID mismatch correction 20 Library validation (context rebuild) 21 Database, journal, commit - 1 22 Identifying interrupted DDL operations 23 Recovering system managed journals 24 POSIX directory recovery 25 Database, journal, commit - 2 26 Commit recovery - 2 27 Cleaning up journal receivers 28 Transfer from danglers 29 Database access path recovery 30 Database cross-reference file merge 31 SPOOL intialization 32 Image catalog synchronization 33 Command analyzer recovery 34 Catalog validation 35 End IASP vary on时间 影响IASP Vary On时间的变量： 处理器 内存 数据库条目数 iASP 的大小 iASP中的对象总数 损坏的权限列表扩展的 删除损坏的权限列表扩展 删除损坏的用户配置文件扩展 创建用户配置文件或转移dangling/orphaned对象的所有权 对 IPL 步骤进行了任何更改或升级后的首次vary on iASP IASP Vary On时间上数据库相关影响官方说明： Vary on ASP组所需的时间受SYSBAS中数据库对象数量的影响 每个ASP组代表一个单独的数据库实例，每个都包含自己的一组交叉引用和目录文件 由于ASP组数据库还包括SYSBAS中的文件，因此Vary on将来自 SYSBAS中的cross-reference和目录文件的信息合并到ASP组的cross-reference和目录文件中(varyon作业日志中的消息CPI32A1-Starting XREF merge) SYSBAS中的文件中包含的记录越多，执行Vary on处理的数据库合并功能所需的时间就越长 要尽可能实现最快的联机时间，可以限制SYSBAS中存在的文件 IASP的推荐使用结构是将用户的应用程序数据对象的大部分放入IASP中，而将最少数量的非程序对象放在SYSBAS中，即system disk pool和所有已配置的basic disk pools。system disk pool和basic user disk pools(SYSBAS)主要包含操作系统对象、许可程序产品库和很少的用户库 待补充 "},"05-IBM_Operating_System/02-AS400/31-AS400-i_Access.html":{"url":"05-IBM_Operating_System/02-AS400/31-AS400-i_Access.html","title":"AS400-i_Access","keywords":"","body":"AS400-i_Access 安装iAccess Linux系统 [root@VM-0-6-centos tmp]# rpm -i ibm-iaccess-1.1.0.15-1.0.x86_64.rpm error: Failed dependencies: /usr/bin/odbcinst is needed by ibm-iaccess-1.1.0.15-1.0.x86_64 libodbcinst.so.2()(64bit) is needed by ibm-iaccess-1.1.0.15-1.0.x86_64 [root@VM-0-6-centos tmp]# yum search unixODBC.x86_64 [root@VM-0-6-centos tmp]# yum install unixODBC.x86_64 以上是草稿，具体安装回头再试。 System i导航器软件 WEB Navigator for i WEB界面导航器卡   有时候使用WEB登录Navigator for i时候很卡，在登录界面那里卡住进不去，可以重启下HTTP服务相关JOB或子系统，对应子系统是QHTTPSVR，首先停止相关作业或子系统(直接停子系统可能会影响其它相关HTTP服务)，然后启动： STRTCPSVR SERVER(*HTTP) HTTPSVR(*ADMIN) 然后再次登录： http://:2001/ 官方参考链接：Configuring an Integrated Web Application Server IBM个人通信   IBM Personal communication软件可以在官方下载，IBM i Access中也有集成Personal communication，完全一样，二选一即可。 常用功能键 功能键 描述 F1 对命令参数或参数值进行帮助 F4 列出参数的所有有效值 F5 刷新屏幕，清除所有的参数值 F10 列出命令的所有参数 F11 激活/取消 参数的关键字显示 F12 退出 待补充 "},"05-IBM_Operating_System/02-AS400/32-AS400-学习笔记.html":{"url":"05-IBM_Operating_System/02-AS400/32-AS400-学习笔记.html","title":"AS400-学习笔记","keywords":"","body":"AS/400-学习笔记   个人在听课学习中记录的要点，仅方便自己随手翻阅巩固知识点。 Storage NAS存储只支持作为服务端，不支持作为客户端 磁盘和内存作为一个整体存储池，内存作为存储池的缓存 PowerHA 环境有Independent disk pools （IASP) 写一次要进行两次读写操作，所有需要cache来提高性能 换完电池后有可能电池需要充电，充电过程中cache会被disable，此时读写会变慢，如果跑批会影响性能 数据写入量根据百分比来写，大盘会写入的比较多，大盘比较少小盘比较多情况下，大盘读写比较多，可能导致性能瓶颈 DS8000 常用raid5、raid6和raid10，推荐raid6 DS8000 一个array对于一个rank（CKD或FB） hot spare hot spare可以用在raid保护，也可以用于mirror保护 hot spare的model是051 hot spare不能在mirroring过程中启动 hot spare可以在mirror前面或者后面启动 raid中的盘可以分给不同的ASP 同样大小的磁盘才可以用hot spare去顶替 supended是坏盘，并且已经开始了替换 SAS concepts and update 57CE SAS adapter 端口从下往上T0-T3 如果一个5887有两个raid，一个给Primary Storage IOA管理，一个给Secondary DBCS for IBM i DBCS:Double Byte Character Set 同一个字符在不同计算机中可能有多种编码方式，通过编码转换方式可以让不同计算机通过编码识别同一个字符 CCSID:Coded Character Set ID 安装系统时候，选择Promary language，根据Promary language 安装Secondary language， Secondary language是把一些菜单等内容转换成设置的语言 如果系统设置成中文，就不需要安装Promary language 国内一般装机默认Promary language是DBCS的English：2984 不同编码集下字符需要进行转换，通过Conversion Table Work Management-subsystem$POOL "},"05-IBM_Operating_System/02-AS400/33-AS400-MIMIX_iCluster.html":{"url":"05-IBM_Operating_System/02-AS400/33-AS400-MIMIX_iCluster.html","title":"AS400-MIMIX_iCluster","keywords":"","body":"AS400-MIMIX_iCluster iCluster 常用命令 Nodes 命令 描述 DMADDNODE Add a cluster node DMCHGNODE Change a cluster node DMRMVNODE Remove a cluster node DMDSPNODE Display a cluster node DMWRKNODE Display the Work With Nodes screen Groups 命令 描述 DMADDGRP Add a group DMCHGGRP Change a group DMRMVGRP Remove a group DMADDBACK Add a node to a recovery domain DMRMVBACK Remove a node from a recovery domain DMDSPGRP Display a group DMWRKGRP Display the Work With Groups screen Cluster operations 命令 描述 DMSTRNODE Start cluster operations at a node DMENDNODE End cluster operations at a node DMREJOIN Start cluster operations at this node DMSTRGRP Start cluster operations for a group DMENDGRP End cluster operations for a group DMSTRSWO Start switchover for a group DMCHGROLE Change a group's primary node Status and history monitor 命令 描述 WRKHASMON Work with the iCluster primary status monitor WRKHATMON Work with the iCluster backup status monitor DSPHASMON Display the iCluster primary status monitor CHGHASMON Change the iCluster primary history monitor PRGHASMON Purge the iCluster primary monitor history WRKCSMON Work with the full cluster status monitor Journal management and analysis 命令 描述 DMWRKJRN Work with journals for iCluster CHGHAJRN iCluster change journal receiver DLTHAJRCV Delete journal receivers ENDHADJRCV End journal management job DMDSPJNMNG Display journal management details DMRMVJNMNG Remove journal management entry DMSTRJNMNG Restart journal management jobs DMANZJRN Analyze journals MIMIX "},"05-IBM_Operating_System/02-AS400/40-AS400-常见系统问题.html":{"url":"05-IBM_Operating_System/02-AS400/40-AS400-常见系统问题.html","title":"AS400-常见系统问题","keywords":"","body":"AS400-常见系统问题 CPU相关 JOB中QDBFSTCCOL占用CPU高 QDBFSTCCOL说明：Performance system values: Allow background database statistics collection解决方法官方说明：MF55781 - LIC QDBFSTCCOL JOB USING HIGH CPU ITM监控相关 QTONVLIC   系统中报错时间可能跟客户监控收到的报错里面写的时间不一致，检查时候需要往前翻找相关message信息。报错Message： CPI93B2:Software problem data for QTONVLIC has been detected CPI93B0:Software problem data for QTONVLIC has been logged. Refer to help text for additional information Message里面重要信息： CPI93B2消息中提示dump在QAUTOMON/CT_AGENT作业的soppled文件中 SYMPTOM STRING：5770 F/QTONVLIC FCK MSGMCH6906 检查Tivoli的事件： CNB7007:Failure for a reprot for situation XXXXXX CNB7006:Stopping situation XXXXXX   其中，第一条时间点跟系统中message报相关事件一致，第二条的时间点跟Tivoli监控报告系统报错事件时间一致。Tivoli里面Message消息官方详细描述链接如下： Distribution queue situation or report fails with CNB7007 error message IV90312: DISTRIBUTION QUEUE SITUATION OR REPORT FAILS WITH CNB7007 ERROR 解决建议： 联系Tivoli监控供应商，排查具体原因，确认是否需要升级打补丁 定期重启Tivoli的Agent。此操作将重置Spool Files的计数 增加Tivoli监控情境间隔。这将延长接收CNB7007 错误消息的时间 增加 QMAXSPLF 系统值。这将延长接收CNB7007 错误消息的时间，更改此系统值将应用于系统上的所有作业 此问题相关参考链接： IBM Support SE42502 - OSP MSGMCH6906 SI66063 - F/QTONVLIC-MSGMCH6902 MSGMCH6902 AND MSGMCH6904 F/QTONVLIC G SE42236 - OSP-OTHER-INCORROUT MSGMCH6906, MSGC2M1212, MSGCPD3E3F LOGGED IN NETSERVER JOBLOG AND NETSERVER BECOMES UNUSABLE. Approach for C2M1212 Messages Questions Diagnosing and Debugging Memory Problems: C2M1211 and C2M1212 Messages SE20438: DPROPR-DPRCAP CAPTURE ENDS WITH MCH6906 AND C2M1212 SI17722 - OSP-MSGMCH6902-PAR BCI JOB ISSUES ERROR MCH6902 AND C2M1212 IBM Support C2M1212 Messages IBM i 7.2 C2M1212 Message iASP相关 iASP failed 使用MustGather工具收集System Snapshot方法： 输入命令ADDLIBLE LIB(QMGTOOLS)，然后回车 输入命令QMGTOOLS/SYSSNAP OUTPUT(*IFS)，然后按F4，各选项设置建议： COLLECTDFT(Y) LICLOGS(Y) PALS(Y) QHST(Y) COLDEVD(Y) SRVDOCS(N) CSDATA(N) DAYSPRV(*DATE)：设置后可以设置STRDATE和ENDDATE选项，注意格式 收集完成后，会提示日志压缩文件zip（可能比较大）的路径，下载到本地即可 官方参考链接：MustGather: Data Collection for General iASP Vary on/off Problems Output Queue相关 JOB log不能写入输出队列 消息代码：CPF2528和CPF4218。示例： Message ID . . . . . . . . . : CPF2528 Message file . . . . . . . . : QCPFMSG Library . . . . . . . . . : QSYS Message . . . . : Job log not written to output queue because of CPF4218   此消息通常是由大量已结束的作业引起的，并且所有作业都试图同时将作业日志写入QEZJOBLOG，导致系统资源争用，因为每个作业都必须等待写出其作业日志。建议检查项目： 检查是否持续报错，是否还有其它消息；如果临时报，并且检查无异常，可以观察下 检查output queue QEZJOBLOG的文件数量 检查系统值QLOGOUTPUT的设置 运行命令GO CLEANUP检查清理设置是否启动，正常每七天清理一次 如果经常报，优化建议： 防止这种情况再次发生，可以将QLOGOUTPUT系统值更改为*JOBLOGSVR。更改后，各个作业将不负责写出自己的作业日志 如果将QLOGOUTPUT更改为*JOBLOGSVR不能清除争用，可以尝试*PND。更改后，作业将不会尝试写入作业日志 参考链接： Messages CPF2528 and CPF4218 for QEZJOBLOG Lock Contention on the QPJOBLOG Printer File or QEZJOBLOG Output Queue Message MCH5802 - Lock Operation for Object QSPUDTQ Not Satisfied MA45698 - OSP-WAIT HUNG JOBS IBM i 7.5 Jobs system values: Produce printer output for job log 更多信息可以参考AS400-Spooled文件管理中Spool Performance节的内容。 磁盘相关 热备盘问题 官方参考链接： IBM i 7.3 诊断热备用保护 Power Systems Solution-Troubleshooting hot-spare device parity protection 待补充 "},"05-IBM_Operating_System/02-AS400/41-AS400-高可用相关问题.html":{"url":"05-IBM_Operating_System/02-AS400/41-AS400-高可用相关问题.html","title":"AS400-高可用相关问题","keywords":"","body":"AS400-高可用相关问题 记录IBM i 中PowerHA及与此相关存储复制关系相关问题。 PowerHA Tools for IBM i-IASP Manager问题 密码过期问题 报错示例： CMUC00201E lsflash:: Authentication failure: Your password has expired。 官方参考连接：PowerHA Tools: CMUC00201E-Authentication Failure: Password Expired PowerHA相关问题 UID和GID问题 参考链接：PowerHA: UID and GID Mismatch and the Impact it has in a High Availability Environment 待补充 "},"05-IBM_Operating_System/03-AS400程序/":{"url":"05-IBM_Operating_System/03-AS400程序/","title":"AS400程序","keywords":"","body":"AS/400程序 简介 IBM i：创新平台-由创新者创造，为创新者享有。 内容 CLP-基础知识 "},"05-IBM_Operating_System/03-AS400程序/01-CLP-基础知识.html":{"url":"05-IBM_Operating_System/03-AS400程序/01-CLP-基础知识.html","title":"CLP-基础知识","keywords":"","body":"CLP-基础知识   CLP全称Control Language Programming，Control language(CL)允许系统程序员和系统管理员使用IBM i命令和其他IBM提供的命令编写程序。官方参考链接： IBM i 7.3 Control language IBM i 7.3 CL command finder-Alphabetic list IBM i 7.3 CL command finder IBM i 7.3 CL commands by product IBM i 7.3 CL concepts IBM i 7.3 CL programming 在CL程序中编写注释 在CL程序中的命令编写注释或添加注释使用字符对/*和*/，注释写在这些符号之间： 起始注释定界符/*需要三个字符，除非这些/*字符出现在命令字符串的前两个位置 在后一种情况下，/*可以在命令前不带空格的情况下使用 注意：注释中不能嵌入注释 可以通过以下任意一种方式输入三字符的起始注释分隔符（b 表示空白）： /*b b/* /** 可以以不同的方式输入起始注释分隔符。起始注释分隔符/*可以： 从命令字符串的第一个位置开始 前面有一个空格 后跟一个空格 后跟一个星号/** 官方示例如下： PGM /* ORD040C ORDER DEPT GENERAL MENU */ DCLF FILE(ORD040CD) START: SNDRCVF RCDFMT(MENU) SELECT WHEN (&RESP=1) THEN(CALL CUS210) /* CUSTOMER INQUIRY */ WHEN (&RESP=2) THEN(CALL ITM210) /* ITEM INQUIRY */ WHEN (&RESP=3) THEN(CALL CUS210) /* CUSTOMER NAME SEARCH */ WHEN (&RESP=4) THEN(CALL ORD215) /* ORDERS BY CUST */ WHEN (&RESP=5) THEN(CALL ORD220) /* EXISTING ORDER */ WHEN (&RESP=6) THEN(CALL ORD410C) /* ORDER ENTRY */ WHEN (&RESP=7) THEN(RETURN) ENDSELECT GOTO START ENDPGM 官方参考链接：Writing comments in CL programs or procedures 创建CL程序过程 所有程序都是分步骤创建的：源代码创建、模块创建和程序创建: Source creation：CL源语句由CL命令组成，源语句按应用程序设计确定的逻辑顺序输入到数据库文件或IFS流文件中 Module creation：使用CRTCLMOD(Create Control Language Module)命令，用于创建系统对象。创建的 CL模块可以绑定到程序中。一个CL模块包含一个CL程序。其他high-level language(HLL)语言可以为每个模块包含多个过程 Program creation：使用CRTPGM(Create Program)命令，该模块（连同其他模块和服务程序）用于创建程序 注意事项： 如果想创建一个只包含一个C 模块的程序，可以使用CRTBNDCL(Create Bound CL Program)命令，结合了上面第二和第三步 如果想从CL源语句创建一个original program model(OPM原始程序模型)CL程序，可以使用CRTCLPGM(Create CL Program)命令 交互式输入 IBM i操作系统提供了很多菜单和屏幕进行交互式输入： 包括编程器的菜单，命令输入显示屏，显示命令提示符和编程开发管理器（PDM）菜单。 经常使用的源输入方法是源输入实用程序 (SEU:source entry utility)，它是WebSphere Development Studio的一部分 还可以使用EDTF(Edit File)命令在数据库源文件中输入或更改CL命令。但是EDTF不提供内置于SEU的集成CL命令提示支持 批量输入   可以在一个批处理输入流中创建CL源、一个CL模块和一个程序。使用SBMDBJOB(Submit Data Base Jobs)命令将输入提交到作业队列。输入流应遵循以下格式： // BCHJOB CRTBNDCL PGM(QGPL/EDUPGM) SRCFILE(PERLIST) // DATA FILE(PERLIST) FILETYPE(*SRC) . . (CL Procedure Source) . // /* // ENDINP   示例从inline source创建程序。如果要将源代码保存在文件中，可以使用CPYF(Copy File) 命令将源代码复制到数据库文件中，然后可以使用数据库文件创建程序。   还可以使用设备文件直接从外部介质（例如磁带）上的CL源创建CL模块。IBM提供的磁带源文件是 QTAPSRC。例如，假设CL源语句位于名为PGMA的磁带上的源文件中。第一步是通过使用以下带有LABEL属性的覆盖命令来识别磁带上源的位置： OVRTAPF FILE(QTAPSRC) LABEL(PGMA)   现在可以将QTAPSRC文件视为CRTCLMOD(Create CL Module)命令的源文件。根据磁带文件的源输入创建CL 模块： CRTCLMOD MODULE(QGPL/PGMA) SRCFILE(QTAPSRC)   处理CRTCLMOD命令时，它会像对待任何数据库源文件一样对待QTAPSRC源文件。使用OVRTAPF，源位于磁带上，PGMA是在QGPL中创建的，并且该模块的源代码保留在磁带上。 CL源程序的组成   尽管作为CL源程序的一部分输入的每个源语句实际上都是一个CL命令，但源可以分为基本部分使用在许多典型的CL源代码程序中。 PGM command PGM PARM(&A)：可选的PGM命令启动源程序并标识收到的任何参数。 Declare commands 声明命令：DCL, DCLF, COPYRIGHT, DCLPRCOPT： 使用变量时程序或过程变量的强制性声明，以及子程序堆栈大小的可选定义 DCLPRCOPT还提供了覆盖在用于调用CL编译器的CL命令上指定的编译器处理选项的功能 声明命令必须在除PGM命令之外的所有其他命令之前 INCLUDE command CL命令在编译时嵌入额外的CL源命令。 CL processing commands CHGVAR, SNDPGMMSG, OVRDBF, DLTF(部分命令)：CL命令用于源语句操作常量或变量。 Logic control commands 逻辑控制命令用于控制CL程序或过程中的处理的命令：IF, THEN, ELSE, DO, ENDDO, DOWHILE, DOUNTIL, DOFOR, LEAVE, ITERATE, GOTO, SELECT, ENDSELECT, WHEN, OTHERWISE, CALLSUBR, SUBR, RTNSUBR, ENDSUBR Built-in functions 用于算术、字符串、关系或逻辑表达式的内置函数和运算符： %SUBSTRING (%SST), %SWITCH, %BINARY (%BIN), %ADDRESS (%ADDR), %OFFSET (%OFS), %CHECK, %CHECKR, %SCAN, %TRIM, %TRIML, %TRIMR, %CHAR, %DEC, %INT, %UINT (%UNS), %LEN, %SIZE, %LOWER, %UPPER, %PARMS Program control commands 用于将控制权传递给其他程序：CALL, RETURN, TFRCTL Procedure control commands 将控制权传递给另一个procedure：CALLPRC ENDPGM commands 可选的结束程序命令：ENDPGM   CL程序可以引用在创建程序、处理命令或两者时必须存在的其他对象。在某些情况下，为了让程序或过程成功运行，可能需要以下对象： A display file。如果程序使用display，则必须在创建模块之前使用CRTDSPF(Create Display File)命令输入和创建显示文件和记录格式。必须使用DCLF(Declare File)命令将其声明到声明部分中 A database file。CL procedure可以读取数据库文件中的记录。如果使用数据库文件，则必须在创建模块之前使用CRTPF(Create Physical File)命令或CRTLF(Create Logical File)命令创建该文件。可以使用数据描述规范(DDS)、结构化查询语言(SQL)或交互式数据定义实用程序(IDDU)来定义文件中记录的格式。还必须使用DCLF(Declare File)命令将文件声明到DCL部分中 Other programs。如果使用CALL命令，则在运行CALL命令之前，被调用的程序必须存在。在编译调用CL程序或 CL过程时它不必存在 Other procedures。如果使用CALLPRC命令，则在运行CRTBNDCL(Create Bound CL Program)或CRTPGM(Create Program)命令时，调用的procedures必须存在 简单的程序示例 创建源文件： CRTSRCPF FILE(SAVFLIB/SRCPF3) 添加member： ADDPFM FILE(SAVFLIB/SRCPF3) MBR(CLRLOGPHS) DSPPFM SAVFLIB/SRCPF3 使用PDM里面的Work with members编辑，或使用SEU编辑： STRSEU SRCFILE(SAVFLIB/SRCPF3) SRCMBR(CLRLOGPHS) 输入命令GO PROGRAM进入Programmer Menu： PROGRAM Programming Select one of the following: 1. Programmer menu 2. Programming Development Manager (PDM) 3. Utilities 4. Programming language debug 5. Structured Query Language (SQL) pre-compiler 6. Question and answer 8. Copy screen image 9. Cross System Product/Application Execution (CSP/AE) 50. System/36 programming 70. Related commands "},"05-IBM_Operating_System/03-AS400程序/02-CLP-常用命令.html":{"url":"05-IBM_Operating_System/03-AS400程序/02-CLP-常用命令.html","title":"CLP-常用命令","keywords":"","body":"CLP-常用命令 CL程序中常用命令或示例。 常用命令 官方命令查找链接： IBM i 命令 IBM i 7.3 CL command finder-Alphabetic list IBM i 7.3 CL command finder IBM i 7.3 CL commands by product IBM i 7.3 CL concepts 常规命令 命令 描述 CRTCLMOD Create Control Language Module CRTPGM Create Program CRTBNDCL Create Bound CL Program CRTCLPGM Create CL Program OVRTAPF Override with Tape File SBMDBJOB Submit Data Base Jobs 变量管理 命令 描述 CHGVAR Change Variable DCL Declare CL Variable 文件处理 命令 描述 CPYF Copy File CRTPF Create Physical File CRTLF Create Logical File CRTDSPF Create Display File DCLF Declare File EDTF Edit File 程序控制命令 命令 描述 CALL Call Program CALLPRC Call Bound Procedure CALLSUBR Call Subroutine DO Do Group DOFOR Do For DOUNTIL Do Until DOWHILE Do While ELSE Else (ELSE) GOTO Go To IF If (IF) ITERATE Iterate LEAVE Leave RETURN Return SELECT Select SUBR Subroutine TFRCTL Transfer Control 检索可用做变量的值 命令 描述 CVTDAT Convert Date RTVSYSVAL Retrieve System Value RTVCFGSRC Retrieve Configuration Source RTVCFGSTS) Retrieve Configuration Status "},"05-IBM_Operating_System/03-AS400程序/03-CLP-变量基本操作.html":{"url":"05-IBM_Operating_System/03-AS400程序/03-CLP-变量基本操作.html","title":"CLP-变量基本操作","keywords":"","body":"CLP-变量基本操作   变量是一个命名的可变值，可以通过引用其名称来访问或更改，变量不存储在库中，它们也不是对象。官方文档主页：IBM i 7.3 CL 命令中的变量 定义变量 所有变量必须先向CL程序或过程声明（定义），然后才能被程序或过程使用。 声明变量的方法 有两种声明变量的方法：Declare variable及Declare file： 声明变量：使用DCL(Declare CL Variable)命令完成的，包括定义变量的属性。这些属性包括类型、长度和初始值: DCL VAR(&AREA) TYPE(*CHAR) LEN(4) VALUE(BOOK) DCL VAR(&TMPDATE) TYPE(*CHAR) LEN(8) DCL VAR(&DATE) TYPE(*CHAR) LEN(6) 声明文件：如果CL程序或过程使用文件，则必须在DCLF(Declare File)命令的FILE参数中指定文件的名称。该文件包含文件中记录的描述（格式）和记录中的字段: DCLF FILE(MCGANN/GUIDE) 在编译期间，DCLF命令为文件中定义的字段和指标隐式声明CL变量。例如，如果文件的DDS中有一个记录，其中包含两个字段（F1和F2），则程序中会自动声明两个变量&F1和&F2 如果文件是在没有DDS的情况下创建的物理文件，则为整个记录声明一个变量。变量与文件同名，长度与文件的记录长度相同 声明命令必须在程序或过程中的所有其他命令之前（除了PGM命令），但它们可以以任何顺序混合。 使用声明CL变量命令的规则   DCL(Declare CL Variable)命令官方链接：IBM i 7.3 Declare CL Variable (DCL)。使用DCL命令时，必须使用以下规则： CL变量名称必须以与号&开头，后跟最多10个字符，并且第一个字符必须是字母，其余字符必须是字母数字。例如&TESTVAR CL变量值必须是以下之一： 长达5000个字符的字符串 一个压缩十进制值，总计最多15位，最多9个小数位 逻辑值0或1，其中0表示off、false或no, 1表示on、true或yes 两个、四个或八个字节的整数值:如果为TYPE参数指定了*INT，则该值可以是负数；如果为TYPE参数指定了 *UINT，则该值必须为正或零。仅当使用CRTCLMOD(Create CL Module)命令或CRTBNDCL(Create Bound CL Program)命令编译CL源时，才能指定LEN(8) 一个指针值，可以保存数据在存储中的位置 如果不指定初始值，则默认如下： 0表示十进制变量 空白的字符变量 0表示逻辑变量 0表示整数变量 指针变量为空 对于十进制和字符类型，如果指定了初始值，不指定LEN参数，则默认长度与初始值的长度相同 对于*CHAR类型，如果不指定LEN参数，则字符串可以长达5000个字符 对于*INT或*UINT类型，如果不指定LEN参数，则默认长度为4 在程序 DCL 语句中将参数声明为变量 基本变量用途   基于变量可用于映射传递给程序的变量或操作值数组。在使用之前，必须使用DCL命令上的ADDRESS关键字或使用%ADDRESS内置函数来设置基础指针。设置基础指针后，变量将像局部变量一样工作。示例： PGM DCL &AUTO *CHAR 20 DCL &PTR *PTR ADDRESS(&AUTO) DCL &BASED *CHAR 10 STG(*BASED) BASPTR(&PTR) : IF COND(%SST(&AUTO 1 10) *EQ &BASED) + THEN(CHGVAR %OFS(&PTR) (%OFS(&PTR) + 10)) : ENDPGM 示例说明： 示例中，基础指针&PTR被声明为等于&AUTO的地址。然后变量&BASED具有指针变量&PTR寻址的前10个字节的值 在条件语句中，将检查变量&BASED的值与变量&AUTO的前10个字节是否相等。如果值相同，意味着指针&PTR寻址&AUTO的第一个字节，则指针偏移量更改为变量&AUTO的地址字节11 现在变量&BASED的值等于变量&AUTO的11-20字节 使用定义的变量   定义的变量通过排除从大变量中提取值的需要，使管理控制语言 (CL) 中的复杂数据结构变得容易。已定义变量可用于以不同方式映射已定义变量的不同部分或给定变量的相同部分。官方示例如下： PGM DCL &OBJECT *CHAR 20 DCL &OBJNAME *CHAR 10 STG(*DEFINED) DEFVAR(&OBJECT) DCL &LIBNAME *CHAR 10 STG(*DEFINED) DEFVAR(&OBJECT 11) : IF COND(&LIBNAME *EQ '*LIBL ') + THEN(...)) : ENDPGM 示例说明： 变量&OBJNAME值取变量&OBJECT的前 10 个字节，变量&LIBNAME值取变量&OBJECT的后10个字节 使用定义的变量&OBJNAME和&LIBNAME提高了代码的可读性并使其更易于使用 变量&OBJECT为&LIBNAME和&OBJNAME变量提供存储   还可以使用多个定义创建相同的存储。下面示例中，变量&BINLEN和&CHARLEN都引用了相同的4字节变量 &STRUCT。然后程序可以使用最适合其要求的定义： PGM DCL &STRUCT *CHAR 30 DCL &BINLEN *INT 4 STG(*DEFINED) DEFVAR(&STRUCT) DCL &CHARLEN *CHAR 4 STG(*DEFINED) DEFVAR(&STRUCT) : ENDPGM   下面示例显示了如何使用定义的变量来更改变量中的值。示例中使用%OFFSET内置函数和基于变量来导航库列表。这不是进行消息替换的最佳方式，但说明了已定义变量的一些功能： PGM DCL &MESSAGE *CHAR 25 VALUE('LIBRARY NNN IS XXXXXXXXXX') DCL &SEQUENCE *CHAR 3 STG(*DEFINED) DEFVAR(&MESSAGE 9) DCL &MSGLIBN *CHAR 10 STG(*DEFINED) DEFVAR(&MESSAGE 16) DCL &COUNTER *INT 2 DCL &LIBL *CHAR 165 DCL &PTR *PTR ADDRESS(&LIBL) DCL &LIBLNAME *CHAR 10 STG(*BASED) BASPTR(&PTR) : RTVJOBA SYSLIBL(&LIBL) CHGVAR &COUNTER 0 DOFOR &COUNTER FROM(1) TO(15) IF (&LIBLNAME *EQ ' ') THEN(LEAVE) CHGVAR &SEQUENCE &COUNTER CHGVAR &MSGLIBN &LIBLNAME SNDPGMMSG MSGID(CPF9898) MSGF(QSYS/QCPFMSG) MSGDTA(&MESSAGE) CHGVAR %OFS(&PTR) (%OFS(&PTR) + 11) ENDDO : ENDPGM 示例说明： 变量&MESSAGE定义了长度为25字符的文本，程序将对其中数据进行替换，替换后进行输出 变量&SEQUENCE取变量&MESSAGE第9个字符开始后3位，即NNN 变量&MSGLIBN取变量&MESSAGE第16个字符开始后10位，即XXXXXXXXXX 变量&COUNTER为两位的数字整型 变量&LIBL定义长度为165的字符 命令RTVJOBA(Retrieve Job Attributes)中选项SYSLIBL为System library list 通过FOR循环语句进行遍历，过程中进行判断，根据判断结果修改变量&SEQUENCE和变量&MSGLIBN的取值 参考链接：Retrieve Job Attributes (RTVJOBA) 用于指定列表或限定名称的变量   变量可用于指定列表或限定名称。参数的值可以是一个列表。例如，CHGLIBL(Change Library List)命令需要LIBL参数上的库列表，每个库由空格分隔。此列表中的元素可以是变量，如果是变量，必须单独声明每个元素：示例： DCL VAR(&LIB1) TYPE(*CHAR) LEN(10) VALUE(QTEMP) DCL VAR(&LIB2) TYPE(*CHAR) LEN(10) VALUE(QGPL) DCL VAR(&LIB3) TYPE(*CHAR) LEN(10) VALUE(HQLIB) CHGLIBL LIBL(&LIB1 &LIB2 &LIB3) 变量元素不能在列表中指定为字符串。错误示例： DCL VAR(&LIBS) TYPE(*CHAR) LEN(20) + VALUE('QTEMP QGPL DISTLIB') CHGLIBL LIBL(&LIBS)   当呈现为单个字符串时，系统不会将列表视为单独元素的列表，并且会发生错误。如果每个限定符都声明为单独的变量，还可以使用变量来指定限定名。示例如下： DCL VAR(&PGM) TYPE(*CHAR) LEN(10) DCL VAR(&LIB) TYPE(*CHAR) LEN(10) CHGVAR VAR(&PGM) VALUE(MYPGM) CHGVAR VAR(&LIB) VALUE(MYLIB) ... DLTPGM PGM(&LIB/&PGM) ENDPGM   上面的示例中，程序名&PGM和库名&LIB的变量是分开声明的。程序名和库名不能在一个变量中指定，错误示例如下： DCL VAR(&PGM) TYPE(*CHAR) LEN(11) CHGVAR VAR(&PGM) VALUE('MYLIB/MYPGM') DLTPGM PGM(&PGM)   上面示例中，系统再次将值视为单个字符串，而不是两个对象（库和对象）。如果必须将限定名称作为具有字符串值的单个变量处理，则可以使用内置函数%SUBSTRING和*TCAT连接函数将对象和库名称分配给单独的变量。 变量中字符的大小写   CL变量中字符的大小写有限制。可用作变量的保留值（例如*LIBL）必须始终以大写字母表示，尤其是当它们以单引号括起来的字符串形式表示时。例如，想在命令中用变量替换库名，正确示例如下： DCL VAR(&LIB) TYPE(*CHAR) LEN(10) VALUE('*LIBL') DLTPGM &LIB/TESTPROG; 指定VALUE参数错误示例如下： DCL VAR(&LIB) TYPE(*CHAR) LEN(10) VALUE('*libl') 注意事项： 如果这个VALUE参数没有用单引号括起来，那么可以写成小写*libl，因为没有单引号它会自动转换为大写 错误示例中没有考虑到转换为大写可能是依赖于语言的事实。记住依赖系统将值转换为大写会产生意想不到的结果 替换保留或数字参数值的变量   字符变量可用于某些命令来表示命令参数的值。某些CL命令允许在某些参数上使用数字或预定义（保留）值。在这种情况下，可以使用字符变量来表示命令参数的值： 命令上的每个参数只能接受某些类型的值。该参数可以允许整数、字符串、保留值、指定类型的变量或这些的某种混合作为值 如果参数允许数值（如果该值在命令中定义为 *INT2、*INT4、*UINT2、*UINT4或 *DEC）并且还允许保留值（前面带有星号的字符串），则可以使用一个变量作为参数的值 如果打算使用保留值，则必须将变量声明为TYPE(*CHAR)   CHGOUTQ(Change Output Queue) 命令有一个作业分隔符 JOBSEP参数，该参数的值可以是数字（0到9）或预定义的默认值*SAME。因为数字和预定义的值都是可接受的，可以编写一个CL源程序，用字符变量代替 JOBSEP值。示例如下： PGM DCL &NRESP *CHAR LEN(6) DCL &SEP *CHAR LEN(4) DCL &FILNAM *CHAR LEN(10) DCL &FILLIB *CHAR LEN(10) DCLF..... ... LOOP: SNDRCVF..... IF (&SEP *EQ IGNR) GOTO END ELSE IF (&SEP *EQ NONE) CHGVAR &NRESP '0' ELSE IF (&SEP *EQ NORM) CHGVAR &NRESP '1' ELSE IF (&SEP *EQ SAME) CHGVAR &NRESP '*SAME' CHGOUTQ OUTQ(&FILLIB/&FILNAM) JOBSEP(&NRESP) GOTO LOOP END: RETURN ENDPGM 示例说明： 示例中，显示站用户在显示器上输入信息，描述指定输出队列所需的作业分隔符的数量 变量&NRESP是一个操作数字和预定义值的字符变量（注意使用单引号） CHGOUTQ(Change Output Queue) 命令上的JOBSEP参数将识别这些值，就好像它们已作为数字或预定义值输入一样 此程序中使用的显示文件的DDS应使用VALUES关键字将用户响应限制为IGNR、NONE、NORM或SAME 如果参数允许数值类型（*INT2、*INT4、*UINT2、*UINT4或 *DEC）并且不打算输入任何保留值（例如 *SAME），则可以使用小数或该参数中的整数变量 更改变量的值   使用CHGVAR(Change Variable)命令更改CL变量的值。可以更改为数。例如将变量&INVCMPLT设置为0(两种写法均可)： CHGVAR (&INVCMPLT) VALUE(100) CHGVAR &INVCMPLT 0 更改到另一个变量的值。例如&VARA设置为变量&VARB的值： CHGVAR VAR(&VARA) VALUE(&VARB) CHGVAR &VARA &VARB 对表达式求值。例如变量&COUNT值增加1： CHGVAR VAR(&COUNT) VALUE(&COUNT + 1) CHGVAR &COUNT (&COUNT + 1) 更改到内置函数%SST产生的值。例如&VARA设置为变量&VARB值的前六个字符： CHGVAR VAR(&VARA) VALUE(%SST(&VARB 1 6))   更改到内置函数%SWITCH产生的值。例如如果作业开关1和8为0，作业开关4、5和6为1，则&VARA设置为1；否则，&VARA设置为0。 CHGVAR VAR(&VARA) VALUE(%SWITCH(0XX111X0))   更改到内置函数%BIN产生的值。例如变量&VARB的前八个字符被转换为等效的十进制并存储在变量&VARA中，如下所示： CHGVAR VAR(&VARA) VALUE(%BIN(&VARB 1 8))   更改到内置函数%CHECK产生的值。下面示例中，检查变量&VARB中的值，并将最左边不是数字的字符的位置存储在变量 &VARA中，如果变量&VARB中的所有字符都是数字，则将零值存储在变量&VARA中： CHGVAR VAR(&VARA) VALUE(%CHECK('0123456789' &VARB))   更改到内置函数%CHECKR产生的值。下面示例中，检查变量&VARB中的值，并且将不是星号 *的最右边字符的位置存储在变量&VARA中。如果变量&VARB中的所有字符都是星号，则将零值存储在变量&VARA中。： CHGVAR VAR(&VARA) VALUE(%CHECKR('*' &VARB))   更改到内置函数%SCAN产生的值。下面示例中，扫描变量&VARB中的值，并将最左边的句点 .字符的位置存储在变量&VARA中。如果变量&VARB中没有句点字符，则将零值存储在变量&VARA中： CHGVAR VAR(&VARA) VALUE(%SCAN('.' &VARB))   更改到内置函数%TRIM产生的值。下面示例中，变量&VARB中的前导星号 *和空白字符将被剪掉，结果字符串将存储在变量&VARA中： CHGVAR VAR(&VARA) VALUE(%TRIM(&VARB '* '))   更改到内置函数%TRIML产生的值。下面示例中，变量&VARB中的前导空白字符将被剪掉，结果字符串将存储在变量&VARA中： CHGVAR VAR(&VARA) VALUE(%TRIML(&VARB))   更改到内置函数%TRIMR产生的值。下面示例中，变量&VARB中的尾随星号 (*) 字符将被剪掉，生成的字符串将存储在变量&VARA中： CHGVAR VAR(&VARA) VALUE(%TRIMR(&VARB '*'))   更改到内置函数%CHAR产生的值。下面示例中，变量&VARB将被转换为字符格式，生成的字符串将存储在变量&VARA中： CHGVAR VAR(&VARA) VALUE(%CHAR(&VARB))   更改到内置函数%UPPER产生的值。下面示例中，变量&VARB中的小写字母将被转换为大写字母，生成的字符串将存储在变量&VARA中： CHGVAR VAR(&VARA) VALUE(%UPPER(&VARB))   更改到内置函数%SIZE产生的值。例如变量&VARB占用的字节数将存储在变量 &VARA 中，如下所示： CHGVAR VAR(&VARA) VALUE(%SIZE(&VARB))   更改到内置函数%PARMS产生的值。例如传递给程序的参数数量将存储在变量&VARA 中，如下所示： CHGVAR VAR(&VARA) VALUE(%PARMS())   CHGVAR命令也可用于检索和更改本地数据区。下面示例中，命令清空本地数据区的10个字节并检索部分本地数据区： CHGVAR %SST(*LDA 1 10) ' ' CHGVAR &A %SST(*LDA 1 10) 从值到变量有效赋值 下表显示了从值（文字或变量）对变量的有效赋值： 变量 逻辑值 字符值 十进制值 有符号整数值 无符号整数值 逻辑变量 X 字符变量 X X X X X 十进制变量 X X X X 有符号整数变量 X X X X 无符号整数变量 X X X X 注意事项： 为字符变量指定数值时，请记住以下几点： 字符变量的值是右对齐的，如有必要，用前导零填充 必要时，字符变量必须足够长以包含小数点和减号- 使用时，减号-将放置在值的最左侧位置   例如，&VARA是要更改为十进制变量&VARB的值的字符变量。&VARA的长度为6。&VARB的长度为5，小数位为2。&VARB的当前值为123，&VARA的结果值为123.00。 为数值变量指定字符值时，请记住以下几点： -小数点由字符值中小数点的位置决定。如果字符值不包含小数点，则小数点放在值的最右边 字符值的左侧可以包含减号-或加号+；中间不允许有空格。如果字符值没有符号，则假定该值为正 如果字符值包含的小数点右侧的数字多于数字变量中的数字，则如果是十进制变量，则截断数字，如果是整数变量，则四舍五入。如果多余的数字在小数点的左边，它们不会被截断并且会发生错误   例如，&VARC是一个十进制变量，要更改为字符变量&VARD的值。&VARC 的长度为 5，小数点后 2 位。&VARD 的长度为10，其当前值为+123.1bbbb（其中 b=空白）。&VARC 的结果值为123.10。 命令参数的尾随空格   在某些命令参数中，可以定义如何处理尾随空格。一些命令参数使用VARY(*YES)的参数值定义。此参数值导致传递的值的长度为单引号之间的字符数： 当CL变量用于指定以这种方式定义的参数的值时，系统会在确定要传递给命令处理器程序的变量长度之前删除尾随空格 如果存在尾随空格并且对参数很重要，则必须采取特殊操作以确保传递的长度包括它们。大多数命令参数的定义和使用方式不会导致这种情况发生。定义可能发生这种情况的参数的一个示例是OVRDBF(Override with Database File)命令上的POSITION参数的值 当这种情况发生时，通过构造一个命令字符串，用单引号将参数值分隔，并将该字符串传递给QCMDEXC或QCAPCMD进行处理，这些参数就可以得到用户想要的结果   下面是一个程序示例，该程序可用于运行OVRDBF(Override with Database File)命令，以便将尾随空格作为键值的一部分。相同的技术可用于其他命令，这些命令具有使用参数VARY(*YES); 定义的参数；尾随空格必须与参数一起传递： PGM PARM(&KEYVAL &LEN) /* PROGRAM TO SHOW HOW TO SPECIFY A KEY VALUE WITH TRAILING */ /* BLANKS AS PART OF THE POSITION PARAMETER ON THE OVRDBF */ /* COMMAND IN A CL PROGRAM. */ /* THE KEY VALUE ELEMENT OF THE POSITION PARAMETER OF THE OVRDBF */ /* COMMAND IS DEFINED USING THE VARY(*YES) PARAMETER. */ /* THE DESCRIPTION OF THIS PARAMETER ON THE ELEM COMMAND */ /* DEFINITION STATEMENT SPECIFIES THAT IF A PARAMETER */ /* DEFINED IN THIS WAY IS SPECIFIED AS A CL VARIABLE THE */ /* LENGTH IS PASSED AS THE VARIABLE WITH TRAILING BLANKS */ /* REMOVED. A CALL TO QCMDEXC USING APOSTROPHES TO DELIMIT */ /* THE LENGTH OF THE KEY VALUE CAN BE USED TO CIRCUMVENT */ /* THIS ACTION. */ /* PARAMETERS-- */ DCL VAR(&KEYVAL) TYPE(*CHAR) LEN(32) /* THE VALUE + OF THE REQUESTED KEY. NOTE IT IS DEFINED AS + 32 CHAR. */ DCL VAR(&LEN) TYPE(*INT) /* THE LENGTH + OF THE KEY VALUE TO BE USED. ANY VALUE OF + 1 TO 32 CAN BE USED */ /* THE STRING TO BE FINISHED FOR THE OVERRIDE COMMAND TO BE */ /* PASSED TO QCMDEXC (NOTE 2 APOSTROPHES TO GET ONE). */ DCL VAR(&STRING) TYPE(*CHAR) LEN(100) + VALUE('OVRDBF FILE(X3) POSITION(*KEY 1 FMT1 '' ') /* POSITION MARKER 123456789 123456789 123456789 123456789 */ DCL VAR(&END) TYPE(*DEC) LEN(15 5) /* A VARIABLE + TO CALCULATE THE END OF THE KEY IN &STRING */ CHGVAR VAR(%SST(&STRING 40 &LEN)) VALUE(&KEYVAL) /* + PUT THE KEY VALUE INTO COMMAND STRING FOR + QCMDEXC IMMEDIATELY AFTER THE APOSTROPHE. */ CHGVAR VAR(&END) VALUE(&LEN + 40) /* POSITION AFTER + LAST CHARACTER OF KEY VALUE */ CHGVAR VAR(%SST(&STRING &END 2)) VALUE('')') /* PUT + A CLOSING APOSTROPHE & PAREN TO END + PARAMETER */ CALL PGM(QCMDEXC) PARM(&STRING 100) /* CALL TO + PROCESS THE COMMAND */ ENDPGM 注意事项： 如果使用VARY(*YES)和RTNVAL(*YES)并传递CL变量，则传递变量的长度不是CL变量中数据的长度 待补充 "},"05-IBM_Operating_System/03-AS400程序/04-CLP-控制语句.html":{"url":"05-IBM_Operating_System/03-AS400程序/04-CLP-控制语句.html","title":"CLP-控制语句","keywords":"","body":"CLP-控制语句 官方文档主页：Controlling processing within a CL program or CL procedure GOTO命令 GOTO命令处理无条件分支，官方文档： GOTO command and command labels in a CL program or procedure IBM i 7.4 Go To (GOTO) GOTO命令说明 标准格式： GOTO CMDLBL(label) 命令说明： 每当遇到GOTO命令时，程序处理过程将被定向到程序或过程的另一部分（由label标识） 在分支到标记语句之后，处理从该语句开始并按连续顺序继续 它不会返回到GOTO命令，除非由另一条指令特别指示返回。也可以定向到向前或向后的分支 不能使用GOTO命令转到程序或过程之外的标签，也不能使用GOTO命令分支进入或退出程序中定义的子例程 GOTO命令示例 A的值小于30就回到LOOP这个Label中更改A的值： LOOP: CHGVAR &A (&A + 1) IF (&A *LT 30) THEN(GOTO LOOP) 满足IF条件定向到END这个label，然后结束程序： PGM DCL VAR(&DATE) TYPE(*CHAR) LEN(6) RTVSYSVAL SYSVAL(QDATE) RTNVAR(&DATE) IF (%SST(&DATE 1 2) *NE '01') THEN(GOTO END) ... END: ENDPGM 回到GOTO所在的Label进行循环： PGM ... START: SNDRCVF RCDFMT(MENU) IF (&RESP=1) THEN(CALL CUS210) ... GOTO START ... ENDPGM IF及ELSE命令 IF命令用于声明一个条件，如果该条件为真，则指定要运行的程序或过程中的一个语句或一组语句。ELSE命令可与IF命令一起使用，以指定在IF命令表示的条件为假时要运行的语句或语句组。 官方参考链接： IF command in a CL program or procedure Embedded IF commands in a CL program or procedure If (IF) ELSE command in a CL program or procedure Else (ELSE) IF命令 IF命令格式： IF COND(logical-expression) THEN(CL-command) 说明： COND参数上的逻辑表达式可以是单个逻辑变量或常量，或者必须描述两个或多个操作数之间的关系；然后表达式判断true或false： 如果逻辑表达式描述的条件被评估为true，则处理THEN参数上的CL命令。可以是单个或一组命令 如果条件不成立，则运行下一个顺序命令 命令名称IF和关键字COND或值之间需要空格。关键字（如果指定）和包含值的左括号之间不允许有空格 COND和THEN都是命令中的关键字，位置输入可以省略 基本格式示例如下： IF COND(&RESP=1) THEN(CALL CUS210) IF (&A *EQ &B) THEN(GOTO LABEL) IF (&A=&B) GOTO LABEL 嵌入CHGVAR命令和DO命令： IF (&A *EQ &B) THEN(CHGVAR &A (&A+1)) IF (&B *EQ &C) THEN(DO) ... ENDDO 多个条件判断示例： PGM DCL VAR(&DATE) TYPE(*CHAR) LEN(6) RTVSYSVAL SYSVAL(QDATE) RTNVAR(&DATE) IF ((%SST(&DATE 1 2) *EQ '03') + *OR (%SST(&DATE 1 2) *EQ '06') + *OR (%SST(&DATE 1 2) *EQ '09') + *OR (%SST(&DATE 1 2) *EQ '12')) THEN(DO) CHGVAR VAR(&TMPDATE) VALUE(%SST(&DATE 1 + 2)||'/'||'21'||'/'||%SST(&DATE 5 2)) ENDDO ELSE命令   如果关联的IF命令的条件为False，则ELSE命令是一种指定替代处理的方法。如果使用ELSE命令，则处理逻辑会发生变化，示例如下： IF (&A=&B) THEN(CALLPRC PROCA) ELSE CMD(CALLPRC PROCB) CHGVAR &C 8 示例说明： 如果&A=&B，则调用PROCA，而不调用PROCB 如果表达式&A=&B不为Ture，则调用PROCB   每个ELSE命令前面必须有一个关联的IF命令。如果存在嵌套级别的IF命令，则每个ELSE命令都与尚未与另一个ELSE命令匹配的最内层IF命令匹配。示例如下： IF ... THEN ... IF ...THEN(DO) IF ...THEN(DO) ... ENDDO ELSE DO IF ...THEN(DO) ... ENDDO ELSE DO ... ENDDO ENDDO ELSE IF ... THEN ... IF ... THEN ... IF ... THEN ...   ELSE命令可用于测试一系列互斥选项。在下面的示例中，在第一次成功的IF测试之后，处理嵌入式命令并且过程处理RCLRSC命令： IF COND(&OPTION=1) THEN(CALLPRC PRC(ADDREC)) ELSE CMD(IF COND(&OPTION=2) THEN(CALLPRC PRC(DSPFILE))) ELSE CMD(IF COND(&OPTION=3) THEN(CALLPRC PRC(PRINTFILE))) ELSE CMD(IF COND(&OPTION=4) THEN(CALLPRC PRC(DUMP))) RCLRSC RETURN 嵌入式IF命令   IF命令可以嵌入到另一个IF命令中。当要在真实评估下处理的命令（放置在THEN参数上的CL命令）本身是另一个IF命令时，可能会嵌入IF命令： IF (&A=&B) THEN(IF (&C=&D) THEN(GOTO END)) GOTO START 在运行某个命令或命令组之前必须满足几个条件时，嵌入式IF可能很有用： 上面例子中，如果第一个表达式为真，则系统读取第一个THEN参数； 如果&C=&D表达式被评估为真，系统将处理第二个THEN参数GOTO END中的命令 两个表达式都必须为真才能处理GOTO END命令 如果其中一个为假，则运行GOTO START命令 请注意使用括号来组织表达式和命令   在CL编程中最多允许25级这样的嵌入。随着嵌入级别的增加和逻辑变得更加复杂，可能希望以自由形式设计输入代码以阐明关系。示例： PGM DCL &A *DEC 1 DCL &B *CHAR 2 DCL &RESP *DEC 1 IF (&RESP=1) + IF (&A=5) + IF (&B=NO) THEN(DO) ... ENDDO CHGVAR &A VALUE(8) CALL PGM(DAILY) ENDPGM 示例说明： 前面的IF系列作为一个嵌入式命令处理 每当任何一个IF条件失败时，处理都会分支到代码的其余部分（CHGVAR)和后续命令） 如果此代码的目的是累积一系列条件，所有这些条件都必须为真，Do组才能处理，那么使用*AND在一个命令中使用多个表达式可以更容易地对其进行编码   在某些情况下，分支必须根据哪个条件失败而有所不同。可以通过为每个嵌入式IF命令添加一个ELSE命令来完成此操作： PGM DCL &A ... DCL &B ... DCL &RESP ... IF (&RESP=1) + IF (&A=5) + IF (&B=NO) THEN(DO) ... SNDPGMMSG ... ... ENDDO ELSE CALLPRC PROCA ELSE CALLPRC PROCB CHGVAR &A 8 CALLPRC PROC(DAILY) ENDPGM 示例中： 如果所有条件都为真，则处理SNDPGMMSG命令，然后处理CHGVAR命令 如果第一个条件&RESP=1和第二个条件&A=5为真，但第三个&B=NO为假，则调用PROCA；当 PROCA 返回时，处理CHGVAR命令 如果第二个条件失败，则调用PROCB（&B=NO未测试），然后调用CHGVAR命令 如果&RESP不等于1，则立即处理CHGVAR命令 ELSE命令已用于为每个测试提供不同的分支 以下三个示例是前面示例中嵌入的IF命令的正确等价语法： IF (&RESP=1) THEN(IF (&A=5) THEN(IF (&B=NO) THEN(DO))) IF (&RESP=1) THEN + (IF (&A=5) THEN + (IF (&B=NO) THEN(DO))) IF (&RESP=1) + (IF (&A=5) + (IF (&B=NO) THEN(DO))) DO命令和组 官方参考链接：DO command and DO groups in a CL program or procedure DO命令和组   DO命令允许用户一起处理一组命令。组定义为DO命令和相应的结束执行组ENDDO命令之间的所有命令。DO组最常与IF、ELSE或MONMSG命令相关联。这是DO组的示例： IF (&A=&B) THEN(DO) ... ENDDO ... ENDPGM 示例说明： 如果逻辑表达式&A=&B为真，则处理DO组 如果表达式不为真，则处理在ENDDO命令之后的命令；DO组被跳过   下面示例中，如果&A不等于&B，则系统调用PROCB。不会调用 PROCA，也不会处理DO组中的任何其他命令： IF (&A=&B) THEN(DO) CALLPRC PROCA CHGVAR &A &B SNDPGMMSG... ENDDO CALLPRC PROCB CHVAR &ACCTS &B   DO组可以嵌套在其他DO组中，最多嵌套25级。下面示例有三层嵌套。注意每个DO组是如何由ENDDO命令完成的： PGM IF (&A=&B) DO CALL PGMA IF (&A=6) DO CHGVAR &A 33 CALL PGMB IF (&AREA=YES) DO CHGVAR &AREA NO CHGVAR &P (&P+1) ENDDO CALLPRC ACCTSPAY ENDDO ENDDO CALL PGMC ENDPGM 示例说明： 示例中，如果第一个嵌套中的&A不等于6，则调用PGMC 如果&A等于6，则处理第二个DO组中的语句 如果第二个DO组中的&AREA不等于YES，则调用过程ACCTSPAY，因为处理移动到DO组之后的下一个命令 显示DO和SELECT嵌套级别   一些CL源程序包含DO命令或SELECT命令，其中这些命令嵌套了好几层。例如，一个DO命令和相应的ENDDO命令之间可以是一个DOFOR和另一个ENDDO命令： CL编译器最多支持DO命令和SELECT命令的25级嵌套 使用多级DO命令或SELECT命令嵌套更改CL源代码可能很困难 必须将每种类型的DO命令与匹配的ENDDO命令正确匹配 还必须将每个SELECT命令与匹配的ENDSELECT命令匹配   CL编译器提供了一个选项来显示CL编译器列表中DO、DOFOR、DOUNTIL、DOWHILE和SELECT命令的嵌套级别： 为创建CL程序CRTCLPGM命令、创建CL模块CRTCLMOD命令或创建绑定CL程序CRTBNDCL命令的OPTION参数指定*DOSLTLVL以使嵌套级别出现在编译器列表中 如果不想看到此嵌套级别信息，可以为OPTION参数指定*NODOSLTLVL DOUNTIL命令   DOUNTIL命令处理一组CL命令一次或多次。命令组定义为DOUNTIL和匹配的ENDDO命令之间的命令。在处理完这组命令之后，评估所述条件： 如果条件为真，则退出DOUNTIL组，并使用相关ENDDO之后的下一个命令继续处理 如果条件为假，组将继续处理组中的第一个命令   COND参数上的逻辑表达式可以是单个逻辑变量或常量，或者必须描述两个或多个操作数之间的关系；然后表达式被评估为真或假。示例关于使用DOUNTIL命令的条件处理： DOUNTIL (&LGL) ... CHGVAR &INT (&INT + 1) IF (&INT *GT 5) (CHGVAR &LGL '1') ENDDO 示例说明： DOUNTIL组的主体将至少运行一次 如果&INT变量的初始值为5或更大，则&LGL将在第一次设置为真，并且在组末尾计算表达式时将继续处理 ENDDO 如果初始值小于5，则组的主体会不断重复，直到&INT的值大于5并且&LGL的值变为true DOUNTIL命令更多用法说明： LEAVE命令可用于退出DOUNTIL组并在ENDDO之后恢复处理 ITERATE命令可用于跳过组中的剩余命令并立即评估所述条件 DOWHILE命令   DOWHILE命令允许在逻辑表达式的值为真时处理一组命令零次或多次。DOWHILE命令用于说明一个条件，如果该条件为真，则指定程序或过程中要运行的一个命令或一组命令。命令组定义为DOWHILE和匹配的ENDDO命令之间的那些命令。在处理命令组之前判断所述条件： 如果所述条件最初为假，则永远不会处理该组命令 如果条件为假，则退出DOWHILE组，并使用相关ENDDO之后的下一个命令继续处理 如果条件为真，该组将继续处理该组中的第一个命令 当到达ENDDO命令时，控制返回到DOWHILE命令以再次判断条件   COND参数上的逻辑表达式可以是单个逻辑变量或常量，或者必须描述两个或多个操作数之间的关系；然后表达式被判断为真或假。示例关于使用DOWHILE命令的条件处理： DOWHILE (&LGL) ... IF (&INT *EQ 2) (CHGVAR &LGL '0') ENDDO 示例说明： 处理DOWHILE组时，将评估所述条件： 如果条件为真，则处理DOWHILE组中的命令组 如果条件为假，则继续处理相关ENDDO命令之后的命令 如果&LGL的值为真，则DOWHILE组中的命令将一直运行，直到&INT等于2，从而导致&LGL变量值设置为假   LEAVE命令可用于退出DOWHILE组并在ENDDO之后恢复处理。ITERATE命令可用于跳过组中的剩余命令并立即评估所述条件。 DOFOR命令   DOFOR命令允许您处理一组命令指定的次数。DOFOR命令指定一个变量、它的初始值、增量或减量量以及终值条件。DOFOR命令的格式为： DOFOR VAR(integer-variable) FROM(initial-value) TO(end-value) BY(integer-constant) 命令说明： 当DOFOR组的处理开始时，VAR参数指定的整数变量被初始化为FROM参数指定的初始值 整数变量的值与TO参数中指定的最终值进行比较 当BY参数上的整数常量为正时，比较会检查大于最终值的整数变量 如果BY参数上的整数常量为负数，则比较检查整数变量是否小于最终值 如果条件不成立，则处理DOFOR组的主体 当达到ENDDO时，将BY参数中的整数常量添加到整数值，并再次评估条件 示例关于使用DOFOR命令的条件处理： CHGVAR &INT2 0 DOFOR VAR(&INT) FROM(2) TO(4) BY(1) ... CHGVAR &INT2 (&INT2 + &INT) ENDDO /* &INT2 = 9 after running the DOFOR group 3 times */ 示例说明： 处理DOFOR组时，&INT初始化为2，检查&INT的值是否大于4 不是，所以处理组体 在该组的第二次迭代中，将一个添加到&INT并重复检查 它小于4，因此再次处理DOFOR组 第二次到达ENDDO时，&INT的值再次增加1。&INT现在的值为4 因为&INT仍然小于或等于4，所以再次处理DOFOR组 第三次到达ENDDO时，&INT的值再次增加1 这一次，值为5，并继续处理ENDDO之后的命令   LEAVE命令可用于退出DOFOR组并在ENDDO之后恢复处理。ITERATE命令可用于跳过组中的剩余命令，增加控制变量，并立即评估最终值条件。 ITERATE命令 "},"05-IBM_Operating_System/03-AS400程序/05-CLP-检索可用作变量的值.html":{"url":"05-IBM_Operating_System/03-AS400程序/05-CLP-检索可用作变量的值.html","title":"CLP-检索可用作变量的值","keywords":"","body":"CLP-检索可用作变量的值 官方文档链接：IBM i 7.4 Retrieving values that can be used as variables 检索系统值   IBM提供了几种类型的系统值。例如，QDATE和QTIME是日期和时间系统值，在操作系统启动时设置它们。可以将系统值带入用户的程序或过程，并使用RTVSYSVAL(Retrieve System Value)命令将它们作为变量进行操作，示例： RTVSYSVAL SYSVAL(system-value-name) RTNVAR(CL-variable-name) 示例说明： RTNVAR参数指定CL程序或过程中要接收系统值的变量名称 变量的类型必须与系统值的类型相匹配 对于字符和逻辑系统值，CL变量的长度必须等于值的长度 对于十进制值，变量的长度必须大于或等于系统值的长度 检索QTIME系统值 官方示例如下： PGM DCL VAR(&PWRDNTME) TYPE(*CHAR) LEN(6) VALUE('183030') DCL VAR(&TIME) TYPE(*CHAR) LEN(6) RTVSYSVAL SYSVAL(QTIME) RTNVAR(&TIME) IF (&TIME *GT &PWRDNTME) THEN(DO) SNDBRKMSG('Powering down in 5 minutes. Please sign off.') PWRDWNSYS OPTION(*CNTRLD) DELAY(300) RESTART(*NO) + IPLSRC(*PANEL) ENDDO ENDPGM 示例说明： 定义了变量&PWRDNTME，值为183030，即18:30:30，格式为HH:MM:SS 定义了变量&TIME，然后检索系统值QTIME，并将值赋给变量&TIME 比较两个变量值，如果&TIME大于&PWRDNTME，向系统发出将要关机消息，然后执行关机命令 将QDATE检索到CL变量中   在许多应用程序中，可能希望通过检索系统值QDATE并将其放入变量中，从而在程序或过程中使用当前日期。可能还想更改该日期的格式以在程序或过程中使用。 CVTDAT命令 使用CVTDAT(Convert Date)命令来转换CL程序或过程中的日期格式： 系统日期的格式是系统值QDATFMT： QDATFMT的包含值因国家或地区而异。例如，062489是1989年6月24日的MDY(月日年)格式 可以将此格式更改为YMD、DMY或JUL(Julian)格式 对于Julian，QDAY值是一个从001到366的三字符值。它用于确定两个日期之间的天数 还可以CVTDAT命令删除日期分隔符或更改日期分隔符 CVTDAT命令格式如下： CVTDAT DATE(date-to-be-converted) TOVAR(CL-variable) + FROMFMT(old-format) TOFMT(new-format) + TOSEP(new-separators) 格式说明： DATE参数可以指定要转换的常量或变量 日期转换后，它被放置在以TOVAR参数命名的变量中   在下面示例中，变量&DATE中的日期格式为MDY，被更改为DMY格式并放置在变量&CVTDAT中，使用的日期分隔符与系统值QDATSEP中指定的保持一致： CVTDAT DATE(&DATE) TOVAR(&CVTDAT) FROMFMT(*MDY) TOFMT(*DMY) TOSEP(*SYSVAL)   在创建对象或添加使用日期作为其名称一部分的成员时，CVTDAT命令非常有用。例如，假设必须使用当前系统日期将成员添加到文件中。此外，假设当前日期为MDY格式，并将转换为Julian格式。如果当前日期是1988年1月5日，则添加的成员将命名为MBR88005： PGM DCL &DATE6 *CHAR LEN(6) DCL &DATE5 *CHAR LEN(5) RTVSYSVAL QDATE RTNVAR(&DATE6) CVTDAT DATE(&DATE6) TOVAR(&DATE5) TOFMT(*JUL) TOSEP(*NONE) ADDPFM LIB1/FILEX MBR('MBR' *CAT &DATE5) . . . ENDPGM 转换时间格式时注意事项： DATE参数中值的长度和TOVAR参数中变量的长度必须与日期格式兼容。如果转换后的日期比变量短，则在右侧用空格填充。TOVAR参数上的变量长度必须至少为： 对于两位数年份的Non-Julian日期： 不使用分隔符时使用六个字符，例如July 28, 1978为072878 使用分隔符时使用八个字符，例如July 28, 1978为07-28-78 对于四位数年份的Non-Julian日期： 不使用分隔符时使用八个字符，例如July 28, 1978为07281978 使用分隔符时使用十个字符，例如July 28, 1978为07-28-1978 对于两位数年份的Julian日期： 不使用分隔符时使用五个字符，例如December 31, 1996为96365 使用分隔符时使用六个字符，例如December 31, 1996为96-365 对于四位数年份的Julian日期： 不使用分隔符时使用七个字符，例如February 4, 1997为1997035 使用分隔符时使用八个字符，例如February 4, 1997为1997-035 在除Julian之外的所有日期格式中，月和日都是2字节字段，无论它们包含什么值。年份可以是2字节或 4字节字段。所有转换后的值都右对齐，并在必要时用前导零填充 在Julian格式中，day是3字节字段，year是2字节或4字节字段。所有转换后的值都右对齐，并在必要时用前导零填充 官方替代程序示例如下： PGM DCL &LILDATE *INT LEN(4) DCL &PICTSTR *CHAR LEN(5) VALUE(YYDDD) DCL &JULDATE *CHAR LEN(5) DCL &SECONDS *CHAR 8 /* Seconds from CEELOCT */ DCL &GREG *CHAR 23 /* Gregorian date from CEELOCT */ /* */ CALLPRC PRC(CEELOCT) /* Get current date and time */ + PARM(&LILDATE /* Date in Lilian format */ + &SECONDS /* Seconds field will not be used */ + &GREG /* Gregorian field will not be used */ + *OMIT) /* Omit feedback parameter */ + /* so exceptions are signalled */ CALLPRC PRC(CEEDATE) + PARM(&LILDATE /* Today's date */ + &PICTSTR /* How to format */ + &JULDATE /* Julian date */ + *OMIT) ADDPFM LIB1/FILEX MBR('MBR' *CAT &JULDATE) ENDPGM 示例说明： 示例是一个CVTDAT命令的替代程序。使用ILE绑定API，CEELOCT(Get Current Local Time)，将日期转换为Julian格式 要创建此程序，必须单独使用CRTBNDCL(Create Bound Control Language Program)命令，或同时使用CRTCLMOD(Create Control Language Module)命令和CRTPGM(Create Program)命令 检索配置源   使用RTVCFGSRC(Retrieve Configuration Source)命令，可以生成CL命令源以创建现有配置对象并将源放在源文件成员中。生成的CL命令源可用于以下目的： 在系统之间迁移 维护现场配置 保存配置（不使用SAVSYS） RTVCFGSRC命令 命令RTVCFGSRC示例如下： RTVCFGSRC CFGD(CTL*) CFGTYPE(*CTLD) SRCMBR(CTLS) RTVOPT(*OBJ) 示例说明： 将CL源语句放在源文件QCLSRC的文件成员CTLS中 这些源语句可用于为名称以CTL开头的所有现有控制器重新创建对象描述 命令参考链接：Retrieve Configuration Source(RTVCFGSRC) 检索配置状态   使用RTVCFGSTS(Retrieve Configuration Status)命令，可以让应用程序能够从三个配置对象中检索配置状态：line、controller和device。 RTVCFGSTS命令 示例检索行配置描述ND01的配置状态，以在CL变量&STSCODE中使用： RTVCFGSTS CFGD(ND01) CFGTYPE(*LIN) STSCDE(&STSCODE) 命令参考链接：Retrieve Configuration Status(RTVCFGSTS) 检索网络属性 "},"05-IBM_Operating_System/03-AS400程序/40-AS400-PDM使用.html":{"url":"05-IBM_Operating_System/03-AS400程序/40-AS400-PDM使用.html","title":"AS400-PDM使用","keywords":"","body":"PDM使用 PDM全称Programming Development Manager。相关资料链接： 开发工具介绍链接：Development tools IBM官方应用开发命令介绍：Application development commands AS/400输入源语句：Entering Source Statements as400i.com网站资料：Program Development Manager (PDM) 百度文库资料：Program Development Manager Overview 简介   在AS/400中，源语句是使用程序开发管理器PDM输入的，PDM提供了一种输入程序源语句然后将语句编译成可执行程序的方法，PDM使用\"Source Entry Utility (SEU)\"作为编辑器。使用STRPDM命令进入，菜单示例： 1. Work with libraries 2. Work with objects 3. Work with members 9. Work with user-defined options Work with libraries 菜单内容示例如下： Work with Libraries Using PDM List type . . . . . . . *ALL Position to . . . . . Type options, press Enter. 2=Change 3=Copy 4=Delete 5=Display 7=Rename 8=Display description 9=Save 10=Restore ... Opt Library BONDHUANG1 更多选项： 12=Work with 13=Change text Work with objects 菜单内容示例如下： Work with Objects Using PDM Library . . . . . BONDHUANG1 Position to . . . . . . . . Position to type . . . . . Type options, press Enter. 2=Change 3=Copy 4=Delete 5=Display 7=Rename 8=Display description 9=Save 10=Restore 11=Move ... Opt Object Type QCLSRC *FILE 更多选项： 11=Mov 12=Work with 13=Change text 15=Copy file 16=Run 18=Change using DFU 25=Find string 26=Create program 27=Create service program 34=Interactive Source Debugger 54=Compare file member Work with members 菜单内容示例如下： Work with Members Using PDM File . . . . . . QCLSRC Library . . . . BONDHUANG1 Position to . . . . . Type options, press Enter. 2=Edit 3=Copy 4=Delete 5=Display 6=Print 7=Rename 8=Display description 9=Save 13=Change text 14=Compile 15=Create module.. Opt Member Type (No members in file) 更多选项： 16=Run procedure 17=Change using SDA 19=Change using RLU 25=Find string 54=Compare file member 55=Merge file member 编辑Member 修改字符 光标移动到需要修改数据的位置，输入即修改了数据。 插入字符 光标移动到需要插入字符的位置，按Insert键，然后输入数据即可。 插入行 插入行： 0004.00 DCL VAR(&DAYDATE) TYPE(*CHAR) LEN(8) I005.00 RTVSYSVAL SYSVAL(QDATE) RTNVAR(&DATE) 0006.00 CHGVAR VAR(&TMPDATE) VALUE(%SST(&DATE 1 + 0007.00 2)||'/'||'21'||'/'||%SST(&DATE 5 2)) 插入多行： 0004.00 DCL VAR(&DAYDATE) TYPE(*CHAR) LEN(8) I205.00 RTVSYSVAL SYSVAL(QDATE) RTNVAR(&DATE) 0006.00 CHGVAR VAR(&TMPDATE) VALUE(%SST(&DATE 1 + 0007.00 2)||'/'||'21'||'/'||%SST(&DATE 5 2)) 回车： 0005.00 RTVSYSVAL SYSVAL(QDATE) RTNVAR(&DATE) ''''''' ''''''' 0006.00 CHGVAR VAR(&TMPDATE) VALUE(%SST(&DATE 1 + 注意事项： 插入的行前面没有编号，为空行，按F5可以直接删除 如果在插入的行输入了数据，前面还是七个分号，按F5同样可以直接删除 输入的数据按回车后就会有编号，按F5不会删除 删除行 删除行： 0011.00 MONMSG MSGID(CPF0000) EXEC(GOTO CMDLBL(PRTBKUX)) D011.01 ENDDO 0012.00 PRTBKUX: SBMJOB CMD(WRKMEDBRM SLTCRTDATE(&TMPDATE) + 回车即可。删除多行： 0005.01 IF ((%SST(&DATE 1 2) *EQ '03') + D305.02 *OR (%SST(&DATE 1 2) *EQ '06') + 0005.03 *OR (%SST(&DATE 1 2) *EQ '09') + 0005.04 *OR (%SST(&DATE 1 2) *EQ '12')) THEN(DO) 0006.00 CHGVAR VAR(&TMPDATE) VALUE(%SST(&DATE 1 + 回车即可 保存数据 按F3退出，第一个选项中选Y： Change/create member . . . Y Y=Yes, N=No 待补充 "},"05-IBM_Operating_System/04-AS400数据库/":{"url":"05-IBM_Operating_System/04-AS400数据库/","title":"AS400数据库","keywords":"","body":"AS/400数据库 简介 IBM i：创新平台-由创新者创造，为创新者享有。 内容 "},"05-IBM_Operating_System/04-AS400数据库/01-AS400-数据库基础知识.html":{"url":"05-IBM_Operating_System/04-AS400数据库/01-AS400-数据库基础知识.html","title":"AS400-数据库基础知识","keywords":"","body":"AS400数据库基础知识 官方参考链接： AS400数据库官方文档首页：IBM i 7.3 Database overview 数据库相关查询：IBM i 7.3 Database information finder DB2相关设置 DB2相关系统极限设置 AS400中DB2相关系统设置限制告警说明：Alerts for IBM i System Limits "},"05-IBM_Operating_System/04-AS400数据库/05-AS400-Commitment Control.html":{"url":"05-IBM_Operating_System/04-AS400数据库/05-AS400-Commitment Control.html","title":"AS400-Commitment Control","keywords":"","body":"AS400 Commitment Control 相关参考链接： 官方Commitment Control文档中心主页：IBM i 7.3 Commitment control 库QRECOVERY作用介绍：IBM Support QRECOVERY Library 独立磁盘池中Commitment Control注意事项：Independent disk pool considerations for commitment definitions Commitment Control概念 概念   Commitment Control是确保数据完整性的功能。它将对资源（例如数据库文件或表）的一组更改定义和处理为一个事务。可以使用Commitment Control来设计应用程序，以便在作业、作业中的激活组或系统异常结束时系统可以重新启动应用程序。通过Commitment Control，可以确保当应用程序再次启动时，数据库中不会因为先前失败的不完整事务而导致部分更新。 Commitment Control工作原理   例如：当用户将资金从储蓄账户转移到支票账户时，会发生多个变化。对用户来说，这种转移似乎是一次更改。但是，由于储蓄账户和支票账户都更新了，数据库发生了不止一个变化。为了保持两个账户的准确性，支票和储蓄账户必须发生所有变化或不发生任何变化。 库QRECOVERY或库QRCYxxxxx   启动Commitment Control控制时，会在QRECOVERY库中创建Commitment定义。每个独立磁盘池或独立磁盘池组都有自己的QRECOVERY库版本。在独立磁盘池上，QRECOVERY库的名称为QRCYxxxxx，其中xxxxx为独立磁盘池编号。例如，独立磁盘池33的QRECOVERY库的名称是QRCY00033。 库QRECOVERY或库QRCYxxxxx说明： 如果独立磁盘池是磁盘池组的一部分，则只有主磁盘池具有QRCYxxxxx库 与磁盘池组内的对象关联的任何恢复对象存储在该组的主磁盘池的此库中。磁盘池组联机时，这些对象可能需要用于恢复 用户不应使用库QRECOVERY，因为它仅供系统使用。库QRECOVERY包含系统正常运行所需的对象 不能使用SAV命令来保存QRECOVERY或库QRCYxxxxx "},"05-IBM_Operating_System/04-AS400数据库/19-AS400-数据库文件管理.html":{"url":"05-IBM_Operating_System/04-AS400数据库/19-AS400-数据库文件管理.html","title":"AS400-数据库文件管理","keywords":"","body":"AS400数据库文件管理 记录学习或遇到的AS/400中数据库相关知识。官方参考链接： IBM i 7.3数据库文件管理 IBM i 7.3 Database file sizes IBM i 7.3 Example: Database file sizes 性能管理 参考链接：IBM i 7.3数据库文件管理-性能 官方示例 检索访问指定文件的查询 官方参考链接：Example: Finding the queries that accessed a specific file 数据库文件大小 参考链接：IBM i 7.5 Database file sizes 物理文件大小 参考链接： Multimember physical file in AS400 Create Physical File (CRTPF) 成员数量   在文件属性中，Maximum members项用来限制成员记录数，从而控制大小。CRTPF命令中MAXMBRS(Maximum members)选项指定物理文件可以包含的最大成员数： 1：物理文件中只能包含一个成员 *NOMAX ：文件中可以包含的成员数是系统限制的最大32767个成员 1-32767 ：自定义物理文件中可以包含的最大成员数 成员记录数量   在文件属性中，Member size选项用来限制成员记录数，从而控制大小。CRTPF命令中SIZE(Member size)选项指定每个Member中记录数量： 指定文件的每个成员中的初始记录数、添加到成员的每个增量的记录数以及自动应用增量的次数 每个文件成员的记录数被指定为可以放入其中的记录数（此数包括所有已删除的记录） 当达到最大记录数时，会向系统操作员发送一条消息（说明成员已满），让用户选择结束请求或扩展成员的记录数： 当操作员选择扩展成员时，成员的最大记录数将增加记录的增量数乘以指定的增量数。 但是，最大记录数的增加并不总是对实际成员大小（以字节为单位）产生相同的影响 可选值说明： 单一值： NOMAX：可以添加到文件的每个成员的记录数不受用户限制。 每个成员的最大记录数由系统确定。 如果指定了*NOMAX，则必须为分配存储 ALLOCATE)(Allocate storage)参数指定*NO 元素 1-Initial number of records：指定每个成员中的初始记录数 10000：默认值，最多可以将10000条记录写入文件的每个成员 1-2147483646：自定义在成员被自动扩展之前可以写入文件的每个成员的记录数 元素2-Increment number of records：指定当成员中的记录数将超过初始记录数或将超过当前增量的记录数时添加到成员的附加记录数 1000：默认值，最大记录数增加1000条记录 整数：自定义要添加到成员的附加记录的数量。如果指定为0，则不会自动扩展成员。 如果Maximum increments值为0，则该值必须为0 元素3-Maximum increments：指定可以自动添加到成员的最大增量数 3：默认值， 最多3个增量会自动添加到成员中 整数：自定义自动添加到成员的最大增量数。 有效值范围从0到32767。如果指定0，则不会自动扩展成员中记录数量 Allocate storage   指定是否将初始存储空间分配给添加到文件中的每个物理文件成员。分配提供足够的空间来容纳为SIZE(Member size)参数指定的记录数。当记录无法添加到成员而不超出其容量时发生的分配由系统和SIZE参数值确定： *NO：由系统确定要分配给添加到文件中的每个成员的存储空间量 *YES ：每次添加新成员时，都会分配在SIZE参数的第一个值中指定的存储空间量。如果指定了 *YES，则不得为SIZE参数指定*NOMAX 创建PF文件示例： CRTPF FILE(IBMTEMP/TEST400) SRCFILE(IBMTEMP/TESTSRC) SRCMBR(SRCMEM) MAXMBRS(50) SIZE(1000 100 5) ALLOCATE(*YES) 示例说明： 此命令创建一个物理文件和物理文件成员，在IBMTEMP库中都命名为TEST400 该文件及其成员是从同一库中TESTSRC源文件的SRCMEM源成员创建的。 放置在文件中的记录的存储空间不必是连续的 文件中最多可包含50个成员 初始分配最多可提供1000条记录，并且可以自动添加最多5次额外空间增量，每次100条记录 这些分配值也适用于稍后添加的此物理文件的每个成员 物理文件和逻辑文件 Physical Files： 物理文件包含存储在系统上的实际数据，以及数据如何呈现给程序或从程序接收的描述 它们只包含一种记录格式和一个或多个成员 数据库文件中的记录可以是外部的，也可以是程序描述的 物理文件可以具有键控序列访问路径，这意味着数据根据文件中的一个或多个关键字段按顺序呈现给程序 Logical Files： 逻辑文件不包含数据 包含在一个或多个物理文件中找到的记录的描述 逻辑文件是一个或多个物理文件的视图或表示 包含一种以上格式的逻辑文件称为多格式逻辑文件。 如果用户的程序处理包含多个记录格式的逻辑文件，用户可以使用按记录格式读取来设置您希望使用的格式 官方参考链接： IBM i 7.3 Physical Files and Logical Files Physical Files 参考链接： IBM i 7.3 Setting up physical files IBM i 7.3 Size of a physical file member IBM i 7.3 Deleted records 创建Physical Files 使用命令CRTPF(Create Physical File)创建，示例如下： CRTPF FILE(PAYLIB/PAYTXS) SRCFILE(SRCLIB/PAYTXS) MBR(*NONE) MAXMBRS(5) 示例说明： 示例在PAYLIB库中创建PAYTXS物理文件 SRCLIB库中源文件PAYTXS中的成员PAYTXS中的源描述用于创建物理文件 MBR(*NONE)创建的文件没有成员，在以后添加成员之前，不能将任何数据放入文件中 文件中最多可以包含五个成员 默认情况下，以后添加的每个文件成员将包含数据记录。每个成员的访问路径将持续保持。 默认情况下，在自动扩展（最多三个增量）发生之前，每个成员最多可以有10000条记录，自动扩展会将1000条记录添加到成员的容量中 默认情况下，每个成员的存储空间仅在需要时分配，不限制空间是否连续；没有初始存储分配 默认情况下，公共对象具有文件的操作、读取、添加、删除和更新权限 更改Physical Files 使用命令CHGPF(Change Physical File)创建，示例： CHGPF FILE(QGPL/DDMF) SIZE(*NOMAX) SYSTEM(*RMT) 示例说明： 示例更改远程系统上QGPL库中文件INV的大小 在指定上述命令之前，此用户已通过指定命令CRTDDMF file(QGPL/DDMF) RMTFILE(QGPL/INV)RMTLOCNAME(AS400)创建了DDM文件 Size of a physical file member 可以使用DSPFD命令查看当前PF文件的属性，关于Member大小的参数： Member size: SIZE Initial number of records . . *SAME 1-2147483646, *SAME Increment number of records . *SAME 0-32767, *SAME Maximum increments . . . . . . *SAME 0-32767, *SAME   参数SIZE指定可以放置在每个物理文件成员中的最大记录数。确定最大值的公式：R + (I * N)，详细说明如下： R：起始记录数，默认值是10000 I：每次添加的记录数（增量），默认值是1000 N：增加增量的次数，CRTPF命令默认值是3，CRTSRCPF命令默认值是499   如果是默认值，增量三次后使总数达到最大值13000。当达到最大值时，系统操作员要么停止作业，要么告诉系统再增加一次记录并继续。添加增量时，会发送一条消息到系统日志。用户可以指定*NOMAX，而不是采用默认大小或指定大小。 Logical Files "},"05-IBM_Operating_System/04-AS400数据库/20-AS400-常用SQL.html":{"url":"05-IBM_Operating_System/04-AS400数据库/20-AS400-常用SQL.html","title":"AS400-常用SQL","keywords":"","body":"AS400常用SQL 记录学习或遇到的AS/400中常用SQL。 Select语句 查询库TEMPLIB下表TMP002所有内容： select * from TEMPLIB/TMP002 查询库TEMPLIB下表TMP002中TMPNAME字段内容： select TMPNAME from TEMPLIB/TMP002 查询库TEMPLIB下表TMP002中TMPNAME字段中数据为huang的数据： select * from TEMPLIB/TMP002 where TMPNAME=huang 查询库TEMPLIB下表TMP002中TMPNAME字段中重复数据计数： select TMPNAME,count(1) from TEMPLIB/TMP002 group by TMPNAME "},"05-IBM_Operating_System/05-RedHat/":{"url":"05-IBM_Operating_System/05-RedHat/","title":"RedHat","keywords":"","body":"RedHat 简介   红帽® 企业 Linux® 是全球领先的企业Linux平台。它是一个开源操作系统（OS）。用户可基于这一平台，在裸机、虚拟环境、容器及各类云环境之间扩展现有应用并部署各种新兴技术。 Red Hat Enterprise Linux可支持多个架构（从IBM Power服务器和IBM Z大型机到支持云工作负载的Arm微芯片）。 官方网站：Red Hat Enterprise Linux Linux教程：https://www.runoob.com/linux/linux-tutorial.html 内容 RedHat-基础配置 RedHat-常用命令 RedHat-用户及用户权限 RedHat-文件和文字处理 RedHat-磁盘管理 "},"05-IBM_Operating_System/05-RedHat/01-RedHat-基础配置.html":{"url":"05-IBM_Operating_System/05-RedHat/01-RedHat-基础配置.html","title":"RedHat-基础配置","keywords":"","body":"RedHat-基础配置 RedHat接触不多，近期安装了RHEL8.0和RHEL7.8，RHEL8.0发现重启后IP不自动up，hostname也会变。配置很简单，不常用容易忘掉，记录下来。 网络和主机名 RHEL8.0修改hostname 临时修改可以用hostname命令，但是重启后失效： [root@192 ~]# hostname redhat8 [root@192 ~]# hostname redhat8 想永久修改，可以修改文件/etc/sysconfig/network文件，加上如下内容： HOSTNAME=redhat8 在/etc/hosts 中增加： 192.168.18.129 redhat8 RHEL7.8_hostname RHEL7.8我在安装的时候配置了网络和主机名，然后默认都是永久生效的，主机名配置在/etc/hostname文件中，修改应该修改此文件即可： [root@redhat PowerVC]# cat /etc/hostname redhat 设置网卡自动启动 REHL8可能是装机时候没配好，重启网络不自动启动，设置方法如下; 配置文件存放目录和文件：/etc/sysconfig/network-scripts/ifcfg-ens160，ens160是我机器网卡设备的编号，要改其它就是对应名字。 将配置文件中选项ONBOOT=no修改为ONBOOT=yes，然后可以重启验证reboot验证。 在RHEL7.8中，修改方法一样，只不过配置文件中值加了引号，如：ONBOOT='no'。 配置本地YUM源 发现在REHL7.8和REHL8中有点不一样，本地YUM源都是用的光盘。安装软件方式有很多，除了YUM方式安装还有编译安装，还有rpm方式安装，rpm安装参考博客：https://www.cnblogs.com/chuijingjing/p/9951267.html REHL8配置本地YUM源 创建镜像挂载点并挂载镜像： [root@redhat8 home]# mkdir -p /mnt/cdrom [root@redhat8 home]# mount /dev/cdrom /mnt/cdrom mount: /dev/sr0 is write-protected, mounting read-only [root@redhat8 home]#df -m 在/etc/yum.repos.d目录下新建一个文件redhat8.repo： [root@redhat8 yum.repos.d]# touch /etc/yum.repos.d/redhat8.repo 在新建的redhat8.repo中写入如下内容： [redhat8_os] name=redhat8_os baseurl=file:///mnt/cdrom/BaseOS enable=1 gpgcheck=0 [redhat8_app] name=redhat8_app baseurl=file:///mnt/cdrom/AppStream enable=1 gpgcheck=0 然后验证一下： [root@redhat8 yum.repos.d]# yum repolist Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscription -manager to register.redhat8_app 149 MB/s | 5.3 MB 00:00 redhat8_os 124 MB/s | 2.2 MB 00:00 repo id repo name status redhat8_app redhat8_app 4,672 redhat8_os redhat8_os 1,658 REHL7.8配置本地YUM源 前面步骤和REHL8一样，只是新建的.repo写入的内容有所差别，新建文件名：redhat7.repo，写入如下内容： [local] name=Red Hat Enterprise Linux 6.8 baseurl=file:///mnt/cdrom enabled=1 gpgcheck=1 gpgkey=file:///mnt//cdrom/RPM-GPG-KEY-redhat-release 然后验证一下： [root@redhat yum.repos.d]# yum repolist Loaded plugins: product-id, search-disabled-repos, subscription-manager This system is not registered with an entitlement server. You can use subscription-manager to register. local | 2.8 kB 00:00:00 (1/2): local/group_gz | 95 kB 00:00:00 (2/2): local/primary | 2.1 MB 00:00:00 local 5231/5231 repo id repo name status local Red Hat Enterprise Linux 6.8 5,231 repolist: 5,231 YUM常用命令 yum常用操作命令如下： 命令 说明 yum repolist 显示仓库列表 yum list 显示仓库的所有软件包 yum search 搜索软件包 yum check-update 检查升级 yum info 查看软件详细信息 yum provides 查看软件包Provide信息 yum deplist 查看软件包的依赖包 yum install 软件安装 yum reinstall 重新安装软件 yum update 软件升级 yum downgrade 软件降级 yum remove 卸载程序 yum history 查看yum安装的历史 设置Python3为默认   RHEL8中自带了Python3，RHEL7.8中自带Python2，Python3会成为趋势，但是每次运行Python都要输入python3命令，会很不习惯，可以修改下。 输入如下命令查看python3命令的位置： [root@redhat8 bin]# whereis python3 python3: /usr/bin/python3.6 /usr/bin/python3.6m /usr/bin/python3 /usr/lib/python3.6 /usr/l ib64/python3.6 /usr/include/python3.6m /usr/share/man/man1/python3.1.gz 进入到/usr/bin目录下，查找python： [root@redhat8 bin]# ls -l |grep python lrwxrwxrwx. 1 root root 25 Jul 18 2020 python3 -> /etc/alternatives/python3 lrwxrwxrwx. 1 root root 31 Jan 23 2019 python3.6 -> /usr/libexec/platform-pytho3.6 lrwxrwxrwx. 1 root root 32 Jan 23 2019 python3.6m -> /usr/libexec/platform-python3.6m lrwxrwxrwx. 1 root root 24 Jul 18 2020 unversioned-python -> /etc/alternatives/python 可以看到python3链接的位置：/etc/alternatives/python3 删除现有的并新建一个软链接： [root@redhat8 bin]# rm python3 rm: remove symbolic link 'python3'? y [root@redhat8 bin]#ln -s /etc/alternatives/python3 python 输入python命令验证： [root@redhat8 bin]# python Python 3.6.8 (default, Jan 11 2019, 02:17:16) [GCC 8.2.1 20180905 (Red Hat 8.2.1-3)] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> 安装git   安装方法在Git章节中，安装过程中出现一些问题也进行了记录，参考链接：GitHub-使用命令行 安装PIP   在使用Python中需要安装一些第三方库，用pip安装比较方便，RHEL中默认没有，需要安装，使用脚本安装和升级pip。参考博客：https://www.cnblogs.com/zhongyehai/p/10619917.html下载get-pip.py脚本： [root@redhat8 ~]# wget https://bootstrap.pypa.io/get-pip.py --2020-12-03 10:10:16-- https://bootstrap.pypa.io/get-pip.py Resolving bootstrap.pypa.io (bootstrap.pypa.io)... 151.101.76.175, 2a04:4e42:12::175 Connecting to bootstrap.pypa.io (bootstrap.pypa.io)|151.101.76.175|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 1886796 (1.8M) [text/x-python] Saving to: ‘get-pip.py’ get-pip.py 100%[==========================>] 1.80M 42.1KB/s in 36s 2020-12-03 10:10:53 (50.9 KB/s) - ‘get-pip.py’ saved [1886796/1886796] 运行get-pip.py脚本: [root@redhat8 ~]# python3 get-pip.py Looking in indexes: https://mirrors.aliyun.com/pypi/simple/, https://pypi.douban.com/simpl e/Collecting pip Downloading https://mirrors.aliyun.com/pypi/packages/ab/11/2dc62c5263d9eb322f2f028f7b56c d9d096bb8988fcf82d65fa2e4057afe/pip-20.3.1-py2.py3-none-any.whl (1.5 MB) |███████████████████████▎ | 1.1 MB 3.0 MB/s eta 0:00:0 |███████████████████████▌ | 1.1 MB 3.0 MB/s eta 0:00:0 ... |████████████████████████████████| 1.5 MB 997 kB/s Collecting wheel Downloading https://mirrors.aliyun.com/pypi/packages/84/e8/3caa0d932d0edd9c9611065831fd0 6cf05c53671f78a0fa553a635da7e2f/wheel-0.36.0-py2.py3-none-any.whl (34 kB)Installing collected packages: pip, wheel Attempting uninstall: pip Found existing installation: pip 9.0.3 Uninstalling pip-9.0.3: Successfully uninstalled pip-9.0.3 Successfully installed pip-20.3.1 wheel-0.36.0 查看pip版本： [root@redhat8 ~]# pip -V pip 20.3.1 from /usr/local/lib/python3.6/site-packages/pip (python 3.6) 使用pip安装Python第三方模块click示例： [root@redhat8 ~]# pip install click Looking in indexes: https://mirrors.aliyun.com/pypi/simple/, https://pypi.douban.com/simpl e/Collecting click Downloading https://pypi.doubanio.com/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7 ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82 kB) |███████████████████████████▊ | 71 kB 601 kB/s eta 0:0 |███████████████████████████████▊| 81 kB 682 kB/s eta |████████████████████████████████| 82 kB 540 kB/s Installing collected packages: click Successfully installed click-7.1.2   对于PIP其它安装方法及常用命令，在本ebook的章节Python运维-基础知识中有详细的介绍和示例演示。 待补充 "},"05-IBM_Operating_System/05-RedHat/02-RedHat-常用命令.html":{"url":"05-IBM_Operating_System/05-RedHat/02-RedHat-常用命令.html","title":"RedHat-常用命令","keywords":"","body":"Redhat-常用命令 系统管理 服务管理 systemctl命令 下表是服务管理实用命令： 命令 任务描述 systemctl status UNIT 查看有关单元状态的详细信息 systemctl stop UNIT 在运行中的系统上停止一项服务 systemctl start UNIT 在运行中的系统上启动一项服务 systemctl restart UNIT 在运行中的系统上重新启动一项服务 systemctl reload UNIT 重新加载运行中服务的配置文件 systemctl mask UNIT 彻底禁用服务，使其无法手动启动或在系统引导时启动 systemctl unmask UNIT 使屏蔽的服务变为可用 systemctl enable UNIT 将服务配置为在系统引导时启动 systemctl disable UNIT 禁止服务在系统引导时启动 systemctl list-dependencies UNIT 列出指定单元需要的单元 网络相关命令 IP命令 IP命令常用命令列表： 命令 用途 ip add show name 查看设备name和地址信息 ip -s link show name 显示关于网络性能的统计信息 ip route 显示IPv4路由信息 ip -6 route 显示IPv6路由信息 nmcli命令 nmcli命令常用命令列表： 命令 用途 nmcli dev status 显示所有网络接口的NetworkManager状态 nmcli con show 列出所有连接 nmcli con show name 列出name连接的当前设置 nmcli con add con-name name 添加一个名为name的新连接 nmcli con mod name 修改name连接 nmcli con reload 重新加载配置文件(在手动编辑配置文件之后使用) nmcli con up name 激活name连接 nmcli dev dis dev 在网络接口dev上停用并断开当前连接 nmcli con del name 删除name连接及其配置文件 软件管理 RPM相关命令 RPM查询命令摘要如下表所示： 命令 任务 rpm -qa 列出当前安装的所有RPM软件包 rpm -q NAME 显示系统上安装的NAME版本 rpm -qi NAME 显示有关软件包的详细信息 rpm -ql NAME 列出软件包中含有的所有文件 rpm -qc NAME 列出软件包中含有的配置文件 rpm -qd NAME 列出软件包中含有的文档文件 rpm -q --changelog NAME 显示软件包新发行版的简短原因摘要 rpm -q --scripts NAME 显示在软件包安装、升级或删除时运行的shell脚本 Yum命令 可以根据名称或软件包组，查找、安装、更新和删除软件包： 命令 任务 yum list [NAME-PATTERN] 按名称列出已安装和可用的软件包 yum group list 列出已安装和可用的组 yum search KEYWORD 按关键字搜索软件包 yum info PACKAGENAME 显示软件包的详细信息 yum install PACKAGENAME 安装软件包 yum group install GROUPNAME 安装软件包组 yum update 更新所有软件包 yum remove PACKAGENAME 删除软件包 yum history 显示事务历史记录 硬件相关 cpu相关 查看CPU信息 查看配置文件示例如下： [root@redhat8 ~]# cat /proc/cpuinfo processor : 0 vendor_id : AuthenticAMD cpu family : 23 model : 96 model name : AMD Ryzen 5 PRO 4650U with Radeon Graphics ...output omitted... 使用lscpu命令查看示例如下： [root@redhat8 ~]# lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 2 On-line CPU(s) list: 0,1 ...output omitted... 内存相关 查看内存信息 命令如下： [root@redhat8 ~]# cat /proc/meminfo MemTotal: 1849432 kB MemFree: 657832 kB MemAvailable: 1148136 kB Buffers: 2312 kB Cached: 464084 kB ...output omitted... free命令 命令示例如下： [root@redhat8 ~]# free total used free shared buff/cache available Mem: 1849432 661268 657760 9776 530404 1148040 Swap: 2097148 0 2097148 [root@redhat8 ~]# free -m total used free shared buff/cache available Mem: 1806 645 642 9 517 1121 Swap: 2047 0 2047 网卡相关 查看网卡信息 查看网口配置文件： [root@redhat8 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens160 TYPE=\"Ethernet\" PROXY_METHOD=\"none\" BROWSER_ONLY=\"no\" BOOTPROTO=\"dhcp\" DEFROUTE=\"yes\" IPV4_FAILURE_FATAL=\"no\" IPV6INIT=\"yes\" IPV6_AUTOCONF=\"yes\" IPV6_DEFROUTE=\"yes\" IPV6_FAILURE_FATAL=\"no\" IPV6_ADDR_GEN_MODE=\"stable-privacy\" NAME=\"ens160\" UUID=\"b561c316-1e2c-4f92-9f28-fb4cc66f0c40\" DEVICE=\"ens160\" ONBOOT=\"yes\" 待补充 "},"05-IBM_Operating_System/05-RedHat/03-RedHat-用户及用户权限.html":{"url":"05-IBM_Operating_System/05-RedHat/03-RedHat-用户及用户权限.html","title":"RedHat-用户及用户权限","keywords":"","body":"RedHat-用户及用户权限笔记 使用RedHat8系统学习时候的一些基础学习笔记。 用户及用户权限 用户及用户组创建 创建名为ftpusers的用户组，组id为4000： [root@redhat8 ~]# groupadd -g 40000 ftpusers [root@redhat8 ~]# cat /etc/group |sed -n '/ftpusers/p' ftpusers:x:40000: 创建名为christ和harry的用户，并将ftpusers作为其附属组： [root@redhat8 ~]# useradd -G ftpusers christ [root@redhat8 ~]# id christ uid=1003(christ) gid=1003(christ) groups=1003(christ),40000(ftpusers) [root@redhat8 ~]# useradd -G ftpusers harry [root@redhat8 ~]# id harry uid=1005(harry) gid=1005(harry) groups=1005(harry),40000(ftpusers) [root@redhat8 ~]# cat /etc/group |sed -n '/ftpusers/p' ftpusers:x:40000:christ,harry   默认情况useradd时候会给用户创建一个同名组，如果需要属于其它组，那么使用-G来指定附属组。使用-g表示创建用户的时设置用户属于主要的用户组，所以不会创建同名组，不指定-g就会创建同名组： [root@redhat8 ~]# useradd -g christ christb [root@redhat8 ~]# id christb uid=1004(christb) gid=1003(christ) groups=1003(christ) 创建名为sarah的用户，不属于ftpusers组，并设定为不可登录shell： [root@redhat8 ~]# useradd -s /sbin/nologin sarah [root@redhat8 ~]# id sarah uid=1006(sarah) gid=1006(sarah) groups=1006(sarah) [root@redhat8 ~]# cat /etc/passwd |grep sarah sarah:x:1006:1006::/home/sarah:/sbin/nologin [root@redhat8 ~]# su - sarah This account is currently not available. [root@redhat8 ~]# sudo -u sarah ls /home/sarah [root@redhat8 ~]# 说明： 命令su表示切用户，后面-表示切换用户后套用用户的环境设置 命令sudo -u sarah ls /home/sarah表示使用sarah用户去执行命令ls /home/sarah 将上述用户密码均设置为test1234,两种方法示例如下： [root@redhat8 ~]# passwd christ Changing password for user christ. New password: BAD PASSWORD: The password fails the dictionary check - it is too simplistic/systematic Retype new password: passwd: all authentication tokens updated successfully. [root@redhat8 ~]# echo \"test1234\" |passwd harry --stdin Changing password for user harry. passwd: all authentication tokens updated successfully. 说明：echo方式不建议在命令行使用，因为命令history可以看到设置的密码。 用户权限 创建/var/ftp/pub目录，按以下要求配置目录权限： /var/ftp/pub目录的所有者为root /var/ftp/pub目录的所属组为root，任何用户对pub目录下的文件有读权限，没有写权限 创建/var/ftp/pub/christ目录，所有者为christ，所属组为ftpusers，ftpusers组用户对目录下文件有读权限，没有写权限，其它用户读写权限都没有并不可见 创建/var/ftp/pub/harry目录，所有者为harry，所属组为ftpusers，ftpusers组用户对目录下文件有读权限，没有写权限其它用户读写权限都没有并不可见 sarah用户对/var/ftp/pub/harry/project目录有读写权限，对其它目录和文件没有读写权限 创建/var/ftp/pub目录： [root@redhat8 ~]# mkdir /var/ftp/pub [root@redhat8 ~]# ls -l /var/ftp total 0 drwxr-xr-x. 2 root root 6 Oct 28 02:01 pub 创建/var/ftp/pub/christ目录并修改权限： [root@redhat8 ~]# mkdir /var/ftp/pub/christ [root@redhat8 ~]# ls -l /var/ftp/pub total 0 drwxr-xr-x. 2 root root 6 Oct 28 03:51 christ [root@redhat8 ~]# chown christ.ftpusers /var/ftp/pub/christ [root@redhat8 ~]# ls -l /var/ftp/pub total 0 drwxr-xr-x. 2 christ ftpusers 6 Oct 28 03:51 christ [root@redhat8 ~]# chmod 750 /var/ftp/pub/christ [root@redhat8 ~]# ls -l /var/ftp/pub total 0 drwxr-x---. 2 christ ftpusers 6 Oct 28 03:51 christ [root@redhat8 ~]# chmod o+r /var/ftp/pub/christ [root@redhat8 ~]# ls -l /var/ftp/pub total 0 drwxr-xr--. 2 christ ftpusers 6 Oct 28 03:51 christ [root@redhat8 ~]# chmod o-r /var/ftp/pub/christ [root@redhat8 ~]# ls -l /var/ftp/pub total 0 drwxr-x---. 2 christ ftpusers 6 Oct 28 03:51 christ [root@redhat8 ~]# sudo -u sarah ls /var/ftp/pub christ 创建一个文件的进行测试验证及修改christ目录： [root@redhat8 ~]# touch /var/ftp/pub/christ/test [root@redhat8 ~]# ls -l /var/ftp/pub/christ/test -rw-r--r--. 1 root root 0 Oct 28 04:31 /var/ftp/pub/christ/test [root@redhat8 ~]# chown christ.ftpusers /var/ftp/pub/christ -R [root@redhat8 ~]# ls -l /var/ftp/pub/christ/test -rw-r--r--. 1 christ ftpusers 0 Oct 28 04:31 /var/ftp/pub/christ/test [root@redhat8 ~]# sudo -u sarah ls /var/ftp/pub/christ ls: cannot open directory '/var/ftp/pub/christ': Permission denied [root@redhat8 ~]# sudo -u sarah ls /var/ftp/pub/christ/test ls: cannot access '/var/ftp/pub/christ/test': Permission denied [root@redhat8 ~]# chmod o-r /var/ftp/pub/christ/test [root@redhat8 ~]# ls -l /var/ftp/pub/christ/test -rw-r-----. 1 christ ftpusers 0 Oct 28 04:31 /var/ftp/pub/christ/test [root@redhat8 ~]# sudo -u harry cat /var/ftp/pub/christ/test test txt [root@redhat8 ~]# sudo -u sarah cat /var/ftp/pub/christ/test cat: /var/ftp/pub/christ/test: Permission denied 创建harry目录并修改权限： [root@redhat8 ~]# mkdir -p /var/ftp/pub/harry/project [root@redhat8 ~]# chown harry.ftpusers /var/ftp/pub/harry -R [root@redhat8 ~]# ls -l /var/ftp/pub total 0 drwxr-x---. 2 christ ftpusers 18 Oct 28 04:41 christ drwxr-xr-x. 3 harry ftpusers 21 Oct 28 04:43 harry [root@redhat8 ~]# chmod o-rx /var/ftp/pub/harry -R [root@redhat8 ~]# ls -l /var/ftp/pub total 0 drwxr-x---. 2 christ ftpusers 18 Oct 28 04:41 christ drwxr-x---. 3 harry ftpusers 21 Oct 28 04:43 harry [root@redhat8 ~]# sudo -u harry echo 123 > /var/ftp/pub/harry/project/test [root@redhat8 ~]# ls -l /var/ftp/pub/harry/project total 4 -rw-r--r--. 1 root root 4 Oct 28 04:49 test [root@redhat8 ~]# chown harry.ftpusers /var/ftp/pub/harry -R [root@redhat8 ~]# ls -l /var/ftp/pub/harry/project total 4 -rw-r--r--. 1 harry ftpusers 4 Oct 28 04:49 test [root@redhat8 ~]# chmod o-rx /var/ftp/pub/harry -R [root@redhat8 ~]# ls -l /var/ftp/pub/harry/project total 4 -rw-r-----. 1 harry ftpusers 4 Oct 28 04:49 test sarah用户对/var/ftp/pub/harry/project目录有读写权限: [root@redhat8 ~]# sudo -u christ cat /var/ftp/pub/harry/project/test 123 [root@redhat8 ~]# sudo -u sarah cat /var/ftp/pub/harry/project/test cat: /var/ftp/pub/harry/project/test: Permission denied [root@redhat8 ~]# sudo -u sarah ls -l /var/ftp/pub total 0 drwxr-x---. 2 christ ftpusers 18 Oct 28 04:41 christ drwxr-x---. 3 harry ftpusers 21 Oct 28 04:43 harry [root@redhat8 ~]# setfacl -R -m u:sarah:rw- /var/ftp/pub/harry/project [root@redhat8 ~]# sudo -u christ cat /var/ftp/pub/harry/project/test 123 [root@redhat8 ~]# ls -l /var/ftp/pub/harry/project total 4 -rw-rw----+ 1 harry ftpusers 4 Oct 28 04:49 test 说明： 权限中多了个+表示有扩充权限,ls是列不出来的 使用gesfacl可以单独给某个用户加权限，加了之后发现还不行，上层目录的权限一样也要改 示例如下： [root@redhat8 ~]# getfacl /var/ftp/pub/harry/project getfacl: Removing leading '/' from absolute path names # file: var/ftp/pub/harry/project # owner: harry # group: ftpusers user::rwx user:sarah:rw- group::r-x mask::rwx other::--- [root@redhat8 ~]# sudo -u sarah cat /var/ftp/pub/harry/project/test cat: /var/ftp/pub/harry/project/test: Permission denied [root@redhat8 ~]# setfacl -R -m u:sarah:rwx /var/ftp/pub/harry [root@redhat8 ~]# sudo -u sarah cat /var/ftp/pub/harry/project/test 123 用户和权限示例 setgid属性的作用   使用sudo -u命令以sarah的身份在/var/ftp/pub/harry/project/目录下建立一个名为sarah的子目录，使用ls -l命令查看子目录的权限位显示： [root@redhat8 ~]# sudo -u sarah mkdir /var/ftp/pub/harry/project/sarah [root@redhat8 ~]# ls -l /var/ftp/pub/harry/project total 4 drwxr-xr-x. 2 sarah sarah 6 Oct 28 07:34 sarah -rw-rwx---+ 1 harry ftpusers 4 Oct 28 04:49 test   使用命令chmod g+s对sarah目录操作，使用ls -l命令查看子目录的权限位显示: [root@redhat8 ~]# ls -l /var/ftp/pub/harry/project total 4 drwxr-sr-x. 2 sarah sarah 6 Oct 28 07:34 sarah -rw-rwx---+ 1 harry ftpusers 4 Oct 28 04:49 test   以root用户建立/var/ftp/pub/harry/project/sarah/folder1，使用ls -l命令查看子目录的所属组: [root@redhat8 ~]# mkdir /var/ftp/pub/harry/project/sarah/folder1 [root@redhat8 ~]# ls -l /var/ftp/pub/harry/project/sarah total 0 drwxr-sr-x. 2 root sarah 6 Oct 28 07:39 folder1   以root用户新建/var/ftp/pub/harry/project/sarah/file1，使用ls -l命令查看文件的所属组： [root@redhat8 ~]# touch /var/ftp/pub/harry/project/sarah/file1 [root@redhat8 ~]# ls -l /var/ftp/pub/harry/project/sarah total 0 -rw-r--r--. 1 root sarah 0 Oct 28 07:40 file1 drwxr-sr-x. 2 root sarah 6 Oct 28 07:39 folder1   以christ, harry用户尝试新建的sarah目录访问和操作: [root@redhat8 ~]# sudo -u christ ls /var/ftp/pub/harry/project/sarah/file1 /var/ftp/pub/harry/project/sarah/file1 [root@redhat8 ~]# sudo -u harry ls /var/ftp/pub/harry/project/sarah/file1 /var/ftp/pub/harry/project/sarah/file1 [root@redhat8 ~]# sudo -u harry ls /var/ftp/pub/harry/project/sarah/folder1 [root@redhat8 ~]# sudo -u christ ls /var/ftp/pub/harry/project/sarah/folder1 setuid属性的作用   将touch命令文件cp过来，并使用ls -l 命令查看目标mytouch文件的权限位、所有者（sarah），所属组(ftpuser或sarah)： [root@redhat8 ~]# sudo -u sarah cp /usr/bin/touch /var/ftp/pub/harry/project/mytouch [root@redhat8 ~]# ls -l /var/ftp/pub/harry/project total 112 -rwxr-xr-x. 1 sarah sarah 109776 Oct 28 08:43 mytouch drwxr-sr-x. 3 sarah sarah 34 Oct 28 07:40 sarah -rw-rwx---+ 1 harry ftpusers 4 Oct 28 04:49 test 尝试使用mytouch： [root@redhat8 ~]# cd /var/ftp/pub/harry/project [root@redhat8 project]# sudo -u sarah ./mytouch sarah1 [root@redhat8 project]# ls -l sarah1 -rw-r--r--. 1 sarah sarah 0 Oct 28 08:52 sarah1 [root@redhat8 project]# sudo -u christ ./mytouch christ1 ./mytouch: cannot touch 'christ1': Permission denied 修改权限后再次尝试示例： [root@redhat8 project]# chmod u+s ./mytouch [root@redhat8 project]# ls -l mytouch -rwsr-xr-x. 1 sarah sarah 109776 Oct 28 08:43 mytouch [root@redhat8 project]# sudo -u christ ./mytouch christ1 [root@redhat8 project]# ls -l total 112 -rw-r--r--. 1 sarah christ 0 Oct 28 08:56 christ1 -rwsr-xr-x. 1 sarah sarah 109776 Oct 28 08:43 mytouch drwxr-sr-x. 3 sarah sarah 34 Oct 28 07:40 sarah -rw-r--r--. 1 sarah sarah 0 Oct 28 08:52 sarah1 -rw-rwx---+ 1 harry ftpusers 4 Oct 28 04:49 test stickybit属性的作用 创建一个tmp目录修改权限后并查看权限位、所有者，所属组： [root@redhat8 project]# mkdir /var/ftp/pub/tmp [root@redhat8 project]# chmod 777 /var/ftp/pub/tmp [root@redhat8 project]# ls -l /var/ftp/pub total 0 drwxr-x---. 2 christ ftpusers 18 Oct 28 04:41 christ drwxrwx---+ 3 harry ftpusers 21 Oct 28 04:43 harry drwxrwxrwx. 2 root root 6 Oct 28 09:00 tmp 用harry用户创建一个文件harry1，查看权限位、所有者，所属组，并尝试用sarah用户删除： [root@redhat8 project]# sudo -u harry touch /var/ftp/pub/tmp/harry1 [root@redhat8 project]# ls -l /var/ftp/pub/tmp total 0 -rw-r--r--. 1 harry harry 0 Oct 28 09:01 harry1 [root@redhat8 project]# sudo -u sarah rm /var/ftp/pub/tmp/harry1 rm: remove write-protected regular empty file '/var/ftp/pub/tmp/harry1'? y [root@redhat8 project]# ls -l /var/ftp/pub/tmp total 0 修改权限后，再次用harry用户创建文件harry2，查看权限位、所有者，所属组，并尝试用sarah用户删除： [root@redhat8 project]# chmod a+t /var/ftp/pub/tmp [root@redhat8 project]# ls -l /var/ftp/pub total 0 drwxr-x---. 2 christ ftpusers 18 Oct 28 04:41 christ drwxrwx---+ 3 harry ftpusers 21 Oct 28 04:43 harry drwxrwxrwt. 2 root root 6 Oct 28 09:02 tmp [root@redhat8 project]# sudo -u harry touch /var/ftp/pub/tmp/harry2 [root@redhat8 project]# ls -l /var/ftp/pub/tmp total 0 -rw-r--r--. 1 harry harry 0 Oct 28 09:03 harry2 [root@redhat8 project]# sudo -u sarah rm /var/ftp/pub/tmp/harry2 rm: remove write-protected regular empty file '/var/ftp/pub/tmp/harry2'? y rm: cannot remove '/var/ftp/pub/tmp/harry2': Operation not permitted 说明： 命令chmod u+s设置用户setuid属性，表示针对修改的目录或文件对于任何用户都有读写这个的权限 命令chmod g+s设置组setgid属性，此权限表示文件是在拥有文件的组的权限下执行的，而不是在执行文件的用户的组的权限下执行的（没有setgid的情况）。如果应用于目录，则在目录中创建的所有文件都归拥有该目录的组所有，而不是由创建文件的用户组所拥有 命令chmod o+t设置其它用户stickybit属性，主要用于目录，该位指示目录中创建的文件只能由创建该文件的用户（或root）删除 英文原文描述： sticky bit：used primarily on directories, this bit dictates that a file created in the directory can be removed only by the user that created the file. It is indicated by the character t in place of the x in the everyone category. If the everyone category does not have execute permissions, the T is capitalized to reflect this fact. setuid：used only for binary files (applications), this permission indicates that the file is to be executed with the permissions of the owner of the file, and not with the permissions of the user executing the file (which is the case without setuid). This is indicated by the character s in the place of the x in the owner category. If the owner of the file does not have execute permissions, a capital S reflects this fact. setgid：used primarily for binary files (applications), this permission indicates that the file is executed with the permissions of the group owning the file and not with the permissions of the group of the user executing the file (which is the case without setgid). If applied to a directory, all files created within the directory are owned by the group owning the directory, and not by the group of the user creating the file. The setgid permission is indicated by the character s in place of the x in the group category. If the group owning the file or directory does not have execute permissions, a capital S reflects this fact. drwxr-sr-x. 4 sarah sarah 34 Oct 15 21:27 sarah "},"05-IBM_Operating_System/05-RedHat/04-RedHat-文件和文字处理.html":{"url":"05-IBM_Operating_System/05-RedHat/04-RedHat-文件和文字处理.html","title":"RedHat-文件和文字处理","keywords":"","body":"RedHat-文件和文字处理 使用RedHat8系统学习文件处理时候记录的学习笔记。 文件链接命令ln 详细介绍及学习参考链接：https://www.runoob.com/linux/linux-comm-ln.html 软链接 使用ln命令创建软链接,并对源进行修改及删除,观察影响： [root@redhat8 linuxone]# touch test1.log [root@redhat8 linuxone]# vi test1.log [root@redhat8 linuxone]# cat test1.log link files test file [root@redhat8 linuxone]# ll total 4 -rw-r--r--. 1 root root 21 Oct 31 01:07 test1.log [root@redhat8 linuxone]# ln -s test1.log link1 [root@redhat8 linuxone]# ll total 4 lrwxrwxrwx. 1 root root 9 Oct 31 01:09 link1 -> test1.log -rw-r--r--. 1 root root 21 Oct 31 01:07 test1.log [root@redhat8 linuxone]# cat link1 link files test file [root@redhat8 linuxone]# vi test1.log [root@redhat8 linuxone]# cat test1.log link files test file try to change the source file [root@redhat8 linuxone]# cat link1 link files test file try to change the source file [root@redhat8 linuxone]# rm test1.log rm: remove regular file 'test1.log'? y [root@redhat8 linuxone]# cat link1 cat: link1: No such file or directory [root@redhat8 linuxone]# ll total 0 lrwxrwxrwx. 1 root root 9 Oct 31 01:09 link1 -> test1.log 硬链接 使用ln命令创建硬链接,并对源进行修改及删除,观察影响：： [root@redhat8 linuxone]# ll total 4 lrwxrwxrwx. 1 root root 9 Oct 31 01:09 link1 -> test1.log -rw-r--r--. 1 root root 21 Oct 31 01:17 test1.log [root@redhat8 linuxone]# cat test1.log link files test file [root@redhat8 linuxone]# ln test1.log ln1 [root@redhat8 linuxone]# ll total 8 lrwxrwxrwx. 1 root root 9 Oct 31 01:09 link1 -> test1.log -rw-r--r--. 2 root root 21 Oct 31 01:17 ln1 -rw-r--r--. 2 root root 21 Oct 31 01:17 test1.log [root@redhat8 linuxone]# cat ln1 link files test file [root@redhat8 linuxone]# vi test1.log [root@redhat8 linuxone]# cat test1.log link files test file change the source file [root@redhat8 linuxone]# cat ln1 link files test file change the source file [root@redhat8 linuxone]# rm test1.log rm: remove regular file 'test1.log'? y [root@redhat8 linuxone]# ll total 4 lrwxrwxrwx. 1 root root 9 Oct 31 01:09 link1 -> test1.log -rw-r--r--. 1 root root 44 Oct 31 01:20 ln1 [root@redhat8 linuxone]# cat ln1 link files test file change the source file 文件查找命令find 详细介绍及学习参考链接：https://www.runoob.com/linux/linux-comm-find.html 使用find命令在指定路径按文件名查找: [root@redhat8 linuxone]# find /var/log -name boot.log /var/log/boot.log 列出当前目录及其子目录下所有扩展名为log的文件: [root@redhat8 log]# find . -name \"*.log\" ./audit/audit.log ./rhsm/rhsmcertd.log ... 列出当前目录及其子目录下所有一般文件: [root@redhat8 linuxone]# find . -type f ./ln1 ./test1.log 列出当前目录及其子目录下所有最近2分钟更新过的文件： [root@redhat8 linuxone]# vi test1.log [root@redhat8 linuxone]# find . -cmin -2 . ./test1.log 查找/var/log目录中更改时间在30天以前的普通文件，并在删除前进行询问： [root@redhat8 linuxone]# find /var/log -type f -mtime +30 -ok rm {} \\; ? n ? n ? n ... 查找当前目录文件属性具有读、写权限，并且文件所属组的哦那个和和其它用户具有读权限的文件： [root@redhat8 linuxone]# find . -type f -perm 644 -exec ls -l {} \\; -rw-r--r--. 1 root root 44 Oct 31 01:20 ./ln1 -rw-r--r--. 1 root root 46 Oct 31 01:40 ./test1.log 查找系统中所有文件长度为0的不同文件，并列出它们的完整路径： [root@redhat8 linuxone]# find / -type f -size 0 -exec ls -l {} \\; -r--r--r--. 1 root root 0 Oct 31 01:46 /proc/fb -r--r--r--. 1 root root 0 Oct 31 01:46 /proc/fs/xfs/xqm -r--r--r--. 1 root root 0 Oct 31 01:46 /proc/fs/xfs/xqmstat ··· 文件查看命令 less命令 详细介绍及学习参考链接：https://www.runoob.com/linux/linux-comm-less.html 使用find命令查找后缀为.sh的文件，使用less命令查看文件内容 less `find . -name \"*.sh\"` tail命令   tail命令用于查看文件的内容，参数-f常用于查阅正在改变的日志文件。详细介绍及学习参考链接：https://www.runoob.com/linux/linux-comm-tail.html 使用tail查看日志文件/var/log/messages，并使用-n参数（显示文件的尾部n行内容 ）控制输出的行数: [root@redhat8 linuxone]# tail -n 4 /var/log/messages Oct 31 02:59:11 redhat8 dbus-daemon[899]: [system] Successfully activated service 'org.fre edesktop.nm_dispatcher'Oct 31 02:59:11 redhat8 systemd[1]: Started Network Manager Script Dispatcher Service. Oct 31 02:59:11 redhat8 nm-dispatcher[4287]: req:1 'dhcp4-change' [ens160]: new request (3 scripts)Oct 31 02:59:11 redhat8 nm-dispatcher[4287]: req:1 'dhcp4-change' [ens160]: start running ordered scripts... 使用tail查看日志文件/var/log/messages，显示从2685行至文件末尾: [root@redhat8 linuxone]# tail -n +2685 /var/log/messages Oct 31 02:59:11 redhat8 systemd[1]: Starting Network Manager Script Dispatcher Service... Oct 31 02:59:11 redhat8 dbus-daemon[899]: [system] Successfully activated service 'org.fre edesktop.nm_dispatcher'Oct 31 02:59:11 redhat8 systemd[1]: Started Network Manager Script Dispatcher Service. Oct 31 02:59:11 redhat8 nm-dispatcher[4287]: req:1 'dhcp4-change' [ens160]: new request (3 scripts)Oct 31 02:59:11 redhat8 nm-dispatcher[4287]: req:1 'dhcp4-change' [ens160]: start running ordered scripts... head命令   head命令用于查看文件的开头部分的内容，常用的参数-n用户显示查看行数。详细介绍及学习参考链接：https://www.runoob.com/linux/linux-comm-head.html 使用haead查看日志文件/var/log/messages，控制输出的行数: [root@redhat8 linuxone]# head -n 5 /var/log/messages Oct 28 04:07:02 redhat8 rsyslogd[1438]: [origin software=\"rsyslogd\" swVersion=\"8.37.0-9.el 8\" x-pid=\"1438\" x-info=\"http://www.rsyslog.com\"] rsyslogd was HUPedOct 28 04:20:00 redhat8 NetworkManager[1045]: [1603873200.6151] dhcp4 (ens160): address 192.168.18.131Oct 28 04:20:00 redhat8 NetworkManager[1045]: [1603873200.6156] dhcp4 (ens160): plen 24Oct 28 04:20:00 redhat8 NetworkManager[1045]: [1603873200.6157] dhcp4 (ens160): expires in 1800 secondsOct 28 04:20:00 redhat8 NetworkManager[1045]: [1603873200.6157] dhcp4 (ens160): nameserver '192.168.18.2' 文件编辑命令sed 详细介绍及学习参考链接：https://www.runoob.com/linux/linux-comm-sed.html 之前学习sed编辑器做的笔记：Shell笔记-sed和gawk基础 sed编辑器进阶学习笔记：Shell笔记-sed编辑器 使用sed命令屏蔽/etc/fstab文件中错误的定义行,例如如下两行定义： [root@redhat8 linuxone]# tail -n 5 /etc/fstab /dev/mapper/rhel-root / xfs defaults 0 0 UUID=0a510af6-8abf-4e64-b559-902804c93568 /boot xfs defaults 0 0/dev/mapper/rhel-swap swap swap defaults 0 0 /tmp/not-existing /mnt/not-existing iso9660 default 0 0 /tmp/test /mnt/test iso9660 default 0 0 [root@redhat8 linuxone]# mkdir /mnt/test [root@redhat8 linuxone]# mount -a mount: /mnt/not-existing: mount point does not exist. mount: /mnt/test: special device /tmp/test does not exist. 如果知道/mnt/not-existing是无效的，在输出中屏蔽示例（如需修改原文件加上-i参数）： [root@redhat8 linuxone]# sed '/mnt\\/not-existing/ s/^/# /' /etc/fstab ... # /dev/mapper/rhel-root / xfs defaults 0 0 UUID=0a510af6-8abf-4e64-b559-902804c93568 /boot xfs defaults 0 0/dev/mapper/rhel-swap swap swap defaults 0 0 #/tmp/not-existing /mnt/not-existing iso9660 default 0 0 /tmp/test /mnt/test iso9660 default 0 0 如果不知道哪些是否有效，可以mount -a查看无效项目，然后使用sed进行屏蔽： #!/bin/bash tmp=$(date +\"%y%m%d\") mount -a 2> mount$tmp.log invalid_list=`cat mount$tmp.log | sed -n '/does not exist/p'|gawk 'BEGIN{FS=\": \"}{print $2}'` echo $invalid_list for i in $invalid_list do i=`echo $i |sed 's/\\//\\\\\\&/g'` sed -i '/'$i'/ s/^/# /' /etc/fstab done 运行后查看/etc/fstab文件如下： [root@redhat8 linuxone]# tail -n 5 /etc/fstab /dev/mapper/rhel-root / xfs defaults 0 0 UUID=0a510af6-8abf-4e64-b559-902804c93568 /boot xfs defaults 0 0/dev/mapper/rhel-swap swap swap defaults 0 0 # /tmp/not-existing /mnt/not-existing iso9660 default 0 0 # /tmp/test /mnt/test iso9660 default 0 0 说明： 脚本中只找出了does not exist的两种情况，不知道mount -a报错还有没有其它情况 如需修改原文件，在使用sed命令注释时候加上-i参数 grep命令   grep比较常用，用于查找文件里符合条件的字符串,常用-i参数（忽略字符大小写的差别）。详细介绍及学习参考链接：https://www.runoob.com/linux/linux-comm-grep.html 使用grep命令列出/var/log/messages文件中包含eth的行: [root@redhat8 linuxone]# grep eth /var/log/messages Oct 31 00:58:58 redhat8 kernel: vmxnet3 0000:03:00.0 eth0: NIC Link is Up 10000 Mbps Oct 31 00:58:58 redhat8 kernel: vmxnet3 0000:03:00.0 ens160: renamed from eth0 ... [root@redhat8 linuxone]# cat /var/log/messages |grep eth Oct 31 00:58:58 redhat8 kernel: vmxnet3 0000:03:00.0 eth0: NIC Link is Up 10000 Mbps Oct 31 00:58:58 redhat8 kernel: vmxnet3 0000:03:00.0 ens160: renamed from eth0 ... "},"05-IBM_Operating_System/05-RedHat/05-RedHat-磁盘管理.html":{"url":"05-IBM_Operating_System/05-RedHat/05-RedHat-磁盘管理.html","title":"RedHat-磁盘管理","keywords":"","body":"RedHat-磁盘管理 使用RedHat8系统学习磁盘管理时候记录的学习笔记。 磁盘空间管理 磁盘空间使用情况 使用df命令查看文件系统空间使用情况，练习示例： [root@redhat8 linuxone]# df Filesystem 1K-blocks Used Available Use% Mounted on devtmpfs 909368 0 909368 0% /dev tmpfs 924716 0 924716 0% /dev/shm tmpfs 924716 9548 915168 2% /run tmpfs 924716 0 924716 0% /sys/fs/cgroup /dev/mapper/rhel-root 17811456 4183628 13627828 24% / /dev/nvme0n1p1 1038336 172892 865444 17% /boot tmpfs 184940 16 184924 1% /run/user/42 tmpfs 184940 4 184936 1% /run/user/1000 [root@redhat8 linuxone]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev tmpfs 904M 0 904M 0% /dev/shm tmpfs 904M 9.4M 894M 2% /run tmpfs 904M 0 904M 0% /sys/fs/cgroup /dev/mapper/rhel-root 17G 4.0G 13G 24% / /dev/nvme0n1p1 1014M 169M 846M 17% /boot tmpfs 181M 16K 181M 1% /run/user/42 tmpfs 181M 4.0K 181M 1% /run/user/1000 详细介绍及学习参考链接：https://www.runoob.com/linux/linux-comm-df.html 磁盘空间占用情况 使用du命令查看指定路径下文件占用情况： [root@redhat8 usr]# cd /var/log [root@redhat8 log]# du ... 3092 ./audit 108 ./rhsm 64 ./tuned 4052 ./anaconda 0 ./httpd 12544 . [root@redhat8 log]# du -s 12544 . [root@redhat8 log]# du -sm 13 . [root@redhat8 log]# du -sh 13M . [root@redhat8 /]# du -s /var/log 12544 /var/log [root@redhat8 /]# du -sh /var/log 13M /var/log 详细介绍及学习参考链接：https://www.runoob.com/linux/linux-comm-du.html 系统挂载命令 mount命令 mount命令详细介绍及学习参考链接：https://www.runoob.com/linux/linux-comm-mount.html 显示当前系统挂载情况： [root@redhat8 /]# mount sysfs on /sys type sysfs (rw,nosuid,nodev,noexec,relatime,seclabel) proc on /proc type proc (rw,nosuid,nodev,noexec,relatime) devtmpfs on /dev type devtmpfs (rw,nosuid,seclabel,size=909368k,nr_inodes=227342,mode=755) securityfs on /sys/kernel/security type securityfs (rw,nosuid,nodev,noexec,relatime) ... /etc/fstab是系统挂载定义文件，每行为一个挂载定义，格式示例如下： [root@redhat8 /]# tail -n 5 /etc/fstab /dev/mapper/rhel-root / xfs defaults 0 0 UUID=0a510af6-8abf-4e64-b559-902804c93568 /boot xfs defaults 0 0/dev/mapper/rhel-swap swap swap defaults 0 0 /tmp/not-existing /mnt/not-existing iso9660 default 0 0 /tmp/test /mnt/test iso9660 default 0 0 说明： mount命令使用只指定源设备路径或者挂载点时候，会查询/etc/fstab文件，有相同定义则执行挂载 在/etc/fstab文件的挂载定义中noauto是个特殊参数，表示系统启动时不进行自动挂载 mount -a命令会根据当前/etc/fstab文件执行挂载操作；每次修改/etc/fstab文件后必须执行此命令确认，有错误回显要及时处理，如未处理将会导致系统启动失败 使用mount命令挂载光盘示例： [root@redhat8 /]# mount /dev/cdrom /mnt mount: /mnt: WARNING: device write-protected, mounted read-only. [root@redhat8 /]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev ... tmpfs 181M 4.0K 181M 1% /run/user/1000 /dev/sr0 6.7G 6.7G 0 100% /mnt 修改/etc/fstab文件挂载光盘： [root@redhat8 /]# tail -n 1 /etc/fstab /dev/sr0 /mnt iso9660 noauto 0 0 [root@redhat8 /]# tail -n 1 /etc/fstab /dev/sr0 /mnt iso9660 noauto 0 0 [root@redhat8 /]# mount /dev/sr0 mount: /mnt: WARNING: device write-protected, mounted read-only. [root@redhat8 /]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev ... tmpfs 181M 4.0K 181M 1% /run/user/1000 /dev/sr0 6.7G 6.7G 0 100% /mnt [root@redhat8 /]# umount /mnt [root@redhat8 /]# mount /mnt mount: /mnt: WARNING: device write-protected, mounted read-only. 在/etc/fstab文件中写入无效的定义，使用mount -a命令： [root@redhat8 /]# tail -n 5 /etc/fstab UUID=0a510af6-8abf-4e64-b559-902804c93568 /boot xfs defaults 0 0/dev/mapper/rhel-swap swap swap defaults 0 0 /tmp/not-existing /mnt/not-existing iso9660 default 0 0 /tmp/test /mnt/test iso9660 default 0 0 /dev/sr0 /mnt iso9660 noauto 0 0 [root@redhat8 /]# mount -a mount: /mnt/not-existing: mount point does not exist. mount: /mnt/test: mount point does not exist. umount命令 umount命令详细介绍及学习参考链接:https://www.runoob.com/linux/linux-comm-umount.html 使用示例： [root@redhat8 /]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev ... tmpfs 181M 4.0K 181M 1% /run/user/1000 /dev/sr0 6.7G 6.7G 0 100% /mnt [root@redhat8 /]# umount /dev/sr0 [root@redhat8 /]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev ... tmpfs 181M 4.0K 181M 1% /run/user/1000 [root@redhat8 /]# mount /mnt mount: /mnt: WARNING: device write-protected, mounted read-only. [root@redhat8 /]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev ... tmpfs 181M 4.0K 181M 1% /run/user/1000 /dev/sr0 6.7G 6.7G 0 100% /mnt [root@redhat8 /]# umount /mnt [root@redhat8 /]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev ... tmpfs 181M 4.0K 181M 1% /run/user/1000 磁盘分区管理 fdisk命令 查看现有磁盘分区： [root@redhat8 /]# fdisk -l Disk /dev/nvme0n1: 20 GiB, 21474836480 bytes, 41943040 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x8b66746c ... 添加一个3G大小的磁盘： [root@redhat8 /]# fdisk -l ... Disk /dev/nvme0n2: 3 GiB, 3221225472 bytes, 6291456 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes ... 在磁盘/dev/nvme0n2上创建新的两个primary分区，一个extended分区： [root@redhat8 ~]# fdisk /dev/nvme0n2 Welcome to fdisk (util-linux 2.32.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Device does not contain a recognized partition table. Created a new DOS disklabel with disk identifier 0x1670baa7. Command (m for help): n Partition type p primary (0 primary, 0 extended, 4 free) e extended (container for logical partitions) Select (default p): p Partition number (1-4, default 1): First sector (2048-6291455, default 2048): Last sector, +sectors or +size{K,M,G,T,P} (2048-6291455, default 6291455): +1G Created a new partition 1 of type 'Linux' and of size 1 GiB. Command (m for help): n Partition type p primary (1 primary, 0 extended, 3 free) e extended (container for logical partitions) Select (default p): p Partition number (2-4, default 2): First sector (2099200-6291455, default 2099200): Last sector, +sectors or +size{K,M,G,T,P} (2099200-6291455, default 6291455): +1G Created a new partition 2 of type 'Linux' and of size 1 GiB. Command (m for help): n Partition type p primary (2 primary, 0 extended, 2 free) e extended (container for logical partitions) Select (default p): e Partition number (3,4, default 3): First sector (4196352-6291455, default 4196352): Last sector, +sectors or +size{K,M,G,T,P} (4196352-6291455, default 6291455): Created a new partition 3 of type 'Extended' and of size 1023 MiB. Command (m for help): wq The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. 查看新建的分区： [root@redhat8 ~]# fdisk -l ... Disk /dev/nvme0n2: 3 GiB, 3221225472 bytes, 6291456 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x9711dc11 Device Boot Start End Sectors Size Id Type /dev/nvme0n2p1 2048 2099199 2097152 1G 83 Linux /dev/nvme0n2p2 2099200 4196351 2097152 1G 83 Linux /dev/nvme0n2p3 4196352 6291455 2095104 1023M 5 Extended ... 删除分区示例： [root@redhat8 ~]# fdisk /dev/nvme0n2 Welcome to fdisk (util-linux 2.32.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): d Partition number (1-3, default 3): 3 Partition 3 has been deleted. Command (m for help): wq The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. 创建一个扩展分区，并在其上面创建一个逻辑分区，并指定大小： [root@redhat8 ~]# fdisk /dev/nvme0n2 Welcome to fdisk (util-linux 2.32.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): n Partition type p primary (2 primary, 0 extended, 2 free) e extended (container for logical partitions) Select (default p): e Partition number (3,4, default 3): First sector (4196352-6291455, default 4196352): Last sector, +sectors or +size{K,M,G,T,P} (4196352-6291455, default 6291455): +1000M Created a new partition 3 of type 'Extended' and of size 1000 MiB. Command (m for help): n Partition type p primary (2 primary, 1 extended, 1 free) l logical (numbered from 5) Select (default p): l Adding logical partition 5 First sector (4198400-6244351, default 4198400): Last sector, +sectors or +size{K,M,G,T,P} (4198400-6244351, default 6244351): +512M Created a new partition 5 of type 'Linux' and of size 512 MiB. Command (m for help): wq The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. 查看创建的分区： [root@redhat8 ~]# fdisk -l ... Device Boot Start End Sectors Size Id Type /dev/nvme0n2p1 2048 2099199 2097152 1G 83 Linux /dev/nvme0n2p2 2099200 4196351 2097152 1G 83 Linux /dev/nvme0n2p3 4196352 6244351 2048000 1000M 5 Extended /dev/nvme0n2p5 4198400 5246975 1048576 512M 83 Linux ... 修改分区类型： [root@redhat8 ~]# fdisk /dev/nvme0n2 Welcome to fdisk (util-linux 2.32.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): t Partition number (1-3, default 3): 2 Hex code (type L to list all codes): L ... Hex code (type L to list all codes): b Changed type of partition 'Linux' to 'W95 FAT32'. Command (m for help): wq The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. 查看分区类型： [root@redhat8 ~]# fdisk -l ... Device Boot Start End Sectors Size Id Type /dev/nvme0n2p1 2048 2099199 2097152 1G 83 Linux /dev/nvme0n2p2 2099200 4196351 2097152 1G b W95 FAT32 /dev/nvme0n2p3 4196352 6244351 2048000 1000M 5 Extended /dev/nvme0n2p5 4198400 5246975 1048576 512M 83 Linux 如果在删除或修改后，分区表没更新，可以使用partprobe命令(RedHat8自动更新，此命令没试过)。 fdisk命令详细介绍及学习参考链接:https://www.runoob.com/linux/linux-comm-fdisk.html lsbik命令 命令示例如下,对比与fdisk -l的差异：： [root@redhat8 ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sr0 11:0 1 6.6G 0 rom nvme0n1 259:0 0 20G 0 disk ├─nvme0n1p1 259:1 0 1G 0 part /boot └─nvme0n1p2 259:2 0 19G 0 part ├─rhel-root 253:0 0 17G 0 lvm / └─rhel-swap 253:1 0 2G 0 lvm [SWAP] nvme0n2 259:3 0 3G 0 disk ├─nvme0n2p1 259:4 0 1G 0 part ├─nvme0n2p2 259:5 0 1G 0 part ├─nvme0n2p3 259:10 0 1K 0 part └─nvme0n2p5 259:11 0 512M 0 part gdisk命令 gdisk用来划分GPT分区，可以划分容量大于2T的硬盘。操作和fdisk基本一致： root@redhat8 ~]# gdisk /dev/nvme0n2 GPT fdisk (gdisk) version 1.0.3 Partition table scan: MBR: MBR only BSD: not present APM: not present GPT: not present *************************************************************** Found invalid GPT and valid MBR; converting MBR to GPT format in memory. THIS OPERATION IS POTENTIALLY DESTRUCTIVE! Exit by typing 'q' if you don't want to convert your MBR partitions to GPT format! *************************************************************** Command (? for help): ? 文件系统管理 mkfs命令 直接挂载上面创建的分区： [root@redhat8 ~]# mount /dev/nvme0n2p5 mount: /dev/nvme0n2p5: can't find in /etc/fstab. 在新的逻辑分区上创建文件系统： [root@redhat8 /]# chmod -R 755 /testfs [root@redhat8 /]# mount /dev/nvme0n2p5 /testfs [root@redhat8 /]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev ... tmpfs 181M 4.0K 181M 1% /run/user/1000 /dev/nvme0n2p5 488M 416K 462M 1% /testfs 将/dev/nvme0n2p5格式化为ext3格式： [root@redhat8 ~]# mkfs -t ext3 /dev/nvme0n2p5 mke2fs 1.44.3 (10-July-2018) Creating filesystem with 131072 4k blocks and 32768 inodes Filesystem UUID: 5c591d3b-5a89-4890-a57d-103e6ab2f77f Superblock backups stored on blocks: 32768, 98304 Allocating group tables: done Writing inode tables: done Creating journal (4096 blocks): done Writing superblocks and filesystem accounting information: done 将挂载定义添加到/etc/fstab文件中，尝试挂载（刚开始提示type不对，重启下再尝试就没问题了）： [root@redhat8 /]# umount /testfs [root@redhat8 /]# vi /etc/fstab [root@redhat8 /]# tail -n 2 /etc/fstab # /dev/sr0 /mnt iso9660 noauto 0 0 /dev/nvme0n2p5 /testfs ext3 default 0 0 [root@redhat8 ~]# mount -a [root@redhat8 ~]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev ... tmpfs 181M 4.0K 181M 1% /run/user/1000 /dev/nvme0n2p5 488M 416K 462M 1% /testfs mkfs命令详细介绍:https://www.runoob.com/linux/linux-comm-mkfs.html blkid命令 使用UUID方式在/etc/fstab文件中挂载文件系统： [root@redhat8 /]# blkid /dev/nvme0n2p5 /dev/nvme0n2p5: UUID=\"f3ad8520-7468-4ec3-938c-39a2fee46fef\" SEC_TYPE=\"ext2\" TYPE=\"ext3\" PA RTUUID=\"9711dc11-05\" [root@redhat8 ~]# tail -n 3 /etc/fstab # /dev/sr0 /mnt iso9660 noauto 0 0 # /dev/nvme0n2p5 /testfs ext3 defaults 0 0 UUID=f3ad8520-7468-4ec3-938c-39a2fee46fef /testfs ext3 defaults 0 0 [root@redhat8 ~]# mount -a [root@redhat8 ~]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev ... tmpfs 181M 4.0K 181M 1% /run/user/1000 /dev/nvme0n2p5 488M 416K 462M 1% /testfs 交换空间管理 查看并新建swap空间： [root@redhat8 ~]# swapon NAME TYPE SIZE USED PRIO /dev/dm-1 partition 2G 0B -2 [root@redhat8 ~]# swapon /dev/nvme0n2p6 [root@redhat8 ~]# swapon NAME TYPE SIZE USED PRIO /dev/dm-1 partition 2G 0B -2 /dev/nvme0n2p6 partition 128M 0B -3 [root@redhat8 ~]# free total used free shared buff/cache available Mem: 1849432 682100 645680 9772 521652 988268 Swap: 2228216 0 2228216 关系新增的swap： [root@redhat8 ~]# swapoff /dev/nvme0n2p6 [root@redhat8 ~]# swapon NAME TYPE SIZE USED PRIO /dev/dm-1 partition 2G 0B -2 [root@redhat8 ~]# free total used free shared buff/cache available Mem: 1849432 682136 645624 9772 521672 988232 Swap: 2097148 0 2097148 swapon命令详细介绍:https://www.runoob.com/linux/linux-comm-swapon.htmlmkswap命令详细介绍:https://www.runoob.com/linux/linux-comm-mkswap.htmlfree命令详细介绍:https://www.runoob.com/linux/linux-comm-free.htmlswapoff命令详细介绍:https://www.runoob.com/linux/linux-comm-swapoff.html 分区扩容 非LVM环境下分区 示例扩容/dev/nvme0n2p5: [root@redhat8 /]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev ... /dev/nvme0n2p5 488M 416K 462M 1% /testfs [root@redhat8 testfs]# ls link1 ln1 lost+found mount201031.log mount.log test1.log test2.sh test3.sh [root@redhat8 testfs]# fdisk -l ... Device Boot Start End Sectors Size Id Type /dev/nvme0n2p1 2048 2099199 2097152 1G 83 Linux /dev/nvme0n2p2 2099200 4196351 2097152 1G b W95 FAT32 /dev/nvme0n2p3 4196352 6244351 2048000 1000M 5 Extended /dev/nvme0n2p5 4198400 5246975 1048576 512M 83 Linux [root@redhat8 /]# umount /testfs [root@redhat8 /]# fdisk /dev/nvme0n2 Welcome to fdisk (util-linux 2.32.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): d Partition number (1-3,5, default 5): Partition 5 has been deleted. Command (m for help): n Partition type p primary (2 primary, 1 extended, 1 free) l logical (numbered from 5) Select (default p): l Adding logical partition 5 First sector (4198400-6244351, default 4198400): Last sector, +sectors or +size{K,M,G,T,P} (4198400-6244351, default 6244351): +700M Created a new partition 5 of type 'Linux' and of size 700 MiB. Partition #5 contains a ext3 signature. Do you want to remove the signature? [Y]es/[N]o: N Command (m for help): wq The partition table has been altered. Calling ioctl() to re-read partition table. Syncing disks. [root@redhat8 testfs]# fdisk -l ... Device Boot Start End Sectors Size Id Type /dev/nvme0n2p1 2048 2099199 2097152 1G 83 Linux /dev/nvme0n2p2 2099200 4196351 2097152 1G b W95 FAT32 /dev/nvme0n2p3 4196352 6244351 2048000 1000M 5 Extended /dev/nvme0n2p5 4198400 5631999 1433600 700M 83 Linux [root@redhat8 /]# mount /testfs [root@redhat8 /]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev ... tmpfs 181M 4.0K 181M 1% /run/user/1000 /dev/nvme0n2p5 488M 444K 462M 1% /testfs [root@redhat8 ~]# ls /testfs link1 ln1 lost+found mount201031.log mount.log test1.log test2.sh test3.sh   虽然看到/dev/nvme0n2p5分区大小改变了，数据虽然没丢，但是挂载文件系统后大小还是原来的，重新启动系统后一样没改变（应该不需要重启），检查文件系统以及变更文件系统大小后，就可以了： [root@redhat8 ~]# e2fsck -f /dev/nvme0n2p5 e2fsck 1.44.3 (10-July-2018) Pass 1: Checking inodes, blocks, and sizes Pass 2: Checking directory structure Pass 3: Checking directory connectivity Pass 4: Checking reference counts Pass 5: Checking group summary information /dev/nvme0n2p5: 18/32768 files (0.0% non-contiguous), 6269/131072 blocks [root@redhat8 ~]# resize2fs /dev/nvme0n2p5 resize2fs 1.44.3 (10-July-2018) Resizing the filesystem on /dev/nvme0n2p5 to 179200 (4k) blocks. The filesystem on /dev/nvme0n2p5 is now 179200 (4k) blocks long. [root@redhat8 ~]# mount -a [root@redhat8 ~]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev ... tmpfs 181M 4.0K 181M 1% /run/user/1000 /dev/nvme0n2p5 672M 568K 637M 1% /testfs [root@redhat8 ~]# ls /testfs link1 ln1 lost+found mount201031.log mount.log test1.log test2.sh test3.sh [root@redhat8 ~]# cat /testfs/ln1 link files test file change the source file LVM环境下扩容   对于在VG中的逻辑卷扩容，如果VG容量足够，使用lvextend命令进行扩容，如果VG容量不够，划分新磁盘过来，创建新的分区，然后用vgextend命令先对VG进行扩容，然后再扩容逻辑卷。参考文档:https://blog.csdn.net/chongxin1/article/details/76072071/。 扩展物理磁盘 VMware上将/dev/nvme0n1原本只有20G的磁盘扩展到40G： [root@redhat8 ~]# fdisk -l Disk /dev/nvme0n1: 40 GiB, 42949672960 bytes, 83886080 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x8b66746c Device Boot Start End Sectors Size Id Type /dev/nvme0n1p1 * 2048 2099199 2097152 1G 83 Linux /dev/nvme0n1p2 2099200 41943039 39843840 19G 8e Linux LVM Disk /dev/nvme0n2: 3 GiB, 3221225472 bytes, 6291456 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x9711dc11 Device Boot Start End Sectors Size Id Type /dev/nvme0n2p1 2048 2099199 2097152 1G 83 Linux /dev/nvme0n2p2 2099200 4196351 2097152 1G b W95 FAT32 /dev/nvme0n2p3 4196352 6244351 2048000 1000M 5 Extended /dev/nvme0n2p5 4198400 5631999 1433600 700M 83 Linux /dev/nvme0n2p6 5634048 5838847 204800 100M 83 Linux Disk /dev/mapper/rhel-root: 17 GiB, 18249416704 bytes, 35643392 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk /dev/mapper/rhel-swap: 2 GiB, 2147483648 bytes, 4194304 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes 新建扩展分区 新建示例如下： [root@redhat8 ~]# fdisk /dev/nvme0n1 Welcome to fdisk (util-linux 2.32.1). Changes will remain in memory only, until you decide to write them. Be careful before using the write command. Command (m for help): n Partition type p primary (2 primary, 0 extended, 2 free) e extended (container for logical partitions) Select (default p): e Partition number (3,4, default 3): First sector (41943040-83886079, default 41943040): Last sector, +sectors or +size{K,M,G,T,P} (41943040-83886079, default 83886079): Created a new partition 3 of type 'Extended' and of size 20 GiB. Command (m for help): p Disk /dev/nvme0n1: 40 GiB, 42949672960 bytes, 83886080 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x8b66746c Device Boot Start End Sectors Size Id Type /dev/nvme0n1p1 * 2048 2099199 2097152 1G 83 Linux /dev/nvme0n1p2 2099200 41943039 39843840 19G 8e Linux LVM /dev/nvme0n1p3 41943040 83886079 41943040 20G 5 Extended Command (m for help): 新建逻辑分区 继续上面的配置： Command (m for help): n All space for primary partitions is in use. Adding logical partition 5 First sector (41945088-83886079, default 41945088): Last sector, +sectors or +size{K,M,G,T,P} (41945088-83886079, default 83886079): Created a new partition 5 of type 'Linux' and of size 20 GiB. Command (m for help): p Disk /dev/nvme0n1: 40 GiB, 42949672960 bytes, 83886080 sectors Units: sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disklabel type: dos Disk identifier: 0x8b66746c Device Boot Start End Sectors Size Id Type /dev/nvme0n1p1 * 2048 2099199 2097152 1G 83 Linux /dev/nvme0n1p2 2099200 41943039 39843840 19G 8e Linux LVM /dev/nvme0n1p3 41943040 83886079 41943040 20G 5 Extended /dev/nvme0n1p5 41945088 83886079 41940992 20G 83 Linux Command (m for help): w The partition table has been altered. Failed to add partition 5 to system: Device or resource busy The kernel still uses the old partitions. The new table will be used at the next reboot. Syncing disks. 保存退出，重启生效。 创建PV 创建PV示例如下： [root@redhat8 ~]# pvcreate /dev/nvme0n1p5 Physical volume \"/dev/nvme0n1p5\" successfully created. [root@redhat8 ~]# pvdisplay /dev/nvme0n1p5 \"/dev/nvme0n1p5\" is a new physical volume of \"扩容VG 查看VG信息： [root@redhat8 ~]# vgdisplay --- Volume group --- VG Name rhel System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 3 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 1 Act PV 1 VG Size 扩容VG： [root@redhat8 ~]# vgextend rhel /dev/nvme0n1p5 Volume group \"rhel\" successfully extended [root@redhat8 ~]# vgdisplay /dev/nvme0n1p5 Volume group \"nvme0n1p5\" not found Cannot process volume group nvme0n1p5 [root@redhat8 ~]# vgdisplay rhel --- Volume group --- VG Name rhel System ID Format lvm2 Metadata Areas 2 Metadata Sequence No 4 VG Access read/write VG Status resizable MAX LV 0 Cur LV 2 Open LV 2 Max PV 0 Cur PV 2 Act PV 2 VG Size 38.99 GiB PE Size 4.00 MiB Total PE 9982 Alloc PE / Size 4863 / LV扩容 查看LV信息： [root@redhat8 ~]# lvdisplay /dev/mapper/rhel-root --- Logical volume --- LV Path /dev/rhel/root LV Name root VG Name rhel LV UUID loJnjf-uQzE-xiMJ-CC18-pox2-Af8J-KItLXi LV Write Access read/write LV Creation host, time redhat8, 2020-07-19 12:12:10 -0400 LV Status available # open 1 LV Size 扩容LV： [root@redhat8 ~]# lvextend -L +19G /dev/mapper/rhel-root Size of logical volume rhel/root changed from 扩容文件系统 扩容文件系统： [root@redhat8 ~]# xfs_growfs / meta-data=/dev/mapper/rhel-root isize=512 agcount=4, agsize=1113856 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=1, sparse=1, rmapbt=0 = reflink=1 data = bsize=4096 blocks=4455424, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0, ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 4455424 to 9436160 查看确认： [root@redhat8 ~]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev tmpfs 904M 0 904M 0% /dev/shm tmpfs 904M 9.4M 894M 2% /run tmpfs 904M 0 904M 0% /sys/fs/cgroup /dev/mapper/rhel-root 36G 8.0G 29G 23% / /dev/nvme0n1p1 1014M 169M 846M 17% /boot /dev/nvme0n2p5 672M 568K 637M 1% /testfs tmpfs 181M 16K 181M 1% /run/user/42 tmpfs 181M 4.0K 181M 1% /run/user/1000 待补充 "},"05-IBM_Operating_System/05-RedHat/20-RedHat-常用软件安装.html":{"url":"05-IBM_Operating_System/05-RedHat/20-RedHat-常用软件安装.html","title":"RedHat-常用软件安装","keywords":"","body":"RedHat-常用软件安装 其它软件 Cmatrix屏保 下载Cmatrix源码包：https://github.com/abishekvashok/cmatrix/releases解压压源码包： [root@VM-0-6-centos tmp]# tar -zxvf cmatrix-2.0.tar.gz [root@VM-0-6-centos tmp]# cd cmatrix-2.0 [root@VM-0-6-centos cmatrix-2.0]# ./configure Make报错： [root@VM-0-6-centos cmatrix]# make CDPATH=\"${ZSH_VERSION+.}:\" && cd . && /bin/sh /root/tmp/cmatrix/missing aclocal-1.16 /root/tmp/cmatrix/missing: line 81: aclocal-1.16: command not found WARNING: 'aclocal-1.16' is missing on your system. You should only need it if you modified 'acinclude.m4' or 'configure.ac' or m4 files included by 'configure.ac'. The 'aclocal' program is part of the GNU Automake package: It also requires GNU Autoconf, GNU m4 and Perl in order to run: make: *** [aclocal.m4] Error 127 automake下载地址：http://ftp.gnu.org/gnu/automake/ 安装： [root@VM-0-6-centos tmp]# tar -zxvf automake-1.16.tar.gz [root@VM-0-6-centos tmp]# cd automake-1.16 [root@VM-0-6-centos automake-1.16]# ./configure ... configure: error: Autoconf 2.65 or better is required. ... yum安装Autoconf： [root@VM-0-6-centos automake-1.16]# yum install autoconf 安装成功后继续安装automake： [root@VM-0-6-centos automake-1.16]# make ... help2man: can't get `--help' info from automake-1.16 Try `--no-discard-stderr' if option outputs to stderr make: *** [doc/automake-1.16.1] Error 255 编辑Makefile源文件 [root@VM-0-6-centos automake-1.16]# vi Makefile.in 修改后如下： doc/aclocal-$(APIVERSION).1: $(aclocal_script) lib/Automake/Config.pm $(update_mans) aclocal-$(APIVERSION) doc/automake-$(APIVERSION).1: $(automake_script) lib/Automake/Config.pm $(update_mans) automake-$(APIVERSION) --no-discard-stderr 参考链接：https://blog.csdn.net/developerof/article/details/88206384 再次make，成功： [root@VM-0-6-centos automake-1.16]# make cd . && /bin/sh ./config.status Makefile config.status: creating Makefile GEN bin/automake GEN bin/aclocal GEN bin/aclocal-1.16 GEN bin/automake-1.16 GEN t/ax/shell-no-trail-bslash GEN t/ax/cc-no-c-o GEN runtest GEN lib/Automake/Config.pm GEN doc/aclocal-1.16.1 GEN doc/automake-1.16.1 GEN t/ax/test-defs.sh [root@VM-0-6-centos automake-1.16]# make install 回到Cmatrix目录，继续make，报错： [root@VM-0-6-centos cmatrix]# make cd . && /bin/sh /root/tmp/cmatrix/missing automake-1.16 --gnu \"none\" is not exported by the List::Util module Can't continue after import errors at /usr/local/bin/automake-1.16 line 76. BEGIN failed--compilation aborted at /usr/local/bin/automake-1.16 line 76. make: *** [Makefile.in] Error 1 将提示中文件76行use List::Util 'none';改为use List::Util;： [root@VM-0-6-centos bin]# vi /usr/local/bin/automake-1.16 继续安装Cmatrix： [root@VM-0-6-centos cmatrix]# make ... cmatrix.c:43:20: fatal error: curses.h: No such file or directory #include ^ compilation terminated. make[1]: *** [cmatrix.o] Error 1 make[1]: Leaving directory `/root/tmp/cmatrix' 需要安装libncurses5-dev： [root@VM-0-6-centos cmatrix]# yum install ncurses-libs [root@VM-0-6-centos cmatrix]# yum install ncurses-devel 参考链接：https://zhidao.baidu.com/question/624814867542104324.html 继续安装cmatrix： [root@VM-0-6-centos cmatrix]# make make all-am make[1]: Entering directory `/root/tmp/cmatrix' gcc -DHAVE_CONFIG_H -I. -g -O2 -MT cmatrix.o -MD -MP -MF .deps/cmatrix.Tpo -c -o c matrix.o cmatrix.cmv -f .deps/cmatrix.Tpo .deps/cmatrix.Po gcc -g -O2 -o cmatrix cmatrix.o -lncurses -lncurses make[1]: Leaving directory `/root/tmp/cmatrix' [root@VM-0-6-centos cmatrix]# make install make[1]: Entering directory `/root/tmp/cmatrix' /usr/bin/mkdir -p '/usr/local/bin' /usr/bin/install -c cmatrix '/usr/local/bin' Installing matrix fonts in /usr/lib/kbd/consolefonts... /usr/bin/mkdir -p '/usr/local/share/man/man1' /usr/bin/install -c -m 644 cmatrix.1 '/usr/local/share/man/man1' make[1]: Leaving directory `/root/tmp/cmatrix' [root@VM-0-6-centos cmatrix]# cmatrix 至此成功安装。 待补充 "},"05-IBM_Operating_System/05-RedHat/21-RedHat-常见问题.html":{"url":"05-IBM_Operating_System/05-RedHat/21-RedHat-常见问题.html","title":"RedHat-常见问题","keywords":"","body":"RedHat-常见问题 应急模式 文件系统挂载异常 进入系统后，提示如下： You are in emergency mode.After logging in,type \"journalctl -xb\" to view system logs,\"systemctl reboot\" to reboot,\"systemctl default\" or \"exit\" to boot into default mode.   一般是挂载磁盘或者文件系统出现问题，根据提示输入journalctl -xb查看logs，查找fsck failed,如果能找到可以找到对应磁盘进行fsck修复，然后重启。如果没有，可能是文件系统挂载出现问题，此次我遇到的是文件系统挂载问题，在/etc/fstab中异常的条目： /dev/sr0 /var/ftp/pub/rhel7 iso9660 loop 0 0 注释掉然后运行命令systemctl reboot重启即可。 YUM源问题 YUM 配置阿里YUM源成功： [root@redhat8 yum.repos.d]# wget https://mirrors.aliyun.com/repo/Centos-8.repo --2022-05-14 11:25:49-- https://mirrors.aliyun.com/repo/Centos-8.repo Resolving mirrors.aliyun.com (mirrors.aliyun.com)... 117.21.230.243, 117.21.230.244, 117.21.230.239, ... Connecting to mirrors.aliyun.com (mirrors.aliyun.com)|117.21.230.243|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 2600 (2.5K) [application/octet-stream] Saving to: ‘Centos-8.repo’ Centos-8.repo 100%[=================================================>] 2.54K --.-KB/s in 0s 2022-05-14 11:25:49 (29.3 MB/s) - ‘Centos-8.repo’ saved [2600/2600] 查看有报错，并且安装软件不行： [root@redhat8 yum.repos.d]# yum repolist Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscription-manager to register. CentOS-8 - AppStream - mirrors.aliyun.com 0.0 B/s | 0 B 00:24 CentOS-8 - Base - mirrors.aliyun.com 0.0 B/s | 0 B 00:24 Failed to synchronize cache for repo 'AppStream', ignoring this repo. Failed to synchronize cache for repo 'base', ignoring this repo. Last metadata expiration check: 0:12:34 ago on Sat 14 May 2022 12:32:44 PM EDT. repo id repo name status extras CentOS-8 - Extras - mirrors.aliyuncom 39 修改掉阿里YUM源文件名称： [root@redhat8 yum.repos.d]# mv Centos-8.repo Centos-8.repo.bk 获取华为的YUM源安装文件： [root@redhat8 yum.repos.d]# wget https://repo.huaweicloud.com/epel/epel-release-latest-7.noarch.rpm --2022-05-14 12:53:26-- https://repo.huaweicloud.com/epel/epel-release-latest-7.noarch.rpm Resolving repo.huaweicloud.com (repo.huaweicloud.com)... 182.106.149.164, 182.106.149.160, 182.106.149.161, ... Connecting to repo.huaweicloud.com (repo.huaweicloud.com)|182.106.149.164|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 15608 (15K) [application/x-redhat-package-manager] Saving to: ‘epel-release-latest-7.noarch.rpm’ epel-release-latest-7.noarch.r 100%[=================================================>] 15.24K --.-KB/s in 0s 2022-05-14 12:53:26 (122 MB/s) - ‘epel-release-latest-7.noarch.rpm’ saved [15608/15608] [root@redhat8 yum.repos.d]# ls Centos-8.repo.bk epel-release-latest-7.noarch.rpm redhat8.repo.bk redhat.repo 安装华为YUM源： [root@redhat8 yum.repos.d]# rpm -ivh --nodeps epel-release-latest-7.noarch.rpm warning: epel-release-latest-7.noarch.rpm: Header V4 RSA/SHA256 Signature, key ID 352c64e5: NOKEY Verifying... ################################# [100%] Preparing... ################################# [100%] Updating / installing... 1:epel-release-7-14 ################################# [100%] [root@redhat8 yum.repos.d]# ls Centos-8.repo.bk epel-release-latest-7.noarch.rpm epel.repo epel-testing.repo redhat8.repo.bk redhat.repo 将epel.repo文件中的#baseurl替换成baseurl： [root@redhat8 yum.repos.d]# sed -i \"s/#baseurl/baseurl/g\" /etc/yum.repos.d/epel.repo 刷新yum源缓存： [root@redhat8 yum.repos.d]# yum clean all Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscription-manager to register. 5 files removed [root@redhat8 yum.repos.d]# yum makecache Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscription-manager to register. Extra Packages for Enterprise Linux 7 - x86_64 944 kB/s | 17 MB 00:18 Last metadata expiration check: 0:00:05 ago on Sat 14 May 2022 12:59:33 PM EDT. Metadata cache created. 再次查看： [root@redhat8 yum.repos.d]# yum repolist Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscription-manager to register. Last metadata expiration check: 0:00:37 ago on Sat 14 May 2022 12:59:33 PM EDT. repo id repo name status *epel Extra Packages for Enterprise Linux 7 - x86_64 13,755 华为官网参考链接：配置yum源 磁盘问题 文件系统扩容问题 Bad magic number 对/文件系统进行扩容： [root@redhat8 ~]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev tmpfs 904M 0 904M 0% /dev/shm tmpfs 904M 9.4M 894M 2% /run tmpfs 904M 0 904M 0% /sys/fs/cgroup /dev/mapper/rhel-root 17G 7.9G 9.2G 47% / /dev/nvme0n1p1 1014M 169M 846M 17% /boot /dev/nvme0n2p5 672M 568K 637M 1% /testfs tmpfs 181M 16K 181M 1% /run/user/42 tmpfs 181M 4.0K 181M 1% /run/user/1000 报错如下： [root@redhat8 ~]# resize2fs /dev/mapper/rhel-root resize2fs 1.44.3 (10-July-2018) resize2fs: Bad magic number in super-block while trying to open /dev/mapper/rhel-root Couldn't find valid filesystem superblock. 检查发现是xfs文件系统： [root@redhat8 ~]# mount |grep root /dev/mapper/rhel-root on / type xfs (rw,relatime,seclabel,attr2,inode64,noquota) 使用xfs文件系统相关命令，依旧报错： [root@redhat8 ~]# xfs_growfs /dev/mapper/rhel-root xfs_growfs: /dev/mapper/rhel-root is not a mounted XFS filesystem 命令xfs_growfs版本新旧使用方法不一样问题，可以查看命令描述。解决示例： [root@redhat8 ~]# xfs_growfs / meta-data=/dev/mapper/rhel-root isize=512 agcount=4, agsize=1113856 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=1, sparse=1, rmapbt=0 = reflink=1 data = bsize=4096 blocks=4455424, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0, ftype=1 log =internal log bsize=4096 blocks=2560, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 data blocks changed from 4455424 to 9436160 查看确认： [root@redhat8 ~]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev tmpfs 904M 0 904M 0% /dev/shm tmpfs 904M 9.4M 894M 2% /run tmpfs 904M 0 904M 0% /sys/fs/cgroup /dev/mapper/rhel-root 36G 8.0G 29G 23% / /dev/nvme0n1p1 1014M 169M 846M 17% /boot /dev/nvme0n2p5 672M 568K 637M 1% /testfs tmpfs 181M 16K 181M 1% /run/user/42 tmpfs 181M 4.0K 181M 1% /run/user/1000 问题解决参考链接： resize2fs: Bad magic number in super-block while trying to open /dev/centos/root Couldn't find valid 在线扩容CentOS 8系统盘报“xfs_growfs:is not a mounted XFS filesystem”错误 Bug 1885875 - xfs_growfs: /dev/mapper/rhel-root is not a mounted XFS filesystem 网络问题 误删网卡 使用如下命令不小心删除了网口： [root@redhat8 ~]# nmcli con del ens160 Connection closed by foreign host. 检查在/etc/sysconfig/network-scripts/下面已经没有配置文件，如果有备份，可以尝试直接恢复配置文件。最简单有效方法是在线重新配置，示例如下： [root@redhat8 network-scripts]# nmcli con add con-name ens160 type ethernet \\ ifname ens160 ipv4.address 192.168.100.131/24 Connection 'ens160' (7bd7a46c-0bdb-485d-a80f-f27f1efc5799) successfully added. 检查网络配置： [root@redhat8 ~]# ip add show ens160 2: ens160: mtu 1500 qdisc mq state UP group defaul t qlen 1000 link/ether 00:0c:29:ee:ed:0e brd ff:ff:ff:ff:ff:ff inet 192.168.100.130/24 brd 192.168.100.255 scope global dynamic noprefixroute e ns160 valid_lft 1748sec preferred_lft 1748sec inet 192.168.100.131/24 brd 192.168.100.255 scope global secondary noprefixroute ens160 valid_lft forever preferred_lft forever inet6 fe80::e79e:afd7:7aa5:8207/64 scope link noprefixroute valid_lft forever preferred_lft forever 检查配置文件也恢复了： [root@redhat8 ~]# ls -l /etc/sysconfig/network-scripts/ total 4 -rw-r--r--. 1 root root 315 May 29 14:11 ifcfg-ens160 用户问题 用户登录问题 SSH服务器拒绝了密码   新安装系统，SSHD服务正常开启，但是SSH登录不了，需要修改/etc/ssh/sshd_config文件相关配置，首先打开22端口监听： Port 22 #AddressFamily any ListenAddress 0.0.0.0 ListenAddress :: 允许远程登录： PermitRootLogin yes 密码认证开启： PasswordAuthentication yes #PermitEmptyPasswords no 找不到匹配的host key算法   OpenSSH版本过高，而shell终端上没有对应的加密算法。例如RHEL9.0默认是OpenSSH_8.7p1版本。需要升级shell终端，例如使用Xshell6版本，或者使用其它版本shell终端。 登录问题 ssh-copy-id命令报错 报错如下： /usr/bin/ssh-copy-id: ERROR: No identities found 使用ssh-keygen -t dsa生成公钥后即可。 待补充 "},"05-IBM_Operating_System/06-RHEL学习笔记/":{"url":"05-IBM_Operating_System/06-RHEL学习笔记/","title":"RHEL学习笔记","keywords":"","body":"RHEL学习笔记 简介   红帽企业Linux(RHEL)是红帽提供的、受商业支持的企业就绪型Linux发行版。它是开源计算的领先平台，而不仅仅是成熟开源项目的集合。RHEL经过广泛测试，拥有庞大的合作伙伴生态系统、硬件和软件认证、咨询服务、培训以及为期多年的支持和维护保障。 官方网站：Red Hat Enterprise Linux 下载评估版本来试用红帽企业Linux：Red Hat Enterprise Linux Server RHEL官方下载链接：Download Red Hat Enterprise Linux 本章节是在官网学习RHEL记录的笔记。 内容 "},"05-IBM_Operating_System/06-RHEL学习笔记/01-RHEL-基础命令及操作.html":{"url":"05-IBM_Operating_System/06-RHEL学习笔记/01-RHEL-基础命令及操作.html","title":"RHEL-基础命令及操作","keywords":"","body":"RHEL-基础命令及操作 复习已知知识，记录学到的新知识。 RHEL中获取帮助 man page   本地系统上通常可用的一个文档源是系统手册页，或称为man page。这些手册页是作为文档所涉及的相应软件包的一部分而提供的，使用man命令从命令行进行访问。Man Page导航： 命令 描述 Space 向前（向下）滚动一个屏幕 PageDown 向前（向下）滚动一个屏幕 PageUp 向后（向上）滚动一个屏幕 DownArrow 向前（向下）滚动一行 UpArrow 向后（向上）滚动一行 D 向前（向下）滚动半个屏幕 U 向后（向上）滚动半个屏幕 /string 在man page中向前（向下）搜索string N 在man page中重复之前的向前（向下）搜索 Shift+N 在man page中重复之前的向后（向上）搜索 G 转到man page的开头。 Shift+G 转到man page的末尾。 Q 退出man，并返回到命令shell提示符   通过man -k keyword对man page执行关键字搜索，会显示与关键字匹配的man page主题和章节编号的列表。man page常见的标题有： 标题 描述 NAME 主题名称。通常是命令或文件名。非常简短的描述 SYNOPSIS 命令语法的概要 DESCRIPTION 提供对主题的基本理解的深度描述 OPTIONS 命令执行选项的说明 EXAMPLES 有关如何使用命令、功能或文件的示例 FILES 与man page相关的文件和目录的列表 SEE ALSO 相关的信息，通常是其他man page主题 BUGS 软件中的已知错误。 AUTHOR 有关参与编写该主题的人员的信息 使用man -k zip命令来列出关于ZIP存档的详细信息： [student@workstation ~]$ man -k zip ...output omitted... zipinfo (1) - list detailed information about a ZIP archive zipnote (1) - write the comments in zipfile to stdout, edit comments and rename files in zipfile zipsplit (1) - split a zipfile into smaller zipfiles   所有man page都位于/usr/share/man。使用whereis命令，查找位于/usr/share/man目录中的二进制文件、源代码和man page。示例： [root@redhat8 ~]# whereis ls ls: /usr/bin/ls /usr/share/man/man1/ls.1.gz /usr/share/man/man1p/ls.1p.gz 使用man -t命令，创建lsman page的格式化文件。 [root@redhat8 ~]# man -t ls >ls.ps [root@redhat8 ~]# ls -al total 1956 -rw-r--r--. 1 root root 20051 May 2 14:39 ls.ps [root@redhat8 ~]# file ~/ls.ps /root/ls.ps: PostScript document text conforming DSC level 3.0 阅读Info文档   man page的格式作为命令参考时很有用，但作为普通文档却用处不大。对于此类文档，GNU项目开发了一种不同的在线文档系统，称为GNU Info。Info文档是Red Hat Enterprise Linux系统上重要的资源。要启动Info文档查看器，可使用pinfo命令。pinfo会在顶级目录中打开： [root@redhat8 ~]# man passwd [root@redhat8 ~]# pinfo passwd 命令及命令行基础 编辑命令行   以交互方式使用时，bash具有命令行编辑功能。可以使用文本编辑器命令在当前键入的命令内移动并进行修改，也可访问命令历史记录。命令行编辑实用快捷键如下表： 快捷键 描述 Ctrl+A 跳到命令行的开头 Ctrl+E 跳到命令行的末尾 Ctrl+U 将光标处到命令行开头的内容清除 Ctrl+K 将光标处到命令行末尾的内容清除 Ctrl+LeftArrow 跳到命令行中前一字的开头 Ctrl+RightArrow 跳到命令行中下一字的末尾 Ctrl+R 在历史记录列表中搜索某一模式的命令 基础命令 date命令   date命令可显示当前的日期和时间，也可以用它来设置系统时钟。以加号+开头的参数可指定日期命令的格式字符串： [root@redhat8 ~]# date Sun May 1 07:48:59 EDT 2022 [root@redhat8 ~]# date +%R 07:49 [root@redhat8 ~]# date +%x 05/01/2022 [root@redhat8 ~]# date +%r 07:51:04 AM [root@redhat8 ~]# date +%s 1651512964 date命令还可用于计算未来的日期，示例： [root@redhat8 ~]# date -d \"+100 days\" -u Sat Aug 13 08:23:57 UTC 2022 示例中，-u选项报告UTC时间。 passwd命令 passwd命令更改用户自己的密码。必须指定该帐户的原始密码，之后才允许进行更改： 默认情况下，需要强密码，其包含小写字母、大写字母、数字和符号， 并且不以字典中的单词为基础 超级用户可以使用passwd命令更改其他用户的密码 file命令   Linux不需要文件扩展名来根据类型分类文件。file命令可以扫描文件内容的开头，显示该文件的类型。要分类的文件作为参数传递至该命令： [root@redhat8 ~]# file /etc/passwd /etc/passwd: ASCII text [root@redhat8 ~]# file /bin/passwd /bin/passwd: setuid ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, interpreter / lib64/ld-linux-x86-64.so.2, for GNU/Linux 3.2.0, BuildID[sha1]=a3637110e27e9a48dced9f38b4ae43388d32d0e4, stripped[root@redhat8 ~]# file /var /var: directory cat命令   命令cat可以创建单个或多个文件，查看文件内容，串联多个文件中的内容，以及将文件内容重定向到终端或文件。查看多个文件时候使用空格间隔，示例如下： [root@redhat8 ~]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 [root@redhat8 ~]# cat /etc/hosts /etc/passwd 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin ...output omitted... less命令   less命令允许在篇幅超过一个终端窗口适合大小的文件中向前和向后翻页。使用UpArrow键和DownArrow键可向上和向下滚动显示。按q键退出该命令。 head及tail命令   head和tail命令分别显示文件的开头和结尾部分。默认情况下显示文件的10行，都有-n选项用来指定不同的行数。要显示的文件作为参数传递至这些命令： [root@redhat8 ~]# head -n 3 /etc/passwd root:x:0:0:root:/root:/bin/bash bin:x:1:1:bin:/bin:/sbin/nologin daemon:x:2:2:daemon:/sbin:/sbin/nologin [root@redhat8 ~]# tail -n 2 /etc/passwd harry:x:1005:1005::/home/harry:/bin/bash sarah:x:1006:1006::/home/sarah:/sbin/nologin wc命令   wc命令可计算文件中行、字和字符的数量。它接受-l、-w或-c选项，分别用于仅显示行数、字数或字符数： [root@redhat8 ~]# wc /etc/passwd 52 112 2814 /etc/passwd [root@redhat8 ~]# wc -l /etc/shadow ; wc -l /etc/passwd 52 /etc/shadow 52 /etc/passwd [root@redhat8 ~]# wc -c /etc/hosts /etc/group 158 /etc/hosts 1087 /etc/group 1245 total history命令   history命令显示之前执行的命令的列表，带有命令编号作为前缀。感叹号字符!是元字符，用于扩展之前的命令而不必重新键入它们。!number命令扩展至与指定编号匹配的命令。!string命令扩展至最近一个以指定字符串开头的命令： [user@host ~]$ history ...output omitted... 510 file /var 511 wc /etc/passwd 512 wc -l /etc/shadow ; wc -l /etc/passwd 513 wc -c /etc/hosts /etc/group 514 ls -l 515 pwd 516 history [root@redhat8 ~]# !ls ls -l total 1856 -rw-------. 1 root root 1364 Jul 19 2020 anaconda-ks.cfg drwxr-xr-x. 2 root root 6 Mar 19 2021 Desktop ...output omitted... [root@redhat8 ~]# !515 pwd /root 更多使用说明： 方向键可用于在shell历史记录中的以往命令之间导航： UpArrow编辑历史记录列表中的上一个命令 DownArrow编辑历史记录列表中的下一个命令 LeftArrow和RightArrow在历史列表中的当前命令中左右移动光标，以便您在运行命令之前进行编辑 可以使用Esc+.或Alt+. 组合键，在光标的当前位置插入上一命令的最后一个单词。重复使用组合键可将该文本替换为历史记录中更早命令的最后一个单词。Alt+.组合键尤其方便，可以按住Alt键，再反复按.键来轻松地回滚到更早的命令 TAP补全   Tab补全允许用户在提示符下键入足够的内容以使其唯一后快速补全命令或文件名。如果键入的字符不唯一，则按Tab键两次可显示以键入的字符为开头的所有命令。许多命令可以通过Tab补全匹配参数和选项，例如useradd： [root@redhat8 ~]# pas \"Push Tap twice\" passwd paste pasuspender [root@redhat8 ~]# useradd -- \"Push Tap twice\" --base-dir --expiredate --home-dir --no-log-init --prefix --skel --comment --gid --inactive --non-unique --root --system --create-home --groups --key --no-user-group --selinux-user --uid --defaults --help --no-create-home --password --shell --user-group 在另一行上继续长命令   具有多个选项和参数的命令可能会很快变得很长，当光标到达右边缘时，命令窗口会自动换行。为了提高命令的易读性，可以使用多行来键入长命令。使用反斜杠字符\\（称为转义字符）忽略紧跟在反斜杠后面的字符的含义。for循环等一些语句中不需要，示例： [root@redhat8 sed_gawk]# sed '/2. I am/c\\ > I will save the world!' test7 [root@redhat8 ~]# for i in {2..5} > do > echo number-$i > done number-2 number-3 number-4 number-5 命令行管理文件 RHEL重要目录 重要目录及描述如下： /usr：安装的软件、共享的库，包括文件和只读程序数据。重要的子目录有： /usr/bin：用户命令 /usr/sbin：系统管理命令 /usr/local：本地自定义软件 /etc：特定于此系统的配置文件 /var：特定于此系统的可变数据，在系统启动之间保持永久性。动态变化的文件（如数据库、缓存目录、日志文件、打印机后台处理文档和网站内容） /run：自上一次系统启动以来启动的进程的运行时数据。这包括进程ID文件和锁定文件等。此目录中的内容在重启时重新创建。此目录合并了早期版本的RHEL中的/var/run和/var/lock /home：主目录是普通用户存储其个人数据和配置文件的位置 /root：管理超级用户root的主目录 /tmp：供临时文件使用的全局可写空间。10天内未访问、未更改或未修改的文件将自动从该目录中删除： 还有一个临时目录/var/tmp，该目录中的文件如果在30 天内未曾访问、更改或修改过，将被自动删除 /boot：开始启动过程所需的文件 /dev：包含特殊的设备文件，供系统用于访问硬件 导航路径 导航路径相关命令说明： pwd命令显示该shell的当前工作目录的完整路径名。这可以帮助确定使用相对路径名来访问文件的语法 ls命令列出指定目录的目录内容；如果未指定目录，则列出当前工作目录的内容。常见且最有用的选项是: -l（长列表格式） -a（包含隐藏文件在内的所有文件）：列表顶部的两个特殊目录是当前目录.和父目录.. -R（递归方式，包含所有子目录的内容） 使用cd命令可更改shell的当前工作目录： 没有为该命令指定任何参数，将切换主目录 cd -命令可更改到用户在进入当前目录之前所处的目录 当当前工作目录是主目录时，提示符显示波形符字符~ touch该命令通常将文件的时间戳更新为当前日期和时间，而不进行其他修改。通常可用于创建空文件，因为touch不存在的文件名会导致创建该文件 cd -命令示例： [root@redhat8 ~]# pwd /root [root@redhat8 ~]# cd /home/huang [root@redhat8 huang]# cd - /root 将工作目录从当前位置上移两个级别： [root@redhat8 test]# pwd /home/huang/test [root@redhat8 test]# cd ../.. [root@redhat8 home]# 常用文件管理命令 最常见的文件管理命令： 命令 描述 命令语法 mkdir 创建目录 mkdir directory cp 复制文件 cp file new-file cp -r 复制目录及其内容 cp -r directory new-directory mv 移动或重命名文件或目录 mv file new-file rm 删除文件 rm file rm -r 删除含有文件的目录 rm -r directory rmdir 删除空目录 rmdir directory 创建目录 使用mkdir命令创建目录说明及注意事项： mkdir命令可创建一个或多个目录或子目录。取要创建的目录的路径列表作为参数 如果创建目录已存在，或者试图在一个不存在的目录中创建子目录，mkdir命令将失败并出现错误。 -p（父级）选项将为请求的目标位置创建缺失的父目录。使用mkdir -p命令时应小心，拼写错误会创建不需要的目录，而不会生成错误消息 创建多个父目录及子目录时候使用空格分隔 示例： [root@redhat8 ~]# mkdir superhero/thor mkdir: cannot create directory ‘superhero/thor’: No such file or directory [root@redhat8 ~]# mkdir -p superhero/thor [root@redhat8 ~]# ls -l superhero/thor total 0 复制文件   cp命令可复制文件，在当前目录或指定目录中创建新文件。它也可将多个文件复制到某一目录中。 注意事项： 如果目标文件已存在，则cp命令会覆盖该文件 在通过一个命令复制多个文件时，最后一个参数必须为目录 复制的文件在新的目录中保留其原有名称 如果目标目录中存在具有相同名称的文件，则会覆盖现有文件 默认情况下，cp不复制目录，而会忽略它们 如果列出了两个目录，A和B，只有最后参数B可以有效作为目标，A目录被忽略 移动文件   mv命令可将文件从一个位置移动到另一个位置。如果将文件的绝对路径视为它的全名，那么移动文件实际上和重命名文件一样，文件内容保持不变。 删除文件和目录 rm命令可删除文件： 默认情况下，除非添加了-r 或--recursive选项，否则rm不会删除包含文件的目录 在删除文件或目录之前，最好先使用pwd验证当前工作目录 如果试图使用rm命令来删除目录，但不使用-r选项，命令将失败： rm -r命令首先遍历每个子目录，在删除每个目录之前逐一删除其中的文件 可以使用rm -ri命令以交互方式提示确认，然后再删除 -f选项强制删除而不提示用户进行确认 如果同时指定了-i和-f选项，-f选项将具有优先权，在rm删除文件之前，不会提示进行确认 不带任何选项的rm命令无法删除空目录。必须使用rmdir命令（不能删除非空目录）、rm -d（等同于rmdir）或rm -r 示例如下： [root@redhat8 ~]# ls -l superhero/thor total 0 -rw-r--r--. 1 root root 0 May 2 14:03 Asgard.txt [root@redhat8 ~]# rmdir superhero/thor rmdir: failed to remove 'superhero/thor': Directory not empty [root@redhat8 ~]# rm superhero/thor rm: cannot remove 'superhero/thor': Is a directory [root@redhat8 ~]# rm -r superhero/thor rm: descend into directory 'superhero/thor'? y rm: remove regular empty file 'superhero/thor/Asgard.txt'? y rm: remove directory 'superhero/thor'? y [root@redhat8 ~]# ls -l superhero/thor ls: cannot access 'superhero/thor': No such file or directory 硬链接   从初始名称到文件系统上的数据，每个文件都以一个硬链接开始。当创建指向文件的新硬链接时，也会创建另一个指向同一数据的名称。新的硬链接与原始文件名的作用完全相同。通过ls -l命令来确定某个文件是否有多个硬链接： [root@redhat8 huang]# ls -l testfile -rw-rw-r--. 1 huang huang 259 Jul 26 2020 testfile   示例中，testfile的链接数为1。有一个绝对路径/home/huang/testfile。可以使用ln命令创建一个指向现有文件的新硬链接（另一个名称）。该命令至少需要两个参数，即现有文件的路径以及要创建的硬链接的路径： [root@redhat8 huang]# ln testfile /tmp/testfile-llink2 [root@redhat8 huang]# ls -l testfile /tmp/testfile-llink2 -rw-rw-r--. 2 huang huang 259 Jul 26 2020 testfile -rw-rw-r--. 2 huang huang 259 Jul 26 2020 /tmp/testfile-llink2   使用ls命令的-i选项，以列出文件的索引节点编号。如果文件位于同一文件系统上，而且它们的索引节点编号相同，那么这两个文件就是指向同一数据的硬链接： [root@redhat8 huang]# ls -il testfile /tmp/testfile-llink2 35330643 -rw-rw-r--. 2 huang huang 259 Jul 26 2020 testfile 35330643 -rw-rw-r--. 2 huang huang 259 Jul 26 2020 /tmp/testfile-llink2 硬链接的特点： 引用同一文件的所有硬链接将具有相同的链接数、访问权限、用户和组所有权、时间戳，以及文件内容 如果使用一个硬链接更改其中的任何信息，指向同一文件的所有其他硬链接也会显示新的信息，因为每个硬链接都指向存储设备上的同一数据 即使原始文件被删除，只要存在至少一个硬链接，该文件的内容就依然可用。只有删除了最后一个硬链接时，才会将数据从存储中删除 硬链接局限性： 硬链接只能用于常规文件，不能使用ln来创建指向目录或特殊文件的硬链接 只有当两个文件都位于同一文件系统上时，才能使用硬链接 软链接   命令ln -s可创建软链接，也称为符号链接。软链接不是常规文件，而是指向现有文件或目录的特殊类型的文件。软链接相比硬链接有一定的优势及不同： 软链接可以链接位于不同文件系统上的两个文件 软链接可以指向目录或特殊文件，而不仅限于常规文件 硬链接是将名称指向存储设备上的数据 软链接则是将名称指向另一个名称，硬链接指向存储设备上的数据 软链接可以指向目录，之后软链接发挥目录一样的作用： 通过cd更改为软链接将使当前工作目录变为链接目录 有些工具可以跟踪使用软链接到达当前工作目录的事实。例如，默认情况下，cd将使用软链接的名称（而非实际目录的名称）来更新当前工作目录 cd命令有一个选项-P会将其更新为实际目录的名称 软链接示例： [root@redhat8 ~]# ln -s /home/huang/testfile-llink2 /tmp/testfile-symlink [root@redhat8 ~]# ls -l /home/huang/testfile-llink2 /tmp/testfile-symlink -rw-r--r--. 1 root root 0 May 2 09:21 /home/huang/testfile-llink2 lrwxrwxrwx. 1 root root 27 May 2 09:22 /tmp/testfile-symlink -> /home/huang/testfile-llink2 [root@redhat8 ~]# rm -f /home/huang/testfile-llink2 [root@redhat8 ~]# ls -l /tmp/testfile-symlink lrwxrwxrwx. 1 root root 27 May 2 09:22 /tmp/testfile-symlink -> /home/huang/testfile-llink2 [root@redhat8 ~]# cat /tmp/testfile-symlink cat: /tmp/testfile-symlink: No such file or directory 示例软链接说明： 示例中/tmp/testfile-symlink的长列表的第一个字符是l，而不是-。表示该文件是软链接而不是常规文件 当原始常规文件被删除后，软链接依然会指向该文件，但目标已消失。指向缺失的文件的软链接称为悬挂的软链接 在上例中，悬挂的软链接有一个副作用，如果稍后创建了一个与已删除文件同名的新文件 (/home/huang/testfile-llink2)，那么软链接将不再悬挂，而是指向此新文件 使用Shell扩展匹配文件名 模式匹配 元字符和匹配项表： 模式 匹配项 * 由零个或更多字符组成的任何字符串 ? 任何一个字符 [abc...] 括起的类（位于两个方括号之间）中的任何一个字符 [!abc...] 不在括起的类中的任何一个字符 [^abc...] 不在括起的类中的任何一个字符 [[:alpha:]] 任何字母字符 [[:lower:]] 任何小写字符 [[:upper:]] 任何大写字符 [[:alnum:]] 任何字母字符或数字 [[:punct:]] 除空格和字母数字以外的任何可打印字符 [[:digit:]] 从0到9的任何单个数字 [[:space:]] 任何一个空白字符。这可能包括制表符、换行符、回车符、换页符或空格 简单模式匹配示例： [root@redhat8 ~]# mkdir glob;cd glob [root@redhat8 glob]# touch alfa bravo charlie delta echo able baker cast dog easy [root@redhat8 glob]# ls able alfa baker bravo cast charlie delta dog easy echo [root@redhat8 glob]# ls c* cast charlie [root@redhat8 glob]# ls *c* cast charlie echo [root@redhat8 glob]# ls [ac]* able alfa cast charlie [root@redhat8 glob]# ls ???? able alfa cast easy echo [root@redhat8 glob]# ls ????? baker bravo delta 波形符扩展 波形符~可匹配当前用户的主目录： 如果开始时使用斜杠/以外的字符串，shell就会将该斜杠之前的字符串解译为用户名 如果存在匹配项，则用该用户的主目录绝对路径来替换此字符串 如果找不到匹配的用户名，则使用实际波形符加上该字符串代替 使用echo命令显示波形符字符的值示例： [root@redhat8 glob]# echo ~root /root [root@redhat8 glob]# echo ~/glob /root/glob [root@redhat8 glob]# echo ~ /root [root@redhat8 glob]# echo ~huang /home/huang 大括号扩展   大括号扩展用于生成任意字符串。大括号包含字符串的逗号分隔列表或顺序表达式。结果包含大括号定义之前或之后的文本。大括号扩展可以互相嵌套。此外，双句点语法..可扩展成一个序列，使得{m..p}扩展为m n o p： [root@redhat8 glob]# echo file{1..4}.txt file1.txt file2.txt file3.txt file4.txt [root@redhat8 glob]# echo file{b..e}.txt fileb.txt filec.txt filed.txt filee.txt [root@redhat8 glob]# echo file{1,2}{a,b}.txt file1a.txt file1b.txt file2a.txt file2b.txt [root@redhat8 glob]# echo file{a{1,2},b,c}.ext filea1.ext filea2.ext fileb.ext filec.ext [root@redhat8 glob]# echo {Monday,Tuesday,Wednesday,Thursday}.log Monday.log Tuesday.log Wednesday.log Thursday.log [root@redhat8 glob]# mkdir ../RHEL{1..4} [root@redhat8 glob]# LS ../RHEL* bash: LS: command not found... Similar command is: 'ls' [root@redhat8 glob]# ls ../RHEL* ../RHEL1: ../RHEL2: ../RHEL3: ../RHEL4: 变量扩展   变量的作用类似于可以在内存中存储值的命名容器。通过变量，可以从命令行或在 shell脚本内轻松访问和修改存储的数据。将数据作为值分配给变量语法如下： [root@redhat8 ~]# VARIABLENAME=value   可以使用变量扩展将变量名称转换为命令行上的值。如果字符串以美元符号$开头，那么shell就会尝试将该字符串的其余部分用作变量名称，并将它替换为变量中包含的任何值。 为了避免因其他shell扩展而引起的错误，可以将变量的名称放在大括号中，如${VARIABLENAME}，示例如下： [root@redhat8 ~]# SUPERHERO=batman [root@redhat8 ~]# echo $SUPERHERO batman [root@redhat8 ~]# echo ${SUPERHERO} batman 命令替换   命令替换允许命令的输出替换命令行上的命令本身。当命令括在括号中并且前面有美元符号$时，会发生命令替换。$(Command)形式可以互相嵌套多个命令扩展： [root@redhat8 ~]# echo Today is $(date +%A). Today is Monday. [root@redhat8 ~]# echo The time is $(date +%M) minutes past $(date +%l%p). The time is 45 minutes past 11AM. 较旧形势的命令喜欢使用反引号Command，缺点： 反引号在视觉上很容易与单引号混淆 反引号无法嵌套 防止参数被扩展   Bash shell中，许多字符有特殊含义。为了防止shell在命令行的某些部分上执行 shell扩展，可以为字符和字符串加引号或执行转义。反斜杠\\是Bash shell中的转义字符： [root@redhat8 ~]# echo My home directory is $HOME My home directory is /root [root@redhat8 ~]# echo My home directory is \\$HOME My home directory is $HOME   如果要保护较长的字符串，则使用单引号'或双引号\"来括起字符串。单引号将阻止所有shell扩展，双引号则阻止大部分shell扩展，双引号可以阻止通配和shell扩展，但依然允许命令和变量替换，示例如下： [root@redhat8 ~]# echo \"$HOSTNAME home directory is $HOME\" redhat8 home directory is /root [root@redhat8 ~]# echo '$HOSTNAME home directory is $HOME' $HOSTNAME home directory is $HOME 练习 "},"05-IBM_Operating_System/06-RHEL学习笔记/02-RHEL-文本及用户操作.html":{"url":"05-IBM_Operating_System/06-RHEL学习笔记/02-RHEL-文本及用户操作.html","title":"RHEL-文本及用户操作","keywords":"","body":"文本及用户 RHEL-文本基本操作 标准输入、标准输出及标准错误   一个运行的程序（或称为进程）需要从某位置读取输入并将输出写入某位置。从shell提示符运行的命令通常会从键盘读取其输入，并将输出发送到其终端窗口。进程使用称为文件描述符的编号通道来获取输入并发送输出。所有进程在开始时至少要有三个文件描述符。标准输入（通道 0）从键盘读取输入。标准输出（通道 1）将正常输出发送到终端。标准错误（通道 2）将错误消息发送到终端。如果程序打开连接至其他文件的单独连接，则可能要使用更大编号的文件描述符。 通道（文件描述符）: 编号 通道名称 描述 默认连接 用法 0 stdin 标准输入 键盘 仅读取 1 stdout 标准输出 终端 仅写入 2 stderr 标准错误 终端 仅写入 3 + filename 其他文件 无 读取和/或写入 将输出重定向到文件 输出重定向操作符: 用法 说明 > file 重定向stdout以覆盖文件 >> file 重定向stdout以附加到文件 2> file 重定向stderr以覆盖文件 2> /dev/null 将stderr错误消息重定向到/dev/null，从而将它丢弃 > file 2>&1 or &> file 重定向stdout和stderr以覆盖同一个文件 >> file 2>&1 or &>> file 重定向stdout和stderr以附加到同一个文件 重定向操作的顺序非常重要： > file 2>&1：将标准输出重定向到file，然后将标准错误作为标准输出重定向到相同位置 (file) 2>&1 > file：相对上示例以相反的顺序执行重定向。这会将标准错误重定向到标准输出的默认位置（终端窗口，因此没有任何更改），然后仅将标准输出重定向到file 通过重定向，可以简化许多日常管理任务。示例： ### 保存时间错以供日后使用 date > /tmp/saved-timestamp ### 将日志文件的最后200行复制到另一文件 tail -n 200 /var/log/messages > /tmp/last-200-messages ### 将三个文件连接为一个 cat file1 file2 file3 > /tmp/all-three-in-one ### 将主目录的隐藏文件名和常规文件名列出到文件中 ls -a > /tmp/my-file-names ### 将输出附加到现有文件 echo \"Miracles happen every day\" >> /tmp/many-lines-of-info diff previous-file current-file >> /tmp/tracking-changes-made ### 忽略并丢弃错误消息 find /etc -name passwd > /tmp/output 2> /dev/null ### 将输出和生成的错误消息存放在一起 find /etc -name passwd &> /tmp/save-both ### 将输出和生成的错误附加到现有文件 find /etc -name paswd >> /tmp/save-both 2>&1 将进程输出和错误消息保存到单独的文件中： [huang@redhat8 ~]$ find /etc -name passwd > /tmp/output 2> /tmp/errors [huang@redhat8 ~]$ cat /tmp/errors find: ‘/etc/pki/rsyslog’: Permission denied ...... 构建管道   管道是一个或多个命令的序列，用竖线字符|分隔。管道将第一个命令的标准输出连接到下一个命令的标准输入。示例如下： [huang@redhat8 ~]$ ls -l /usr/bin |less [huang@redhat8 ~]$ cat /etc/passwd |more [huang@redhat8 ~]$ ls -l |wc -l 11 [huang@redhat8 ~]$ ls -l |head -n 5 > /tmp/five-last-files 管道、重定向和tee命令   当重定向与管道组合时，shell会首先设置整个管道，然后重定向输入/输出。如果在管道的中间使用了输出重定向，则输出将转至文件，而不是前往管道中的下一个命令。下面示例不会在终端上显示任何内容： [huang@redhat8 ~]$ ls -al > /tmp/saved-output | less   tee命令克服了这个限制。在管道中，tee将其标准输入复制到其标准输出中，并且还将标准输出重定向到指定为命令参数的文件。示例将ls命令的输出重定向到文件，并且将输出传递到less以便在终端上以一次一屏的方式显示： [huang@redhat8 ~]$ cat /etc/hosts |tee /tmp/saved-hosts |less 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 (END) 在管道末尾使用了tee，可以保存命令的最终输出并且同时输出到终端： [huang@redhat8 ~]$ ls -t |head -n 3 |tee /tmp/five-last-files test testfile Desktop   可通过管道来重定向标准错误，但是不能使用合并重定向运算符（&>和&>>）执行此操作。以下是通过管道重定向标准输出和标准错误的正确方法： [huang@redhat8 ~]$ find -name / passwd 2>&1 | less Vim Vim通过单字符击键操作进入各个其他模式，访问特定的编辑功能： 按i键进入插入模式，其中键入的所有文本将变为文件内容 u键可撤销最近的编辑 按x键可删除单个字符 按Esc键可退出插入模式，返回到命令模式 按v键进入可视模式，可在其中选择多个字符进行文本操作： 字符模式：v 行模式：Shift+v，可以选择多行 块模式：Ctrl+v，可以选择文本块 按:键启动扩展命令模式，可以执行的任务包括写入文件（进行保存），以及退出Vim编辑器等： :w命令可写入（保存）文件，并保留在命令模式中以进行更多编辑 :wq命令可写入（保存）文件并退出Vim :q!命令可退出Vim，同时放弃上次写入以来进行的所有更改 在Vim 中，复制和粘贴称为拖拉和放置，使用的命令字符是y和p： 首先将光标定位到要选择的第一个字符，然后进入可视模式 使用箭头键扩展可视选择。准备好时，按y将所选内容拖拉到内存中 将光标定位到新位置上，然后按p将所选内容放置到光标处   最初开发vi时，用户无法依赖箭头键或箭头键的键盘映射来移动光标。因此，vi设计了使用标准字符键的命令来移动光标：H、J、K和L。以下是记忆它们的一种方式： H：hang back J：jump down K：kick up L：leap forward 使用shell变量   Shell变量对于特定shell会话是唯一的。如果打开了两个终端窗口，或者通过两个独立的登录会话登录同一远程服务器，那么您在运行两个shell。每个shell都有自己的一组shell变量值。 使用以下语法将值分配给shell变量： VARIABLENAME=value   变量名称可以包含大写或小写字母、数字和下划线字符_。使用`set命令列出当前设置的所有 shell 变量。（它还会列出所有shell函数，可以忽略它们）此列表足够长： [root@redhat8 ~]# set |more BASH=/bin/bash BASHOPTS=checkwinsize:cmdhist:complete_fullquote:expand_aliases:extglob:extquote:force_fignore:histappend:int eractive_comments:login_shell:progcomp:promptvars:sourcepath BASHRCSOURCED=Y BASH_ALIASES=() BASH_ARGC=() ...output omitted...   使用变量扩展来指代已设置的变量值，需在变量名称前加上美元符号$。如果变量名称旁边有任何尾随字符，可能需要使用花括号来保护变量名称： [root@redhat8 ~]# COUNT=100 [root@redhat8 ~]# echo $COUNT 100 [root@redhat8 ~]# echo Repeat $COUNTx Repeat [root@redhat8 ~]# echo Repeat ${COUNT}x Repeat 100x 使用Shell变量配置Bash   一些shell变量在Bash启动时设置，但可以进行修改来调整shell的行为。例如，两个影响shell历史记录和history命令的变量是HISTFILE和HISTFILESIZE： 如果设置了HISTFILE，将指定文件的位置，以便在退出时保存shell历史记录 HISTFILE默认情况下是用户的~/.bash_history文件 HISTFILESIZE变量指定应将历史记录中的多少个命令保存到该文件中   另一个例子是PS1，这是一个控制shell提示符外观的shell变量。如果更改此值，它将改变shell提示符的外观，示例如下： [root@redhat8 ~]$ PS1=\"mybash\\$ \" mybash$ PS1=\"[\\u@\\h \\W]# \" [root@redhat8 ~]# 使用环境变量配置程序   shell提供了一个环境，供用户从该shell中运行程序。例如，此环境包括有关文件系统上当前工作目录的信息、传递给程序的命令行选项，以及环境变量的值。程序可以使用这些环境变量来更改其行为或其默认设置。 [root@redhat8 ~]# EDITOR=vim [root@redhat8 ~]# export EDITOR [root@redhat8 ~]# export EDITOR=vim   应用程序和会话使用这些变量来确定其行为。例如，shell启动时自动将HOME变量设置为用户主目录的文件名。LANG变量可以设定的是区域设置。这会调整程序输出的首选语言，字符集，日期、数字和货币的格式，以及程序的排序顺序： [root@redhat8 ~]# export export LANG=en_US.UTF-8 [root@redhat8 ~]# date Wed May 4 02:28:24 EDT 2022   PATH变量包含一个含有程序的目录的冒号分隔列表。运行ls等命令时，shell会按照顺序逐一在这些目录中查找可执行文件ls，并且运行找到的第一个匹配文件。可以将其他目录添加到PATH的末尾。例如，在/home/huang/sbin中可能具有像常规命令一样运行的可执行程序或脚本： [root@redhat8 ~]# echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin [root@redhat8 ~]# export PATH=${PATH}:/home/huang/sbin [root@redhat8 ~]# echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/home/huang/sbin 要列出特定shell的所有环境变量，运行env命令： [root@redhat8 ~]# env HISTCONTROL=ignoredups DISPLAY=localhost:10.0 HOSTNAME=redhat8 EDITOR=vim ...output omitted...   EDITOR环境变量指定要用作命令行程序的默认文本编辑器的程序。如果不指定，很多程序都使用vi或vim，也可以根据需要自定义设置： [root@redhat8 ~]# export EDITOR=nano [root@redhat8 ~]# echo $EDITOR nano 自动设置变量   如果希望在shell启动时自动设置shell或环境变量，可以编辑Bash启动脚本。运行的确切脚本取决于 shell的启动方式，是交互式登录shell、交互式非登录shell 还是shell脚本。假设是默认的/etc/profile、/etc/bashrc和~/.bash_profile文件，如要更改启动时影响所有交互式shell提示符的用户帐户，编辑~/.bashrc文件。例如，可以通过编辑要读取的文件，将该帐户的默认编辑器设置为nano： [root@redhat8 ~]# vi ~/.bashrc [root@redhat8 ~]# cat ~/.bashrc # .bashrc # User specific aliases and functions alias rm='rm -i' alias cp='cp -i' alias mv='mv -i' # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi export EDITOR=nano   调整影响所有用户帐户的设置的最佳方式是添加名称以.sh结尾的文件，并在该文件中包含对/etc/profile.d目录的更改，并需要以root用户身份登录。 取消设置和取消导出变量   要完全取消设置和取消导出变量，使用unset命令。要取消导出变量但不取消设置它，使用export -n命令。示例如下： [root@redhat8 ~]# echo $fileX /tmp/testdir/fileX [root@redhat8 ~]# unset fileX [root@redhat8 ~]# echo $fileX [root@redhat8 ~]# export -n PS1 管理本地用户和组 用户类型 用户帐户有三种主要类型：超级用户、系统用户和普通用户： 超级用户帐户用于管理系统。超级用户的名称为root，其帐户UID为0。超级用户对系统具有完全访问权限 系统的系统用户帐户供提供支持服务进程使用。这些进程（或守护进程）通常不需要以超级用户身份运行。系统会为它们分配非特权帐户，允许它们确保其文件和其他资源不受彼此以及系统上普通用户的影响。用户无法使用系统用户帐户以交互方式登录 大多数用户都有用于处理日常工作的普通用户帐户。与系统用户一样，普通用户对系统具有有限的访问权限   id命令显示有关当前已登录用户的信息，也可以将用户名作为参数传递给 id 命令，示例如下： [root@redhat8 ~]# id uid=0(root) gid=0(root) groups=0(root) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023 [root@redhat8 ~]# id huang uid=1000(huang) gid=1000(huang) groups=1000(huang),40001(Archivers)   使用ps命令查看进程信息，默认为仅显示当前shell中的进程。使用a选项可查看与某一终端相关的所有进程。使用u选项查看与进程相关联的用户。示例如下： [root@redhat8 ~]# ps -au USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND gdm 1777 0.0 2.7 498652 50240 tty1 Sl 01:45 0:00 /usr/libexec/ huang 2443 0.0 0.2 26432 5056 pts/0 Ss 01:46 0:00 -bash root 4698 0.0 0.2 57172 3880 pts/0 R+ 05:33 0:00 ps -au   以上命令的输出按名称显示用户，但操作系统内部利用UID来跟踪用户。用户名到UID的映射在帐户信息数据库中定义。默认情况下，系统使用/etc/passwd文件存储有关本地用户的信息。它分为七个以冒号分隔的字段。以下是/etc/passwd中某一用户的示例： [root@redhat8 ~]# cat /etc/passwd huang:x:1000:1000:huang:/home/huang:/bin/bash 示例中字段依次说明： 该用户huang的用户名 用户的密码曾以加密格式存储在此处。现在它已移至/etc/shadow文件，该字段始终应为x 该用户帐户的UID号1000 该用户帐户的主要组的GID号1000 该用户的真实姓名 该用户的主目录/home/huang。这是shell启动时的初始工作目录，其中包含有用户数据和配置设置 该用户的默认shell程序，会在登录时运行/bin/bash。如果系统用户不允许进行交互式登录，该用户可能会使用/sbin/nologin 组Group   组是需要共享文件和其他系统资源访问权限的用户的集合。组可用于向一组用户授予文件访问权限，而非仅仅向一个用户授予访问权限。系统通过分配的唯一标识号GID来区分不同的组。默认情况下，系统使用/etc/group文件存储有关本地组的信息。每个组条目被分为四个以冒号分隔的字段。以下是/etc/group中某一行的示例： [root@redhat8 ~]# cat /etc/group ftpusers:x:40000:christ,harry 实例中字段依次说明： 该组的组名称ftpusers 过时的组密码字段。该字段始终应为x 该组的GID号40000 该组成员的用户列表christ,harry 主要组和补充组： 每个用户有且只有一个主要组。对于本地用户而言，这是按/etc/passwd文件中的GID号列出的组。默认情况下，这是拥有用户创建的新文件的组。通常，在创建新的普通用户时，会创建一个与该用户同名的新组。该组将用作新用户的主要组，而该用户是这一用户专用组的唯一成员。这有助于简化文件权限的管理 用户也可以有补充组。补充组的成员资格由/etc/group文件确定。根据所在的组是否具有访问权限，将授予用户对文件的访问权限。具有访问权限的组是用户的主要组还是补充组无关紧要 超级用户   大多数操作系统具有某种类型的超级用户，即具有系统全部权限的用户。在红帽企业Linux中，此为root 用户。该用户的特权高于文件系统上的一般特权，用于管理系统。要执行诸如安装或删除软件以及管理系统文件和目录等任务，必须将特权升级到root用户。 切换用户   su命令可让用户切换至另一个用户帐户。如果从普通用户帐户运行su，系统会提示您输入要切换的帐户的密码。当以 root用户身份运行su时，则无需输入用户密码。如果省略用户名，则默认情况下su或su -命令会尝试切换到root。示例如下： [christ@redhat8 ~]$ su - huang Password: [huang@redhat8 ~]$ su - Password: [root@redhat8 ~]#   命令su将启动非登录shell，而命令su -（带有短划线选项）会启动登录shell。两个命令的主要区别在于，su -会将shell环境设置为如同以该用户身份重新登录一样，而su仅以该用户身份启动shell，但使用的是原始用户的环境设置。su命令最常用于获得以另一个用户身份（通常是root）运行的命令行界面（shell提示符）。如果结合-c选项，该命令的作用将与Windows实用程序runas一样，能够以另一个用户身份运行任意程序。可以运行info su来查看更多详情。 通过Sudo运行命令   有时为安全起见，root用户的帐户可能根本没有有效的密码。在这种情况下，用户无法使用密码直接以 root身份登录系统，也不能使用su获取交互式shell。可以用sudo获取root访问权限： 与su不同，sudo通常要求用户输入其自己的密码以进行身份验证 sudo可以配置为允许特定用户像某个其他用户一样运行任何命令，或仅允许以该用户身份运行部分命令   例如，如果sudo已配置为允许huang用户以root身份运行命令usermod，那么就可运行以下命令来锁定或解锁用户帐户： [huang@redhat8 ~]$ sudo usermod -L christ [sudo] password for huang: huang is not in the sudoers file. This incident will be reported.   上面示例中，sudo配置不允许，命令被阻止，这次尝试也会被记录下来，并且默认情况下还会向root用户发送一封电子邮件。使用sudo的另一个优点在于，执行的所有命令都默认为将日志记录到/var/log/secure中。示例： [root@redhat8 ~]# sudo tail /var/log/secure sliceMay 4 09:12:07 redhat8 su[6852]: pam_unix(su-l:session): session opened for user huang by huang(uid=0) May 4 09:12:20 redhat8 sudo[6879]: huang : user NOT in sudoers ; TTY=pts/0 ; PWD=/home/huang ; USER=root ; COMMAND=/sbin   在红帽企业Linux 7和红帽企业Linux 8中，wheel组的所有成员都可以使用sudo以任何用户身份运行命令，包括 root 在内。系统将提示用户输入其自己的密码。 通过Sudo获取交互式Root Shell   如果系统上的非管理员用户帐户能够使用sudo来运行su命令，则可以从该帐户运行sudo su -来获取root用户的交互式shell。这是因为sudo将以root用户身份运行su -，而root用户无需输入密码即可使用su。 通过sudo访问root帐户的另一种方式是使用sudo -i命令。这将切换到root帐户并运行该用户的默认shell（通常为 bash）及关联的shell登录脚本。如果只想运行shell，可使用sudo -s命令。sudo su -命令与sudo -i的行为不完全相同。 配置sudo   sudo的主配置文件为/etc/sudoers。如果多个管理员试图同时编辑该文件，为了避免出现问题，只应使用特殊的visudo命令进行编辑： [root@redhat8 ~]# cat /etc/sudoers ## Allow root to run any commands anywhere root ALL=(ALL) ALL ## Allows people in group wheel to run all commands %wheel ALL=(ALL) ALL   上面示例中，%wheel是规则适用的用户或组。%指定这是一个组，即组wheel。ALL=(ALL)指定在可能包含此文件的任何主机上，wheel可以运行任何命令。最后的ALL指定wheel可以像系统上的任何用户一样运行这些命令。  默认情况下，/etc/sudoers还包含/etc/sudoers.d目录中所有文件的内容，作为配置文件的一部分。管理员只需将相应的文件放入/etc/sudoers.d目录中，即可为用户添加sudo访问权限。将文件复制到目录中或从目录中删除文件，即可启用或禁用sudo访问权限。示例如下： [root@redhat8 ~]# touch /etc/sudoers.d/huang [root@redhat8 ~]# vi /etc/sudoers.d/huang [root@redhat8 ~]# cat /etc/sudoers.d/huang huang ALL=(ALL) ALL [root@redhat8 ~]# cat /etc/sudoers.d/ftpusers %ftpusers ALL=(ALL) ALL [root@redhat8 ~]# vi /etc/sudoers.d/ansible [root@redhat8 ~]# cat /etc/sudoers.d/ansible ansible ALL=(ALL) NOPASSWD:ALL 示例说明： 第一个示例为用户huang启用完整的sudo访问权限 第二个示例为组ftpusers启用完整的sudo访问权限 第三个示例设置sudo，允许ansible用户在不输入密码的前提下以其他用户身份运行命令 sudo中两个命令区别 sudo su -和sudo -i这两个命令之间存在一些细微差别： sudo su -命令可以完全像正常登录那样设置root环境，因为su -命令会忽略sudo所做的设置并从头开始设置环境 sudo -i命令的默认配置实际上会设置在一些细节上与正常登录不同的root用户环境。例如，它设置的PATH环境变量便略有不同，这会影响shell查找命令的位置 通过用visudo编辑/etc/sudoers，可以让sudo -i的行为与su -更为相似。找到行： Defaults secure_path = /sbin:/bin:/usr/sbin:/usr/bin 替换为以下两行： Defaults secure_path = /usr/local/bin:/usr/bin Defaults>root secure_path = /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin 管理本地用户 创建用户 从命令行创建用户： useradd username命令将创建名为username的新用户。会设置用户的主目录和帐户信息，并为用户创建一个专用组。默认未设置有效的密码，需要设置了后才能登录，可以通过root用户su过去 useradd --help命令将显示可用于覆盖默认值的基本选项。大多数情形中，可以将相同的选项用于usermod命令，以修改现有的用户 一些默认值从/etc/login.defs文件中读取，如有效UID编号的范围和默认密码过期规则。此文件中的值仅在创建新用户时使用，更改此文件对现有用户毫无影响 示例： [root@redhat8 ~]# useradd testuser1 [root@redhat8 ~]# su - testuser1 [testuser1@redhat8 root]$ exit [root@redhat8 ~]# su - testuser1 [testuser1@redhat8 ~]$ 从命令行修改现有的用户 usermod --help命令常见选项包括： 选项 用法 -c, --comment COMMENT 将用户的真实姓名添加到注释字段 -g, --gid GROUP 为用户帐户指定主要组 -G, --groups GROUPS 为用户帐户指定补充组的逗号分隔列表 -a, --append 利用-G选项将补充组添加到用户当前的组成员集合中，而不是将补充组集合替换为新的集合 -d, --home HOME_DIR 为用户帐户指定特定的主目录 -m, --move-home 将用户的主目录移到新的位置。必须与-d选项搭配使用 -s, --shell SHELL 为用户帐户指定特定的登录shell -L, --lock 锁定用户帐户 -U, --unlock 解锁用户帐户 从命令行删除用户 从命令行删除用户： userdel username命令从/etc/passwd中删除username的详细信息，但保留用户的主目录不变 userdel -r username命令删除username的详细信息，同时删除用户的主目录 在未指定-r选项的情况下使用userdel删除某一用户，系统将具有未分配UID所拥有的文件。如果创建新用户，旧用户的UID将被重新分配给新用户，为新用户提供旧用户剩余文件的所有权，除非使用-u选项指定了UID 示例如下： [testuser1@redhat8 ~]$ ls -l /home drwx------. 3 testuser1 testuser1 99 May 5 00:30 testuser1 [root@redhat8 ~]# ls -l /home drwx------. 3 1007 1007 99 May 5 00:30 testuser1 [root@redhat8 ~]# useradd testuser2 [root@redhat8 ~]# ls -l /home drwx------. 3 testuser2 testuser2 99 May 5 00:30 testuser1 drwx------. 3 testuser2 testuser2 78 May 5 00:42 testuser2 解决这一问题的方案有： 在删除创建了文件的用户时，同时从系统删除所有这些无人拥有的文件 另一种方案是手动为不同用户分配无人拥有的文件。root用户可以使用find / -nouser -o -nogroup命令来查找所有无人拥有的文件和目录 从命令行设置密码   passwd username命令可为username设置初始密码，或更改其现有的密码。root 用户可以将密码设为任何值。如果密码不符合最低建议标准，系统将显示消息。示例如下： [root@redhat8 ~]# passwd testuser2 Changing password for user testuser2. New password: BAD PASSWORD: The password is shorter than 8 characters Retype new password: passwd: all authentication tokens updated successfully. [root@redhat8 ~]# passwd testuser2 Changing password for user testuser2. New password: BAD PASSWORD: The password contains the user name in some form Retype new password: passwd: all authentication tokens updated successfully. UID范围 RHEL中UID编号和编号范围及目的： UID 0始终分配至超级用户帐户root UID 1-200是一系列系统用户，由红帽静态分配给系统进程 UID 201-999是一系列系统用户，供文件系统中没有自己的文件的系统进程使用。通常在安装需要它们的软件时，从可用池中动态分配它们 UID 1000+是可供分配给普通用户的范围 管理本地组 从命令行创建组   groupadd命令用于创建组。不带选项时，命令会在创建组时使用/etc/login.defs文件中指定范围内的下一个可用GID。-g选项指定GID。-r选项使用/etc/login.defs文件中(SYS_GID_MIN和SYS_GID_MAX配置项定义系统GID的范围)所列有效系统GID范围内的GID。示例如下： [root@redhat8 ~]# groupadd -g 10000 group1 [root@redhat8 ~]# groupadd -r group2 [root@redhat8 ~]# tail /etc/group ...output omitted... group1:x:10000: group2:x:975: 从命令行修改现有的组   groupmod命令可更改现有组的属性。-n指定组的新名称，-g选项指定新的GID。修改现有组示例如下： [root@redhat8 ~]# groupmod -n group02 group2 [root@redhat8 ~]# groupmod -g 20000 group02 [root@redhat8 ~]# tail /etc/group ...output omitted... group02:x:20000: 从命令行删除组 使用groupdel命令删除组，示例： [root@redhat8 ~]# groupdel group02 [root@redhat8 ~]# cat /etc/group |grep group02 [root@redhat8 ~]# 从命令行更改组成员资格   使用usermod -g命令来更改用户的主要组；使用usermod -aG命令，将用户添加到某一补充组。示例如下： [root@redhat8 ~]# id Tony uid=1002(Tony) gid=1002(Tony) groups=1002(Tony) [root@redhat8 ~]# usermod -g group1 Tony [root@redhat8 ~]# id Tony uid=1002(Tony) gid=10000(group1) groups=10000(group1) [root@redhat8 ~]# id testuser2 uid=1007(testuser2) gid=1007(testuser2) groups=1007(testuser2) [root@redhat8 ~]# usermod -aG group1 testuser2 [root@redhat8 ~]# id testuser2 uid=1007(testuser2) gid=1007(testuser2) groups=1007(testuser2),10000(group1) 管理用户密码 shadow密码和密码策略   早期加密的密码存储在全局可读的/etc/passwd文件中。目前一般存储到只有root用户才能读取的独立/etc/shadow文件中。并且允许实施密码期限和到期功能。每个用户在/etc/shadow文件中都有对应的一行。使用九个冒号分隔字段，示例： huang:$6$TwYrj0gr3EMjRAlU$N3aIbs/Dq7cT4hGMavXQjgCY9w/QmhFXlnZDs0vXLM3YlHdyPBKjqpqyR6G86wu9APHoVvvf31ffPULETrXO7/::0:99999 :7::: 九个字段说明依次如下： 此密码所属帐户的用户名 此用户的加密密码。字段中存储了三段信息：所用的哈希算法、salt及加密哈希值。每段信息由$符号分隔，三个字段依次说明： 此密码所用的哈希算法。数字6表示SHA-512哈希算法，这是RHEL8中的默认算法。1表示MD5哈希算法，5表示SHA-256哈希算法 用于加密密码的salt。这原先是随机选取的 用户密码的加密哈希值。salt和未加密密码组合并加密，生成加密的密码哈希 上次更改密码的日期。自1970年1月1日起的天数，并按UTC时区计算 自用户上次更改密码以来到可以再次更改之前必须经过的最短天数 在密码过期之前不进行密码更改可以经过的最长天数。空字段表示它不会根据上次更改以来的时间失效 警告期。当用户在截止日期之前登录达到该天数时，会收到有关密码过期的警告 非活动期。一旦密码过期，在这些天内仍可以接受登录。过了这一时期后，帐户将被锁定 帐户过期日。自1970年1月1日起的天数，并按UTC时区计算。空字段表示它不会在特定的日期失效 最后一个字段通常为空，预留字段   用户尝试登录时，系统在/etc/shadow中查询用户的条目，将用户的salt和键入的未加密密码组合，再使用指定的哈希算法加密： 如果结果与已加密哈希匹配，则用户键入了正确的密码 如果结果与已加密密码不符，则用户键入了错误的密码，登录尝试也会失败 配置密码期限   通过chage命令调整密码期限策略。chage命令-m、-M、-W和-I选项分别用于设置用户密码的最短期限、最长期限、警告周期和失效期限。示例如下： [root@redhat8 ~]# chage -m 0 -M 60 -W 7 -I 14 Tony [root@redhat8 ~]# cat /etc/shadow ...output omitted... Tony:!!:18475:0:60:7:14:: 强制用户Tony在下一次登录时更新其密码： [root@redhat8 ~]# chage -d O Tony 设置Tony用户的帐户于2022-10-01到期： [root@redhat8 ~]# chage -E 2022-10-01 Tony 显示用户Tony的密码期限详细信息： [root@redhat8 ~]# chage -l Tony Last password change : May 05, 2022 Password expires : Jul 04, 2022 Password inactive : Jul 18, 2022 Account expires : Oct 01, 2022 Minimum number of days between password change : 0 Maximum number of days between password change : 60 Number of days of warning before password expires : 7   可以编辑/etc/login.defs文件中的密码期限配置项，以设置默认的密码期限策略。默认密码期限策略的任何更改都仅对新用户有效。现有用户将继续使用旧密码期限设置。配置项说明： PASS_MAX_DAYS设置密码的默认最长期限 PASS_MIN_DAYS设置密码的默认最短期限 PASS_WARN_AGE设置密码的默认警告周期 限制访问   可以用chage命令来设置帐户到期日期。限制访问通过usermod命令的-L选项锁定帐户。-e选项来设置给定用户帐户的帐户到期日期。示例如下： [root@redhat8 ~]# usermod -L Tony [root@redhat8 ~]# su - huang [huang@redhat8 ~]$ su - Tony Password: su: Authentication failure [root@redhat8 ~]# usermod -L -e 2022-10-01 Tony   对应锁定的用户，其帐户可通过usermod -U解锁。如果帐户也已到期，还需要更改到期日期。还有种限制登录方法是将用户的登录shell设为/sbin/nologin，以限制交互方式登录用户帐户，示例： [root@redhat8 ~]# usermod -s /sbin/nologin testuser2 [root@redhat8 ~]# su - testuser2 This account is currently not available.   nologin shell可以防止以交互方式使用系统，但不会阻止所有访问。如果用户使用用户密码进行身份验证，有时可以通过身份验证，并使用Web应用、文件传输程序或邮件读取程序等应用上传或检索文件。 练习   通过编辑文件/etc/login.defs中PASS_MAX_DAYS选项，确保新建的用户具有必须每30天更改一次的密码，文件示例如下： [root@redhat8 ~]# cat /etc/login.defs ...output omitted... # Password aging controls: # # PASS_MAX_DAYS Maximum number of days a password may be used. # PASS_MIN_DAYS Minimum number of days allowed between password changes. # PASS_MIN_LEN Minimum acceptable password length. # PASS_WARN_AGE Number of days warning given before a password expires. # PASS_MAX_DAYS 30 PASS_MIN_DAYS 0 PASS_MIN_LEN 5 PASS_WARN_AGE 7 ...output omitted... 创建新组consultants，GID设为35000： [root@redhat8 ~]# groupadd -g 35000 consultants [root@redhat8 ~]# cat /etc/group ...output omitted... consultants:x:35000: 为consultants的所有成员配置管理权限，使其能够以任何用户身份执行任何命令： [root@redhat8 ~]# touch /etc/sudoers.d/consultants [root@redhat8 ~]# echo \"%consultants ALL=(ALL) ALL\" > /etc/sudoers.d/consultants [root@redhat8 ~]# cat /etc/sudoers.d/consultants %consultants ALL=(ALL) ALL 创建consultant1、consultant2和consultant3用户，并使consultants作为它们的补充组： [root@redhat8 ~]# useradd -G consultants consultant1 [root@redhat8 ~]# useradd -G consultants consultant2 [root@redhat8 ~]# useradd -G consultants consultant3 将consultant1、consultant2和consultant3帐户设为从当天起60天后过期： [root@redhat8 ~]# date -d \"+60 days\" +%F 2022-07-04 [root@redhat8 ~]# chage -E 2022-07-04 consultant1 [root@redhat8 ~]# chage -E 2022-07-04 consultant2 [root@redhat8 ~]# chage -E 2022-07-04 consultant3 更改consultant2帐户的密码策略，使其每30天要求创建新密码： [root@redhat8 ~]# chage -M 30 consultant2 强制consultant1用户在第一次登录时更改密码： [root@redhat8 ~]# chage -d O consultant1 "},"05-IBM_Operating_System/06-RHEL学习笔记/03-RHEL-文件访问及进程管理.html":{"url":"05-IBM_Operating_System/06-RHEL学习笔记/03-RHEL-文件访问及进程管理.html","title":"RHEL-文件访问及进程管理","keywords":"","body":"RHEL-文件访问及进程管理 控制对文件访问 解释Linux文件系统权限 Linux文件系统权限   文件权限控制对文件的访问。可以为所属用户、所属组和系统上的非用户和非所属组成员的其他用户设置不同的权限。用户权限覆盖组权限，组权限覆盖other权限。有三种权限类别可应用：读取、写入和执行。如下表所示： 权限 对文件的影响 对目录的影响 r(读取) 可以读取文件内容 可以列出目录的内容(文件名) w(写入) 可以更改文件内容 可以创建或删除目录中的任一文件 x(执行) 可以作为命令执行文件 目录可以成为当前工作目录(可以cd，但需读取权限才能列出其中文件) 文件权限更多说明： 用户通常对只读目录具有读取和执行权限，可以列出该目录，并且对其内容具有完整的只读访问权限 如果用户仅对某目录具有读取访问权限，可以列出其中文件的名称，但是其他信息（包括权限或时间戳）都不可用，也不可访问 如果用户仅对目录具有执行权限，则无法列出目录中的文件名。 如果知道有读取权限的文件的名称，可通过显式指定相对文件名，以便从目录外部访问该文件的内容 在文件所在的目录中拥有所有权或写入权限的任何人都可以删除此文件，不论此文件本身的所有权或权限如何（可以通过特殊权限粘滞位将其覆盖） 查看文件和目录的权限及所有权   命令ls的-l可以显示文件权限及所有权详细信息，-d选项可显示有关目录本身(非其内容)的详细信息。示例如下： [root@redhat8 ~]# ls -l ls.ps -rw-r--r--. 1 root root 20051 May 2 14:39 ls.ps [root@redhat8 ~]# ls -ld Downloads drwxr-xr-x. 2 root root 6 Mar 19 2021 Downloads 字段说明： 长列表的第一个字符表示文件类型，解译如下： -是常规文件 d是目录 l是软链接 其他字符代表硬件设备(b和c)或其他具有特殊用途的文件(p和s) 接下来的九个字符是文件权限。它们分为三组，每组三个字符，分别对应： 应用于拥有该文件的用户的权限 应用于拥有该文件的组的权限 应用于其他所有用户的权限 如果组中显示rwx，说明该类别具有读取、写入和执行三种权限。如果是-，则表示该类别没有这个权限 在链接数之后，第一个名称指定拥有该文件的用户，第二个名称指定拥有该文件的组 从命令行管理文件系统权限 更改文件和目录权限   更改权限的命令为chmod，意为change mode（更改模式，权限也称为文件的模式）。可使用符号（符号法）或数值（数值法）来发布权限说明。通过符号法更改权限： chmod WhoWhatWhich file/directory 示例说明： Who指u、g、o、a，分别代表用户、组、其他、全部 What指+、-、=，根本代表添加、删除、精确设置 Which指r、w、x，分别代表读取、写入、执行 说明： 在使用chmod通过符号法来更改权限时，仅当文件是目录或者已经为用户、组或其他人设置了执行权限时，使用大写的X作为权限标志才会添加执行权限 chmod命令支持-R选项以递归方式对整个目录树中的文件设置权限。   在使用-R选项时，使用X选项以符号形式设置权限会非常有用。这将能够对目录设置执行（搜索）权限，以便在不更改大部分文件权限的情况下，访问这些目录的内容。使用X选项时要谨慎，如果某个文件设置有任何执行权限，则X也将会对该文件设置指定的执行权限。示例： [root@redhat8 ~]# chmod -R g+rwX Videos   示例中以递归方式为组所有者设置对Videos及其所有子代的读、写访问权限，但将仅向已为用户、组或其他人设置了执行权限的目录和文件应用组执行权限。 示例如下： [root@redhat8 testdir]# ls -l total 0 -rw-r--r--. 1 root root 0 May 5 08:26 testfile1 -rw-r--r--. 1 root root 0 May 5 08:57 testfile2 [root@redhat8 testdir]# chmod go+wx testfile1 [root@redhat8 testdir]# chmod u-w testfile2 [root@redhat8 testdir]# ls -l total 0 -rw-rwxrwx. 1 root root 0 May 5 08:26 testfile1 -r--r--r--. 1 root root 0 May 5 08:57 testfile2 通过数值法更改权限(*字符代表一个数字)： chmod *** file|directory 示例说明： 每个数字代表一个访问级别的权限：用户、组、其他。 将所要添加的每个权限的数值加在一起，其中4代表读取，2代表写入，1代表执行。 权限由三位（或在设置高级权限时为四位）八进制数来表示 对于权限-rwxr-x---计算方法如下： 对于用户，rwx计算为4+2+1=7 对于组，r-x计算为4+0+1=5， 对于其他用户，---表示为0 将这三个放在一起，这些权限的数值法表示为750 示例如下： [root@redhat8 testdir]# chmod 755 testfile2 [root@redhat8 testdir]# chmod 644 testfile1 [root@redhat8 testdir]# ls -l total 0 -rw-r--r--. 1 root root 0 May 5 08:26 testfile1 -rwxr-xr-x. 1 root root 0 May 5 08:57 testfile2 更改文件和目录的用户   只有root用户可以更改拥有文件的用户。组所有权可以由root用户或文件的所有者来设置。root用户可将文件所有权授予任何组，而普通用户仅可将文件所有权授予他们所属的组。使用chown命令可更改文件所有权。示例更改文件所有权： [root@redhat8 testdir]# chown huang testfile1 [root@redhat8 testdir]# ls -l total 0 -rw-r--r--. 1 huang root 0 May 5 08:26 testfile1 使用-R选项，以递归更改整个目录树的所有权： [root@redhat8 ~]# chown -R christ testdir [root@redhat8 ~]# ls -ld testdir drwxr-xr-x. 2 christ root 40 May 5 08:57 testdir 在组名称之前加上冒号:，可以更改文件的组所有权： [root@redhat8 testdir]# chown :huang testfile1 [root@redhat8 testdir]# ls -l total 0 -rw-r--r--. 1 christ huang 0 May 5 08:26 testfile1 同时更改所有者和组，使用语法owner:group： [root@redhat8 testdir]# chown root:root testfile1 [root@redhat8 testdir]# ls -l total 0 -rw-r--r--. 1 root root 0 May 5 08:26 testfile1   可以使用chgrp命令来更改组所有权。该命令的作用与chown类似，不同之处在于它仅用于更改组所有权，而且不需要组名前的冒号:。 管理默认权限和文件访问 特殊权限   特殊权限构成了除了基本用户、组和其他类型之外的第四种权限类型。这些权限提供了额外的访问相关功能，超出了基本权限类型允许的范畴。特殊权限对文件和目录的影响如下表： 特殊权限 对文件的影响 对目录的影响 u+s (suid) 以拥有文件的用户身份，而不是以运行文件的用户身份执行文件 无影响 g+s (sgid) 以拥有文件的组身份执行文件 在目录中最新创建的文件将其组所有者设置为与目录的组所有者相匹配 o+t (sticky) 无影响 对目录具有写入访问权限的用户仅可以删除其所拥有的文件，而无法删除或强制保存到其他用户所拥有的文件   对可执行文件的setuid权限表示将以拥有该文件的用户的身份运行命令，而不是以运行命令的用户身份。如果所有者不具有执行权限，将由大写的S取代。示例如下： [root@redhat8 ~]# ls -l /etc/passwd -rw-r--r--. 1 root root 3027 May 5 04:59 /etc/passwd [root@redhat8 ~]# chmod u+s /etc/passwd [root@redhat8 ~]# ls -l /etc/passwd -rwSr--r--. 1 root root 3027 May 5 04:59 /etc/passwd [root@redhat8 ~]# chmod u-s /etc/passwd [root@redhat8 ~]# chmod u+x /etc/passwd [root@redhat8 ~]# chmod u+s /etc/passwd [root@redhat8 ~]# ls -l /etc/passwd -rwsr--r--. 1 root root 3027 May 5 04:59 /etc/passwd   对某目录的特殊权限setgid表示在该目录中创建的文件将继承该目录的组所有权，而不是继承自创建用户。这通常用于组协作目录，将文件从默认的专有组自动更改为共享组，或者当目录中的文件始终都应由特定的组所有时使用。典型示例目录是/run/log/journal： [root@redhat8 ~]# ls -ld /run/log/journal drwxr-sr-x. 3 root systemd-journal 60 May 13 04:54 /run/log/journal   如果对可执行文件设置了setgid，则命令以拥有该文件的组运行，而不是以运行命令的用户身份运行，其方式与setuid类似。如果组不具有执行权限，将会由大写S取代。locate命令为例： [root@redhat8 ~]# ls -ld /usr/bin/locate -rwx--s--x. 1 root slocate 47128 Aug 12 2018 /usr/bin/locate   针对目录的粘滞位将对文件删除设置特殊限制。只有文件的所有者（以及root）才能删除该目录中的文件。如果其他权限中不具有执行权限，将会由大写T取代。例如/tmp目录： [root@redhat8 ~]# ls -ld /tmp drwxrwxrwt. 19 root root 4096 May 13 09:07 /tmp 设置特殊权限 设置方式： 用符号表示：setuid=u+s；setgid=g+s；sticky=o+t 用数值表示（第四位）：setuid=4；setgid=2；sticky=1 示例如下： [root@redhat8 ~]# chmod g+s testdir [root@redhat8 ~]# ls -ld testdir drwxr-sr-x. 2 christ root 40 May 5 08:57 testdir [root@redhat8 ~]# chmod 2770 Videos [root@redhat8 ~]# ls -ld Videos drwxrws---. 2 root root 6 Mar 19 2021 Videos 默认文件权限   创建新文件或目录时，会为其分配初始权限。有两个因素会影响这些初始权限。首先是您要创建常规文件还是目录。其次是当前的umask： 创建新目录，操作系统首先会为其分配八进制权限0777(drwxrwxrwx) 创建新的常规文件，操作系统则为其分配八进制权限0666(-rw-rw-rw-) shell会话还会设置一个umask，以进一步限制初始设置的权限： 这是一个八进制位掩码，用于清除由该进程创建的新文件和目录的权限。 如果在umask中设置了一个位，则新文件中的对应的权限将被清除 例如umask为0002可清除其他用户的写入位。前导零表示特殊的用户和组权限未被清除。umask为0077时，清除新创建文件的所有组和其他权限 通过一个数字参数使用umask命令，可以更改当前shell的umask。umask中的任何前导零均可以省略 Bash shell用户的系统默认umask值在/etc/profile和/etc/bashrc文件中定义 用户可以在其主目录的.bash_profile 和.bashrc文件中覆盖系统默认值 umask示例如下： [huang@redhat8 ~]$ umask 0002 [huang@redhat8 ~]$ touch umask.test [huang@redhat8 ~]$ ls -l umask.test -rw-rw-r--. 1 huang huang 0 May 13 10:17 umask.test [huang@redhat8 ~]$ mkdir umasktest [huang@redhat8 ~]$ ls -ld umasktest drwxrwxr-x. 2 huang huang 6 May 13 10:18 umasktest umask更多示例及说明： 将umask值设置为0，其他的文件权限将从读取改为读取和写入。其他权限中的目录权限将从读取和执行改为读取、写入和执行 将umask值设置为007，可以屏蔽其他权限中的所有文件和目录权 umask为027可确保新文件的用户具有读写权限，并且组具有读取权限。新目录的组具有读取和写入权限，而其他权限中则没有访问权限 用户的默认umask由shell启动脚本设置。默认情况下，如果用户帐户的UID为200或以上，并且用户名和主要组名相同，就会分配一个值为002的umask。否则umask将为022   root用户可以通过添加/etc/profile.d/local-umask.sh的shell启动脚本来更改此设置。配置文件脚本示例如下： [root@redhat8 profile.d]# cat /etc/profile.d/local-umask.sh # Overrides default umask configuration if [ $UID -gt 199 ] && [ \"`id -gn`\" = \"`id -un`\" ]; then umask 007 else umask 022 fi 监控和管理Linux进程 列出进程 进程的定义   进程是已启动的可执行程序的运行中实例。在RHEL8系统上，第一个系统进程是systemd。进程由以下组成部分： 已分配内存的地址空间 安全属性，包括所有权凭据和特权 程序代码的一个或多个执行线程 进程状态 进程的环境包括： 本地和全局变量 当前调度上下文 分配的系统资源，如文件描述符和网络端口 进程状态   多任务处理操作系统中，每个CPU（或CPU核心）在一个时间点上处理一个进程。在进程运行时，它对CPU时间和资源分配的直接要求会有变化。进程分配有一个状态，它随着环境要求而改变。状态如下表所示： 名称 标志 内核定义的状态名称和描述 运行 R TASK_RUNNING：进程正在CPU上执行，或者正在等待运行。处于Running(或可运行)状态时，进程可能正在执行用户例程或内核例程(系统调用)，或者已排队并就绪 睡眠 S TASK_INTERRUPTIBLE：进程正在等待某一条件：硬件请求、系统资源访问或信号。当事件或信号满足该条件时，该进程将返回到Running 睡眠 D TASK_UNINTERRUPTIBLE：此进程也在睡眠，与S状态不同，不会响应信号。仅在进程中断可能会导致意外设备状态的情况下使用 睡眠 K TASK_KILLABLE：与不可中断的D状态相同，但有所修改，允许等待中的任务响应要被中断（彻底退出）的信号。实用程序通常将可中断的进程显示为D状态 睡眠 I TASK_REPORT_IDLE：D状态的一个子集。在计算负载平均值时，内核不会统计这些进程。用于内核线程。设置了 TASK_UNINTERRUPTABLE和TASK_NOLOAD标志。类似于TASK_KILLABLE，也是D状态的一个子集。它接受致命信号 已停止 T TASK_STOPPED：进程已被停止(暂停)，通常是通过用户或其他进程发出的信号。进程可以通过另一信号返回到Running状态，继续执行(恢复) 已停止 T TASK_TRACED：正在被调试的进程也会临时停止，并且共享同一个T状态标志 僵停 Z EXIT_ZOMBIE：子进程在退出时向父进程发出信号。除进程身份(PID)之外的所有资源都已释放 僵停 X EXIT_DEAD：当父进程清理(获取)剩余的子进程结构时，进程现在已彻底释放。此状态从不会在进程列出实用程序中看到   在创建进程时，系统会为进程分配一个状态。top命令的S列或ps的STAT列显示每个进程的状态。在单CPU系统上，一次只能运行一个进程。示例： [root@redhat8 ~]# top top - 08:40:03 up 9:34, 1 user, load average: 0.00, 0.00, 0.00 Tasks: 275 total, 1 running, 274 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.2 us, 0.5 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st MiB Mem : 1806.1 total, 229.5 free, 506.6 used, 1069.9 buff/cache MiB Swap: 2048.0 total, 1869.7 free, 178.2 used. 1265.7 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 954 root 20 0 144636 8252 6684 S 0.7 0.4 0:28.66 vmtoolsd 952 root 20 0 100456 1404 1240 S 0.3 0.1 0:03.32 irqbalance 1105 root 20 0 36088 3164 2272 S 0.3 0.2 0:00.41 crond ...output omitted... 列出进程 命令ps用于列出当前的进程，可以提供详细的进程信息，包括： 用户识别符(UID)，它确定进程的特权 唯一进程识别符(PID) CPU和已经花费的实时时间 进程在各种位置上分配的内存数量 进程stdout的位置，称为控制终端 当前的进程状态   ps命令中，aux是常见的选项集，可显示包括无控制终端的进程在内的所有进程。选项lax(长列表)提供更多技术详细信息，但可通过避免查询用户名来加快显示。相似的UNIX语法使用选项-ef来显示所有进程。示例： [root@redhat8 ~]# ps -aux USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND root 2 0.0 0.0 0 0 ? S May14 0:00 [kthreadd] root 3 0.0 0.0 0 0 ? I控制作业 描述作业和会话   作业控制是shell的一种功能，允许单个shell实例运行和管理多个命令。作业与在shell提示符中输入的每个管道相关联。该管道中的所有进程均是作业的一部分，并且是同一个进程组的成员： 如果在shell提示符处仅输入了一条命令，则这条命令可视为命令的最小“管道”，创建仅含有一个成员的一个作业 一次只能有一个作业从特定终端窗口中读取输入和键盘生成的信号： 属于该作业的进程是该控制终端的前台进程 该控制终端的后台进程是与该终端相关联的任何其他作业的成员。终端的后台进程无法从终端读取输入或接收键盘生成的中断，但可以写入终端。 后台中的作业可能已停止（暂停），也可能正在运行。如果某个正在运行的后台作业尝试从终端读取内容，则该作业将自动暂停 每个终端是其自身的会话，并且可以具有一个前台进程和任意数量的独立后台进程。一个作业只能属于一个会话，也就是属于其控制终端的会话 命令ps在TTY列中显示进程的控制终端的设备名称。某些进程（如系统守护进程）由系统启动，并不是从shell提示符启动。这些进程没有控制终端，也不是作业的成员，并且无法转至前台。ps命令在TTY列中针对这些进程显示一个问号? 在后台运行作业   任何命令或管道都可以在后台启动，在命令行的结尾处附加符号&即可。Bash shell显示作业编号（特定于会话的唯一编号）和新建子进程的PID。可以使用jobs命令显示Bash为特定会话跟踪的作业列表。示例： [root@redhat8 ~]# sleep 60 & [1] 17824 [root@redhat8 ~]# ps -ef |grep sleep root 17823 1002 0 09:14 ? 00:00:00 sleep 60 root 17824 2947 0 09:14 pts/0 00:00:00 sleep 60 root 17826 2947 0 09:14 pts/0 00:00:00 grep --color=auto sleep [root@redhat8 ~]# jobs [1]+ Running sleep 60 &   如果利用＆符号将包含管道的命令行发送到后台，管道中最后一个命令的PID将用作输出。管道中的所有进程仍是该作业的成员。示例： [root@redhat8 ~]# ls -l |sort|sleep 30 & [1] 17869 [root@redhat8 ~]# jobs [1]+ Running ls --color=auto -l | sort | sleep 30 & [root@redhat8 ~]# ps -ef |grep sleep root 17866 1002 0 09:17 ? 00:00:00 sleep 60 root 17869 2947 0 09:17 pts/0 00:00:00 sleep 30 root 17871 2947 0 09:17 pts/0 00:00:00 grep --color=auto sleep   可以使用fg命令和后台作业的ID（%作业编号）将该后台作业转至前台。要将前台进程发送到后台，首先在终端中按键盘生成的暂停请求Ctrl+z，该作业将立即置于后台并暂停。要启动在后台运行的已暂停进程，可使用bg命令。示例如下： [root@redhat8 ~]# sleep 30 & [1] 18033 [root@redhat8 ~]# fg %1 sleep 30 ^Z [1]+ Stopped sleep 30 [root@redhat8 ~]# bg %1 [1]+ sleep 30 & [root@redhat8 ~]# jobs [1]+ Running sleep 30 &   ps j命令显示与作业相关的信息。PID是进程的唯一进程ID。PPID是此进程的父进程（即启动（分叉）此进程的进程）的PID。PGID是进程组首进程的PID，通常是作业管道中的第一个进程。SID是会话首进程的PID，对于作业而言，这通常是正在其控制终端上运行的交互shell。示例sleep命令当前已暂停，因此其进程状态为T。示例： [root@redhat8 ~]# sleep 30 & [3] 18071 [root@redhat8 ~]# fg %3 sleep 30 ^Z [3]+ Stopped sleep 30 [root@redhat8 ~]# ps j PPID PID PGID SID TTY TPGID STAT UID TIME COMMAND 18001 18009 18009 2885 pts/0 18080 S 0 0:00 -bash 18009 18071 18071 2885 pts/0 18080 T 0 0:00 sleep 30 18009 18080 18080 2885 pts/0 18080 R+ 0 0:00 ps j   上面示例中[1]后面的+符号表示此作业是当前的默认作业。如果使用的某个命令需要参数%作业编号，但并没有提供作业编号，那么将对具有+指示符的作业执行该操作。 中断进程 使用信号控制进程   信号是传递至进程的软件中断。信号向执行中的程序报告事件。生成信号的事件可以是错误或外部事件（I/O 请求或定时器过期），或者来自于显式使用信号发送命令或键盘序列。系统管理员用于日常进程管理的基本信号如下表所示： 信号编号 短名称 定义 用途 1 HUP 挂起 用于报告终端控制进程的终止。也用于请求进程重新初始化(重新加载配置)而不终止 2 INT 键盘中断 导致程序终止。可以被拦截或处理。通过按INTR键序列(Ctrl+c)发送 3 QUIT 键盘退出 与SIGINT相似；在终止时添加进程转储。通过按QUIT键序列(Ctrl+\\)发送 9 KILL 中断，无法拦截 导致立即终止程序。无法被拦截、忽略或处理。对程序是致命的 15默认 TERM 终止 导致程序终止。可以被拦截、忽略或处理。友好的方式让程序终止；允许自我清理 18 CONT 继续 发送至进程使其恢复(若已停止)。无法被拦截。即使被处理，也始终恢复进程 19 STOP 停止，无法拦截 暂停进程。无法被拦截或处理 20 TSTP 键盘停止 和SIGSTOP不同，可以被拦截、忽略或处理。通过按SUSP键序列(Ctrl+z)发送 每个信号都有一个默认操作，通常是如下之一： Term：导致程序立即终止（退出） Core：导致程序保存内存镜像（核心转储），然后终止 Stop：导致程序停止执行（暂停），再等待继续（恢复）   向当前的前台进程发送信号，可以按下键盘控制序列以暂停Ctrl+z、中止Ctrl+c或核心转储Ctrl+\\该进程。发送命令向后台进程或另一会话中的进程发送信号需使用信号。用户可以中断自己的进程，终止由其他人拥有的进程需要root特权。kill命令根据PID编号向进程发送信号。kill -l命令列出所有可用信号的名称和编号。示例如下： [root@redhat8 ~]# kill -l 1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP ...output omitted... [root@redhat8 ~]# sleep 60 & [1] 18361 [root@redhat8 ~]# sleep 120 & [2] 18362 [root@redhat8 ~]# ps -ef |grep sleep root 18361 18009 0 10:01 pts/0 00:00:00 sleep 60 root 18362 18009 0 10:01 pts/0 00:00:00 sleep 120 root 18364 18009 0 10:01 pts/0 00:00:00 grep --color=auto sleep [root@redhat8 ~]# ps aux |grep sleep root 18361 0.0 0.0 7284 732 pts/0 S 10:01 0:00 sleep 60 root 18362 0.0 0.0 7284 712 pts/0 S 10:01 0:00 sleep 120 root 18374 0.0 0.0 12112 1080 pts/0 S+ 10:01 0:00 grep --color=auto sleep [root@redhat8 ~]# kill 18361 [root@redhat8 ~]# ps -ef |grep sleep root 18362 18009 0 10:01 pts/0 00:00:00 sleep 120 root 18377 18009 0 10:02 pts/0 00:00:00 grep --color=auto sleep [1]- Terminated sleep 60 [root@redhat8 ~]# kill -SIGTERM 18362 [root@redhat8 ~]# ps -ef |grep sleep root 18379 18009 0 10:02 pts/0 00:00:00 grep --color=auto sleep [2]+ Terminated sleep 120   命令pkill向一个或多个符合选择条件的进程发送信号。选择条件可以是命令名称、特定用户拥有的进程，或所有系统范围进程。pkill命令包括高级选择条件： 命令：具有模式匹配的命令名称的进程 UID：由某一 Linux 用户帐户拥有的进程，无论是有效的还是真实的 GID：由某一 Linux 组帐户拥有的进程，无论是有效的还是真实的 父级：特定父进程的子进程 终端：运行于特定控制终端的进程 示例如下： [huang@redhat8 ~]$ sleep 120 & [1] 18677 [huang@redhat8 ~]$ sleep 110 & [2] 18678 [huang@redhat8 ~]$ exit logout [root@redhat8 ~]# ps -ef |grep sleep huang 18677 1 0 10:29 pts/0 00:00:00 sleep 120 huang 18678 1 0 10:29 pts/0 00:00:00 sleep 110 root 18688 18009 0 10:29 pts/0 00:00:00 grep --color=auto sleep [root@redhat8 ~]# pkill -U huang [root@redhat8 ~]# ps -ef |grep sleep root 18832 18809 0 10:30 pts/0 00:00:00 grep --color=auto sleep 以管理员身份注销用户 出于各种各样的原因，用户可能需要注销其他用户。例如： 用户做出了安全违规行为 用户可能过度使用了资源 用户的系统可能不响应 用户不当访问了资料   要注销某个用户，首先确定要终止的登录会话。命令w列出用户登录和当前运行的进程。记录TTY和FROM列，以确定要关闭的会话。所有用户登录会话都与某个终端设备TTY相关联： 如果设备名称的格式为pts/N，说明这是一个与图形终端窗口或远程登录会话相关联的伪终端 如果格式为ttyN，则说明用户位于一个系统控制台、替代控制台或其他直接连接的终端设备上   首先使用pgrep确定要中断的PID编号，与pkill相似，使用相同的选项，但pgrep是列出进程而非中断进程。示例如下： [root@redhat8 ~]# w 10:35:53 up 11:30, 2 users, load average: 0.00, 0.00, 0.00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT huang pts/0 192.168.100.1 10:30 9.00s 0.02s 0.02s -bash root pts/1 192.168.100.1 10:32 0.00s 0.03s 0.01s w [root@redhat8 ~]# pgrep -l -u huang 18727 systemd 18735 (sd-pam) 18741 pulseaudio 18742 sshd 18747 bash 18799 dbus-daemon [root@redhat8 ~]# pkill -SIGKILL -u huang [root@redhat8 ~]# pgrep -l -u huang [root@redhat8 ~]# w 10:40:40 up 11:35, 1 user, load average: 0.00, 0.00, 0.00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT root pts/1 192.168.100.1 10:32 0.00s 0.04s 0.00s w   当需要注意的进程在同一登录会话中时，可能不需要中断用户的所有进程。通过w命令确定会话的控制终端，然后仅中断引用同一终端ID的进程。除非指定了SIGKILL，否则会话首进程（此处为Bash登录shell）可以成功处理终止请求并保留，但所有其他会话进程将被终止。示例如下： [root@redhat8 ~]# pgrep -l -u huang 19315 systemd 19322 (sd-pam) 19330 pulseaudio 19331 sshd 19337 bash 19388 dbus-daemon 19658 sleep [root@redhat8 ~]# w -h -u huang huang pts/0 192.168.100.1 10:47 16.00s 0.06s 0.01s -bash [root@redhat8 ~]# pkill -t pts/0 [root@redhat8 ~]# w -h -u huang huang pts/0 192.168.100.1 10:47 23.00s 0.04s 0.04s -bash [root@redhat8 ~]# pgrep -l -u huang 19315 systemd 19322 (sd-pam) 19330 pulseaudio 19331 sshd 19337 bash 19388 dbus-daemon [root@redhat8 ~]# pkill -SIGKILL -t pts/0 [root@redhat8 ~]# pgrep -l -u huang [root@redhat8 ~]# 示例说明： 在pts/0终端中，登录了huang用户，然后后台运行了sleep命令，切换到了root用户，同样后台运行了sleep命令 另外一个终端pts/1登录了root用户，示例中操作均在此终端执行 运行pkill -t pts/0时，pts/0终端中root用户退出到huang用户，并且huang用户的sleep进程终止了，但是会话还保持，huang用户还在登录 运行pkill -SIGKILL -t pts/0时，用户注销，会话结束   也可利用父进程和子进程关系来应用相同的选择性进程终止。使用pstree命令查看系统或单个用户的进程树。使用父进程的PID中断其创建的所有子进程。此时，父进程Bash登录 shell可以保留，因为信号仅定向至它的子进程。示例： [root@redhat8 ~]# pstree -p huang sshd(19809)───bash(19817)─┬─sleep(19880) └─sleep(19881) systemd(19789)─┬─(sd-pam)(19798) ├─dbus-daemon(19866)───{dbus-daemon}(19867) └─pulseaudio(19808)───{pulseaudio}(19865) [root@redhat8 ~]# pkill -P 19817 [root@redhat8 ~]# pgrep -l -u huang 19789 systemd 19798 (sd-pam) 19808 pulseaudio 19809 sshd 19817 bash 19866 dbus-daemon [root@redhat8 ~]# pstree -p huang sshd(19809)───bash(19817) systemd(19789)─┬─(sd-pam)(19798) ├─dbus-daemon(19866)───{dbus-daemon}(19867) └─pulseaudio(19808)───{pulseaudio}(19865) 监控进程活动 负载平均值   负载平均值是Linux内核提供的一种度量方式，它可以简单地表示一段时间内感知的系统负载。可以用它来粗略衡量待处理的系统资源请求数量，并确定系统负载是随时间增加还是减少： 根据处于可运行和不可中断状态的进程数，内核会每五秒钟收集一次当前的负载数 通过报告CPU上准备运行的进程数以及等待磁盘或网络I/O完成的进程数，Linux可以确定负载平均值 负载数是准备运行的进程数（进程状态为R）或等待 I/O 完成的进程数（进程状态为D）的运行平均值 负载平均值可粗略衡量在可以执行其他任何作业之前，有多少进程当前在等待请求完成： 请求可能是用于运行进程的CPU时间。 或者，请求可能是让关键磁盘I/O操作完成； 在请求完成之前，即使CPU空闲，也不能在CPU上运行该进程 无论是哪种方式，都会影响系统负载；系统的运行看起来会变慢，因为有进程正在等待运行 一些UNIX系统仅考虑CPU使用率或运行队列长度来指示系统负载。Linux还包含磁盘或网络利用率，因为它们与CPU负载一样会对系统性能产生重大影响。遇到负载平均值很高但CPU活动很低时，请检查磁盘和网络活动   uptime命令是显示当前负载平均值的一种方法。它可显示当前时间、计算机启动时长、运行的用户会话数以及当前的负载平均值。后面三个负载平均值代表了最近1、5和15分钟的负载情况。很直观指出系统负载似乎在增高还是降低。示例如下： [root@redhat8 ~]# uptime 11:11:22 up 12:06, 2 users, load average: 0.02, 0.01, 0.00   如果等待CPU处理的进程是负载平均值的主要贡献因素，则可以计算近似的每CPU负载值以判断系统是否在遭遇显著的等待。lscpu命令可以确定系统又多少CPU。w和top工具也可报告负载平均值。 示例： [root@redhat8 ~]# lscpu Architecture: x86_64 CPU op-mode(s): 32-bit, 64-bit Byte Order: Little Endian CPU(s): 2 On-line CPU(s) list: 0,1 Thread(s) per core: 1 Core(s) per socket: 2 Socket(s): 1 NUMA node(s): 1 ...output omitted... [root@redhat8 ~]# w 11:24:00 up 12:18, 2 users, load average: 0.10, 0.03, 0.00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT huang pts/0 192.168.100.1 11:00 21:39 0.03s 0.03s -bash root pts/1 192.168.100.1 10:32 0.00s 0.14s 0.01s w [root@redhat8 ~]# top top - 11:24:22 up 12:19, 2 users, load average: 0.07, 0.02, 0.00 Tasks: 275 total, 1 running, 274 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.0 us, 0.0 sy, 0.0 ni,100.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st MiB Mem : 1806.1 total, 183.0 free, 523.7 used, 1099.4 buff/cache MiB Swap: 2048.0 total, 1875.0 free, 173.0 used. 1247.6 avail Mem ...output omitted... 实时进程监控   top程序是系统进程的动态视图，显示一个摘要标题，以及与ps信息类似的进程或线程列表。与ps输出不同，top以可配置的间隔持续刷新，而且也提供列重新排列、排序和突出显示功能。用户配置可以保存，变为永久。默认输出列： 进程ID(PID) 用户名称(USER)是进程所有者 虚拟内存(VIRT)是进程正在使用的所有内存，包括常驻集合、共享库，以及任何映射或交换的内存页（ps命令中为VSZ） 常驻内存(RES)是进程所用的物理内存，包括任何驻留的共享对象（ps命令中为RSS） 进程状态(S) 显示为： D：不可中断睡眠 R：运行中或可运行 S：睡眠中 T：已停止或已跟踪 Z：僵停 CPU时间(TIME)是进程启动以来总的处理时间。可以切换为包含所有过去子进程的累计时间 进程命令名称(COMMAND) top中的基本击键操作如下表： 按键 用途 ?或h 交互式击键操作的帮助 l、t、m 切换到负载、线程和内存标题行 1 标题中切换显示单独CPU信息或所有CPU的汇总 s 更改刷新（屏幕）率，以带小数的秒数表示（如 0.5、1、5）。安全模式不可用 b 切换反向突出显示Running的进程；默认为仅粗体。 Shift+b 在显示中使用粗体，用于标题以及Running的进程 Shift+h 切换线程；显示进程摘要或单独线程 u、Shift+u 过滤任何用户名称（有效、真实） Shift+m 按照内存使用率，以降序方式对进程列表排序 Shift+p 按照处理器使用率，以降序方式对进程列表排序 k 中断进程。若有提示，输入PID，再输入signal。安全模式不可用 r 调整进程的nice值。若有提示，输入PID，再输入nice_value。安全模式不可用 Shift+w 写入（保存）当前的显示配置，以便在下一次重新启动 top 时使用 q 退出，ctrl+c也可以 f 通过启用或禁用字段的方式来管理列。同时还允许用户为top设置排序字段 练习 生成人为CPU负载   下面脚本会一直运行到被终止为止。它通过执行五万个加法题来生成人为CPU负载。然后休眠一秒钟，重置变量，再重复。脚本内容如下： #!/bin/bash while true; do var=1 while [[ var -lt 50000 ]]; do var=$(($var+1)) done sleep 1 done "},"05-IBM_Operating_System/06-RHEL学习笔记/04-RHEL-服务和守护进程及SSH.html":{"url":"05-IBM_Operating_System/06-RHEL学习笔记/04-RHEL-服务和守护进程及SSH.html","title":"RHEL-服务和守护进程及SSH","keywords":"","body":"RHEL-服务和守护进程及SSH 控制服务和守护进程 systemctl命令摘要   systemctl命令可以在运行中的系统上启动和停止服务，也可启用或禁用服务在系统引导时自动启动。下表是服务管理实用命令： 命令 任务描述 systemctl status UNIT 查看有关单元状态的详细信息 systemctl stop UNIT 在运行中的系统上停止一项服务 systemctl start UNIT 在运行中的系统上启动一项服务 systemctl restart UNIT 在运行中的系统上重新启动一项服务 systemctl reload UNIT 重新加载运行中服务的配置文件 systemctl mask UNIT 彻底禁用服务，使其无法手动启动或在系统引导时启动 systemctl unmask UNIT 使屏蔽的服务变为可用 systemctl enable UNIT 将服务配置为在系统引导时启动 systemctl disable UNIT 禁止服务在系统引导时启动 systemctl list-dependencies UNIT 列出指定单元需要的单元 识别自动启动的系统进程 systemd进程   systemd守护进程管理Linux的启动，一般包括服务启动和服务管理。它可在系统引导时以及运行中的系统上激活系统资源、服务器守护进程和其他进程。守护进程是在执行各种任务的后台等待或运行的进程： 一般情况下，守护进程在系统引导时自动启动并持续运行至关机或被手动停止 按照惯例，许多守护进程的名称以字母d结尾 systemd意义上的服务通常指的是一个或多个守护进程，但启动或停止一项服务可能会对系统的状态进行一次性更改，不会留下守护进程之后继续运行（称为oneshot 在RHEL中，第一个启动的进程(PID 1)是systemd，提供的几项功能如下： 并行化功能（同时启动多个服务），它可提高系统的启动速度 按需启动守护进程，而不需要单独的服务 自动服务依赖关系管理，可以防止长时间超时。例如，只有在网络可用时，依赖网络的服务才会尝试启动 利用Linux控制组一起追踪相关进程的方式 描述服务单元 systemd使用单元来管理不同类型的对象。常用单元类型： 服务单元具有.service扩展名，代表系统服务。这种单元用于启动经常访问的守护进程，如web服务器 套接字单元具有.socket扩展名，代表systemd应监控的进程间通信(IPC)套接字。如果客户端连接套接字，systemd将启动一个守护进程并将连接传递给它。套接字单元用于延迟系统启动时的服务启动，或者按需启动不常使用的服务 路径单元具有.path扩展名，用于将服务的激活推迟到特定文件系统更改发生之后。这通常用于使用假脱机目录的服务，如打印系统   systemctl命令用于管理单元。可通过systemctl -t help命令来显示可用的单元类型。命令示例如下： [root@redhat8 ~]# systemctl -t help Available unit types: service socket target device mount automount swap timer path slice scope 列出服务单元   可以使用systemctl命令来探索系统的当前状态。以下命令会列出所有当前加载的服务单元，通过--type=service选项将列出的单元类型限制为服务单元： [root@redhat8 ~]# systemctl list-units --type=service UNIT LOAD ACTIVE SUB DESCRIPTION accounts-daemon.service loaded active running Accounts Service atd.service loaded active running Job spooling tools auditd.service loaded active running Security Auditing Service avahi-daemon.service loaded active running Avahi mDNS/DNS-SD Stack bluetooth.service loaded active running Bluetooth service bolt.service loaded active running Thunderbolt system service chronyd.service loaded active running NTP client/server ...output omitted... systemctl list-units命令输出中的列描述： UNIT：服务单元名称 LOAD：systemd是否正确解析了单元的配置并将该单元加载到内存中 ACTIVE：单元的高级别激活状态。此信息表明单元是否已成功启动 SUB：单元的低级别激活状态。此信息指示有关该单元的更多详细信息。信息视单元类型、状态以及单元的执行方式而异 DESCRIPTION：单元的简短描述 命令systemctl更多说明： 默认情况下，systemctl list-units --type=service命令仅列出激活状态为active的服务单元 --all选项可列出所有服务单位，不论激活状态如何 可以使用--state=选项可按照LOAD、ACTIVE或SUB字段中的值进行筛选 不带任何参数运行systemctl命令可列出已加载和活动的单元   systemctl list-units命令显示systemd服务尝试解析并加载到内存中的单元；不显示已安装但未启用的服务。要查看所有已安装的单元文件的状态，使用systemctl list-unit-files命令，命令中STATE字段的有效条目有enabled、disabled、static和masked： [root@redhat8 ~]# systemctl list-unit-files --type=service UNIT FILE STATE accounts-daemon.service enabled alsa-restore.service static arp-ethers.service disabled atd.service enabled auth-rpcgss-module.service static avahi-daemon.service enabled ...output omitted... 查看服务状态   使用systemctl status name.type来查看特定单元的状态。如果未提供单元类型，则 systemctl将显示服务单元的状态（如果存在）： [root@redhat8 ~]# systemctl status sshd.service ● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2022-05-14 23:05:22 EDT; 18h ago Docs: man:sshd(8) man:sshd_config(5) Main PID: 1091 (sshd) Tasks: 1 (limit: 11366) Memory: 5.7M CGroup: /system.slice/sshd.service └─1091 /usr/sbin/sshd -D -oCiphers=aes256-gcm@openssh.com,chacha20-poly1305@openssh.com,aes256-ctr,aes256-cbc> May 15 10:39:48 redhat8 sshd[19043]: Accepted password for huang from 192.168.100.1 port 64838 ssh2 May 15 10:39:48 redhat8 sshd[19043]: pam_unix(sshd:session): session opened for user huang by (uid=0) ...output omitted... 此命令将显示服务的当前状态。各个字段的含义如下： 字段 描述 Loaded 服务单元是否已加载到内存中 Active 服务单元是否正在运行，若是，它已经运行了多久 Main PID 服务的主进程ID，包括命令名称 Status 有关该服务的其他信息 systemctl输出中的服务状态： 关键字 描述 loaded 单元配置文件已处理 active (running) 正在通过一个或多个持续进程运行 active (exited) 已成功完成一次性配置 active (waiting) 运行中，但正在等待事件 inactive 不在运行 enabled 在系统引导时启动 disabled 未设为在系统引导时启动 static 无法启用，但可以由某一启用的单元自动启动 验证服务的状态   systemctl命令提供了一些方法来验证服务的具体状态。可使用以下命令验证服务单元当前是否处于活动状态（正在运行）： [root@redhat8 ~]# systemctl is-active sshd.service active 验证服务单元是否已启用在系统引导期间自动启动： [root@redhat8 ~]# systemctl is-enabled sshd.service enabled 验证单元是否在启动过程中失败： [root@redhat8 ~]# systemctl is-failed sshd.service active 命令说明： 如果单元运行正常，该命令将返回active 如果启动过程中发生了错误，则返回failed 如果单元已被停止，将返回unknown或inactive 要列出所有失败的单元，命令及示例如下： [root@redhat8 ~]# systemctl --failed --type=service UNIT LOAD ACTIVE SUB DESCRIPTION ● mcelog.service loaded failed failed Machine Check Exception Logging Daemon LOAD = Reflects whether the unit definition was properly loaded. ACTIVE = The high-level unit activation state, i.e. generalization of SUB. SUB = The low-level unit activation state, values depend on unit type. 1 loaded units listed. Pass --all to see loaded but inactive units, too. To show all installed unit files use 'systemctl list-unit-files'. 控制系统服务 启动和停止服务   要启动服务，首先通过systemctl status验证它是否未在运行。然后，以root用户身份（必要时使用sudo）使用systemctl start命令。要停止当前正在运行的服务，使用stop参数来运行systemctl命令。示例如下： [root@redhat8 ~]# systemctl status sshd.service ● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset> Active: active (running) since Sat 2022-05-14 23:05:22 EDT; 19h ago ...output omitted... [root@redhat8 ~]# systemctl stop sshd [root@redhat8 ~]# systemctl status sshd.service ● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset> Active: inactive (dead) since Sun 2022-05-15 18:13:40 EDT; 3s ago ...output omitted... [root@redhat8 ~]# systemctl start sshd.service [root@redhat8 ~]# systemctl status sshd.service ● sshd.service - OpenSSH server daemon Loaded: loaded (/usr/lib/systemd/system/sshd.service; enabled; vendor preset> Active: active (running) since Sun 2022-05-15 18:15:32 EDT; 2s ago ...output omitted... 重新启动和重新加载服务   重新启动服务使用restart参数来运行systemctl命令。重新加载使用reload参数来运行systemctl命令。重新启动和重新加载服务示例如下： [root@redhat8 ~]# systemctl status sshd.service ● sshd.service - OpenSSH server daemon ...output omitted... Main PID: 23572 (sshd) ...output omitted... [root@redhat8 ~]# systemctl restart sshd [root@redhat8 ~]# systemctl status sshd.service ● sshd.service - OpenSSH server daemon ...output omitted... Main PID: 23579 (sshd) ...output omitted... [root@redhat8 ~]# systemctl reload sshd [root@redhat8 ~]# systemctl status sshd.service ● sshd.service - OpenSSH server daemon ...output omitted... Main PID: 23579 (sshd) ...output omitted... 重新启动和重新加载服务说明： 在重新启动正在运行的服务期间，服务将停止然后启动。在重新启动服务时，进程ID会改变，并且在启动期间会关联新的进程ID 某些服务可以重新加载其配置文件，而无需重新启动。这个过程称为服务重新加载。重新加载服务不会更改与各种服务进程关联的进程ID   如果不确定服务是否具有重新加载配置文件更改的功能，使用reload-or-restart参数来运行 systemctl命令。如果重新加载功能可用，该命令将重新加载配置更改。否则，该命令将重新启动服务以实施新的配置更改。示例如下： [root@redhat8 ~]# systemctl reload-or-restart sshd [root@redhat8 ~]# systemctl status sshd.service ● sshd.service - OpenSSH server daemon ...output omitted... Main PID: 23579 (sshd) ...output omitted... 列出单元依赖项   某些服务要求首先运行其他服务，从而创建对其他服务的依赖项。其他服务并不在系统引导时启动，而是仅在需要时启动。在这两种情况下，systemd和systemctl根据需要启动服务，不论是解决依赖项，还是启动不经常使用的服务。systemctl list-dependencies UNIT命令显示启动服务单元所需的依赖项的层次结构映射，使用--reverse选项列出反向依赖项。示例： [root@redhat8 ~]# systemctl list-dependencies sshd.service sshd.service ● ├─system.slice ● ├─sshd-keygen.target ● │ ├─sshd-keygen@ecdsa.service ● │ ├─sshd-keygen@ed25519.service ● │ └─sshd-keygen@rsa.service ● └─sysinit.target ● ├─dev-hugepages.mount ...output omitted... [root@redhat8 ~]# systemctl list-dependencies sshd.service --reverse sshd.service ● └─multi-user.target ● └─graphical.target 屏蔽未屏蔽的服务   有时系统中安装的不同服务之间可能彼此冲突，屏蔽服务可防止管理员意外启动与其他服务冲突的服务。例如，有多种方法可以管理邮件服务器（如postfix和sendmail等）。示例如下： [root@redhat8 ~]# systemctl mask sendmail.service Created symlink /etc/systemd/system/sendmail.service → /dev/null. [root@redhat8 ~]# systemctl list-unit-files --type=service UNIT FILE STATE sendmail.service masked [root@redhat8 ~]# systemctl start sendmail.service Failed to start sendmail.service: Unit sendmail.service is masked. [root@redhat8 ~]# systemctl unmask sendmail.service Removed /etc/systemd/system/sendmail.service. 示例说明及注意事项： 使用systemctl mask命令执行屏蔽服务单元 屏蔽操作会在配置目录中创建指向/dev/null文件的链接，该文件可阻止服务启动 尝试启动已屏蔽的服务单元会失败 使用systemctl unmask命令可取消屏蔽服务单元 禁用的服务可以手动启动，或通过其他单元文件启动，但不会在系统引导时自动启动。屏蔽的服务无法手动启动，也不会自动启动 使服务在系统引导时启动或停止   在systemd配置目录中创建链接，使服务在系统引导时启动。systemctl命令可以创建和删除这些链接。示例命令如下： [root@redhat8 ~]# systemctl enable cups.service Created symlink /etc/systemd/system/printer.target.wants/cups.service → /usr/lib/sy stemd/system/cups.service.Created symlink /etc/systemd/system/sockets.target.wants/cups.socket → /usr/lib/sys temd/system/cups.socket.Created symlink /etc/systemd/system/multi-user.target.wants/cups.path → /usr/lib/sy stemd/system/cups.path. [root@redhat8 ~]# systemctl disable cups.service Removed /etc/systemd/system/multi-user.target.wants/cups.path. Removed /etc/systemd/system/sockets.target.wants/cups.socket. Removed /etc/systemd/system/printer.target.wants/cups.service. [root@redhat8 ~]# systemctl is-enabled cups.service disabled 示例说明及注意事项： 在系统引导时启动服务，使用systemctl enable命令 执行引导启动命令后，会从服务单元文件（通常位于/usr/lib/systemd/system目录）创建一个符号链接，指向磁盘上供systemd寻找文件的位置，即/etc/systemd/system/TARGETNAME.target.wants目录 要禁用服务自动启动，使用systemctl disable命令，该命令将删除在启用服务时创建的符号链接。请注意禁用服务不会停止该服务 要验证服务是启用还是禁用状态，使用systemctl is-enabled命令 配置和保护SSH 使用SSH访问远程命令行   OpenSSH在RHEL系统上实施Secure Shell或SSh协议。SSH协议使系统能够通过不安全的网络以加密和安全的方式进行通信： 可以使用ssh命令来创建与远程系统的安全连接、以特定用户身份进行身份验证，并以该用户身份在远程系统上获取交互式shell会话 也可以使用ssh命令在远程系统上运行单个命令，而不运行交互式shell 安全Shell示例 使用与当前本地用户相同的用户名登录远程服务器remotehost，会提示进行身份验证： [root@redhat8 ~]# ssh remotehost 使用用户名huang登录远程服务器remotehost。会提示进行身份验证： [root@redhat8 ~]# ssh huang@remotehost 在remotehost远程系统上以huang用户身份运行hostname命令，而不访问远程交互式shell： [root@redhat8 ~]# ssh huang@remotehost hostname 使用exit命令来注销远程系统。 识别远程用户   w命令可显示当前登录到计算机的用户列表。这对于显示哪些用户使用ssh从哪些远程位置进行了登录以及执行了何种操作等内容特别有用。示例： [root@redhat8 ~]# w 21:25:35 up 22:20, 3 users, load average: 0.06, 0.02, 0.00 USER TTY FROM LOGIN@ IDLE JCPU PCPU WHAT huang tty2 tty2 18:12 22:20m 36.18s 0.12s /usr/libexec/tracke root pts/2 192.168.100.1 20:13 0.00s 0.22s 0.02s w huang pts/3 192.168.100.1 21:02 23:28 0.02s 0.02s -bash SSH主机密匙   SSH通过公钥加密的方式保持通信安全。当用户使用ssh命令连接到SSH服务器时，该命令会检查它在本地已知主机文件中是否有该服务器的公钥副本： 系统管理员可能在/etc/ssh/ssh_known_hosts中已进行预配置，或者用户的主目录中可能有包含公钥的~/.ssh/known_hosts文件 在特定于用户的~/.ssh/config文件或系统范围的/etc/ssh/ssh_config中将StrictHostKeyChecking参数设为yes，使得ssh命令在公钥不匹配时始终中断SSH连接。 如果客户端的已知主机文件中没有公钥的副本，ssh命令会询问是否仍要登录。如果仍进行登录，公钥的副本就会保存到~/.ssh/known_hosts文件中，以便将来能自动确认服务器的身份   如果由于硬盘驱动器故障而导致公钥丢失或由于某些正当理由而导致公钥被更换，并由此更改了服务器的公钥，用户需要编辑已知的主机文件以确保将旧公钥条目替换为新公钥条目。公钥存储在/etc/ssh/ssh_known_hosts及SSH客户端上每个用户的~/.ssh/known_hosts文件中。示例： [root@redhat8 ~]# cat ~/.ssh/known_hosts 192.168.122.106 ecdsa-sha2-nistp256 AAAAE2VjZHNhLXNoYTItbmlzdHAyNTYAAAAIbmlzdHAyNTYA AABBBNPBB8DiAz6yrGleDV5/py/heyo9is/Ym0mvyvZ4Ivx0+NfxP4T3jBG18mdf7cVKJROhdjH49204YB2MbJ7/UKM= 每个公钥各占一行，字段说明： 第一个字段是共享该公钥的主机名和IP地址的列表 第二个字段是公钥的加密算法 最后一个字段是公钥本身   用户所连接的每个远程SSH服务器都将其公钥存储在/etc/ssh目录下扩展名为.pub的文件中。文件查看示例如下： [root@redhat8 ~]# ls /etc/ssh/*key.pub /etc/ssh/ssh_host_ecdsa_key.pub /etc/ssh/ssh_host_rsa_key.pub /etc/ssh/ssh_host_ed25519_key.pub 配置基于SSH密钥的身份验证 基于SSH密钥的身份验证   用户可以配置SSH服务器，以便能通过基于密钥的身份验证在不使用密码的情况下进行身份验证。这种身份验证基于私钥-公钥方案。用户需要生成加密密钥文件的一个匹配对，一个是私钥，另一个是匹配的公钥： 私钥文件用作身份验证凭据，像密码一样，必须妥善保管 公钥复制到用户希望连接到的系统，用于验证私钥。公钥并不需要保密   使用ssh-keygen命令创建用于进行身份验证的私钥和匹配的公钥。默认情况下，私钥和公钥分别保存~/.ssh/id_rsa和~/.ssh/id_rsa.pub文件中： [root@redhat8 ~]# ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa. Your public key has been saved in /root/.ssh/id_rsa.pub. The key fingerprint is: SHA256:3sVt/1S1jOf72M4GvoERmWoo/LwaN8CuQPuA0c/lDvI root@redhat8 The key's randomart image is: +---[RSA 2048]----+ | | | o | | + .| | . o . o oo o| |. o * S o +.o+.| | + + + * o . ++..| |. = + + * . ...oo| | * + o o .*+| | E o.. o=B| +----[SHA256]-----+   如果未在ssh-keygen提示时指定密语，则生成的私钥不受保护。在这种情况下，任何拥有此私钥文件的人都可以使用它进行身份验证。如果设置了密码，则在使用私钥进行身份验证时需要输入此密语。下例中的ssh-keygen命令显示创建受密语保护的私钥及其公钥： [root@redhat8 ~]# ssh-keygen -f .ssh/key-with-pass Generating public/private rsa key pair. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in .ssh/key-with-pass. Your public key has been saved in .ssh/key-with-pass.pub. The key fingerprint is: SHA256:R7lppczeSK/cUd7vHlqzz1md2RT27OdsMQLQfmG2Fd8 root@redhat8 The key's randomart image is: +---[RSA 2048]----+ | . ..| | . o + .o| | = + +oE| | + B o..o| | S X o . +| | = + + *=| | o + o*X| | . o .o+X| | o .. *X| +----[SHA256]-----+ 示例说明： -f选项与ssh-keygen命令配合可用来确定保存密钥的文件。在示例中，私钥和公钥分别保存在/home/user/.ssh/key-with-pass及/home/user/.ssh/key-with-pass.pub文件中。 在进一步生成SSH密钥对期间，除非指定唯一的文件名，否则系统会询问您是否允许覆盖现有的id_rsa和 id_rsa.pub文件。如果覆盖现有的id_rsa和id_rsa.pub文件，那么必须在具有旧公钥的所有SSH服务器上使用新公钥替换旧公钥 生成SSH密钥后，密钥将默认存储在用户主目录下的.ssh/目录中。私钥和公钥的权限模式必须分别为600和 644 共享公钥   在可以使用基于密钥的身份验证之前，需要将公钥复制到目标系统上。ssh-copy-id命令可将 SSH密钥对的公钥复制到目标系统。如果在运行ssh-copy-id时省略了公钥文件的路径，会使用默认的/home/user/.ssh/id_rsa.pub文件。命令示例： [root@redhat8 ~]# ssh-copy-id -i .ssh/key-with-pass huang@remotehost   将公钥成功传输到远程系统后，可以使用对应的私钥对远程系统进行身份验证，同时通过SSH登录远程系统。如果在运行ssh命令时省略了私钥文件的路径 ，会使用默认的/home/user/.ssh/id_rsa文件。命令示例： [root@redhat8 ~]# ssh -i .ssh/key-with-pass huang@remotehost 使用ssh-agent进行非交互式身份验证   如果用户的SSH私钥受密语保护，通常必须输入密语才能使用私钥进行身份验证。可以使用名为ssh-agent的程序临时将密语缓存到内存中，当使用SSH通过私钥登录另一个系统时，ssh-agent会自动提供密语： 如果是初始登录GNOME图形桌面环境，可能会自动启动并配置ssh-agent程序，具体取决于您本地系统的配置 如果是在文本控制台上进行登录，使用ssh进行登录，或者使用sudo或su，可能需要为该会话手动启动 ssh-agent 当用户注销启动了ssh-agent的会话时，将退出进程，并且用户的私钥密语也将从内存中清除 使用以下命令手动启动： [root@redhat8 ~]# eval $(ssh-agent) Agent pid 3812   ssh-agent开始运行后，需要告诉它用户的私钥密语或密钥。使用ssh-add命令。示例使用ssh-add命令添加分别来自/home/user/.ssh/id_rsa（默认）和/home/user/.ssh/key-with-pass文件的私钥： [root@redhat8 ~]# ssh-add Identity added: /root/.ssh/id_rsa (root@redhat8) [root@redhat8 ~]# ssh-add .ssh/key-with-pass Enter passphrase for .ssh/key-with-pass: Identity added: .ssh/key-with-pass (root@redhat8) 自定义OpenSSH服务配置 配置OpenSSH服务器   sshd守护进程提供OpenSSH服务。主配置文件为/etc/ssh/sshd_config。OpenSSH服务器的默认配置也能良好运行。用户可能希望进行一些更改以增强系统的安全性。例如可能希望禁止直接远程登录root帐户，或者可能希望禁止使用基于密码的身份验证（偏向于使用SSH私钥身份验证）。 禁止超级用户使用SSH登录 最好禁止从远程系统直接登录root用户帐户。允许以root直接登录的一些风险包括： 所有Linux系统上都默认存在用户名root，因此潜在的攻击者只需要猜测其密码，而不必猜测有效的用户名与密码组合。这为攻击者降低了复杂度 root用户具有不受限制的特权，因此它的泄露可能会给系统造成最大的损坏 从审核的角度看，很难跟踪是哪个授权用户以root的身份登录并做出了更改。如果用户必须以普通用户身份登录并切换到root帐户，则会生成一个日志事件，可用于帮助确定责任   OpenSSH服务使用/etc/ssh/sshd_config配置文件中的PermitRootLogin配置设置，以允许或禁止用户以root身份登录系统。查看示例如下： [root@redhat8 ~]# cat /etc/ssh/sshd_config |grep PermitRootLogin PermitRootLogin yes # the setting of \"PermitRootLogin without-password\". 参数配置说明： 当PermitRootLogin参数默认设为yes，用户被允许以root身份登录系统。 要防止用户以root身份登录系统，可将该值设为no。 若要禁止基于密码的身份验证，但允许对root执行基于私钥的身份验证，可将PermitRootLogin参数设为 without-password SSH服务(sshd)必须重新加载才能使更改生效。示例如下： [root@host ~]# systemctl reload sshd 禁止对SSH进行基于密码的身份验证 仅允许基于私钥登录远程命令行有诸多优点： 攻击者无法使用密码猜测攻击来远程入侵系统上的已知帐户 对于受密语保护的私钥而言，攻击者同时需要密语和私钥的副本。对于密码而言，攻击者则只需要密码 通过将受密语保护的私钥与ssh-agent配合使用，由于密语的输入频率较低，因此被泄露的几率会较小，而且对用户来说会更便于登录   OpenSSH服务使用/etc/ssh/sshd_config配置文件中的PasswordAuthentication参数，用于控制用户在登录系统时能否使用基于密码的身份验证。查看示例如下： [root@redhat8 ~]# cat /etc/ssh/sshd_config |grep PasswordAuthentication #PasswordAuthentication yes PasswordAuthentication yes # PasswordAuthentication. Depending on your PAM configuration, # PAM authentication, then enable this but set PasswordAuthentication 参数配置说明： 配置文件中PasswordAuthentication参数的默认值是yes，SSH服务允许用户在登录系统时使用基于密码的身份验证 PasswordAuthentication的值为no时禁止用户使用基于密码的身份验证 注意事项 用户每当更改/etc/ssh/sshd_config文件时，都必须重新加载sshd服务让更改生效 如果为ssh关闭基于密码的身份验证，则需要有一种办法来确保用户在远程服务器上的~/.ssh/authorized_keys文件中有公钥，以便可以登录 练习 "},"05-IBM_Operating_System/06-RHEL学习笔记/05-RHEL-日志分析及管理.html":{"url":"05-IBM_Operating_System/06-RHEL学习笔记/05-RHEL-日志分析及管理.html","title":"RHEL-日志分析及管理","keywords":"","body":"RHEL-日志分析及管理 系统日志架构 系统日志记录   进程和操作系统内核为发生的事件记录日志。这些日志用于系统审核和问题的故障排除。许多系统都以文本文件的方式记录事件日志，保存在/var/log目录中。RHEL中内建了一个基于Syslog协议的标准日志记录统。systemd-journald和rsyslog服务处理RHEL8中的syslog消息： systemd-journald服务是操作系统事件日志架构的核心。它收集许多来源的事件消息，包括内核、引导过程早期阶段的输出、守护进程启动和运行时的标准输出及标准错误，以及syslog事件。然后，它会将它们重构为一种标准格式，并写进带有索引的结构化系统日志中。默认情况下，该日志存储在系统重启后不保留的文件系统上。 rsyslog服务会从日志中读取systemd-journald收到的syslog消息。之后将处理syslog事件，将它们记录到日志文件中，或根据自己的配置将它们转发给其他服务： rsyslog服务对syslog消息进行排序，并将它们写入到在系统重启后不保留的日志文件中(/var/log) rsyslog服务会根据发送每条消息的程序类型或设备以及每条syslog消息的优先级，将日志消息排序到特定的日志文件 除了syslog消息文件外，/var/log目录中还包含系统上其他服务的日志文件 /var/log目录中一些有用的文件： 日志文件 存储的消息类型 /var/log/messages 大多数系统日志消息记录在此处。不包括与身份验证、电子邮件处理和调度作业执行相关的消息以及纯粹与调试相关的消息 /var/log/secure 与安全性和身份验证事件相关的syslog消息 /var/log/maillog 与邮件服务器相关的syslog消息 /var/log/cron 与调度作业执行相关的syslog消息 /var/log/boot.log 与系统启动相关的非syslog控制台消息 查看系统日志文件 将事件记录到系统   许多程序使用syslog协议将事件记录到系统。每一日志消息根据设备（消息的类型）和优先级（消息的严重性）分类。下表从高到低列出了八个标准syslog优先级： 代码 优先级 严重性 0 emerg 系统不可用 1 alert 必须立即采取措施 2 crit 临界情况 3 err 非严重错误状况 4 warning 警告情况 5 notice 正常但重要的事件 6 info 信息性事件 7 debug 调试级别消息   rsyslog服务使用日志消息的设备和优先级来确定如何进行处理。其配置规则位于/etc/rsyslog.conf文件和/etc/rsyslog.d目录中扩展名为.conf的任何文件。通过在/etc/rsyslog.d目录中安装适当的文件，软件包可以轻松地添加规则。以下示例会将发送给authpriv设备的任何优先级的消息记录到文件/var/log/secure中： # The authpriv file has restricted access. authpriv.* /var/log/secure 示例说明： 每个控制着syslog消息排序方式的规则都对应了其中一个配置文件中的一行 每行左侧表示与规则匹配的syslog消息的设备和严重性 每行右侧表示要将日志消息保存到的文件（或消息所要发送到的其他位置） 星号*是一个匹配所有值的通配符 日志消息其它说明： 日志消息有时会匹配rsyslog.conf中的多条规则。在这种情况下，一条消息会存储到多个日志文件中。为限制存储的消息，优先级字段中的关键字none指出不应将指定设备的消息存储在给定的文件中 除了将syslog消息记录到文件中外，也可将它们显示到所有已登录用户的终端。rsyslog.conf文件中有一项设置，可将优先级为emerg的所有syslog消息显示到所有已登录用户的终端。 Rsyslog规则(查看/etc/rsyslog.conf文件)示例如下： # rsyslog configuration file #### RULES #### # Log all kernel messages to the console. # Logging much else clutters up the screen. #kern.* /dev/console # The authpriv file has restricted access. authpriv.* /var/log/secure # Log all the mail messages in one place. mail.* -/var/log/maillog # Log cron stuff cron.* /var/log/cron # Everybody gets emergency messages *.emerg :omusrmsg:* # Save news errors of level crit and higher in a special file. uucp,news.crit /var/log/spooler # Save boot messages also to boot.log local7.* /var/log/boot.log 日志文件轮转   logrotate工具会轮转日志文件，以防止它们在含有/var/log目录的文件系统中占用太多空间。轮转日志文件时，使用指示轮转日期的扩展名对其重命名。轮转原日志文件之后，会创建新日志文件，并通知对它执行写操作的服务： 例如，如果在2022-01-30轮转，旧的/var/log/messages文件可能会变成/var/log/messages-20220130 轮转若干次之后（通常在四周之后），丢弃最旧的日志文件以释放磁盘空间 调度作业每日运行一次logrotate程序，以查看是否有任何日志需要轮转 大多数日志文件每周轮转一次，但是logrotate轮转文件的速度有时较快，有时较慢，或在文件达到特定大小时进行轮转 分析Syslog条目   日志消息在文件的开头显示最旧的消息，在文件的末尾显示最新的消息。rsyslog服务在日志文件中记录条目时采用一种标准的格式。示例/var/log/secure日志文件中的日志消息： [root@redhat8 ~]# cat /var/log/secure May 23 06:28:10 redhat8 unix_chkpwd[6502]: password check failed for user (huang) May 23 06:28:10 redhat8 sshd[6500]: pam_unix(sshd:auth): authentication failure; log name= uid=0 euid=0 tty=ssh ruser= rhost=192.168.100.1 user=huang 日志消息条目依次说明： 记录该日志条目的时间戳 发送该日志消息的主机名称 发送该日志消息的程序或进程名称和PID编号 发送的实际消息 监控日志   监控一个或多个日志文件中的事件有助于重现问题。tail -f /path/to/file命令输出指定文件的最后10行(或自定义行)，并在新行写入到文件中时继续输出它们。可以一个终端运行命令，另一个终端进行日志监控。示例： [root@redhat8 ~]# tail -f /var/log/secure May 23 06:28:10 redhat8 unix_chkpwd[6502]: password check failed for user (huang) May 23 06:28:10 redhat8 sshd[6500]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=192.168.100.1 user=huang May 23 06:28:11 redhat8 sshd[6500]: Failed password for huang from 192.168.100.1 port 52524 ssh2 May 23 06:28:14 redhat8 sshd[6500]: error: Received disconnect from 192.168.100.1 port 52524:0: [preauth] May 23 06:28:14 redhat8 sshd[6500]: Disconnected from authenticating user huang 192.168.100.1 port 52524 [preauth] ^C 手动发送Syslog消息   logger命令可以发送消息到rsyslog服务。默认情况下，它将优先级为notice(user.notice)的消息发送给user设备，除非通过-p选项另有指定。对测试rsyslog服务配置更改很有用。向rsyslog服务发送消息并记录在/var/log/boot.log日志文件中示例如下： [root@redhat8 ~]# logger -p local7.notice \"Log entry created on host redhat8\" [root@redhat8 ~]# tail -n 2 /var/log/boot.log May 23 06:50:11 redhat8 root[6720]: Log entry created on host redhat8 查看系统日志条目 查找事件   systemd-journald服务将日志数据存储在带有索引的结构化二进制文件中，该文件称为日志。此数据包含与日志事件相关的额外信息。在RHEL8中，默认情况下/run/log目录用于存储系统日志。/run/log的内容在系统重启后将被清除。用户可以更改此设置。  使用journalctl命令来查看日志中的所有消息，或根据各种选项和标准来搜索特定事件。如果以root身份运行该命令，则对日志具有完全访问权限。普通用户也可以使用此命令，但可能会被限制查看某些消息。命令示例： [root@redhat8 ~]# journalctl |grep sshd May 22 22:20:57 redhat8 systemd[1]: Reached target sshd-keygen.target. May 22 22:20:59 redhat8 sshd[1137]: Server listening on 0.0.0.0 port 22. May 22 23:43:49 redhat8 sshd[1137]: Received SIGHUP; restarting. May 22 23:43:49 redhat8 sshd[1137]: Server listening on :: port 22. May 23 06:28:10 redhat8 sshd[6500]: pam_unix(sshd:auth): authentication failure; logname= uid=0 euid=0 tty=ssh ruser= rhost=192.168.100.1 user=huang May 23 06:28:11 redhat8 sshd[6500]: Failed password for huang from 192.168.100.1 port 52524 ssh2 journalctl命令突出显示重要的日志消息： 优先级为notice或warning的消息显示为粗体文本 优先级为·error或以上的消息则显示为红色文本   默认情况下journalctl -n显示最后10个日志条目。可以借助可选参数对此进行调整，它可以指定要显示的日志条目数。示例显示最后3个日志条目： [root@redhat8 ~]# journalctl -n 3 -- Logs begin at Sun 2022-05-22 22:20:52 EDT, end at Mon 2022-05-23 08:20:01 EDT. -- May 23 08:18:01 redhat8 nm-dispatcher[7546]: req:1 'dhcp4-change' [ens160]: start running ordered scripts... May 23 08:18:27 redhat8 PackageKit[7494]: daemon quit May 23 08:20:01 redhat8 CROND[7577]: (root) CMD (/usr/lib64/sa/sa1 1 1)   与tail -f命令相似，journalctl -f命令输出系统日志的最后10行，并在新日志条目写入到日志中时继续输出它们。退出journalctl -f进程使用Ctrl+C组合键。示例： [root@redhat8 ~]# journalctl -f -- Logs begin at Sun 2022-05-22 22:20:52 EDT. -- ...output omitted... May 23 08:18:01 redhat8 systemd[1]: Started Network Manager Script Dispatcher Service. May 23 08:18:27 redhat8 PackageKit[7494]: daemon quit May 23 08:20:01 redhat8 CROND[7577]: (root) CMD (/usr/lib64/sa/sa1 1 1) ^C   journalctl -p可以接受优先级的名称或编号作为参数，并显示该优先级别及以上的日志条目。journalctl命令支持debug、info、notice、warning、err、crit、alert和emerg优先级。示例列出优先级为err或以上的日志条目： [root@redhat8 ~]# journalctl -p err -- Logs begin at Sun 2022-05-22 22:20:52 EDT, end at Mon 2022-05-23 08:20:01 EDT. -- May 22 22:20:52 redhat8 kernel: Detected CPU family 17h model 96 May 22 22:21:05 redhat8 dnsmasq[2095]: FAILED to start up ...output omitted...   查找具体的事件时，可以将输出限制为特定的时间段。journalctl命令有两个选项，分别是 --since和--until选项，它们可以将输出限制为特定的时间范围： 这两个选项都采用格式为YYYY-MM-DD hh:mm:ss的时间参数（必须使用双引号，以保留选项中的空格） 如果省略日期，则命令会假定日期为当天 如果省略时间，则命令假定为自00:00:00起的一整天 除了日期和时间字段外，这两个选项还接受yesterday、today和tomorrow作为有效的参数 示例列出昨天记录中的所有日志条目： [root@redhat8 ~]# journalctl --since yesterday -- Logs begin at Sun 2022-05-22 22:20:52 EDT, end at Mon 2022-05-23 08:33:00 EDT. -- May 22 22:20:52 redhat8 kernel: BIOS-provided physical RAM map: May 22 22:20:52 redhat8 kernel: vmware: using sched offset of 7866811847 ns May 22 22:20:52 redhat8 kernel: e820: remove [mem 0x000a0000-0x000fffff] usable May 22 22:20:52 redhat8 kernel: MTRR default type: uncachable ...output omitted... 列出范围从2022-05-23 20:30:00到2022-05-24 12:00:00的所有日志条目： [root@redhat8 ~]# journalctl --since \"2022-05-23 20:30:00\" --until \"2022-05-24 12:00 :00\"-- Logs begin at Sun 2022-05-22 22:20:52 EDT, end at Mon 2022-05-23 08:33:00 EDT. -- -- No entries -- 可以指定相对于当前的某个时间以后的所有条目，例如上一小时所有条目： [root@redhat8 ~]# journalctl --since \"-1 hour\" -- Logs begin at Sun 2022-05-22 22:20:52 EDT, end at Mon 2022-05-23 08:40:01 EDT. -- May 23 07:48:00 redhat8 NetworkManager[1112]: [1653306480.3308] dhcp4 (ens160): address 192.168.100.131 May 23 07:48:00 redhat8 NetworkManager[1112]: [1653306480.3312] dhcp4 (ens160): expires in 1800 seconds May 23 07:48:00 redhat8 NetworkManager[1112]: [1653306480.3312] dhcp4 (ens160): nameserver '192.168.100.2' ...output omitted...   除了日志的可见内容外，日志条目中还附带了只有在打开详细输出时才可看到的字段。任何显示的额外字段都可用于过滤日志查询的输出。这可减少查找日志中特定事件的复杂搜索的输出。示例： [root@redhat8 ~]# journalctl -o verbose -- Logs begin at Sun 2022-05-22 22:20:52 EDT, end at Mon 2022-05-23 08:50:01 EDT. -- Sun 2022-05-22 22:20:52.615448 EDT [s=4180d79441bd4539bc3992ce20aa83ba;i=1;b=65c88922c4b5449a95f86d8d7fdf9580;m=100fd7;t=5dfa47d414d18;x=fde612134042eb16] _SOURCE_MONOTONIC_TIMESTAMP=0 _TRANSPORT=kernel PRIORITY=5 SYSLOG_FACILITY=0 SYSLOG_IDENTIFIER=kernel MESSAGE=Linux version 4.18.0-80.el8.x86_64 (mockbuild@x86-vm-08.build.eng.bos.redhat.com) (gcc version 8.2.1 20180905 (Red Hat 8.2.1-3) (GCC)) #1 SMP Wed Mar 13 12:02> _BOOT_ID=65c88922c4b5449a95f86d8d7fdf9580 _MACHINE_ID=0d4f35dc451749ecad3ae466d7cbf09a _HOSTNAME=redhat8 ...output omitted... 以下是系统日志的常用字段，可用于搜索与特定进程或事件相关的行： _COMM是命令的名称 _EXE是进程的可执行文件的路径 _PID是进程的PID _UID是运行该进程的用户的UID _SYSTEMD_UNIT是启动该进程的systemd单元 显示与PID为1137的sshd.service systemd进程单元相关的所有日志条目： [root@redhat8 ~]# journalctl _SYSTEMD_UNIT=sshd.service _PID=1137 -- Logs begin at Sun 2022-05-22 22:20:52 EDT, end at Mon 2022-05-23 08:57:09 EDT. -- May 22 22:20:59 redhat8 sshd[1137]: Server listening on 0.0.0.0 port 22. May 22 22:20:59 redhat8 sshd[1137]: Server listening on :: port 22. May 22 23:43:49 redhat8 sshd[1137]: Received SIGHUP; restarting. May 22 23:43:49 redhat8 sshd[1137]: Server listening on 0.0.0.0 port 22. May 22 23:43:49 redhat8 sshd[1137]: Server listening on :: port 22. 保留系统日志 永久存储系统日志   默认情况下，系统日志保存在/run/log/journal目录中，系统重启时这些日志会被清除。可以在/etc/systemd/journald.conf文件中更改systemd-journald服务的配置设置，文件中的Storage参数决定系统日志以易失性方式存储，还是在系统重启后持久保留。参数选项说明如下： persistent：将日志存储在/var/log/journal目录中，在系统重启后持久保留： 如果/var/log/journal目录不存在，systemd-journald服务会创建 volatile：将日志存储在易失性/run/log/journal目录中： 因为/run文件系统是临时的，仅存在于运行时内存中，存储在其中的数据（包括系统日志）不会在系统启后保留 auto：如果/var/log/journal目录存在，那么会使用持久存储，否则使用易失性存储： 如果未设置Storage参数，此为默认操作 none：不使用任何存储。所有的日志都会被丢弃，但日志转发仍将按预期工作   持久系统日志的优点是系统启动后就可立即利用历史数据。然而，即便是持久日志，并非所有数据都将永久保留。限制规则说明如下： 该日志具有一个内置日志轮转机制，会在每个月触发 默认情况下，日志的大小不能超过所处文件系统的10%，也不能造成文件系统的可用空间低于15%。 可以在/etc/systemd/journald.conf中为运行时和持久日志调整这些值 当systemd-journald进程启动时，会记录当前的日志大小限额 示例命令输出显示了反映当前大小限额的日志条目： [root@redhat8 ~]# journalctl | grep -E 'Runtime|System journal' May 23 03:51:14 redhat8 systemd-journald[5081]: Runtime journal (/run/log/journal/0d4f35dc451749ecad3ae466d7cbf09a) is 24.0M, max 90.3M, 66.3M free. May 23 04:26:30 redhat8 systemd-journald[5247]: Runtime journal (/run/log/journal/0d4f35dc451749ecad3ae466d7cbf09a) is 32.0M, max 90.3M, 58.3M free. May 23 07:16:30 redhat8 systemd-journald[6837]: Runtime journal (/run/log/journal/0d4f35dc451749ecad3ae466d7cbf09a) is 40.0M, max 90.3M, 50.3M free. 配置持久系统日志   以超级用户身份运行编辑/etc/systemd/journald.conf文件，将Storage设为persistent，systemd-journald服务配置在系统重启后持久保留系统日志。配置查询示例： [root@redhat8 ~]# cat /etc/systemd/journald.conf |grep Storage Storage=putstents 编辑完成后需重启systemd-journald服务使配置更改生效： [root@redhat8 ~]# systemctl restart systemd-journald   systemd-journald服务重启成功后，/var/log/journal目录已创建好，并包含一个或多个子目录。这些子目录的长名称中包含十六进制字符，目录中有*.journal文件，它是存储带有索引的结构化日志条目的二进制文件： [root@redhat8 ~]# ls /var/log/journal 0d4f35dc451749ecad3ae466d7cbf09a [root@redhat8 ~]# ls /var/log/journal/0d4f35dc451749ecad3ae466d7cbf09a/ system.journal   由于系统日志在系统重启后保留，在journalctl命令的输出中会有大量的条目，包括当前系统引导以及之前系统引导的条目。要将输出限制为特定的系统启动，使用-b选项。示例检索第一次系统启动的条目： [root@redhat8 ~]# journalctl -b 1 检索第二次系统启动的条目，当系统重启至少两次时，参数才有意义： [root@redhat8 ~]# journalctl -b 2 Data from the specified boot (+2) is not available: No such boot ID in journal 仅检索当前系统启动的条目： [root@redhat8 ~]# journalctl -b   利用永久日志调试系统崩溃时，通常需要将日志查询限制为崩溃发生之前的重新启动。可以给-b选项附上一个负数值，指示输出中应包含过去多少次系统引导。例如，journalctl -b -1将输出限制为上一次启动。 维护准确的时间 设置本地时钟和时区   对于在多个系统间分析日志文件而言，正确同步系统时间至关重要。网络时间协议(NTP)是计算机用于通过互联网提供并获取正确时间信息的一种标准方法。还可以通过高质量硬件时钟为本地客户端提供准确时间。 timedatectl命令简要显示当前的时间相关系统设置： [root@redhat8 ~]# timedatectl Local time: Mon 2022-05-23 09:37:45 EDT Universal time: Mon 2022-05-23 13:37:45 UTC RTC time: Tue 2022-05-24 09:44:05 Time zone: America/New_York (EDT, -0400) System clock synchronized: no NTP service: active RTC in local TZ: no 系统提供了包含时区的数据库，timedatectl list-timezones命令列出： [root@redhat8 ~]# timedatectl list-timezones Africa/Abidjan Africa/Accra Africa/Addis_Ababa Africa/Algiers Africa/Asmara ...output omitted...   可以使用tzselect命令识别正确的zoneinfo时区名称。它以交互方式向用户提示关于系统位置的问题，然后输出正确时区的名称。它不会对系统的时区设置进行任何更改。命令示例如下： [root@redhat8 ~]# tzselect Please identify a location so that time zone rules can be set correctly. Please select a continent, ocean, \"coord\", or \"TZ\". 1) Africa 2) Americas 3) Antarctica 4) Asia 5) Atlantic Ocean 6) Australia 7) Europe 8) Indian Ocean 9) Pacific Ocean 10) coord - I want to use geographical coordinates. 11) TZ - I want to specify the time zone using the Posix TZ format. #?   超级用户可以用timedatectl set-timezone命令更改系统设置来更新当前的时区。以下 timedatectl命令将当前时区更新为Asia/Shanghai： [root@redhat8 ~]# timedatectl set-timezone Asia/Shanghai [root@redhat8 ~]# timedatectl Local time: Mon 2022-05-23 21:47:39 CST Universal time: Mon 2022-05-23 13:47:39 UTC RTC time: Tue 2022-05-24 09:53:14 Time zone: Asia/Shanghai (CST, +0800) System clock synchronized: no NTP service: active RTC in local TZ: no   如果需要在特定服务器上使用协调世界时(UTC)，可将其时区设置为UTC。tzselect命令不包括UTC时区的名称。使用timedatectl set-timezone UTC命令可将系统的当前时区设置为UTC。示例： [root@redhat8 ~]# timedatectl set-timezone UTC [root@redhat8 ~]# timedatectl Local time: Mon 2022-05-23 13:49:32 UTC Universal time: Mon 2022-05-23 13:49:32 UTC RTC time: Tue 2022-05-24 09:54:58 Time zone: UTC (UTC, +0000) System clock synchronized: no NTP service: active RTC in local TZ: no   使用timedatectl set-time命令可更改系统的当前时间。时间以YYYY-MM-DD hh:mm:ss格式指定，其中可以省略日期或时间。示例将时间更改为23:57:00： [root@redhat8 ~]# timedatectl set-time 23:57:00 Failed to set time: NTP unit is active [root@redhat8 ~]# timedatectl set-ntp false [root@redhat8 ~]# timedatectl set-time 23:57:00 [root@redhat8 ~]# timedatectl Local time: Mon 2022-05-23 23:57:03 UTC Universal time: Mon 2022-05-23 23:57:03 UTC RTC time: Mon 2022-05-23 23:57:03 Time zone: UTC (UTC, +0000) System clock synchronized: no NTP service: inactive RTC in local TZ: no   上面示例中NTP服务开启了无法提示设置时间失败，使用timedatectl set-ntp命令可启用或禁用NTP同步（自动调整时间）。选项需要true或false参数将它打开或关闭。 配置和监控Chronyd   chronyd服务通过与配置的NTP服务器进行同步，使通常不准确的本地硬件时钟(RTC)保持正确运行。如果没有可用的网络连接，chronyd将计算RTC时钟漂移，记录在/etc/chrony.conf配置文件指定的driftfile变量中： 默认情况下，chronyd服务使用NTP Pool Project的服务器同步时间，不需要额外的配置。当涉及的计算机位于孤立网络中时，可能需要更改NTP服务器 NTP时间源的stratum决定其质量。stratum确定计算机与高性能参考时钟偏离的跃点数。参考时钟是stratum 0时间源。与之直接关联的NTP服务器是stratum 1，而与该NTP服务器同步时间的计算机则是 stratum 2时间源 server和peer是用户可以在/etc/chrony.conf配置文件中声明的两种时间源类别。server比本地 NTP服务器高一个级别，而peer则属于同一级别。可以指定多个server和多个peer，每行指定一个： server行的第一个参数是NTP服务器的IP地址或DNS名称 在服务器IP地址或名称后，可以列出该服务器的一系列选项。建议使用iburst选项，因为在服务启动后，会在很短时间内执行四种测量，获得更加精确的初始时钟同步 /etc/chrony.conf文件示例： [root@redhat8 ~]# cat /etc/chrony.conf # Use public servers from the pool.ntp.org project. # Please consider joining the pool (http://www.pool.ntp.org/join.html). pool 2.rhel.pool.ntp.org iburst # Record the rate at which the system clock gains/losses time. driftfile /var/lib/chrony/drift # Allow the system clock to be stepped in the first three updates # if its offset is larger than 1 second. makestep 1.0 3 ...output omitted...   /etc/chrony.conf文件中的以下server classroom.example.com iburst行会使chronyd服务使用 classroom.example.com NTP时间源： # Use public servers from the pool.ntp.org project. ...output omitted... server classroom.example.com iburst ...output omitted... chronyd指向本地时间源classroom.example.com后需重启该服务： [root@redhat8 ~]# systemctl restart chronyd   chronyc命令充当chronyd服务的客户端。设置NTP同步后，使用chronyc sources命令验证本地系统是否使用NTP服务器无缝同步系统时钟。如需更详细输出，使用chronyc sources -v命令。示例如下： [root@redhat8 ~]# chronyc sources -v 210 Number of sources = 4 .-- Source mode '^' = server, '=' = peer, '#' = local clock. / .- Source state '*' = current synced, '+' = combined , '-' = not combined, | / '?' = unreachable, 'x' = time may be in error, '~' = time too variable. || .- xxxx [ yyyy ] +/- zzzz || Reachability register (octal) -. | xxxx = adjusted offset, || Log2(Polling interval) --. | | yyyy = measured offset, || \\ | | zzzz = estimated error. || | | \\ MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^- makaki.miuku.net 2 6 175 96 +87ms[ +74ms] +/- 121ms ^- de-user.deepinid.deepin.> 3 6 377 31 +8635us[+8635us] +/- 118ms ^- stratum2-1.ntp.mow01.ru.> 2 6 377 32 +43ms[ +43ms] +/- 106ms ^* 111.230.189.174 2 6 377 32 -2532us[ -15ms] +/- 28ms 示例说明： S（源状态）字段中的*字符表示111.230.189.174服务器已被用作时间源，是计算机当前与之同步的NTP服务器 练习 "},"05-IBM_Operating_System/06-RHEL学习笔记/06-RHEL-系统网络管理.html":{"url":"05-IBM_Operating_System/06-RHEL学习笔记/06-RHEL-系统网络管理.html","title":"RHEL-系统网络管理","keywords":"","body":"RHEL-系统网络管理 描述网络概念 TCP/IP 网络模型   TCP/IP网络模型是一种简化的四层抽象集合，用于描述不同的协议如何进行互操作，以便计算机通过互联网将流量从一台计算机发送到另一台计算机。由RFC 1122 互联网主机要求--通信层规定。这四层是： 应用：每一应用程序具有用于通信的规范，以便客户端和服务器可以跨平台通信。常用的协议有SSH（远程登录）、HTTPS（安全Web）、NFS或CIFS（文件共享），以及SMTP（电子邮件递送）等。 传输：传输协议有TCP和UDP。应用协议使用TCP或UDP端口。/etc/services文件中可以找到常用和已注册的端口列表。协议及传输说明： TCP是可靠连接导向型通信 UDP属于无连接数据报协议 当数据包在网络上发送时，服务端口和IP地址组合形成套接字。每个数据包具有一个源套接字和目标套接字。此信息可以在监控和过滤时使用 互联网：互联网或网络层将数据从源主机传送到目标主机。IPv4和IPv6协议是互联网层协议。每一主机具有IP 地址和前缀，用于确定网络地址。路由器用于连接网络 链路：链路或介质存取层提供与物理介质的连接。最常见的网络类型是有线以太网(802.3)和无线局域网(802.11)。每一物理设备具有一个硬件地址(MAC)，用于标识局域网络段中数据包的目的地 描述网络接口名称   系统上的每个网络端口都有一个名称，可以使用该名称来配置和识别它。旧版RHEL将eth0、eth1和eth2等名称用于各个网络接口： 名称eth0是操作系统检测到的第一个网络端口，eth1则是第二个，以此类推。 随着设备的添加和移除，检测设备并给它们命名的机制可能会改变哪个接口获得哪个名称 此外，PCIe标准无法保证在启动时检测PCIe设备的顺序；鉴于设备或系统启动期间的变化，可能会意外改变设备命名   较新版本的RHEL采用另一种命名体系。系统将基于固件信息、PCI总线拓扑及网络设备的类型来分配网络接口名称，而非基于检测顺序。网络接口名称以接口类型开头： 以太网接口以en开头 WLAN接口以wl开头 WWAN接口以ww开头 在类型之后，接口名称的其余部分将基于服务器固件所提供的信息，或由PCI拓扑中设备的位置确定： oN表示这是一个板载设备，且服务器的固件提供设备的索引编号N。例如eno1代表板载以太网设备1 sN表示该设备位于PCI热插拔插槽N中。例如ens3代表PCI热插拔插槽3中的以太网卡 pMsN表示这是一个位于插槽N中总线M上的PCI设备。例如wlp4s0代表位于插槽0中PCI总线4上的 WLAN卡： 如果该卡是一个多功能设备（可能是有多个端口的以太网卡，或是具有以太网外加其他一些功能的设备），设备名称中就可能会添加fN 例如enp0s1f0代表插槽1中总线0上的以太网卡的功能0。可能还有一个名为enp0s1f1的接口，它代表了同一设备的功能1 IPv4网络 IPv4是当今互联网上使用的主要网络协议。 IPv4地址   IPv4地址是一个32位数字，通常使用点号分隔的四个十进制八位字节（取值范围从0到255）表示。此类地址分网络部分和主机部分： 位于同一子网中的所有主机可以在彼此之间直接通信，无需路由器，这些主机具有相同的网络部分 网络部分用于标识子网 同一子网中的任何两台主机都不能具有相同的主机部分 主机部分用于标识子网中的特定主机   在现代互联网中，IPv4子网的大小是可变的。要分清IPv4地址中的网络部分和主机部分，管理员必须知道分配给子网的子网掩码。子网掩码指明有多少位的IPv4地址属于子网。可供主机部分使用的位数越多，子网中就能有越多的主机： 有时，将子网中可能达到的最低地址（主机部分的二进制值全为零）称为网络地址 在IPv4中，子网中可能达到的最高地址（主机部分的二进制值全为一）用于广播消息，该地址称为广播地址 子网掩码可用两种格式表示： 较早的子网掩码语法中将24位用于网络部分，即255.255.255.0 较新的语法称为CIDR表示法，它指定了一个网络前缀/24。两种格式都传达同样的信息，即IP地址中有多少前导位组成其网络地址   特殊地址127.0.0.1始终指向本地系统localhost，而网络127.0.0.0/8属于本地系统，所以它能够使用网络协议与自己通信。 地址计算示例 计算192.168.1.108/24的网络地址： 说明 十进制 二进制 主机地址 192.168.1.107 11000000.10101000.00000001.01101100 网络前缀 /24(255.255.255.0) 11111111.11111111.11111111.00000000 网络地址 192.168.1.0 11000000.10101000.00000001.00000000 广播地址 192.168.1.255 11000000.10101000.00000001.11111111 计算10.1.1.18/8的网络地址： 说明 十进制 二进制 主机地址 10.1.1.18 00001010.00000001.00000001.00010010 网络前缀 /8(255.0.0.0) 11111111.00000000.00000000.00000000 网络地址 10.0.0.0 00001010.00000000.00000000.00000000 广播地址 10.255.255.255 00001010.11111111.11111111.11111111 计算172.16.180.20/19的网络地址： 说明 十进制 二进制 主机地址 172.168.181.23 10101100.10101000.10110100.00010100 网络前缀 /19(255.255.224.0) 11111111.11111111.11100000.00000000 网络地址 172.168.160.0 10101100.10101000.10100000.00000000 广播地址 172.168.191.255 10101100.10101000.10111111.11111111 IPv4路由   不管使用IPv4还是IPv6，网络流量都需要以主机到主机和网络到网络的形式进行传输。每一主机具有一个路由表，该表告诉主机如何路由特定网络的通信： 路由表条目将列出目标网络、用于向其发送流量的接口，以及任何中间路由器的IP地址（用于将消息中继到最终目的地）。与网络流量目的地相符的路由表条目用于路由该流量。如果两个条目匹配，则使用前缀最长的那一个 如果网络流量不匹配更为具体的路由，路由表通常具有一个代表整个IPv4互联网的默认路由条目：0.0.0.0/0。此默认路由指向可通达的子网上的路由器（也就是说，在主机路由中具有更具体路由的子网上） 如果路由器收到的流量并非将其作为寻址目标，则路由器不会像普通主机那样忽略该流量，而是根据自己的路由表转发该流量。这种处理方式可能会将流量直接发送到目标主机（如果路由器恰巧与目标位于同一子网中），也可能转发到其他路由器。这种转发过程会一直进行，直到流量到达最终目标 路由表示例： 目的地|接口|路由器（若需要） :---:|:---:|:---: 192.0.2.0/24|wlo1192.168.5.0/24|enp3s00.0.0.0/0(默认)|enp3s0|192.168.5.254 示例说明： 从此主机发往IP地址192.0.2.100的流量将通过wlo1无线接口直接传输到该目的地，它与192.0.2.0/24路由的匹配度最高 发往IP地址192.168.5.100的流量将通过enp3s0以太网接口直接传输到该目的地，它与192.168.5.0/24路由的匹配度最高 发往IP地址10.2.24.100的流量将从enp3s0以太网接口发送到192.168.5.254的路由器，该路由器将该通信转发到其最终目的地。该流量与0.0.0.0/0路由的匹配度最高，因为此主机的路由表中没有更加具体的路由。该路由器将使用自身的路由表来判断流量需要转发到的下一个位置 IPv4地址和路由配置 配置方式： 可以在引导时从DHCP服务器自动配置其IPv4网络设置。本地客户端守护进程查询链路以获取服务器和网络设置，并获得租约以便在特定时间内使用这些设置。如果客户端未定期请求续订租约，则可能会丢失其网络配置设置 用户可以将服务器配置为使用静态网络配置。在这种情况下，网络设置读取自本地配置文件。用户必须从网络管理员处获取正确的设置，并根据需要手动更新它们，以避免与其他服务器冲突 IPv6网络   IPv6旨在最终取代IPv4网络协议。IPv6可以在双栈模型中与IPv4并行使用，在这种配置中，网络接口可以同时具有IPv6地址和IPv4地址，RHEL默认在双栈模式下运行。 IPv6地址   IPv6地址是一个128位数字，通常表示为八组以分号分隔的四个十六进制半字节。每个半字节均表示4位的 IPv6地址，因此每个组表示16位的IPv6地址。示例： 2001:0db8:0000:0010:0000:0000:0000:0001   为了便于编写IPv6地址，不需要编写分号分隔的组中的前导零。但是，每个冒号分隔的组中必须至少写入一个十六进制数字。示例： 2001:db8:0:10:0:0:0:1   由于带有很长的零字符串的地址很常见，一组或多组连续零可以通过正好一个::块来合并。上面示例合并后示例如下： 2001:db8:0:10::1 有关编写始终可读的地址的一些提示如下： 抑制组中的前导零 使用::来尽可能地缩短 如果地址包含两个连续的零组，且长度相同，则最好将每个组最左边的零组缩短为::，最右边的组缩短为:0: 尽管允许这样做，但不要使用::来缩短一组零。应改为使用:0:，而将::留给连续的零组 始终对十六进制数字使用小写字母a到f   如果在IPv6地址后面包括TCP或UDP网络端口，请始终将IPv6地址括在方括号中，以便端口不会被误认为是地址的一部分。示例如下： [2001:db8:0:10::1]:80 IPv6子网划分   普通的IPv6单播地址分为两部分：网络前缀和接口ID。网络前缀标识子网。同一子网上的任何两个子网接口都不能具有相同接口ID，接口ID可标识子网上的特定接口。  与IPv4不同的是，IPv6具有一个标准的子网掩码/64，用于几乎所有的普通地址。在此情况下，地址的一半是网络前缀，另一半是接口ID。这意味着单个子网可以根据需要容纳任意数量的主机。  通常，网络提供商将为组织分配一个较短的前缀，如/48。这会保留其余网络部分以用于通过这一分配的前缀来指定子网（长度始终为/64）。对于/48分配，将保留16位以用于子网（最多65536个子网）。 常用IPv6地址和网络： IPv6地址或网络 用途 描述 ::1/128 本地主机 等效于127.0.0.1/8的IPv6，在回环接口上设置 :: 未指定的地址 等效于0.0.0.0的IPv6。对于网络服务，这可能表示其正在侦听所有已配置的IP地址 ::/0 默认路由（IPv6 互联网） 等效于 0.0.0.0/0 的IPv6。路由表中的默认路由与此网络匹配；此网络的路由器是在没有更好路由的情况下发送所有流量的位置 2000::/3 全局单播地址 “普通”的IPv6地址目前由IANA从该空间进行分配。等同于范围从2000::/16到 3fff::/16的所有网络 fd00::/8 唯一本地地址(RFC 4193) IPv6没有RFC1918专用地址空间的直接等效对象，尽管这很接近。站点可以使用这些以在组织中自助分配可路由的专用IP地址空间，但是这些网络不能在全局Internet上使用。站点必须随机从该空间中选择一个/48，但是它可以正常将分配空间划分为/64网络 fe80::/10 本地链路地址 每个IPv6接口自动配置一个本地链路地址，该地址仅在fe80::/64网络中的本地链路有效。但是，整个fe80::/10范围保留供本地链路以后使用 ff00::/8 多播 等效于224.0.0.0/4的IPv6。多播用于同时传输到多个主机，并且在IPv6中特别重要，因为其没有广播地址   IPv6中的本地链路地址是一个无法路由的地址，仅用于与特定网络链路上的主机进行通信。系统上的每个网络接口都通过fe80::/64网络上的本地链路地址来自动配置。为确保其唯一性，本地链路地址的接口 ID是通过网络接口的以太网硬件地址来构建的。将48位MAC地址转换为64位接口ID的一般方法是反转7位的MAC地址，然后在其两个中间字节之间插入ff:fe。 网络前缀：fe80::/64 MAC 地址：00:11:22:aa:bb:cc 本地链路地址：fe80::211:22ff:feaa:bbcc/64   其他计算机的本地链路地址可以由相同链路上的其他主机像普通地址那样使用。由于每个链路具有fe80::/64网络，不能使用路由表来正确地选择出站接口。在地址的结尾必须使用作用域标识符来指定与本地链路地址进行通信时使用的链路。作用域标识符由%以及后跟的网络接口名称组成。   要使用ping6对本地链路地址fe80::69af:c449:76d3:770进行ping操作（使用连接到ens160网络接口的链路），正确的命令语法及示例如下所示： [root@redhat8 ~]# ping6 fe80::69af:c449:76d3:770%ens160 PING fe80::69af:c449:76d3:770%ens160(fe80::69af:c449:76d3:770%ens160) 56 data bytes 64 bytes from fe80::69af:c449:76d3:770%ens160: icmp_seq=1 ttl=64 time=0.066 ms 64 bytes from fe80::69af:c449:76d3:770%ens160: icmp_seq=2 ttl=64 time=0.180 ms ^C --- fe80::69af:c449:76d3:770%ens160 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 3ms rtt min/avg/max/mdev = 0.066/0.123/0.180/0.057 ms   多播允许一个系统将流量发送到多个系统接收的特殊IP地址。它与广播不同，因为只有网络上的特定系统才能接收流量。它也与IPv4中的广播不同，因为某些多播流量可能会路由到其他子网，具体取决于网络路由器和系统的配置： 多播在IPv6中比在IPv4中扮演着更重要的角色，因为IPv6中没有广播地址 IPv6中的一个重要多播地址是ff02::1，即all-nodes本地链路址。对此地址进行 Ping 操作会将流量都发送到链路上的所有节点 与本地链路地址一样，需要使用作用域标识符来指定链路作用域多播地址（从ff02::/8开始） 示例如下： [root@redhat8 ~]# ping6 ff02::1%ens160 PING ff02::1%ens160(ff02::1%ens160) 56 data bytes 64 bytes from fe80::69af:c449:76d3:770%ens160: icmp_seq=1 ttl=64 time=0.080 ms 64 bytes from fe80::69af:c449:76d3:770%ens160: icmp_seq=2 ttl=64 time=0.358 ms ^C --- ff02::1%ens160 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 4ms rtt min/avg/max/mdev = 0.080/0.219/0.358/0.139 ms IPv6地址配置   IPv6也支持手动配置以及两种动态配置方法，其中一种便是DHCPv6。与IPv4一样，可以随意选择静态IPv6地址的接口ID。在IPv4中，网络上有两个地址无法使用：子网中的最低地址和子网中的最高地址。在IPv6中，以下接口ID是保留的，无法用于主机上的普通网络地址。 由链路上的所有路由器使用的全零标识符0000:0000:0000:0000（“子网路由器任意广播”）。（对于 2001:db8::/64网络，这可能是地址2001:db8::） 标识符fdff:ffff:ffff:ff80到fdff:ffff:ffff:ffff 由于没有广播地址，DHCPv6的工作原理与适用于IPv4的DHCP有所不同： 主机将DHCPv6请求从其本地链路地址发送到ff02::1:2上的端口547/UDP，即all-dhcp-servers本地链路多播组 然后DHCPv6服务器通常向客户端的本地链路地址上的端口546/UDP发送一个包含相应信息的回复。 除了DHCPv6之外，IPv6也支持另外一个动态配置方法，称为无状态地址自动配置(SLAAC)： 使用SLAAC时，主机通常使用本地链路fe80::/64地址来调出其接口 主机随后向ff02::2（即全路由器本地链路多播组）发送一个“路由器请求” 本地链路上的IPv6路由器以网络前缀以及其他可能的信息来响应主机的本地链路地址 主机随后将该网络前缀与其通常构建的接口ID（构建方式与本地链路地址相同）配合使用 路由器定期发送多播更新（“路由器播发”）以确认或更新其提供的信息   红帽企业Linux中的radvd软件包允许基于RHEL的IPv6路由器通过路由器播发提供SLAAC。SLAAC注意事项如下： 配置为通过DHCP获取IPv4地址的典型RHEL8计算机通常也配置为使用SLAAC来获取IPv6地址。当网络中添加了IPv6路由器时，这可能导致计算机意外获取IPv6地址 部分IPv6部署将SLAAC与DHCPv6组合，SLAAC仅用于提供网络地址信息，而DHCPv6仅用于提供其他信息（如要配置的DNS服务器和搜索域） 主机名和IP地址   如果用户总是必须使用IP地址连接用户的服务器，这会很不方便。人们通常更愿意使用名称而不是一长串难记的数字。因此，Linux有多种机制可以将主机名映射到IP地址，统称为名称解析。 一种方法是在各个系统上的/etc/hosts文件中为每个名称设置一个静态条目。这需要手动更新每台服务器的文件副本 对于大多数主机，可以借助称为域名系统(DNS)的网络服务，从主机名查找地址（或从地址查找主机名）： DNS是提供主机名到IP地址映射的分布式服务器网络 为使名称服务起作用，主机需要指向某一个名称服务器。该名称服务器只需可供主机访问即可。这通常通过DHCP或/etc/resolv.conf文件中的静态设置来配置 验证网络配置 收集网络接口信息 识别网络接口 ip link命令将列出系统上可用的所有网络接口： [root@redhat8 ~]# ip link show 1: lo: mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT gro up default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 2: ens160: mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether 00:0c:29:ee:ed:0e brd ff:ff:ff:ff:ff:ff 示例中，服务器有两个网络接口： lo：这是连接到服务器本身的环回设备 ens160：一个以太网接口 显示IP地址 使用ip命令来查看设备和地址信息，ip add show ens160命令输出示例： # 1 2: ens160: mtu 1500 qdisc mq state UP group defaul t qlen 1000 # 2 link/ether 00:0c:29:ee:ed:0e brd ff:ff:ff:ff:ff:ff # 3 inet 192.168.100.131/24 brd 192.168.100.255 scope global dynamic noprefixroute e ns160 valid_lft 900sec preferred_lft 900sec # 4 inet6 fe80::69af:c449:76d3:770/64 scope link noprefixroute valid_lft forever preferred_lft forever 单个网络接口可以具有多个IPv4或IPv6地址。示例中四个部分说明： 1：活动接口为UP 2：link/ether行指定设备的硬件(MAC)地址 3：inet行显示IPv4地址、其网络前缀长度和作用域 4：该inet6行显示接口具有链路作用域的IPv6地址，并且只能用于本地以太网链路上的通信： 如果为scope global,此inet6行显示IPv6地址、其网络前缀长度和作用域。此地址属于全局作用域，通常使用此地址 显示性能统计信息   ip命令也可用于显示关于网络性能的统计信息。每个网络接口的计数器可用于识别网络问题的存在。计时器记录的统计信息包括收到(RX)和传出(TX)的数据包数、数据包错误数，以及丢弃的数据包数。示例如下： [root@redhat8 ~]# ip -s link show ens160 2: ens160: mtu 1500 qdisc mq state UP mode DEFAULT group default qlen 1000 link/ether 00:0c:29:ee:ed:0e brd ff:ff:ff:ff:ff:ff RX: bytes packets errors dropped overrun mcast 382475257 278554 0 0 0 3614 TX: bytes packets errors dropped carrier collsns 2884634 36418 0 0 0 0 检查主机之间的连接   ping命令可用于测试连接。该命令将持续运行，直到按下Ctrl+c（除非已指定了限制发送数据包数量的选项）。示例如下： PING 192.168.100.131 (192.168.100.131) 56(84) bytes of data. 64 bytes from 192.168.100.131: icmp_seq=1 ttl=64 time=0.050 ms 64 bytes from 192.168.100.131: icmp_seq=2 ttl=64 time=0.144 ms ^C --- 192.168.100.131 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 28ms rtt min/avg/max/mdev = 0.050/0.097/0.144/0.047 ms   ping6命令是RHEL中ping的IPv6版本。它通过IPv6进行通信，并且采用IPv6地址，但是其他工作方式类似于ping。示例如下： [root@redhat8 ~]# ping6 fe80::69af:c449:76d3:770 PING fe80::69af:c449:76d3:770(fe80::69af:c449:76d3:770) 56 data bytes 64 bytes from fe80::69af:c449:76d3:770%ens160: icmp_seq=1 ttl=64 time=0.089 ms 64 bytes from fe80::69af:c449:76d3:770%ens160: icmp_seq=2 ttl=64 time=0.092 ms ^C --- fe80::69af:c449:76d3:770 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 19ms rtt min/avg/max/mdev = 0.089/0.090/0.092/0.009 ms   当ping本地链路地址和本地链路全节点多播组(ff02::1) 时，必须使用作用域标识符（如 ff02::1%ens3）来显式指定要使用的网络接口。如果遗漏，则将显示错误connect: Invalid argument。示例如下： [root@redhat8 ~]# ping6 ff02::1%ens160 PING ff02::1%ens160(ff02::1%ens160) 56 data bytes 64 bytes from fe80::69af:c449:76d3:770%ens160: icmp_seq=1 ttl=64 time=0.084 ms 64 bytes from fe80::69af:c449:76d3:770%ens160: icmp_seq=2 ttl=64 time=0.198 ms ^C --- ff02::1%ens160 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 56ms rtt min/avg/max/mdev = 0.084/0.141/0.198/0.057 ms 跟普通地址一样，IPv6本地链路地址可以由同一链路上的其他主机使用： [root@redhat8 ~]# ssh fe80::69af:c449:76d3:770%ens160 The authenticity of host 'fe80::69af:c449:76d3:770%ens160 (fe80::69af:c449:76d3:770% ens160)' can't be established.ECDSA key fingerprint is SHA256:pCN6N5A3ex61KwcBYkR8sUiNKBE/hPO5c4FJkvGIJhY. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added 'fe80::69af:c449:76d3:770%ens160' (ECDSA) to the list of known hosts.root@fe80::69af:c449:76d3:770%ens160's password: Activate the web console with: systemctl enable --now cockpit.socket Last login: Wed May 25 01:29:25 2022 from 192.168.100.1 路由故障排除 显示路由表 使用ip命令及route选项来显示路由信息： Connection to fe80::69af:c449:76d3:770%ens160 closed. [root@redhat8 ~]# ip route default via 192.168.100.2 dev ens160 proto dhcp metric 100 192.168.100.0/24 dev ens160 proto kernel scope link src 192.168.100.131 metric 100 示例说明： 示例显示IPv4路由表 目标为192.168.100.0/24网络的所有数据包将通过设备ens160直接发送到该目标位置 所有其他数据包将发送到位于192.168.100.2的默认路由器，而且也通过设备ens160传输 添加-6选项可显示IPv6路由表，示例如下： [root@redhat8 ~]# ip -6 route ::1 dev lo proto kernel metric 256 pref medium fe80::/64 dev ens160 proto kernel metric 100 pref medium 追踪流量采用的路由   要追踪网络流量通过多个路由器到达远程主机而采用的路径，可使用traceroute或tracepath命令。这可以识别用户的某个路由器或中间路由器是否存在问题： 默认情况下，两个命令都使用UDP数据包来追踪路径； 许多网络阻止UDP和ICMP流量。traceroute命令拥有可以跟踪UDP（默认）、ICMP(-I) 或TCP (-T)数据包路径的选项 默认情况下通常不安装traceroute命令 示例如下： [root@redhat8 ~]# tracepath 115.152.254.112 1?: [LOCALHOST] pmtu 1500 1: localhost 0.474ms 1: localhost 0.307ms 2: no reply ...output omitted... 30: no reply Too many hops: pmtu 1500 Resume: pmtu 1500 命令及示例说明： tracepath输出中的每一行表示数据包在来源和最终目标位置之间所经过的路由器或跃点 命令也提供了其他信息，如往返用时(RTT)和最大传输单元(MTU)大小中的任何变化等 asymm表示流量使用了不同的(非对称)路由到达该路由器的流量和从该路由器返回 显示的路由器是用于出站流量的路由器，而不是返回流量 tracepath6和traceroute -6命令等效于IPv6版本的tracepath和traceroute 端口和服务故障排除   TCP服务使用套接字作为通信的端点，其由IP地址、协议和端口号组成。服务通常侦听标准端口，而客户端则使用随机的可用端口。/etc/services文件中列出了标准端口的常用名称。  ss命令可用于显示套接字统计信息。ss命令旨在替换net-tools软件包中所含的较旧工具 netstat（这个工具可能更为某些系统管理员所熟知，但未必始终安装在系统中）。示例如下： [root@redhat8 ~]# ss -ta State Recv-Q Send-Q Local Address:Port Peer Address:Port LISTEN 0 128 0.0.0.0:ssh 0.0.0.0:* LISTEN 0 128 127.0.0.1:x11-ssh-offset 0.0.0.0:* LISTEN 0 128 0.0.0.0:sunrpc 0.0.0.0:* ESTAB 0 0 192.168.100.131:ssh 192.168.100.1:52684 LISTEN 0 32 *:ftp *:* LISTEN 0 128 [::]:ssh [::]:* LISTEN 0 128 [::1]:x11-ssh-offset [::]:* LISTEN 0 128 [::]:sunrpc [::]:* 命令ss和netstat的选项： 选项 描述 -n 显示接口和端口的编号，而不显示名称 -t 显示TCP套接字 -u 显示UDP套接字 -l 仅显示侦听中的套接字 -a 显示所有（侦听中和已建立的）套接字 -p 显示使用套接字的进程 -A inet 对于inet地址系列，显示活动的连接(但不显示侦听套接字)，忽略本地UNIX域套接字。对于ss，同时显示IPv4和IPv6连接。对于netstat ，仅显示IPv4连接(netstat -A inet6显示IPv6连接，netstat -46则同时显示IPv4和IPv6) 从命令行配置网络 NetworkManager概念   NetworkManager是监控和管理网络设置的守护进程。除了该守护进程外，还有一个提供网络状态信息的GNOME通知区域小程序。命令行和图形工具与NetworkManager通信，并将配置文件保存在/etc/sysconfig/network-scripts目录中： 设备是网络接口 连接是可以为设备配置的设置的集合 对于任何一个设备，在同一时间只能有一个连接处于活动状态。可能存在多个连接，以供不同设备使用或者以便为同一设备更改配置。如果需要临时更改网络设置，而不是更改连接的配置，可以更改设备的哪个连接处于活动状态 每个连接具有一个用于标识自身的名称或ID nmcli实用程序可用于从命令行创建和编辑连接文件 查看联网信息 nmcli dev status命令可显示所有网络设备的状态： [root@redhat8 ~]# nmcli dev status DEVICE TYPE STATE CONNECTION ens160 ethernet connected ens160 lo loopback unmanaged -- nmcli con show命令可显示所有连接的列表。使用--active列出活动的连接： [root@redhat8 ~]# nmcli con show NAME UUID TYPE DEVICE ens160 b561c316-1e2c-4f92-9f28-fb4cc66f0c40 ethernet ens160 [root@redhat8 ~]# nmcli con show --active NAME UUID TYPE DEVICE ens160 b561c316-1e2c-4f92-9f28-fb4cc66f0c40 ethernet ens160 添加网络连接 nmcli con add命令用于添加新的网络连接。示例： [root@redhat8 ~]# nmcli con add con-name ens160 type ethernet ifname ens160 Connection 'ens160' (09521237-47ec-484f-8df8-db071b8ccd7a) successfully added. 示例说明： 示例将为接口ens160添加一个新连接ens160，此连接将使用DHCP获取IPv4联网信息并在系统启动后自动连接 示例还将通过侦听本地链路上的路由器播发来获取IPv6联网设置 配置文件的名称基于的con-name选项的值ens160，并保存到/etc/sysconfig/network-scripts/ifcfg-ens160文件   下面示例使用静态IPv4地址为ens160设备创建ens160连接，使用IPv4地址和网络前缀192.168.100.131/24及默认网关192.168.100.254，仍在启动时自动连接并将其配置保存到相同文件中： [root@redhat8 ~]# nmcli con add con-name ens160 type ethernet \\ ifname ens160 ipv4.address 192.168.100.131/24 ipv4.gateway 192.168.100.254 Connection 'ens160' (ff73ccde-8a3c-42aa-a2c1-8a60a01c1a9c) successfully added. [root@redhat8 ~]# nmcli con show NAME UUID TYPE DEVICE ens160 ff73ccde-8a3c-42aa-a2c1-8a60a01c1a9c ethernet ens160   示例使用静态IPv6和IPv4地址为eno2设备创建eno2连接，且使用IPv6地址和网络前缀2001:db8:0:1::c000:207/64及默认IPv6网关2001:db8:0:1::1，以及IPv4地址和网络前缀192.0.2.7/24及默认IPv4网关192.0.2.1，在启动时自动连接，并将其配置保存到/etc/sysconfig/network-scripts/ifcfg-eno2： nmcli con add con-name eno2 type ethernet ifname eno2 \\ ipv6.address 2001:db8:0:1::c000:207/64 ipv6.gateway 2001:db8:0:1::1 \\ ipv4.address 192.0.2.7/24 ipv4.gateway 192.0.2.1 控制网络连接   nmcli con up name命令将在其绑定到的网络接口上激活name连接。注意，命令采用连接的名称，而非网络接口的名称。nmcli con show命令显示所有可用连接的名称。示例： [root@redhat8 ~]# nmcli con up ens160 Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManage r/ActiveConnection/6)   nmcli dev disconnect device命令将断开与网络接口device的连接并将其关闭。此命令可以缩写为nmcli dev dis device。示例如下： [root@redhat8 ~]# nmcli dev dis ens160 Device 'ens160' successfully disconnected.   使用nmcli dev dis device可停用网络接口。nmcli con down name命令可以关闭连接，但通常并非是停用网络接口的最佳方法。示例如下： [root@redhat8 ~]# nmcli con down ens160 Connection 'ens160' successfully deactivated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/8) [root@redhat8 ~]# nmcli con show NAME UUID TYPE DEVICE ens160 ff73ccde-8a3c-42aa-a2c1-8a60a01c1a9c ethernet -- 说明： 默认情况下，大部分有线系统连接是在启用了autoconnect的情况下配置的。这将在其网络接口可用后立即激活连接 由于连接的网络接口仍可用，因此nmcli con down name将关闭接口，但是NetworkManager会立即将其重新开启，除非连接完全与接口断开 修改网络连接设置 NetworkManager连接具有两种类型的设置。有静态连接属性，它们是由管理员配置并存储在/etc/sysconfig/network-scripts/ifcfg-*中的配置文件中。还可能有活动连接数据，这些数据是连接从DHCP服务器获取的，不会持久存储。nmcli con show name命令列出某个连接的当前设置，小写的设置是静态属性，管理员可以更改全大写的设置是活动设置，临时用于此连接实例： [root@redhat8 ~]# nmcli con show ens160 connection.id: ens160 connection.uuid: ff73ccde-8a3c-42aa-a2c1-8a60a01c1a9c connection.stable-id: -- connection.type: 802-3-ethernet connection.interface-name: ens160 connection.autoconnect: yes connection.autoconnect-priority: 0 ...output omitted... GENERAL.NAME: ens160 GENERAL.UUID: ff73ccde-8a3c-42aa-a2c1-8a60a01c1a9c GENERAL.DEVICES: ens160 GENERAL.STATE: activated GENERAL.DEFAULT: yes GENERAL.DEFAULT6: no GENERAL.SPEC-OBJECT: -- GENERAL.VPN: no ...output omitted...   nmcli con mod name命令可用于更改连接的设置，更改保存在对应的/etc/sysconfig/network-scripts/ifcfg-name文件中。示例将ens160连接将IPv4地址设置为192.160.100.130/24： [root@redhat8 ~]# nmcli con mod ens160 ipv4.address 192.160.100.130/24 [root@redhat8 ~]# ip add show ens160 2: ens160: mtu 1500 qdisc mq state UP group defaul t qlen 1000 link/ether 00:0c:29:ee:ed:0e brd ff:ff:ff:ff:ff:ff inet 192.168.100.130/24 brd 192.168.100.255 scope global dynamic noprefixroute e ns160 valid_lft 1491sec preferred_lft 1491sec inet 192.168.100.131/24 brd 192.168.100.255 scope global secondary noprefixroute ens160 valid_lft forever preferred_lft forever inet6 fe80::78cd:cdad:d838:916f/64 scope link noprefixroute valid_lft forever preferred_lft forever   更改后，之前192.168.100.131的连接未断开，down关闭接口后再up，192.168.100.131的连接就断开，更改完成。示例更改IPv6地址设置： nmcli con mod static-ens3 ipv6.address 2001:db8:0:1::a00:1/64 \\ ipv6.gateway 2001:db8:0:1::1 重要说明： 如果某个连接之前通过DHCPv4服务器获取其IPv4信息，而现在更改为仅通过静态配置文件来获取，那么设置ipv4.method也应从auto更改为manual 如果某个连接之前通过SLAAC或DHCPv6服务器获取其IPv6信息，而现在更改为仅通过静态配置文件来获取，那么ipv6.method设置也应从auto或dhcp更改为manual 如果不更改，连接在激活后可能挂起或者无法成功完成，或者除了静态地址外还从DHCP获取IPv4地址或从 SLAAC或DHCPv6获取IPv6地址 很多设置可能具有多个值。通过向设置名称的开头添加+或-符号，可以在列表中添加或从列表中删除特定值 删除网络连接   nmcli con del name命令将从系统中删除名为 name 的连接，同时断开它与设备的连接并删除文件/etc/sysconfig/network-scripts/ifcfg-name。示例如下： [root@redhat8 ~]# nmcli con del ens160 Connection 'ens160' (ff73ccde-8a3c-42aa-a2c1-8a60a01c1a9c) successfully deleted. [root@redhat8 ~]# ls -l /etc/sysconfig/network-scripts/ total 0 修改网络设置权限 修改网络设置说明： root用户可以使用nmcli对网络配置进行任何必要的更改 在本地控制台上登录的普通用户也可以对系统进行多项网络配置更改。要获得此控制权，必须在系统键盘上登录基于文本的虚拟控制台或图形桌面环境。背后的逻辑是： 如果某人实际出现在计算机控制台上，就说明该计算机可能被用作工作站或笔记本电脑，因此他们可能需要随意配置、激活和停用无线或有线网络接口 反之，如果系统是数据中心中的服务器，则通常以本地方式登录到计算机本身的用户只能是管理员 使用ssh登录的普通用户在成为root之前无权更改网络权限 可以使用nmcli gen permissions命令来查看自己的当前权限 命令摘要 下表是此次学习中关键nmcli命令的列表： 命令 用途 nmcli dev status 显示所有网络接口的NetworkManager状态 nmcli con show 列出所有连接 nmcli con show name 列出name连接的当前设置 nmcli con add con-name name 添加一个名为name的新连接 nmcli con mod name 修改name连接 nmcli con reload 重新加载配置文件(在手动编辑配置文件之后使用) nmcli con up name 激活name连接 nmcli dev dis dev 在网络接口dev上停用并断开当前连接 nmcli con del name 删除name连接及其配置文件 编辑网络配置文件 描述连接配置文件   默认情况下，通过nmcli con mod name进行的更改会自动保存到/etc/sysconfig/network-scripts/ifcfg-name。还可以使用文本编辑器手动编辑此文件。执行此操作后，运行nmcli con reload以便NetworkManager读取配置更改。出于向后兼容性的原因，此文件中保存的指令具有不同于 nm-settings名称的名称和语法。下表将部分关键设置名称映射到ifcfg-*指令。nm-settings与 ifcfg-*指令的比较： nmcli con mod ifcfg-* file 影响 ipv4.method manual BOOTPROTO=none IPv4以静态方式配置 ipv4.method auto BOOTPROTO=dhcp 从DHCPv4服务器中查找配置设置。如果还设置了静态地址，则在从DHCPv4中获取信息之前，将不会激活这些静态地址 ipv4.addresses 192.0.2.1/24 IPADDR=192.0.2.1 PREFIX=24 设置静态IPv4地址和网络前缀。如果为连接设置了多个地址，则第二个地址由IPADDR1和PREFIX1指令定义，以此类推 ipv4.gateway 192.0.2.254 GATEWAY=192.0.2.254 设置默认网关 ipv4.dns 8.8.8.8 DNS1=8.8.8.8 修改/etc/resolv.conf以使用此nameserver ipv4.dns-search example.com DOMAIN=example.com 修改/etc/resolv.conf，以在search指令中使用这个域 ipv4.ignore-auto-dns true PEERDNS=no 忽略来自DHCP服务器的DNS服务器信息 ipv6.method manual IPV6_AUTOCONF=no IPv6 地址以静态方式配置 ipv6.method auto IPV6_AUTOCONF=yes 使用路由器播发中的SLAAC来配置网络设置 ipv6.method dhcp IPV6_AUTOCONF=no DHCPV6C=yes 使用DHCPv6（而不使用 SLAAC）来配置网络设置 ipv6.addresses 2001:db8::a/64 IPV6ADDR=2001:db8::a/64 设置静态IPv6地址和网络前缀。如果为连接设置了多个地址，IPV6ADDR_SECONDARIES将采用空格分隔的地址/前缀定义的双引号列表 ipv6.gateway 2001:db8::1 IPV6_DEFAULTGW=2001:... 设置默认网关。 ipv6.dns fde2:6494:1e09:2::d DNS1=fde2:6494:... 修改/etc/resolv.conf以使用此名称服务器。与IPv4完全相同 ipv6.dns-search example.com IPV6_DOMAIN=example.com 修改/etc/resolv.conf，以在search指令中使用这个域 ipv6.ignore-auto-dns true IPV6_PEERDNS=no 忽略来自DHCP服务器的DNS服务器信息 connection.autoconnect yes ONBOOT=yes 在系统引导时自动激活此连接 connection.id ens3 NAME=ens3 此连接的名称 connection.interface-name ens3 DEVICE=ens3 连接与具有此名称的网络接口绑定 802-3-ethernet.mac-address ... HWADDR=... 连接与具有此MAC地址的网络接口绑定 修改网络配置   可以通过直接编辑连接配置文件来配置网络。连接配置文件控制单个网络设备的软件接口，这些文件通常命名为/etc/sysconfig/network-scripts/ifcfg-name。以下是在用于静态或动态 IPv4 配置的文件中找到的标准变量： 静态： BOOTPROTO=none IPADDR0=172.25.250.10 PREFIX0=24 GATEWAY0=172.25.250.254 DEFROUTE=yes DNS1=172.25.254.254 动态灵活：BOOTPROTO=dhcp 任意： DEVICE=ens3 NAME=\"static-ens3\" ONBOOT=yes UUID=f3e8(...)ad3e USERCTL=yes   在静态设置中，IP地址、前缀和网关等变量的末尾都是数字。这允许将多组值指定到该接口。DNS 变量也有一个数字，用于在指定了多个服务器时指定查询的顺序。在修改了配置文件后，运行nmcli con reload使NetworkManager读取配置更改。接口依然需要重新启动，以便更改生效。示例如下： [root@redhat8 ~]# nmcli con reload [root@redhat8 ~]# nmcli con down ens160 Connection 'ens160' successfully deactivated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/13) [root@redhat8 ~]# nmcli con up ens160 Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/14) 配置主机名和名称解析 更改系统主机名 hostname命令显示或临时修改系统的完全限定主机名： [root@redhat8 ~]# hostname redhat8   可以在/etc/hostname文件中指定静态主机名。hostnamectl命令用于修改此文件，也可用于查看系统的完全限定主机名的状态。如果此文件不存在，则主机名在接口被分配了IP地址时由反向DNS查询设定。示例如下： [root@redhat8 ~]# hostnamectl status Static hostname: redhat8 Icon name: computer-vm Chassis: vm Machine ID: 0d4f35dc451749ecad3ae466d7cbf09a Boot ID: 6d74b4812217402dadc582db9d479dd0 Virtualization: vmware Operating System: Red Hat Enterprise Linux 8.0 (Ootpa) CPE OS Name: cpe:/o:redhat:enterprise_linux:8.0:GA Kernel: Linux 4.18.0-80.el8.x86_64 Architecture: x86-64 [root@redhat8 ~]# hostnamectl set-hostname redhat8 配置名称解析   根解析器用于将主机名称转换为IP地址，反之亦可。它将根据/etc/nsswitch.conf文件的配置来确定查找位置。默认情况下，先检查/etc/hosts文件的内容。 示例如下： [root@redhat8 ~]# cat /etc/hosts [root@redhat8 ~]# cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 115.152.254.112 access.redhat.com   可以通过getent hosts hostname命令，利用/etc/hosts文件测试主机名解析。使用ping命令尝试解析。示例如下： [root@redhat8 ~]# getent hosts access.redhat.com 115.152.254.112 access.redhat.com [root@redhat8 ~]# ping access.redhat.com PING access.redhat.com (115.152.254.112) 56(84) bytes of data. 64 bytes from access.redhat.com (115.152.254.112): icmp_seq=1 ttl=128 time=8.16 ms 64 bytes from access.redhat.com (115.152.254.112): icmp_seq=2 ttl=128 time=8.66 ms ^C --- access.redhat.com ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 3ms rtt min/avg/max/mdev = 8.158/8.410/8.663/0.268 ms   如果在/etc/hosts文件中未找到条目，默认情况下，根解析器会尝试使用DNS名称服务器来查询主机名。/etc/resolv.conf文件控制如何执行这一查询： search：对于较短主机名尝试搜索的域名列表。不应在同一文件中设置此参数和domain，如果在同一文件中设置它们，将使用最后一个实例 nameserver：要查询的名称服务器的IP地址。可以指定最多三个名称服务器指令，以在其中一个名称服务器停机时提供备用名称服务器 /etc/resolv.conf文件示例如下： [root@redhat8 ~]# cat /etc/resolv.conf # Generated by NetworkManager search localdomain nameserver 192.168.100.2   NetworkManager将使用连接配置文件中的DNS设置更新/etc/resolv.conf文件。使用 nmcli命令修改连接。示例如下： [root@redhat8 ~]# nmcli con mod ens160 ipv4.dns 8.8.8.8 [root@redhat8 ~]# nmcli con down ens160 Connection 'ens160' successfully deactivated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/14) [root@redhat8 ~]# nmcli con up ens160 Connection successfully activated (D-Bus active path: /org/freedesktop/NetworkManager/ActiveConnection/15) [root@redhat8 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens160 |grep -i dns DNS1=8.8.8.8   nmcli con mod ID ipv4.dns IP的默认行为是将任何旧的DNS设置替换为提供的新IP列表。ipv4.dns参数前面的+或-符号可添加或删除个别条目。示例如下： [root@redhat8 ~]# nmcli con mod ens160 -ipv4.dns 8.8.8.8 [root@redhat8 ~]# cat /etc/sysconfig/network-scripts/ifcfg-ens160 |grep -i dns [root@redhat8 ~]#   要将IPv6地址为2001:4860:4860::8888的DNS服务器添加到要与 static-ens3连接一起使用的名称服务器的列表： nmcli con mod static-ens3 +ipv6.dns 2001:4860:4860::8888 测试DNS名称解析   通过Ping可以测试DNS服务器连接，也可以使用host HOSTNAME命令测试DNS服务器连接。示例如下： [root@redhat8 ~]# host access.redhat.com access.redhat.com is an alias for access.redhat.com2.edgekey.net. access.redhat.com2.edgekey.net is an alias for access.redhat.com2.edgekey.net.global redir.akadns.net.access.redhat.com2.edgekey.net.globalredir.akadns.net is an alias for e40408.ca2.s.t l88.net.e40408.ca2.s.tl88.net has address 115.152.254.112 e40408.ca2.s.tl88.net has address 115.152.254.98 [root@redhat8 ~]# host 115.152.254.112 Host 112.254.152.115.in-addr.arpa. not found: 3(NXDOMAIN)   DHCP会在接口启动时自动重写/etc/resolv.conf文件，除非在相关的接口配置文件中指定了PEERDNS=no。使用nmcli命令设置此项，示例： nmcli con mod \"ens160\" ipv4.ignore-auto-dns yes 练习 "},"05-IBM_Operating_System/06-RHEL学习笔记/07-RHEL-归档和传输文件.html":{"url":"05-IBM_Operating_System/06-RHEL学习笔记/07-RHEL-归档和传输文件.html","title":"RHEL-归档和传输文件","keywords":"","body":"RHEL-归档和传输文件 管理压缩的tar存档 tar命令   创建备份和通过网络传输数据时，归档和压缩文件非常有用。用来创建和使用备份存档的其中一个最早也是最常见的命令是tar命令： 通过tar命令，用户可以将大型文件集汇集为一个文件（存档） tar存档是一个结构化的文件数据序列，其中包含有关每个文件和索引的元数据，以便可以提取单个文件 该存档可以使用gzip、bzip2或xz压缩方式进行压缩 tar命令能够列出存档内容，或者将其文件提取到当前系统 所选的tar选项   tar命令选项划分成不同的操作，其中包括一般选项和压缩选项。下面表格显示了常用选项、选项的长版本及其说明。tar操作概述： 选项 描述 -c、--create 创建一个新存档 -x、--extract 从现有存档提取 -t、--list 列出存档的目录 所选的tar一般选项： 选项 描述 -v、--verbose 详细信息。显示存档或提取的文件有哪些 -f、--file= 文件名。此选项必须后接要使用或创建的存档的文件名 -p、--preserve-permissions 在提取存档时保留文件和目录的权限，而不去除umask tar压缩选项概述： 选项 描述 -z、--gzip 使用gzip压缩方式(.tar.gz) -j、--bzip2 使用bzip2压缩方式(.tar.bz2)。bzip2的压缩率通常比gzip高 -J、--xz 使用xz压缩方式(.tar.xz)。xz的压缩率通常比bzip2更高 归档文件和目录   创建新存档时要使用的第一个选项为c选项，后跟f选项，接着是一个空格，然后是要创建的存档的文件名，最后是应当添加到该存档中的文件和目录列表。存档会创建在当前目录中，除非另外指定。示例如下： [root@redhat8 testdir]# tar -cf test.tar testfile1 testfile2 [root@redhat8 testdir]# ls -l test.tar -rw-r--r--. 1 root root 10240 May 30 06:29 test.tar 以上示例tar命令也可以使用长版本选项执行： [root@redhat8 testdir]# tar -cf --file=test.tar --create testfile1 testfile2 [root@redhat8 testdir]# ls -l test.tar -rw-r--r--. 1 root root 10240 May 30 06:29 test.tar 注意事项： 在创建tar存档之前，请先验证目录中没有其他存档与要创建的新存档名称相同。tar命令将覆盖现有的存档，而不提供警告 在使用绝对路径名归档文件时，将默认从文件名中删除该路径中的前面的/符号。删除路径中的前导/可帮助用户在提取存档时避免覆盖重要文件 执行tar命令的用户必须要可以读取这些文件： 为/etc文件夹及其所有内容创建新存档需要root特权，只有root用户才可读取/etc目录的所有文件 非特权用户可以创建/etc目录的存档，但是该存档将忽略用户没有读取权限的文件，并且将忽略用户没有读取和执行权限的目录 示例以root身份创建名为/root/etc.tar且内容为/etc目录的tar存档： [root@redhat8 ~]# tar -cf /root/etc.tar /etc tar: Removing leading `/' from member names [root@redhat8 ~]# ls -l etc.tar -rw-r--r--. 1 root root 27381760 May 30 06:37 etc.tar 列出存档的内容 t选项指示列出存档的内容。使用f选项加上要查询的存档的名称。示例： [root@redhat8 ~]# tar -tf etc.tar |more etc/ etc/mtab etc/fstab etc/crypttab etc/resolv.conf etc/dnf/ etc/dnf/modules.d/ etc/dnf/modules.d/container-tools.module ...output omitted... 从存档中提取文件 从文档中提取文件注意事项： tar存档通常应当提取到空目录中，以确保它不会覆盖任何现有的文件 当root提取存档时，tar命令会保留文件的原始用户和组所有权 如果普通用户使用tar提取文件，文件所有权将属于从存档中提取文件的用户 示例将/root/etc.tar存档中的文件恢复到/root/etcbackup目录： [root@redhat8 ~]# mkdir /root/etcbackup [root@redhat8 ~]# cd /root/etcbackup [root@redhat8 etcbackup]# tar -xf /root/etc.tar [root@redhat8 etcbackup]# ls -l total 12 drwxr-xr-x. 137 root root 8192 May 29 16:23 etc   默认情况下，从存档中提取文件时，将从存档内容的权限中去除umask。要保留存档文件的权限，可在提取存档时使用p选项。示例将存档/root/scripts.tar提取到/root/scripts目录，同时保留所提取文件的权限： [huang@redhat8 ~]$ ls -l ~/scripts/test.sh -rw-rw----. 1 huang huang 0 May 30 06:49 /home/huang/scripts/test.sh [huang@redhat8 ~]$ tar -cf /root/scripts.tar /home/huang/scripts/test.sh tar: Removing leading `/' from member names [huang@redhat8 ~]$ ls -l /root/scripts.tar -rw-rw----. 1 huang huang 10240 May 30 06:51 /root/scripts.tar [huang@redhat8 ~]$ exit logout [root@redhat8 ~]# cd scripts [root@redhat8 scripts]# tar -xpf /root/scripts.tar [root@redhat8 scripts]# ls -l ./home/huang/scripts/test.sh -rw-rw----. 1 huang huang 0 May 30 06:49 ./home/huang/scripts/test.sh 创建压缩存档 tar命令支持三种压缩方式： gzip压缩速度最快，历史最久，使用也最为广泛，能够跨发行版甚至跨平台使用 -z或--gzip进行gzip压缩（filename.tar.gz 或 filename.tgz） bzip2压缩创建的存档文件通常比gzip创建的文件小，但可用性不如gzip广泛 -j或--bzip2进行 bzip2 压缩 (filename.tar.bz2) xz压缩方式相对较新，但通常提供可用方式中最佳的压缩率 创建三种格式的压缩文件，内容都来自/etc目录： [root@redhat8 tartest]# tar -czf /root/etcbackup.tar.gz /etc tar: Removing leading `/' from member names [root@redhat8 tartest]# tar -cjf /root/etcbackup.tar.bz2 /etc tar: Removing leading `/' from member names [root@redhat8 tartest]# tar -cJf /root/etcbackup.tar.xz /etc tar: Removing leading `/' from member names [root@redhat8 ~]# ls -l |grep etcbackup drwxr-xr-x. 3 root root 17 May 30 06:44 etcbackup -rw-r--r--. 1 root root 4800745 May 30 07:16 etcbackup.tar.bz2 -rw-r--r--. 1 root root 6398813 May 30 07:11 etcbackup.tar.gz -rw-r--r--. 1 root root 4045228 May 30 07:17 etcbackup.tar.xz   创建存档后，使用tf选项来验证存档的内容。在列出压缩存档文件的内容时，不必强制使用压缩代理选项。例如列出/root/etcbackup.tar.gz文件中存档的内容： [root@redhat8 ~]# tar -tf /root/etcbackup.tar.gz |more etc/ etc/mtab etc/fstab etc/crypttab etc/resolv.conf etc/dnf/ etc/dnf/modules.d/ etc/dnf/modules.d/container-tools.module ...output omitted... 提取压缩的存档   提取压缩的tar存档时，要执行的第一步是决定存档文件应提取到的位置，然后创建并更改到目标目录。tar命令会判断之前使用的压缩方式。也可以在tar命令中添加解压缩方式，必须使用正确的解压缩类型选项；否则，tar会生成错误来指出选项中指定的解压缩类型与文件的解压缩类型不匹配。示例： [root@redhat8 etcbackup]# tar -xjf /root/etcbackup.tar.gz |more bzip2: (stdin) is not a bzip2 file. tar: Child returned status 2 tar: Error is not recoverable: exiting now 解压三种类型对应压缩文件到/tmp/etcbackup目录： [root@redhat8 ~]# mkdir /tmp/etcbackup [root@redhat8 ~]# cd /tmp/etcbackup [root@redhat8 etcbackup]# tar -xvf /root/etcbackup.tar.gz etc/ etc/mtab etc/fstab etc/crypttab etc/resolv.conf ...output omitted... [root@redhat8 etcbackup]# tar -xjf /root/etcbackup.tar.bz2 |more [root@redhat8 etcbackup]# tar -xJf /root/etcbackup.tar.xz |more 注意事项及更多说明： 列出压缩的tar存档的工作方式与列出未压缩的tar存档相同 gzip、bzip2和xz也可单独用于压缩单个文件。例如： gzip etc.tar 命令将生成etc.tar.gz压缩文件 bzip2 abc.tar命令将生成abc.tar.bz2压缩文件 xz myarchive.tar命令则生成myarchive.tar.xz压缩文件 对应的解压缩命令为gunzip、bunzip2和unxz。例如： gunzip /tmp/etc.tar.gz命令将生成etc.tar解压缩tar文件 bunzip2 abc.tar.bz2命令将生成abc.tar解压缩tar文件 unxz myarchive.tar.xz命令则生成myarchive.tar解压缩tar文件 在系统之间安全地传输文件 使用Secure Copy传输文件   Secure Copy命令scp是OpenSSH套件的一部分，可将文件从远程系统复制到本地系统或从本地系统复制到远程系统。此命令利用SSH服务进行身份验证，并在数据传输之前对其进行加密。  用户可以为所要复制的文件的源或目标指定一个远程位置。远程位置的格式为 [user@]host:/path。命令说明如下： 该参数的user@部分是可选的，如果不指定该部分，则使用用户当前的本地用户名 运行此命令时，scp客户端将使用基于密钥的身份验证或以提示用户输入密码的方式向远程SSH服务器进行身份验证，像ssh一样   示例将本地文件/root/etcbackup.tar.gz复制到192.168.100.131远程系统的/home/huang目录，并指定用户为huang： [root@redhat8 ~]# scp /root/etcbackup.tar.gz huang@192.168.100.131:/home/huang huang@192.168.100.131's password: etcbackup.tar.gz 100% 6249KB 205.8MB/s 00:00   还可以沿另一个方向复制文件，即从远程系统复制到本地文件系统。示例192.168.100.131上的文件/home/huang/umask.test复制到本地目录/root： [root@redhat8 ~]# scp huang@192.168.100.131:/home/huang/umask.test /root huang@192.168.100.131's password: umask.test 100% 0 0.0KB/s 00:00 [root@redhat8 ~]# ls -l umask.test -rwx---r-x. 1 root root 0 May 30 10:36 umask.test   要以递归方式复制整个目录树，可使用-r选项。示例192.168.100.131上的远程目录/home/huang/test以递归方式复制到host上的本地目录/tmp/： [root@redhat8 ~]# scp -r huang@192.168.100.131:/home/huang/test /tmp huang@192.168.100.131's password: cltopinfo 100% 274 56.3KB/s 00:00 clshowsrv 100% 846 1.0MB/s 00:00 cldump 100% 1486 1.3MB/s 00:00 df.log 100% 539 481.8KB/s 00:00 使用安全文件传输程序传输文件   以交互方式从SSH服务器上传或下载文件，使用安全文件传输程序sftp。sftp命令的会话使用安全身份验证机制，并将数据加密后再与SSH服务器来回传输。与scp命令一样，sftp使用[user@]host来标识目标系统和用户名。如果未指定用户，该命令将尝试使用本地用户名作为远程用户名进行登录。随后会显示sftp>提示符。示例如下： [root@redhat8 ~]# sftp huang@192.168.100.131 huang@192.168.100.131's password: Connected to huang@192.168.100.131. sftp> quit [root@redhat8 ~]#   交互式sftp会话接受各种命令，这些命令在远程文件系统上运行的方式与在本地文件系统上相同，如ls、cd、mkdir、rmdir和pwd。传输相关常用命令： put命令将文件上载到远程系统 get命令从远程系统下载文件 exit命令可退出sftp会话   示例将本地系统上的/root/scripts.tar文件上传到192.168.100.131上新建的目录 /home/huang/hostbackup。sftp会话始终假设put命令后跟的是本地文件系统上的文件，并且首先连接用户的主目录（此例中为/home/huang）： [root@redhat8 ~]# sftp huang@192.168.100.131 huang@192.168.100.131's password: Connected to huang@192.168.100.131. sftp> mkdir hostbackup sftp> cd hostbackup sftp> put /root/scripts.tar Uploading /root/scripts.tar to /home/huang/hostbackup/scripts.tar /root/scripts.tar 100% 10KB 1.1MB/s 00:00   示例从远程主机下载/etc/yum.conf到本地系统上的当前目录，可执行 get /etc/yum.conf 命令，然后使用 exit 命令退出 sftp 会话： huang@192.168.100.131's password: Connected to huang@192.168.100.131. sftp> get /etc/yum.conf Fetching /etc/yum.conf to yum.conf /etc/yum.conf 100% 82 48.7KB/s 00:00 sftp> exit [root@redhat8 ~]# ls -l yum.conf -rw-r--r--. 1 root root 82 May 30 11:05 yum.conf 在系统间安全地同步文件 使用rsync同步文件和目录   rsync命令是在系统之间安全复制文件的另一种方式。此工具采用的算法可通过仅同步已更改的文件部分来将复制的数据量最小化： 它与scp的区别在于，如果两个服务器间的两个文件或目录相似，rsync将仅复制文件系统间的差异部分，而scp仍复制所有内容。 rsync的优点是它能够在本地系统和远程系统之间安全而高效地复制文件。虽然首次目录同步的用时与复制操作大致相同，但之后的同步只需通过网络复制差异部分，从而会大幅加快更新的速度 命令rsync选项说明： rsync的一个重要选项是-n选项，它用于执行空运行： 空运行是对执行命令时所发生情况的模拟 空运行显示了在命令正常运行时 rsync所要进行的更改。 在进行实际rsync操作前先执行空运行，以确保重要的文件不会被覆盖或删除 使用rsync进行同步时，两个常用的选项为-v和-a选项： -v或--verbose选项可提供更详细的输出。这对于故障排除和查看实时进度非常有用 -a或--archive选项将启用“存档模式”。这样可实现递归复制并开启很多有用的选项，以保留文件的大部分特征 存档模式不会保留硬链接，因为这会大幅增加同步时间。如果想保留硬链接，使用-H选项 如果使用的是高级权限，则可能还需要另外两个选项： -A用于保留ACL -X用于保留SELinux上下文 存档模式与指定以下选项的作用相同，通过rsync -a启用的选项： 选项 描述 -r、--recursive 以递归方式同步整个目录树 -l、--links 同步符号链接 -p、--perms 保留权限 -t、--times 保留时间戳 -g、--group 保留组所有权 -o、--owner 保留文件所有者 -D、--devices 同步设备文件   可以使用rsync将本地文件或目录的内容与远程计算机上的文件或目录进行同步（使用任一计算机作为源）。也可以同步两个本地文件或目录的内容。例如让/home/huang/hostbackup目录的内容与/home/huang/rsynctmp目录保持同步： [root@redhat8 ~]# ls /home/huang/hostbackup scripts.tar [root@redhat8 ~]# ls /home/huang/rsynctmp [root@redhat8 ~]# rsync -av /home/huang/hostbackup /home/huang/rsynctmp sending incremental file list hostbackup/ hostbackup/scripts.tar sent 10,389 bytes received 39 bytes 20,856.00 bytes/sec total size is 10,240 speedup is 0.98 [root@redhat8 ~]# ls /home/huang/rsynctmp hostbackup [root@redhat8 ~]# cd /home/huang/rsynctmp/hostbackup [root@redhat8 hostbackup]# ls scripts.tar   通过为源目录加上尾随斜杠，可以同步该目录的内容，而不在目标目录中新建子目录。在下面示例，hostbackup目录不是在/home/huang/rsynctmp目录中创建的，仅/home/huang/hostbackup的内容同步： [root@redhat8 ~]# rsync -av /home/huang/hostbackup/ /home/huang/rsynctmp sending incremental file list ./ scripts.tar sent 10,370 bytes received 38 bytes 20,816.00 bytes/sec total size is 10,240 speedup is 0.98 [root@redhat8 ~]# ls /home/huang/rsynctmp scripts.tar 注意事项： 为rsync命令键入源目录时，目录名称中是否存在尾随斜杠至关重要。它将决定同步到目标中的是目录还是仅目录中的内容 Tab补全可自动在目录名称中添加尾随斜杠   同scp和sftp命令一样，rsync使用[user@]host:/path格式来指定远程位置。远程位置可以是源或目标系统，但两台计算机中的一台必须是本地计算机： 要保留文件所有权，需要是目标系统上的root用户 如果目标为远程目标，则以root身份进行验证 如果目标为本地目标，则必须以root身份运行rsync   示例将本地的/home/huang/hostbackup目录同步到192.168.100.131远程系统上的/home/huang/rsynctest目录： [root@redhat8 ~]# rsync -av /home/huang/hostbackup \\ 192.168.100.131:/home/huang/rsync testroot@192.168.100.131's password: sending incremental file list created directory /home/huang/rsynctest hostbackup/ hostbackup/scripts.tar sent 10,389 bytes received 83 bytes 2,327.11 bytes/sec total size is 10,240 speedup is 0.98   同样，192.168.100.131远程系统上的/home/huang/rsynctest远程目录也可同步到host上的/home/huang/hostbackup本地目录： [root@redhat8 ~]# rsync -av 192.168.100.131:/home/huang/rsynctest \\ /home/huang/hostba ckup root@192.168.100.131's password: receiving incremental file list rsynctest/ rsynctest/hostbackup/ rsynctest/hostbackup/scripts.tar sent 55 bytes received 10,432 bytes 2,996.29 bytes/sec total size is 10,240 speedup is 0.98 练习 "},"05-IBM_Operating_System/06-RHEL学习笔记/08-RHEL-安装和更新软件包.html":{"url":"05-IBM_Operating_System/06-RHEL学习笔记/08-RHEL-安装和更新软件包.html","title":"RHEL-安装和更新软件包","keywords":"","body":"RHEL-安装和更新软件包 注册系统以获取红帽支持 红帽订阅管理   红帽订阅管理提供可用于向计算机授权产品订阅的工具，让管理员能够获取软件包的更新，并且跟踪系统所用支持合同和订阅的相关信息。PackageKit和yum等标准工具可以通过红帽提供的内容分发网络获取软件包和更新。可以通过红帽订阅管理工具执行下列四项基本任务： 注册系统，将该系统与某一红帽帐户关联。这可以让订阅管理器唯一地清查该系统 订阅系统，授权它获取所选红帽产品的更新。订阅包含特定的支持级别、到期日期和默认存储库 启用存储库，以提供软件包。默认情况下每一订阅会启用多个存储库，但可以根据需要启用或禁用更新或源代码等其他存储库 审核和跟踪可用或已用的授权。可以在具体系统上本地查看订阅信息，也可在红帽客户门户的订阅页面或订阅资产管理器(SAM)查看具体帐户的订阅信息 注册系统   将系统注册到红帽客户门户的方法有很多种。可以使用GNOME应用程序或通过Web控制台服务访问相应的图形界面，也可以使用命令行工具。 命令行注册 通过subscription-manager命令可在不使用图形环境的前提下注册系统。subscription-manager命令可以自动将系统关联到最适合该系统的兼容订阅。注册系统到红帽帐户： [user@host ~]$ subscription-manager register --username=yourusername \\ --password=yourpassword 查看可用的订阅： [user@host ~]$ subscription-manager list --available | less 自动附加订阅： [user@host ~]$ subscription-manager attach --auto 从可用订阅列表的特定池中附加订阅： [user@host ~]$ subscription-manager attach --pool=poolID 查看已用的订阅： [user@host ~]$ subscription-manager list --consumed 取消注册系统： [user@host ~]$ subscription-manager unregister 注意事项： subscription-manager也可搭配激活密钥使用，以此注册和分配预定义的订阅，而不必使用用户名或密码。这种注册方式对于自动化安装和部署非常有用 激活密钥通常由内部订阅管理服务颁发，如订阅资产管理器或红帽卫星 授权证书   授权是附加至某一系统的订阅。数字证书用于存储本地系统上有关授权的当前信息。注册之后，授权证书存储在/etc/pki和其子目录中： /etc/pki/product中的证书指明系统上安装了哪些红帽产品 /etc/pki/consumer中的证书指明系统所注册到的红帽帐户 /etc/pki/entitlement中的证书指明该系统附加有哪些订阅   可以通过rct实用程序直接检查证书，但subscription-manager工具更加容易查看系统所附加的订阅。 RPM软件包 软件包和RPM   RPM Package Manager最初是由红帽开发的，该程序提供了一种标准的方式来打包软件进行分发。与使用从存档提取到文件系统的软件相比，采用RPM软件包形式管理软件要简单得多： 管理员可以通过它跟踪软件包所安装的文件，需要删除哪些软件（如果卸载）并检查确保显示支持软件包（如果安装） 有关已安装软件包的信息存储在各个系统的本地RPM数据库中 红帽为红帽企业Linux提供的所有软件都以RPM软件包的形式提供   RPM软件包文件名由四个元素组成（再加上.rpm后缀）：name-version-release.architecture，openssh的RPM软件包名称示例如下： openssh-7.8p1-4.el8.x86_64.prm 字段说明： Name是描述其内容的一个或多个词语(openssh) Version是原始软件的版本号(7.8p1) Release是基于该版本的软件包的发行版号，由软件打包商设置，后者不一定是原始软件开发商(4.el8) Architecture是编译的软件包运行的处理器架构： noarch表示此软件包的内容不限定架构 x86_64表示64位的x86_64架构 aarch64表示64位的ARM架构 从存储库安装软件包时，只需要软件包的名称。如果存在多个版本，则会安装具有更高版本号的软件包。如果一个版本存在多个发行版，则会安装具有更高发行版号的软件包。 每个RPM软件包是包含以下三个组成部分的特殊存档： 软件包安装的文件 与软件包（元数据）有关的信息，如： name、version、release和arch 软件包的摘要和描述 是否要求安装其他软件包 授权许可信息 软件包更改日志 其他详细信息 在安装、更新或删除此软件包时可能运行的脚本，或者在安装、更新或删除其他软件包时触发的脚本   软件提供商使用GPG密钥对RPM软件包进行数字签名（红帽为其发行的所有软件包签署数字签名）。RPM系统通过确认软件包已由相应的GPG密钥签名来验证软件包的完整性。如果GPG签名不匹配，RPM系统拒绝安装软件包。 通过RPM软件包更新软件 红帽生成一个完整的RPM软件包来更新软件： 管理员安装该软件包时，仅获取该软件包的最新版本 红帽不要求先安装旧软件包，再打补丁 为了更新软件，RPM会删除旧版本的软件包，再安装新版本 更新通常会保留配置文件，但新版本的打包程序会定义确切的行为 在大多数情形中，一次仅可安装软件包的一个版本或发行版： 如果软件包构建为没有冲突的文件名，则可安装多个版本 最重要的相关例子是kernel软件包。由于新的内核只有通过启动至该内核才能进行测试，该软件包进行了特殊设计，以便一次能够安装多个版本。如果新内核启动失败，则旧内核依然可用并可启动 通过RPM软件包更新软件   rpm实用程序可获取软件包文件和已安装软件包的内容的相关信息。默认情况下，它从已安装软件包的本地数据库中获取信息。可以使用-p选项来指定想获取有关已下载软件包文件的信息。一般查询格式是： rpm -q [select-options] [query-options] RPM查询关于已安装的软件包的一般信息： rpm -qa：列出所有已安装的软件包 rpm -qf FILENAME：查找提供FILENAME的软件包，示例： [root@redhat8 ~]# rpm -qf /etc/yum.repos.d redhat-release-8.0-0.44.el8.x86_64 RPM查询关于特定软件包的信息： rpm -q：列出当前安装的软件包的版本，示例： [root@redhat8 ~]# rpm -q openssh openssh-7.8p1-4.el8.x86_64 rpm -qi：获取有关软件包的详细信息 rpm -ql：列出软件包安装的文件，示例： [root@redhat8 ~]# rpm -ql yum /etc/yum.conf /etc/yum/pluginconf.d /etc/yum/protected.d /etc/yum/vars /usr/bin/yum /usr/share/man/man1/yum-aliases.1.gz /usr/share/man/man5/yum.conf.5.gz /usr/share/man/man8/yum-shell.8.gz /usr/share/man/man8/yum.8.gz rpm -qc：仅列出软件包安装的配置文件，示例： [root@redhat8 ~]# rpm -qc openssh-clients /etc/ssh/ssh_config /etc/ssh/ssh_config.d/05-redhat.conf rpm -qd：仅列出软件包安装的文档文件，示例： [root@redhat8 ~]# rpm -qd yum /usr/share/man/man1/yum-aliases.1.gz /usr/share/man/man5/yum.conf.5.gz /usr/share/man/man8/yum-shell.8.gz /usr/share/man/man8/yum.8.gz rpm -q --scripts：列出在安装或删除软件包前后运行的shell脚本，示例： [root@redhat8 ~]# rpm -q --scripts openssh preinstall scriptlet (using /bin/sh): getent group ssh_keys >/dev/null || groupadd -r ssh_keys || : rpm -q --changelog：列出软件包的更改信息，示例： [root@redhat8 ~]# rpm -q --changelog python3-pip * Mon Dec 03 2018 Miro Hrončok - 9.0.3-13 - Use the system level root certificate instead of the one bundled in certifi - Resolves: rhbz#1655255 * Wed Nov 28 2018 Tomas Orsava - 9.0.3-12 - Do not show the \"new version of pip\" warning outside of venv - Resolves: rhbz#1656171 ...output omitted... 查询本地软件包文件： [root@redhat8 Downloads]# ls -l oracle-database-preinstall-19c-1.0-1.el7.x86_64.rpm -rwx---rwx. 1 huang huang 18204 May 14 14:12 oracle-database-preinstall-19c-1.0-1.el7.x86_64.rpm[root@redhat8 Downloads]# rpm -qlp oracle-database-preinstall-19c-1.0-1.el7.x86_64.r pm /etc/rc.d/init.d/oracle-database-preinstall-19c-firstboot /etc/security/limits.d/oracle-database-preinstall-19c.conf /etc/sysconfig/oracle-database-preinstall-19c /etc/sysconfig/oracle-database-preinstall-19c/oracle-database-preinstall-19c-verify /etc/sysconfig/oracle-database-preinstall-19c/oracle-database-preinstall-19c.param /usr/bin/oracle-database-preinstall-19c-verify /var/log/oracle-database-preinstall-19c /var/log/oracle-database-preinstall-19c/results 安装RPM软件包 rpm命令可用于安装本地目录的RPM软件包。示例： [root@redhat8 tmp]# rpm -ivh vsftpd-3.0.3-32.el8.x86_64.rpm warning: vsftpd-3.0.3-32.el8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 8483c65d: NOKEYVerifying... ################################# [100%] Preparing... ################################# [100%] Updating / installing... 1:vsftpd-3.0.3-32.el8 ################################# [100%] 注意事项： 安装第三方软件包时一定要小心，不仅是因为它们可能安装的软件，而且还因为RPM软件包可能会含有在安装过程中以root用户身份运行的任意脚本   从RPM软件包文件中提取文件，而不安装此软件包。rpm2cpio实用程序可以将RPM的内容传递给名为cpio的特殊归档工具，后者可以提取所有文件或单个文件。将rpm2cpio PACKAGEFILE.rpm的输出传送到cpio -id，以提取RPM软件包中存储的所有文件。需要时，会相对于当前工作目录创建子目录树。示例： [root@redhat8 Downloads]# rpm2cpio libstdc++-devel-8.2.1-3.5.el8.x86_64.rpm \\ | cpio -id 23311 blocks [root@redhat8 Downloads]# ls libstdc++-devel-8.2.1-3.5.el8.x86_64.rpm usr oracle-database-preinstall-19c-1.0-1.el7.x86_64.rpm [root@redhat8 Downloads]# ls -ld usr drwxr-xr-x. 5 root root 45 Jun 1 15:38 usr 可以通过指定文件的路径来提取各个文件： [root@redhat8 Downloads]# rpm2cpio libstdc++-devel-8.2.1-3.5.el8.x86_64.rpm \\ | cpio -id \"*txt\" 23311 blocks [root@redhat8 Downloads]# ls -l usr/share/doc/libstdc++-devel/ total 768 -rw-r--r--. 1 root root 233 Jun 1 15:38 README RPM查询命令摘要   可以直接通过rpm命令查询已安装的软件包。加上-p选项即可在安装之前查询软件包文件。RPM查询命令摘要如下表所示： 命令 任务 rpm -qa 列出当前安装的所有RPM软件包 rpm -q NAME 显示系统上安装的NAME版本 rpm -qi NAME 显示有关软件包的详细信息 rpm -ql NAME 列出软件包中含有的所有文件 rpm -qc NAME 列出软件包中含有的配置文件 rpm -qd NAME 列出软件包中含有的文档文件 rpm -q --changelog NAME 显示软件包新发行版的简短原因摘要 rpm -q --scripts NAME 显示在软件包安装、升级或删除时运行的shell脚本 使用Yum安装和更新软件包 yum目前已被dnf命令取代，用法大同小异。 Yum命令摘要 可以根据名称或软件包组，查找、安装、更新和删除软件包： 命令 任务 yum list [NAME-PATTERN] 按名称列出已安装和可用的软件包 yum group list 列出已安装和可用的组 yum search KEYWORD 按关键字搜索软件包 yum info PACKAGENAME 显示软件包的详细信息 yum install PACKAGENAME 安装软件包 yum group install GROUPNAME 安装软件包组 yum update 更新所有软件包 yum remove PACKAGENAME 删除软件包 yum history 显示事务历史记录 使用Yum管理软件包   Yum设计目标是在管理基于RPM的软件安装和更新方面成为一个更理想的系统。yum命令允许安装、更新、删除和获取有关软件包及其依赖项的信息。可以获取已执行事务的历史记录并使用多个红帽及第三方软件存储库。 使用Yum查找软件 yum help显示用法信息： [root@redhat8 ~]# yum help Updating Subscription Management repositories. You can use subscr iption-manager to register.usage: dnf [options] COMMAND List of Main Commands: alias List or create command aliases autoremove remove all unneeded packages that were originally installe d as dependenciescheck check for problems in the packagedb check-update check for available package upgrades clean remove cached data ...output omitted... yum list显示已安装和可用的软件包，示例： [root@redhat8 ~]# yum list 'http*' httpd.x86_64 2.4.37-10.module+el8+2764+7127e69e @redhat8_app httpd-filesystem.noarch 2.4.37-10.module+el8+2764+7127e69e @redhat8_app httpd-tools.x86_64 2.4.37-10.module+el8+2764+7127e69e @redhat8_app Available Packages http-parser.i686 2.7.1-9.el7 ol7_latest http-parser.src 2.7.1-9.el7 ol7_latest ...output omitted... yum search KEYWORD根据仅在名称和摘要字段中找到的关键字列出软件包： [root@redhat8 ~]# yum search 'python' ========================= Name Exactly Matched: python ========================= python.src : An interpreted, interactive, object-oriented programming language python.x86_64 : An interpreted, interactive, object-oriented programming : language ======================== Name & Summary Matched: python ======================== python-ply.noarch : Python Lex-Yacc python-ply.src : Python Lex-Yacc ...output omitted... 搜索名称、摘要和描述字段中包含web server的软件包，使用search all： eyboardInterrupt: Terminated. [root@redhat8 ~]# yum search all 'web server' ==================== Description & Summary Matched: web server ===================== yawn-server.noarch : Standalone web server for yawn erlang-inets.x86_64 : A set of services such as a Web server and a ftp client etc ...output omitted... yum info PACKAGENAME返回与软件包相关的详细信息，包括安装所需的磁盘空间： [root@redhat8 ~]# yum info httpd Available Packages Name : httpd Version : 2.4.6 Release : 97.0.5.el7_9.5 Arch : src Size : 5.0 M Source : None Repo : ol7_latest Summary : Apache HTTP Server URL : http://httpd.apache.org/ License : ASL 2.0 Description : The Apache HTTP Server is a powerful, efficient, and extensible : web server. yum provides PATHNAME显示与指定的路径名（通常包含通配符）匹配的软件包： [root@redhat8 ~]# yum provides /var/www/html httpd-filesystem-2.4.37-10.module+el8+2764+7127e69e.noarch : The basic directory ...: layout for the Apache HTTP server Repo : @System Matched from: Filename : /var/www/html httpd-2.4.6-80.0.1.el7.x86_64 : Apache HTTP Server Repo : ol7_latest Matched from: Filename : /var/www/html ...output omitted... 使用yum安装和删除软件 yum install PACKAGENAME获取并安装软件包，包括所有依赖项： [root@redhat8 ~]# yum install python3 ...output omitted... Running transaction Installing : libtirpc-0.2.4-0.16.el7.x86_64 1/5 Installing : python3-setuptools-39.2.0-10.el7.noarch 2/5 Installing : python3-pip-9.0.3-8.el7.noarch 3/5 Installing : python3-3.6.8-18.el7.x86_64 4/5 Installing : python3-libs-3.6.8-18.el7.x86_64 5/5 ...output omitted...   yum update PACKAGENAME获取并安装指定软件包的较新版本，包括所有依赖项。通常，该进程尝试适当保留配置文件，但是在某些情况下，如果打包商认为旧文件在更新后将无法使用，则可能对其进行重命名。如果未指定 PACKAGENAME，将安装所有相关更新： [root@redhat8 ~]# yum update python   由于新的内核只有通过启动至该内核才能进行测试，该软件包进行了特殊设计，以便一次能够安装多个版本。如果新内核启动失败，则依然可以使用旧的内核。使用yum update kernel实际上会安装新的内核。配置文件中保存一份软件包列表，即使在管理员要求更新时也始终安装这些软件包。使用yum list kernel可列出所有已安装和可用的内核： [root@redhat8 ~]# yum list kernel Installed Packages kernel.x86_64 4.18.0-80.el8 @anaconda Available Packages kernel.src 3.10.0-1160.66.1.el7 ol7_lates   若要查看当前运行中的内核，请使用uname命令。-r选项仅显示内核的版本和发行版本，而-a选项显示内核发行版和其他信息。示例如下： [root@redhat8 ~]# uname -r 4.18.0-80.el8.x86_64 [root@redhat8 ~]# uname -a Linux redhat8 4.18.0-80.el8.x86_64 #1 SMP Wed Mar 13 12:02:46 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux yum remove PACKAGENAME删除安装的软件包，包括所有受支持的软件包： [root@redhat8 ~]# yum remove python3 Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscr iption-manager to register.Dependencies resolved. ==================================================================================== Package Arch Version Repository Size ==================================================================================== Removing: python36 x86_64 3.6.8-1.module+el8+2710+846623d6 @AppStream 13 k Removing unused dependencies: python3-pip noarch 9.0.3-13.el8 @AppStream 2.5 k python3-setuptools noarch 39.2.0-4.el8 @anaconda 450 k Transaction Summary ==================================================================================== Remove 3 Packages Freed space: 466 k Is this ok [y/N]: n Operation aborted. 使用yum安装和删除各组软件   yum也具有组的概念，即针对特定目的而一起安装的相关软件集合。在RHEL8中，有两种类型的组。常规组是软件包的集合。环境组是常规组的集合。一个组提供的软件包或组可能为： mandatory（安装该组时必须予以安装） default（安装该组时通常会安装） optional（安装该组时不予以安装，除非特别要求）   yum group list命令可显示已安装和可用的组的名称(有些组一般通过环境组安装，默认为隐藏。可通过yum group list hidden命令列出这些隐藏组)： [root@redhat8 ~]# yum group list Available Environment Groups: Minimal Install Infrastructure Server ...output omitted... Installed Environment Groups: Server with GUI Available Groups: Cinnamon Educational Software ...output omitted... yum group info显示组的相关信息。它将列出必选、默认和可选软件包名称： [root@redhat8 ~]# yum group info \"Internet Applications\" Group: Internet Applications Description: Email, chat, and video conferencing software. Optional Packages: checkgmail konversation mail-notification yum group install将安装一个组，同时安装其必选和默认的软件包，以及它们依赖的软件包： [root@redhat8 ~]# yum group install \"RPM Development Tools\" 查看事务历史记录 所有安装和删除事务的日志记录在/var/log/dnf.rpm.log中： [root@redhat8 ~]# tail -5 /var/log/dnf.rpm.log 2022-06-07T14:14:19Z INFO --- logging initialized --- 2022-06-07T14:17:13Z INFO --- logging initialized --- 2022-06-07T14:19:18Z INFO --- logging initialized --- 2022-06-07T14:19:39Z INFO --- logging initialized --- 2022-06-07T14:20:38Z INFO --- logging initialized --- history undo选项可以撤销事务： [root@redhat8 ~]# yum history undo 5 启用Yum软件存储库 启用红帽软件存储库 查看所有可用的存储库： [root@redhat8 ~]# yum repolist all repo id repo name status *epel Extra Packages for Enterprise Linux 7 - x86 enabled: 13,753 epel-debuginfo Extra Packages for Enterprise Linux 7 - x86 disabled ...output omitted... ol7_developer_php72 Oracle Linux 8 PHP 7.2 Packages for Develop disabled ol7_gluster312 Oracle Linux 8 Gluster 3.12 Packages (x86_6 disabled ol7_latest Oracle Linux 8 Latest (x86_64) enabled: 24,399 ol7_latest_archive Oracle Linux 8 Archive (x86_64) disabled ...output omitted...   yum config-manager命令可用于启用或禁用存储库。为启用存储库，该命令将enabled参数设为1。示例如下： [root@redhat8 ~]# yum config-manager --enable rhel-8-server-debug-rpms   要启用对新的第三方存储库的支持，可在/etc/yum.repos.d/目录中创建一个文件。存储库配置文件必须以.repo扩展名结尾。存储库定义包含存储库的URL和名称，也定义是否使用GPG检查软件包签名；如果是，则还检查URL是否指向受信任的GPG密钥。示例： [root@redhat8 ~]# ls -l /etc/yum.repos.d total 80 -rw-r--r--. 1 root root 1355 May 14 16:58 epel.repo -rw-r--r--. 1 root root 16402 Aug 26 2019 public-yum-ol7.repo -rw-r--r--. 1 root root 358 Jul 19 2020 redhat.repo 创建Yum存储库 使用yum config-manager命令来创建Yum存储库。示例： # yum config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo Loaded plugins: fastestmirror, langpacks adding repo from: https://download.docker.com/linux/centos/docker-ce.repo grabbing file https://download.docker.com/linux/centos/docker-ce.repo to /etc/yum.repos.d/ docker-ce.reporepo saved to /etc/yum.repos.d/docker-ce.repo   修改此文件，以提供GPG密钥的自定义值和位置所示。密钥存储在远程存储库站点上的不同位置，如http://dl.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-8。管理员应将该密钥下载到本地文件，而不是让yum从外部来源检索该密钥。例如： [EPEL] name=EPEL 8 baseurl=https://dl.fedoraproject.org/pub/epel/8/Everything/x86_64/ enabled=1 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-8 本地存储库的RPM配置软件包   一些存储库将一个配置文件和GPG公钥作为RPM软件包的一部分提供，该软件包可以使用yum localinstall命令来下载和安装。例如，Extra Packages for Enterprise Linux (EPEL)提供红帽不支持的、但与RHEL兼容的软件。以下命令将安装RHEL8 EPEL存储库软件包： [root@redhat8 ~]# rpm --import \\ > http://dl.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-8 [root@redhat8 ~]# yum install \\ > https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscr iption-manager to register.Extra Packages for Enterprise Linux 7 - x86_64 3.0 kB/s | 7.6 kB 00:02 Latest Unbreakable Enterprise Kernel Release 5 for 1.5 kB/s | 3.0 kB 00:01 Oracle Linux 8 Latest (x86_64) 1.5 kB/s | 3.6 kB 00:02 epel-release-latest-8.noarch.rpm 5.4 kB/s | 23 kB 00:04 Dependencies resolved. ==================================================================================== Package Arch Version Repository Size ==================================================================================== Upgrading: epel-release noarch 8-15.el8 @commandline 23 k Transaction Summary ==================================================================================== Upgrade 1 Package Total size: 23 k Is this ok [y/N]: Y Downloading Packages: Running transaction check Transaction check succeeded. Running transaction test Transaction test succeeded. Running transaction Preparing : 1/1 Running scriptlet: epel-release-8-15.el8.noarch 1/1 Upgrading : epel-release-8-15.el8.noarch 1/2 warning: /etc/yum.repos.d/epel.repo created as /etc/yum.repos.d/epel.repo.rpmnew Cleanup : epel-release-7-14.noarch 2/2 Running scriptlet: epel-release-7-14.noarch 2/2 Verifying : epel-release-8-15.el8.noarch 1/2 Verifying : epel-release-7-14.noarch 2/2 Installed products updated. Upgraded: epel-release-8-15.el8.noarch Complete!   配置文件通常在一个文件中列举多个存储库引用。每一存储库引用的开头为包含在方括号里的单一词语名称。示例如下： [root@redhat8 ~]# cat /etc/yum.repos.d/epel.repo [epel] name=Extra Packages for Enterprise Linux 7 - $basearch # It is much more secure to use the metalink, but if you wish to use a local mirror # place its address here. baseurl=http://download.example/pub/epel/7/$basearch metalink=https://mirrors.fedoraproject.org/metalink?repo=epel-7&arch=$basearch&infra =$infra&content=$contentdirfailovermethod=priority enabled=1 gpgcheck=1 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7 ...output omitted...   先安装RPM GPG密钥，再安装签名的软件包。这将验证软件包是否属于已经导入的密钥。否则，yum命令会因为缺少密钥而失败。可以通过--nogpgcheck选项忽略缺少的GPG密钥，但这可能会导致伪造或不安全的软件包被安装到系统上。 管理软件包模块流 应用流简介   RHEL8引入了应用流的概念。现在可同时提供发行版随附的多个版本的用户空间组件。它们可能比核心操作系统软件包更新得更频繁。这可以更灵活地自定义RHEL，而不会影响平台或特定部署的底层稳定性。  从传统上看，管理应用软件包的备用版本及其相关软件包意味着为每个不同版本维护不同的存储库。如果开发人员想要最新版本的应用，而管理员希望获得该应用的最稳定版本，便会造成一种难以管理的繁琐局面。RHEL8中运用一种称为模块化的新技术简化了这个过程。模块化允许单个存储库承载应用软件包及其依赖项的多个版本。RHEL8内容通过两个主要的软件存储库进行分发，分别为BaseOS和AppStream(应用流)： BaseOS存储库以RPM软件包的形式为RHEL提供核心操作系统内容。BaseOS组件的生命周期与之前RHEL发行版中的内容相同 应用流存储库提供具有不同生命周期的内容，作为模块和传统软件包。应用流包含系统的必要部分，以及以前作为红帽软件集合的一部分以及其他产品和程序提供的各种应用。应用流存储库包含两种类型的内容： 模块和传统的RPM软件包。模块描述了属于一个整体的一组RPM软件包。模块可以包含多个流，使多个版本的应用可供安装。启用模块流后，系统能够访问该模块流中的RPM软件包 模块   模块是一组属于一个整体的、协调一致的 RPM 软件包。通常，这是围绕软件应用或编程语言的特定版本进行组织的。典型的模块可以包含应用的软件包、应用特定依赖库的软件包、应用文档的软件包，以及帮助器实用程序的软件包。 模块流   每个模块可以具有一个或多个模块流，其包含不同版本的内容。每个流独立接收更新。模块流可以视为应用流物理存储库中的虚拟存储库。对于每个模块，只能启用其中一个流并提供它的软件包。 模块配置文件   每个模块可以有一个或多个配置文件。配置文件是要为特定用例一起安装的某些软件包的列表，这些用例包括服务器、客户端、开发或最小安装等。安装特定的模块配置文件只是从模块流安装一组特定的软件包。可以随后正常安装或卸载软件包。如果未指定配置文件，模块将安装它的默认配置文件。 使用Yum管理模块   Yum版本4是RHEL8的增加了对应用流新模块化功能的支持。为处理模块化内容，添加了yum module命令。否则，yum很大程度上会像常规软件包一样处理模块。 列出模块 使用yum module list显示可用模块的列表： [root@redhat8 ~]# yum module list Extra Packages for Enterprise Linux Modular 8 - x86_64 Name Stream Profiles Summary 389-directory-server next minimal, 389 Directory Server default 389-directory-server stable minimal, 389 Directory Server legacy, default [d] ...output omitted... 列出特定模块的模块流并检索其状态： [root@redhat8 ~]# yum module list nodejs Extra Packages for Enterprise Linux Modular 8 - x86_64 Name Stream Profiles Summary nodejs 13 development, minimal, default Javascript runtime nodejs 16-epel development, minimal, default Javascript runtime Hint: [d]efault, [e]nabled, [x]disabled, [i]nstalled 显示模块的详细信息： [root@redhat8 ~]# yum module info nodejs Name : nodejs Stream : 13 Version : 820200419230336 Context : 9edba152 Profiles : development, minimal, default Repo : epel-modular Summary : Javascript runtime Description : Node.js is a platform built on Chrome''s JavaScript runtime for easily building fast, scalable network applications. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient, perfect for data-intensive real-time applications that run across distributed devices. : This is the 13.x development stream and may not be suitible for produc tion workloads.Artifacts : c-ares-0:1.16.0-1.module_el8+8692+52300fb6.src : c-ares-0:1.16.0-1.module_el8+8692+52300fb6.x86_64 : c-ares-debuginfo-0:1.16.0-1.module_el8+8692+52300fb6.x86_64 ...output omitted... ...output omitted...   若不指定模块流，yum module info将显示使用默认流的模块的默认配置文件所安装的软件包列表。使用module-name:stream格式来查看特定的模块流。添加--profile选项可显示有关各个模块的配置文件所安装的软件包的信息。例如： [root@redhat8 ~]# yum module info --profile perl:5.24 启用模块流和安装模块   必须启用模块流才能安装其模块。为了简化此过程，在安装模块时，它将根据需要启用其模块流。可以使用yum module enable并提供模块流的名称来手动启用模块流。对于给定的模块，仅可启用一个模块流。启用其他模块流将禁用原始的模块流。   使用默认流和配置文件安装模块(运行yum install @perl效果一样。@表示法告知yum参数是模块名称而非软件包名称)： [root@redhat8 ~]# yum module install zabbix 验证模块流和已安装配置文件的状态： [root@redhat8 ~]# yum module list nginx Extra Packages for Enterprise Linux Modular 8 - x86_64 Name Stream Profiles Summary nginx 1.20 common nginx webserver nginx mainline common nginx webserver Hint: [d]efault, [e]nabled, [x]disabled, [i]nstalled 删除模块和禁用模块流   删除模块会删除当前启用的模块流的配置集所安装的所有软件包，以及依赖于这些软件包的任何其他软件包和模块。从此模块流安装的软件包如果未在其配置文件中列出，则会保持安装在系统上，可以手动删除。注意事项： 删除模块和切换模块流可能会有点棘手。切换为模块启用的流相当于重置当前流并启用新流。它不会自动更改任何已安装的软件包，必须手动来完成。 建议不要直接安装与当前所安装的模块流不同的模块流，因为升级脚本可能会在安装期间运行，从而破坏原始模块流。这可能会导致数据丢失或其他配置问题 要删除已安装的模块： [root@redhat8 ~]# yum module remove nginx   删除模块后，其模块流仍然为启用状态。使用命令yum module list验证模块流是否仍处于启用状态。要禁用模块流： [root@redhat8 ~]# yum module disable nginx Dependencies resolved. ==================================================================================== Package Arch Version Repository Size ==================================================================================== Disabling module streams: nginx Transaction Summary ==================================================================================== Is this ok [y/N]: y Complete! [root@redhat8 ~]# yum module list nginx Extra Packages for Enterprise Linux Modular 8 - x86_64 Name Stream Profiles Summary nginx 1.20 [x] common nginx webserver nginx mainline [x] common nginx webserver Hint: [d]efault, [e]nabled, [x]disabled, [i]nstalled 切换模块流   切换模块流通常需要将内容升级或降级到不同版本。为确保顺利切换，应首先删除模块流提供的模块。这将删除模块的配置文件所安装的所有软件包，以及这些软件包依赖的任何模块和软件包。 为列出从模块安装的软件包，在下面的示例中安装了postgresql:9.6模块(官方示例)： [user@host ~]$ sudo yum module info postgresql | grep module+el8 | \\ sed 's/.*: //g;s/\\n/ /g' | xargs yum list installed Installed Packages postgresql.x86_64 9.6.10-1.module+el8+2470+d1bafa0e @rhel-8.0-for-x86_64-appstream-rpms postgresql-server.x86_64 9.6.10-1.module+el8+2470+d1bafa0e @rhel-8.0-for-x86_64-appstream-rpms 删除在上一个命令中列出的软件包。标记要卸载的模块配置文件(官方示例)： [user@host ~]$ sudo yum module remove postgresql ...output omitted... Is this ok [y/N]: y ...output omitted... Removed: postgresql-server-9.6.10-1.module+el8+2470+d1bafa0e.x86_64 libpq-10.5-1.el8.x86_64 postgresql-9.6.10-1.module+el8+2470+d1bafa0e.x86_64 Complete 删除模块配置文件后，重置模块流。使用yum module reset命令重置模块流(官方示例)： [user@host ~]$ sudo yum module reset postgresql ================================================================= Package Arch Version Repository Size ================================================================= Resetting module streams: postgresql 9.6 Transaction Summary ================================================================= Is this ok [y/N]: y Complete! 要启用其他模块流并安装模块(官方示例)： [user@host ~]$ sudo yum module install postgresql:10   将启用新的模块流，并禁用当前的流。可能需要更新或降级先前模块流中未在新配置文件中列出的软件包。必要时，可使用yum distro-sync来执行此任务。此外，也可能会有从先前模块流中保持安装的软件包，可通过yum remove删除它们。 练习 "},"05-IBM_Operating_System/06-RHEL学习笔记/09-RHEL-访问Linux文件系统.html":{"url":"05-IBM_Operating_System/06-RHEL学习笔记/09-RHEL-访问Linux文件系统.html","title":"RHEL-访问Linux文件系统","keywords":"","body":"RHEL-访问Linux文件系统 识别文件系统和设备 存储管理概念   Linux服务器上的文件是按文件系统层次结构（一个颠倒的目录树）访问的。该文件系统层次结构则是由系统可用的存储设备所提供的文件系统组装而来。每个文件系统都是一个已格式化的存储设备，可用于存储文件。 文件系统和挂载点   要让文件系统的内容在文件系统层次结构中可用，必须将它挂载到一个空目录上。该目录被称为挂载点。挂载后，如果使用ls列出该目录，就会看到已挂载文件系统的内容，并可以正常访问和使用这些文件。许多文件系统都会作为启动进程的一部分自动挂载。 文件系统、存储和块设备   在Linux中，对存储设备的低级别访问是由一种称为块设备的特殊类型文件提供的。在挂载这些块设备前，必须先使用文件系统对其进行格式化： 块设备文件与其他的设备文件一起存储在/dev目录中 设备文件是由操作系统自动创建的 在RHEL中，检测到的第一个SATA/PATA、SAS、SCSI或USB硬盘驱动器被称为/dev/sda，第二个被称为/dev/sdb，以此类推。这些名称代表整个硬盘驱动器 其他类型的存储设备有另外的命名方式 许多虚拟机都采用了较新的virtio-scsi超虚拟化存储，对应的命名形式为/dev/sd* 块设备命名如下表 设备类型 设备命名模式 SATA/SAS/USB附加存储 /dev/sda、/dev/sdb ... virtio-blk超虚拟化存储（部分虚拟机） /dev/vda、/dev/vdb ... NVMe附加存储（很多 SSD） /dev/nvme0, /dev/nvme1 ... SD/MMC/eMMC存储（SD卡） /dev/mmcblk0, /dev/mmcblk1 ... 磁盘分区   通常不会将整个存储设备设为一个文件系统。存储设备通常划分为更小的区块，称为分区。分区用于划分硬盘： 不同的部分可以通过不同的文件系统进行格式化或用于不同的用途 例如，一个分区可以包含用户主目录，另一个分区则可包含系统数据和日志 如果用户在主目录分区中填满了数据，系统分区可能依然有可用的空间 分区本身就是块设备： 在SATA附加存储中， 第一磁盘上的第一个分区是/dev/sda1 第二磁盘上的第三个分区是/dev/sdb3，以此类推 超虚拟化存储设备采用了类似的命名体系 NVMe附加 SSD 设备命名分区的方式却有所不同： 其第一磁盘上的第一个分区是/dev/nvme0p1 第二磁盘上的第三个分区是/dev/nvme1p3，以此类推 SD或MMC卡采用了类似的命名体系 host上/dev/nvme0n2p1设备文件的长列表显示其特殊文件类型为b，代表块设备： [root@redhat8 ~]# ls -l /dev/nvme0n2p1 brw-rw----. 1 root disk 259, 6 Jun 6 21:43 /dev/nvme0n2p1 逻辑卷   整理磁盘和分区的另一种方式是通过逻辑卷管理(LVM)。通过LVM，一个或多个块设备可以汇集为一个存储池，称为卷组。然后，卷组中的磁盘空间被分配到一个或多个逻辑卷，它们的功能等同于驻留在物理磁盘上的分区。LVM系统在创建时为卷组和逻辑卷分配名称： LVM在/dev中创建一个名称与组名匹配的目录，然后在该新目录中创建一个与逻辑卷同名的符号链接。之后，可以挂载该逻辑卷文件 例如，如果一个卷组名为myvg，其中有一个名为mylv的逻辑卷，那么其逻辑卷设备文件的完整路径名为/dev/myvg/mylv 检查文件系统   若要对本地和远程文件系统设备及可用空间大小有个简略了解，可以运行df命令。不带参数运行df时，它会报告所有已挂载的普通文件系统的总磁盘空间、已用磁盘空间、可用磁盘空间，以及已用磁盘空间占总磁盘空间的百分比。它会同时报告本地和远程文件系统。示例： [root@redhat8 ~]# df Filesystem 1K-blocks Used Available Use% Mounted on devtmpfs 909368 0 909368 0% /dev tmpfs 924716 0 924716 0% /dev/shm tmpfs 924716 1372 923344 1% /run tmpfs 924716 0 924716 0% /sys/fs/cgroup /dev/mapper/rhel-root 37734400 13701212 24033188 37% / /dev/nvme0n1p1 1038336 172968 865368 17% /boot /dev/nvme0n2p5 688048 568 651644 1% /testfs tmpfs 184940 16 184924 1% /run/user/42 tmpfs 184940 4 184936 1% /run/user/0 文件系统说明： 示例host系统上的分区显示了两个物理文件系统，它们挂载于/和/boot。这对于虚拟机而言很常见 tmpfs和devtmpfs设备是系统内存中的文件系统。在系统重启后，写入tmpfs或devtmpfs的文件都会消失   若要改善输出大小的可读性，可以使用两个不同的用户可读选项，即-h或-H。这两个选项的区别是： 使用-h时报告单位是KiB、MiB或GiB，分别是2的10、20及30次方 使用-H选项时报告单位是SI单位，即KB、MB或GB分别是10的3、6及9次方 硬盘驱动器制造商在广告其产品时通常使用SI单位 示例如下： [root@redhat8 ~]# df -h Filesystem Size Used Avail Use% Mounted on devtmpfs 889M 0 889M 0% /dev tmpfs 904M 0 904M 0% /dev/shm tmpfs 904M 1.4M 902M 1% /run tmpfs 904M 0 904M 0% /sys/fs/cgroup /dev/mapper/rhel-root 36G 14G 23G 37% / /dev/nvme0n1p1 1014M 169M 846M 17% /boot /dev/nvme0n2p5 672M 568K 637M 1% /testfs tmpfs 181M 16K 181M 1% /run/user/42 tmpfs 181M 4.0K 181M 1% /run/user/0   如需有关某一特定目录树使用的空间的详细信息，可以使用du命令。du 命令具有-h和-H选项，可以将输出转换为可读的格式。du命令以递归方式显示当前目录树中所有文件的大小。示例： [root@redhat8 ~]# du /home/huang ...output omitted... 9080 /home/huang/.pyenv 0 /home/huang/umasktest 0 /home/huang/rsyctest 57660 /home/huang 以可读的格式显示上面示例目录的磁盘使用报告： [root@redhat8 ~]# du -h /home/huang ...output omitted... 8.9M /home/huang/.pyenv 0 /home/huang/umasktest 0 /home/huang/rsyctest 57M /home/huang 挂载和卸载文件系统 手动挂载文件系统   驻留于可移动存储设备上的文件系统需要挂载后才能访问。mount命令允许root用户手动挂载文件系统。命令说明： mount命令的第一个参数指定要挂载的文件系统 第二个参数指定在文件系统层次结构中用作挂载点的目录 有两种常用方法可以为mount命令指定磁盘分区的文件系统： 在/dev的设备文件名称中包含文件系统 将UUID（一个通用唯一标识符）写入文件系统 挂载设备相对较为简单。需要识别要挂载的设备，确保挂载点存在，然后将设备挂载到挂载点上。 识别块设备   每次连接到系统时，热插拔存储设备（不管是服务器caddy中的硬盘驱动器(HDD)或固态设备 (SSD)，还是USB存储设备）都可能插接到不同的端口上。使用lsblk命令可列出指定块设备或所有可用设备的详细信息： [root@redhat8 ~]# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT sr0 11:0 1 1024M 0 rom nvme0n1 259:0 0 40G 0 disk ├─nvme0n1p1 259:1 0 1G 0 part /boot ├─nvme0n1p2 259:2 0 19G 0 part │ ├─rhel-root 253:0 0 36G 0 lvm / │ └─rhel-swap 253:1 0 2G 0 lvm [SWAP] ├─nvme0n1p3 259:3 0 1K 0 part └─nvme0n1p5 259:4 0 20G 0 part └─rhel-root 253:0 0 36G 0 lvm / nvme0n2 259:5 0 3G 0 disk ├─nvme0n2p1 259:6 0 1G 0 part ├─nvme0n2p2 259:7 0 1G 0 part ├─nvme0n2p3 259:8 0 1K 0 part ├─nvme0n2p5 259:9 0 700M 0 part /testfs └─nvme0n2p6 259:10 0 100M 0 part   如果知道自己刚添加了一台有多个分区的3GB存储设备从上面的输出中/dev/nvme0n2p1等就是要挂载的分区。 按块设备名称挂载 示例在/mnt/testfs目录上/dev/nvme0n2p5分区中挂载文件系统： [root@redhat8 ~]# mount /dev/nvme0n2p5 /mnt/testfs [root@redhat8 ~]# df -h Filesystem Size Used Avail Use% Mounted on ...output omitted... /dev/nvme0n2p5 672M 568K 637M 1% /mnt/testfs [root@redhat8 ~]# ls -l /testfs total 4 -rw-r--r--. 1 root root 10 Jun 7 22:02 test.sh [root@redhat8 ~]# ls -l /mnt/testfs total 44 ...output omitted... -rw-r--r--. 1 root root 276 Oct 31 2020 test3.sh 示例说明： 若要挂载文件系统，目标目录必须已存在。默认情况下，/mnt目录存在并用作临时挂载点 可以将/mnt目录用作临时挂载点（创建/mnt的一个子目录会更好），除非有充分的理由将它挂载到文件系统层次结构中的特定位置 注意事项： 如果用作挂载点的目录不为空，则在挂载文件系统前复制到此目录中的任何文件均不可访问，直到将该文件系统再次卸载 这种方法在短期内可以正常工作。但是，如果从系统中添加或删除了设备，则操作系统检测磁盘的顺序可能会发生变化 这将更改与该存储设备关联的设备名称。更好的方法是通过内置于文件系统的某些特性进行挂载 示例在/testfs目录中写入文件，然后挂载文件系统（有其他数据），再次卸载： [root@redhat8 ~]# ls -l /testfs total 4 -rw-r--r--. 1 root root 10 Jun 7 22:02 test.sh [root@redhat8 ~]# mount /dev/nvme0n2p5 /testfs [root@redhat8 ~]# df -h Filesystem Size Used Avail Use% Mounted on ...output omitted... /dev/nvme0n2p5 672M 568K 637M 1% /testfs [root@redhat8 ~]# ls -l /testfs total 44 ...output omitted... -rw-r--r--. 1 root root 50 Oct 31 2020 test1.log -rw-r--r--. 1 root root 183 Oct 31 2020 test2.sh -rw-r--r--. 1 root root 276 Oct 31 2020 test3.sh [root@redhat8 ~]# umount /dev/nvme0n2p5 /testfs umount: /testfs: not mounted. [root@redhat8 ~]# ls -l /testfs total 4 -rw-r--r--. 1 root root 10 Jun 7 22:02 test.sh 按文件系统UUID挂载   一个稳定且与文件系统关联的标识符是UUID，这是一个非常长的十六进制数字，用作通用唯一标识符。该UUID是文件系统的一部分，只要文件系统没有重新创建过，它就会保持不变。lsblk -fp命令会列出设备的完整路径、其 UUID 和挂载点，以及分区中文件系统的类型。如果未挂载文件系统，挂载点将为空。示例： [root@redhat8 ~]# lsblk -fp NAME FSTYPE LABEL UUID MOUNTPOINT /dev/sr0 /dev/nvme0n1 ├─/dev/nvme0n1p1 xfs 0a510af6-8abf-4e64-b559-902804c93568 /boot ├─/dev/nvme0n1p2 LVM2_m JIsKJl-M87D-CZHf-1SUD-Jo7p-jaKG-ZqWR0x │ ├─/dev/mapper/rhel-root │ │ xfs de085a1b-1289-450c-b62b-c95f7a0918d3 / │ └─/dev/mapper/rhel-swap │ swap 8384993e-b65f-4953-b727-c6db639e6c12 [SWAP] ├─/dev/nvme0n1p3 └─/dev/nvme0n1p5 LVM2_m 0RcVoT-1YY2-HOZ2-jXAd-BKdK-OJTP-SUOFaf └─/dev/mapper/rhel-root xfs de085a1b-1289-450c-b62b-c95f7a0918d3 / /dev/nvme0n2 ├─/dev/nvme0n2p1 ├─/dev/nvme0n2p2 ├─/dev/nvme0n2p3 ├─/dev/nvme0n2p5 ext3 f3ad8520-7468-4ec3-938c-39a2fee46fef └─/dev/nvme0n2p6 根据文件系统的UUID挂载文件系统示例： [root@redhat8 ~]# mount UUID=\"f3ad8520-7468-4ec3-938c-39a2fee46fef\" /testfs [root@redhat8 ~]# df -h Filesystem Size Used Avail Use% Mounted on ...output omitted... /dev/nvme0n2p5 672M 568K 637M 1% /testfs [root@redhat8 ~]# ls -l /test/fs ls: cannot access '/test/fs': No such file or directory [root@redhat8 ~]# ls -l /testfs total 44 ...output omitted... -rw-r--r--. 1 root root 276 Oct 31 2020 test3.sh 自动挂载可移动存储设备   如果已登录并且使用的是图形桌面环境，则在插入任何可移动存储介质时，它将自动挂载。 可移动存储设备将挂载到/run/media/USERNAME/LABEL，其中USERNAME是登录图形环境的用户名，而 LABEL是一个标识符，通常是创建时给文件系统取的名称（如果存在）。在移除设备之前，应手动将它卸载。 卸载文件系统   关机和重新引导过程会自动卸载所有文件系统。作为此过程的一部分，缓存在内存中的任何文件系统数据都会刷新到存储设备，从而确保文件系统不会遭受数据损坏。注意事项： 文件系统数据通常缓存在内存中。因此，为了避免损坏磁盘上的数据，务必先卸载可移动驱动器，然后再拔下它们 卸载过程会在释放驱动器之前同步数据，以确保数据完整性 umount命令卸载文件系统，需要使用挂载点作为参数： [root@redhat8 ~]# df -h Filesystem Size Used Avail Use% Mounted on ...output omitted... /dev/nvme0n2p5 672M 568K 637M 1% /testfs [root@redhat8 ~]# umount /testfs 分区写上也可以： [root@redhat8 ~]# umount /dev/nvme0n2p5 /testfs umount: /testfs: not mounted.   如果挂载的文件系统正在使用之中，则无法卸载。要成功执行umount命令，所有进程都需要停止访问挂载点下的数据。示例文件系统正在使用中（shell正将/testfs用作其当前工作目录），umount将失败，并生成错误消息： [root@redhat8 ~]# cd /testfs [root@redhat8 testfs]# pwd /testfs [root@redhat8 testfs]# umount /testfs umount: /testfs: target is busy.   lsof命令列出所给目录中所有打开的文件以及访问它们的进程。识别哪些进程正在阻止文件系统被成功卸载非常有用。示例： [root@redhat8 testfs]# lsof /testfs COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME bash 7487 root cwd DIR 259,9 4096 2 /testfs lsof 8021 root cwd DIR 259,9 4096 2 /testfs lsof 8022 root cwd DIR 259,9 4096 2 /testfs 查找系统中的文件 搜索文件   系统管理员需要使用工具来搜索文件系统中符合特定条件的文件。可以在文件系统层次结构中搜索文件的两个常用命令： locate命令搜索预生成索引中的文件名或文件路径，并即时返回结果 find命令通过爬取整个文件系统层次结构来实时搜索文件 根据名称查找文件   locate命令根据文件的名称或路径查找文件。这种方式速度比较快，是从mlocate数据库中查找这些信息。但是，该数据库不会实时更新（每日自动更新），意味着locate将找不到自上次数据库更新以来创建的文件。root用户可在任何时候通过发出updatedb命令来强制即时更新： [root@redhat8 ~]# updatedb   locate命令限制非特权用户的结果。若要查看生成的文件名，用户必须对文件所在的目录具有搜索权限。示例可由huang读取的目录树中，搜索名称或路径中包含passwd的文件： [huang@redhat8 ~]$ locate passwd /etc/passwd /etc/passwd- /etc/pam.d/passwd /etc/security/opasswd ...output omitted... 即使文件名或路径仅部分匹配搜索查询，也会返回结果： [root@redhat8 ~]# locate image /images /etc/selinux/targeted/contexts/virtual_image_context /home/huang/.local/share/libvirt/images /images/debian_wheezy_amd64_standard.qcow2 ...output omitted... -i选项执行不区分大小写的搜索： [huang@redhat8 ~]$ locate -i message |more ...output omitted... /usr/share/vim/vim80/lang/zh_TW.UTF-8/LC_MESSAGES /usr/share/vim/vim80/lang/zh_TW.UTF-8/LC_MESSAGES/vim.mo /usr/share/vim/vim80/syntax/messages.vim /var/log/messages /var/log/messages-20220515 -n选项限制locate返回的搜索结果数量，返回的搜索结果限制为前五个匹配项： [huang@redhat8 ~]$ locate -n 3 snow.png /usr/share/icons/Adwaita/16x16/status/weather-snow.png /usr/share/icons/Adwaita/22x22/status/weather-snow.png /usr/share/icons/Adwaita/24x24/status/weather-snow.png 实时搜索文件   find命令通过在文件系统层次结构中执行实时搜索来查找文件。比locate慢，但准确度更高。此外，它还可以根据文件名以外的条件搜索文件，例如文件权限、文件类型、文件大小或修改时间： find命令使用执行搜索的用户帐户查看文件系统中的文件 调用find命令的用户必须具有要查看其内容的目录的读取和执行权限 find命令的第一个参数是要搜索的目录。如果省略了目录参数，则find将从当前目录中开始搜索，并在任何子目录中查找匹配项 若要按文件名搜索文件，可使用-name FILENAME选项。使用此选项时，find将返回与FILENAME完全匹配的文件的路径 对于find命令，完整词语选项使用单个短划线，选项跟在路径名参数后 例如从/目录开始搜索名为sshd_config的文件： [root@redhat8 ~]# find / -name sshd_config /etc/ssh/sshd_config /root/etcbackup/etc/ssh/sshd_config   可以使用通配符搜索文件名，并返回部分匹配的所有结果。使用通配符时，请务必将要查找的文件名用引号括起，以防止终端对通配符进行解译。示例从/目录开始搜索名称以.sh结尾的文件： [root@redhat8 ~]# find / -name '*.sh' /boot/grub2/i386-pc/modinfo.sh /etc/X11/xinit/xinitrc.d/50-systemd-user.sh /etc/X11/xinit/xinitrc.d/localuser.sh /etc/profile.d/lang.sh /etc/profile.d/colorgrep.sh ...output omitted... 示例在/etc/目录中搜索名称的任何位置上含有词语pass的文件： [root@redhat8 ~]# find /etc -name '*pass*' /etc/security/opasswd /etc/pam.d/passwd /etc/pam.d/gdm-password /etc/pam.d/password-auth /etc/passwd- /etc/passwd /etc/authselect/password-auth   要对所给文件名执行不区分大小写的搜索，可使用-iname选项，后面加上要搜索的文件名。示例如下： [root@redhat8 ~]# find / -iname '*message*' /proc/sys/net/core/message_burst /proc/sys/net/core/message_cost /python/git-2.29.2/po/build/locale/de/LC_MESSAGES /python/git-2.29.2/po/build/locale/tr/LC_MESSAGES ...output omitted... 根据所有权或权限搜索文件   find可以根据所有权或权限搜索文件。按所有者搜索时的有用选项为-user和-group（按名称搜索），以及 -uid和-giz（按ID搜索）。示例在/home/huang目录中搜索由root拥有的文件： [huang@redhat8 ~]$ find -user root ./Downloads/usr ./Downloads/usr/include ./Downloads/usr/include/c++ ./Downloads/usr/include/c++/8 ...output omitted... 示例在/home/huang目录中搜索由root组拥有的文件： [huang@redhat8 ~]$ find -group root |more ./Downloads/usr ./Downloads/usr/include ./Downloads/usr/include/c++ ./Downloads/usr/include/c++/8 ...output omitted...   -user和-group选项可以一起使用，以搜索文件所有者和组所有者不同的文件。示例列出由用户root所有并且附属于mail组的文件： [root@redhat8 ~]# find / -user root -group mail /var/spool/mail   -perm选项用于查找具有特定权限集的文件。权限可以描述为八进制值，包含代表读取、写入和执行的4、2和1的某些组合。权限前面可以加上/或-符号： 前面带有/的数字权限将匹配文件的用户、组、其他人权限集中的至少一位 权限为r--r--r--的文件并不匹配/222，权限为rw-r--r--的文件才匹配 权限前带有-符号表示该位的所有三个实例都必须存在，因此前面的两个示例都不匹配，但诸如rw-rw-rw- 的对象则匹配   示例命令将匹配用户具有读取、写入和执行权限，组成员具有读取和写入权限且其他人具有只读权限的任何文件： [root@redhat8 ~]# find /home -perm 764   示例匹配用户至少具有写入和执行权限，并且组至少具有写入权限，并且其他人至少具有读取权限的文件： [root@redhat8 ~]# find /home -perm -324 /home/huang/.config/libvirt/storage/autostart/default.xml   示例匹配用户具有读取权限，或者组至少具有读取权限，或者其他人至少具有写入权限的文件： [root@redhat8 ~]# find /home -perm /442 /home /home/huang /home/huang/.mozilla ...output omitted...   与/或-一起使用时，0值类似于通配符，因为其表示至少无任何内容的权限。示例匹配/home/huang目录中其他人至少具有读取权限的任何文件： [huang@redhat8 ~]$ find -perm -004 |more . ./.mozilla ./.mozilla/extensions ...output omitted... 示例在/home/huang目录中查找其他人拥有写入权限的所有文件： [huang@redhat8 ~]$ find -perm -002 |more . ./.mozilla ./.mozilla/extensions ./.mozilla/plugins ./.bash_logout ...output omitted... 根据大小搜索文件   find命令可以查找与指定的大小相符的文件，该大小是通过-size选项加上数字值与单位来指定的。作-size选项的单位： k，表示千字节 M，表示兆字节 G，表示千兆字节 示例显示如何搜索大小为3兆字节（向上取整）的文件： [huang@redhat8 ~]$ find -size 3M ./Downloads/libstdc++-devel-8.2.1-3.5.el8.x86_64.rpm 搜索大小超过1千兆字节的文件： [root@redhat8 ~]# find / -size +1G /proc/kcore 列出大小不到10KB的所有文件： [huang@redhat8 ~]$ find -size -10k . ./.mozilla ./.mozilla/extensions ./.mozilla/plugins ...output omitted...   -size选项单位修饰符将所有内容向上取整为一个单位。例如，find -size 1M命令将显示小于1MB的文件，因为它将所有文件都向上取整为1MB。 根据修改时间搜索文件   -mmin选项加上以分钟表示的时间，将搜索内容在过去n分钟前更改的所有文件。文件的时间戳始终向下舍入。与范围（+n和-）一起使用时支持分数值。示例查找文件内容在180分钟以前更改的所有文件： [huang@redhat8 ~]$ find ./test -mmin 180 分钟数前加上+修饰符将查找在n分钟以前修改过的所有文件。示例： [huang@redhat8 ~]$ find ./test -mmin +10 ./test/cltopinfo ./test/test1 ./test/clshowsrv ./test/clshowsrv1 ...output omitted...   -修饰符则将搜索改为查找目录中在过去n分钟内更改的所有文件。示例过去十分钟内修改文件： [huang@redhat8 ~]$ find ./test -mmin -10 ./test ./test/testfind 根据文件类型搜索文件   find命令中的-type选项将搜索范围限制为给定的文件类型。使用以下列表传递所需的标志以限制搜索范围： f，表示普通文件 d，表示目录 l，表示软链接 b，表示块设备 示例搜索/home/huang目录中的所有目录： [huang@redhat8 ~]$ find -type d . ./.mozilla ./.mozilla/extensions ./.mozilla/plugins ...output omitted... 搜索所有软连接： [huang@redhat8 ~]$ find -type l ./.config/libvirt/storage/autostart/default.xml /dev目录中所有块设备的列表： [root@redhat8 ~]# find /dev -type b /dev/dm-1 /dev/dm-0 /dev/sr0 /dev/nvme0n2p6 /dev/nvme0n2p5 ...output omitted... -links选项加上数字将查找具有特定硬链接数的所有文件： 数字前面带有+修饰符将查找硬链接数超过所给数目的文件 如果数字前面是-修饰符，则搜索将限制为硬链接数小于所给数目的所有文件 示例搜索硬链接数大于3的所有普通文件： [root@redhat8 ~]# find / -type f -links +3 |more /usr/bin/sha1hmac /usr/bin/sha224hmac /usr/bin/sha256hmac /usr/bin/sha384hmac /usr/bin/sha512hmac /usr/sbin/e2fsck /usr/sbin/fsck.ext2 ...output omitted... 练习 "},"05-IBM_Operating_System/06-RHEL学习笔记/10-RHEL-分析服务器及获取支持.html":{"url":"05-IBM_Operating_System/06-RHEL学习笔记/10-RHEL-分析服务器及获取支持.html","title":"RHEL-分析服务器及获取支持","keywords":"","body":"RHEL-分析服务器及获取支持 分析和管理远程服务器 Web控制台描述   Web控制台是适用于RHEL8 的基于Web型管理界面，专为管理和监控您的服务器而设计。它的基础是开源Cockpit服务。可以使用 Web 控制台监控系统日志并查看系统性能图表。 启用Web控制台   除了最小安装外，RHEL8的所有安装版本中都默认安装Web控制台。可以使用yum命令安装Web控制台： [root@redhat8 ~]# yum install cockpit   启用并启动cockpit.socket服务，它会运行一个Web服务器。如果需要通过Web界面连接系统，必须执行这个步骤： [root@redhat8 ~]# systemctl enable --now cockpit.socket Created symlink /etc/systemd/system/sockets.target.wants/cockpit.socket → /usr/lib/ systemd/system/cockpit.socket.   如果使用的是自定义防火墙配置集，需要将cockpit服务添加到firewalld，以在防火墙中开启端口9090： [root@redhat8 ~]# firewall-cmd --add-service=cockpit --permanent Warning: ALREADY_ENABLED: cockpit success [root@redhat8 ~]# firewall-cmd --reload success 登录Web控制台   Web控制台提供自己的Web服务器。可以使用系统上任何本地帐户的用户名和密码登录，包括root 用户在内。在Web浏览器中打开地址： https://servername:9090 说明： 其中servername是服务器的主机名或IP地址 连接将受到TLS会话的保护。默认情况下，系统安装有一个自签名的 TLS 证书，首次连接时，Web浏览器可能会显示安全警告。 在登录屏幕中输入用户名和密码 选择Reuse my password for privileged tasks选项。这将允许使用sudo特权执行命令，从而执行诸如修改系统信息或配置新帐户之类的任务 登录后Web控制台在标题栏右侧显示用户名。如果选择了Reuse my password for privileged tasks选项，用户名的左侧会显示Privileged图标 如果以某个非特权用户身份登录，则不显示Privileged图标 更改密码   特权和非特权用户都可在登录Web控制台期间更改自己的密码。单击导航栏中的Accounts。单击帐户标签，以打开帐户详细信息页面： 作为非特权用户时，只能设置或重置自己的密码，或者更改SSH公钥 若要设置或重置密码，单击Set Password 使用Web控制台进行故障排除   Web控制台是一个功能强大的故障排除工具。可以实时监控基本系统统计信息，检查系统日志，并快速切换到Web控制台中的终端会话，以便从命令行界面中收集其他信息。 实时监控系统统计信息   单击导航栏中的Overview来查看系统的相关信息，如硬件类型、操作系统和主机名等。如果以非特权用户身份登录，可以查看所有信息，但不能修改值： 单击Overview页面上的View graphs，查看列出CPU活动、内存用量、磁盘 I/O 和网络利用率等当前系统性能的图表 检查和过滤Syslog事件 通过导航栏中的Logs，可以访问系统日志分析工具： 可以使用页面上的菜单，根据日志记录日期范围或严重性级别来过滤日志消息 Web控制台使用当前日期作为默认日期，可以单击日期菜单并指定任何日期范围 Severity菜单提供了从Everything到更具体严重性条件（如Alert and above和Debug and above等）等不同范围的选项 从终端会话运行命令   通过导航栏中的Terminal，可以在Web控制台界面内访问全功能终端会话。这样就能运行任意命令来管理和操作系统，还能执行Web控制台提供的其他工具所不支持的任务。 创建诊断报告   诊断报告中汇集了来自RHEL系统的配置详情、系统信息和诊断信息。已完成报告中收集的数据包括可用于对问题进行故障排除的系统日志和调试信息： 以特权用户身份登录Web控制台 单击导航栏中的Diagnostic Reports，打开用于创建这些报告的页面 单击Create Report以生成新的诊断报告 报告完成时，界面中显示Done! 单击Download report以保存该报告 单击Save File以保存文件并完成此流程 完成的报告将保存到托管用于访问Web控制台的Web浏览器的系统上的Downloads目录 使用Web控制台管理系统服务   作为Web控制台中的特权用户，可以停止、启动、启用和重新启动系统服务。此外，还可以配置网络接口，配置防火墙服务，以及管理用户帐户等。 系统电源选项 Web控制台允许重新启动或关闭系统。以特权用户身份登录Web控制台。单击导航栏上的 Overview访问系统电源选项，从右上角的菜单中选择需要的选项，以重启或关闭系统。 控制运行中的系统服务 可以使用Web控制台中的图形工具启动、启用、禁用和停止服务： 单击导航栏上的Services，访问Web控制台中的服务初始页面 要管理服务，可单击位于服务初始页面顶部的System Services 在搜索栏中搜索或滚动页面以选择要管理的服务 单击相应的Stop、Restart或Disallow running(mask)以管理服务 配置网络接口和防火墙 单击导航栏上的Networking管理防火墙规则和网络接口： 在Interfaces部分中，单击所需的接口名称来访问管理页面 管理页面的顶部显示所选设备的网络流量活动。向下滚动以查看配置设置和管理选项 若修改配置选项或将其添加到接口，可单击所需配置的突出显示链接 单击Manual列表选项右侧的+，以添加其他IP地址，在相应字段中输入IP地址和网络掩码 单击Apply 以激活新设置 显示画面自动切回到接口管理页面，可以在其中确认新的IP地址 管理用户帐户 作为特权用户，可以在Web控制台中创建新的用户帐户： 单击导航栏上的Accounts，以查看现有的帐户 单击Create New Account以打开帐户管理页面 输入新帐户的信息，然后单击Create 显示画面自动切回到帐户管理页面，可以在其中确认新的用户帐户 从红帽客户门户网站获取帮助 访问红帽客户门户网站上的支持资源   红帽用户门户网站https://access.redhat.com为用户提供文档、下载、工具和技术专业知识的访问途径。客户可以通过知识库搜索解决方案、常见问题和文章。可以在用户门户网站中： 访问官方的产品文档 提交和管理支持case 管理软件订阅和权利 获取软件下载、更新和评估 查阅可帮助您优化系统配置的工具 客户门户网站使用入门   可以通过Web浏览器访问红帽客户门户网站。本节介绍客户门户网站导览。此导览可在https://access.redhat.com/start找到。此导览是一个非常实用的工具，可用于探索门户网站的所有功能，以及了解如何充分利用红帽订阅。 使用红帽支持工具搜索知识库   红帽支持工具实用程序redhat-support-tool提供基于文本的界面，可从系统的命令行使用此工具在客户门户网站上搜索知识库文章并提交支持案例： 此工具没有图形界面；由于它会与红帽客户门户网站交互，因此需要接入互联网 redhat-support-tool命令可以在交互模式中使用，也可加入选项和参数作为一个命令来调用。两种方式中该工具的语法均相同。默认情况下，其程序在交互模式中启动。 使用help子命令来查看所有可用的命令 交互模式支持Tab补全，以及在父级shell中调用程序的功能 命令示例： [user@host ~]$ redhat-support-tool Welcome to the Red Hat Support Tool. Command (? for help): redhat-support-tool使用说明： 第一次调用时，redhat-support-tool会提示输入红帽客户门户网站订阅者登录信息。为避免重复提供此信息，工具会询问是否要将帐户信息存储在用户的主目录中(~/.redhat-support-tool/redhat-support-tool.conf) 如果问题都通过特定的红帽客户门户网站帐户提交，--global选项可以将帐户信息及其他系统范围的配置保存到/etc/redhat-support-tool.conf中。工具的config命令可修改工具配置设置 redhat-support-tool命令允许订阅者搜索和显示红帽客户门户网站中的知识库内容。 知识库允许关键字搜索，与man命令相似。您可以输入错误代码、日志文件中的语法，或者任何关键字组合，以此生成相关解决方案文档的列表 官方初始配置和基本搜索演示： [user@host ~]$ redhat-support-tool Welcome to the Red Hat Support Tool. Command (? for help): search How to manage system entitlements with subscription-manager Please enter your RHN user ID: subscriber Save the user ID in /home/student/.redhat-support-tool/redhat-support-tool.conf (y/n): y Please enter the password for subscriber: password Save the password for subscriber in /home/student/.redhat-support-tool/redhat-support-tool.conf (y/n): y 在提示用户输入必要的用户配置后，工具将继续执行原先的搜索请求： Type the number of the solution to view or 'e' to return to the previous menu. 1 [ 253273:VER] How to register and subscribe a system to the Red Hat Customer Portal using Red Hat Subscription-Manager 2 [ 265523:VER] Enabling or disabling a repository using Red Hat Subscription Management 3 [ 100423:VER] Why does subscription-manager list return: \"No Installed Products found\" ? ...output omitted... Select a Solution: 1   如上所述选择文章编号1，系统将提示选择要阅读的文档章节。最后，使用Q键退出所在的章节，或重复使用它来退出redhat-support-tool命令： Select a Solution: 1 Type the number of the section to view or 'e' to return to the previous menu. 1 Title 2 Issue 3 Environment 4 Resolution 5 Display all sections End of options. Section: 1 Title =============================================================================== How to register and subscribe a system to the Red Hat Customer Portal using Red Hat Subscription-Manager URL: https://access.redhat.com/solutions/253273 Created On: None Modified On: 2017-11-29T15:33:51Z (END) q Section: Section: q Select a Solution: q Command (? for help): q [user@hosts ~]# 根据文档ID访问知识库文章   使用工具的kb命令及知识库文档ID，直接查找在线文章。返回的文档在屏幕上滚动而不进行分页，但可以将其重定向到文件以进行保存，并使用less一次滚动一个屏幕。官方示例： [user@host ~]$ redhat-support-tool kb 253273 Title =============================================================================== How to register and subscribe a system to the Red Hat Customer Portal using Red Hat Subscription-Manager URL: https://access.redhat.com/solutions/253273 Created On: None Modified On: 2017-11-29T15:33:51Z Issue =============================================================================== * How to register a new `Red Hat Enterprise Linux` system to the Customer Portal using `Red Hat Subscription-Manager` ...output omitted... 用红帽支持工具管理支持案例   产品订阅的一个优点是能够通过红帽客户门户网站访问技术支持。根据系统的订阅支持级别，可以通过在线工具或电话联系红帽。更多信息参见 https://access.redhat.com/site/support/policy/support_process。 准备错误报告 在联系红帽支持部门之前，务必要为错误报告收集相关的信息： 定义问题。能够清晰地陈述问题及其症状，尽可能具体，详述可重现该问题的步骤 收集背景信息： 受影响的产品和版本是什么？准备好提供相关的诊断信息。这可能包含sosreport的输出 对于内核问题，这可能包含系统的kdump崩溃转储或者崩溃系统的监控器上显示的内核回溯的数字照片 确定严重级别。红帽使用四个严重级别为问题分类。报告紧急和高严重级别问题后，应致电相关的当地支持中心。参见https://access.redhat.com/site/support/contact/technicalSupport 严重级别定义： 严重性 描述 紧急(严重级别1) 严重影响生产环境中使用该软件的问题。这包括生产数据丢失或生产系统故障。这种情况使业务运作暂停，也不存在其他可绕过问题的解决方法 高(严重级别2) 软件可以正常运行，但生产环境中的使用被严重削弱的问题。这种情况对业务运作有高度影响，也不存在其他可绕过问题的解决方法 中(严重级别3) 涉及生产环境或开发环境中软件部分的使用、非关键损失的问题。对于生产环境，业务会受到中低影响。业务可通过其他可绕过问题的解决方法继续正常运作。在开发环境中，这种情况将导致项目迁移至生产时出现问题 低(严重级别4) 一般使用问题，报告文档错误或未来产品增强或修改建议。在生产环境中，对业务或系统的性能或功能影响较低或没有影响。在开发环境中，对业务有中低级影响，但是业务可通过其他可绕过问题的解决方法继续正常运作 通过redhat-support-tool管理错误报告 可以通过redhat-support-tool创建、查看、修改和关闭红帽支持案例： 当支持案例处于 opened或maintained状态时，用户可以附上文件或文档，如诊断报告(sosreport)。工具将上传并附加文件到案例中 可以通过命令选项来指定产品名称、版本、摘要、描述、严重级别和案例组等案例详细信息，也可让工具提示输入必要的信息 示例打开一个新案例，已指定了--product和--version选项： [user@host ~]$ redhat-support-tool Welcome to the Red Hat Support Tool. Command (? for help): opencase --product=\"Red Hat Enterprise Linux\" --version=\"7.0\" Please enter a summary (or 'q' to exit): System fails to run without power Please enter a description (Ctrl-D on an empty line when complete): When the server is unplugged, the operating system fails to continue. 1 Urgent 2 High 3 Normal 4 Low Please select a severity (or 'q' to exit): 4 Would you like to assign a case group to this case (y/N)? N Would see if there is a solution to this problem before opening a support case? (y/N) N ------------------------------------------------------------------------------- Support case 01034421 has successfully been opened. 如果未指定--product和--version选项，将提供这些选项的选项列表： [user@host ~]$ redhat-support-tool Welcome to the Red Hat Support Tool. Command (? for help): opencase Do you want to use the default product - \"Red Hat Enterprise Linux\" (y/N)?: y ...output omitted... 29 7.4 30 7.5 31 7.6 32 8.0 Beta Please select a version (or 'q' to exit): 32 Please enter a summary (or 'q' to exit): yum fails to install apache Please enter a description (Ctrl-D on an empty line when complete): yum cannot find correct repo 1 Urgent 2 High 3 Normal 4 Low Please select a severity (or 'q' to exit): 4 Would you like to use the default (Ungrouped Case) Case Group (y/N)? : y Would you like to see if there's a solution to this problem before opening a support case? (y/N) N ------------------------------------------------------------------------------- Support case 010355678 has successfully been opened. 将诊断信息附加到支持案例 包含诊断信息可以更快地解决问题，建议打开案例时附上sosreport： sosreport命令生成压缩的tar存档，内含从运行中的系统收集的诊断信息 如果之前创建过存档，则redhat-support-tool将提示包含该存档 示例如下： Please attach a SoS report to support case 01034421. Create a SoS report as the root user and execute the following command to attach the SoS report directly to the case: redhat-support-tool addattachment -c 01034421 path to sosreport Would you like to attach a file to 01034421 at this time? (y/N) N Command (? for help):   如果不存在当前的SoS报告，管理员可以稍后生成并附加一份报告。使用redhat-support-tool addattachment命令来附加报告。订阅者可以查看、修改和关闭支持案例： Command (? for help): listcases Type the number of the case to view or 'e' to return to the previous menu. 1 [Waiting on Red Hat] System fails to run without power No more cases to display Select a Case: 1 Type the number of the section to view or 'e' to return to the previous menu. 1 Case Details 2 Modify Case 3 Description 4 Recommendations 5 Get Attachment 6 Add Attachment 7 Add Comment End of options. Option: q Select a Case: q Command (? for help):q [user@host ~]$ redhat-support-tool modifycase --status=Closed 01034421 Successfully updated case 01034421 [user@host ~]$ 红帽支持工具更多说明： 红帽支持工具具有高级应用诊断和分析功能： 利用内核崩溃转储核心文件，redhat-support-tool可以创建和提取回溯追踪。回溯追踪是崩溃转储点处活动堆栈帧的报告，也能提供现场诊断 redhat-support-tool的选项之一是打开支持案例 该工具也提供日志文件分析功能： 通过工具的analyze命令，可以解析许多类型的日志文件（如操作系统、JBoss、Python、Tomcat 和 oVirt）来识别问题症状 日志文件可以单独进行查看和诊断 与崩溃转储或日志文件等原始数据相比，提供预处理过的分析可以更加快速地创建支持案例并提交给工程师 加入红帽开发者计划 红帽提供的另一个有用资源是红帽开发者计划： 此计划托管于https://developer.redhat.com，提供开发专用红帽软件订阅权利、相关文档，以及我们微服务、无服务器计算、Kubernetes和Linux领域的专家推出的优质图书 另外，也提供博客、即将举办的活动与培训的信息链接和其他帮助资源，以及红帽客户门户网站的链接 注册免费，注册地址：https://developer.redhat.com/register 通过红帽智能分析工具检测和解决问题 红帽智能分析工具简介   红帽智能分析工具是一种预测分析工具，可帮助用户识别和修复基础架构中运行红帽产品的系统上面临的安全性、性能、可用性和稳定性威胁： 智能分析工具作为软件即服务(SaaS)产品提供，因此可以快速部署和扩展它，没有额外的基础架构要求 可以立即利用特定于已部署系统的红帽最新建议和更新 红帽会定期更新智能分析工具使用的知识库，这些知识库基于常见的支持风险、安全漏洞、已知错误的配置，以及红帽识别的其他问题 缓解或修复这些问题的措施会得到红帽的检验和验证 有了这种支持，用户可以在问题成为更大问题之前主动识别问题，确定其优先级并加以解决 对于检测到的每个问题，智能分析工具提供所呈现风险的估测以及有关如何缓解或修复问题的建议： 这些建议可提供诸如Ansible Playbook或易于阅读的分步骤说明等资料来帮助用户解决问题 智能分析工具会针对注册到服务的每个系统定制推荐内容： 安装各个客户端系统时会一同安装一个代理，它将收集有关系统运行时配置的元数据 使用sosreport命令向红帽支持部门提供数据时应包含这一数据，以便能解决支持票据 可以限制或模糊处理客户端发送的数据。这会使某些分析规则无法运作，具体取决于用户的限制 在用户注册服务器并且服务器完成初始系统元数据同步之后不久，就能够在红帽云门户网站上的智能分析工具控制台中看到用户的服务器和对应的建议。 智能分析工具目前为下列红帽产品提供预测分析和建议： 红帽企业Linux 6.4及更高版本 红帽企业虚拟化4及更高版本 红帽OpenShift容器平台 红帽OpenStack平台7及更高版本 使用智能分析工具注册系统时，它会立即将有关其当前配置的元数据发送到智能分析工具平台 注册后，系统会定期更新提供给智能分析工具的元数据。系统会使用TLS加密发送元数据，以便在传输中保护元数据 智能分析工具收到数据后，会对其进行分析，并在位于https://cloud.redhat.com/insights的智能分析工具Web控制台上显示结果 安装智能分析工具客户端   智能分析工具已作为订阅的一部分随附于RHEL8中。旧版的RHEL服务器需要在系统上安装 insights-client软件包。如果系统通过客户门户网站订阅管理服务注册了软件权利，则可以使用一个命令来激活智能分析工具。使用insights-client --register命令来注册系统： [root@host ~]# insights-client --register   智能分析工具客户端定期更新提供给智能分析工具的元数据。用户随时可以使用 insights-client命令刷新客户端的元数据： [root@host ~]# insights-client Starting to collect Insights data for host.example.com Uploading Insights data. Successfully uploaded report for host.example.com. View details about this system on cloud.redhat.com: https://cloud.redhat.com/insights/inventory/dc480efd-4782-417e-a496-cb33e23642f0 将RHEL系统注册到智能分析工具 使用红帽订阅管理服务，以交互方式注册系统： [root@host ~]# subscription-manager register --auto-attach   确保系统上已安装insights-client软件包(在RHEL8系统上不需要此步骤)。在RHEL 7中，此软件包位于rhel-7-server-rpms中： [root@host ~]# yum install insights-client   使用insights-client --register命令，将系统注册到智能分析工具服务并上传初始系统元数据: [root@host ~]# insights-client --register   确认系统在位于https://cloud.redhat.com/insights的智能分析工具Web控制台中的Inventory下可见。 智能分析工具控制台导航   智能分析工具提供一系列服务供您通过位于https://cloud.redhat.com/insights的Web控制台访问。 使用顾问服务检测配置问题 可以使用顾问服务检测配置问题，顾问服务将会报告对用户系统有影响的配置问题。可以从Advisor→ Recommentations菜单访问该服务： 对于每个问题，智能分析工具都会提供附加信息，以帮助了解问题，确定解决问题的工作的优先级，确定可用的缓解或修复措施，并通过Ansible Playbook自动解决问题 智能分析工具还会提供客户门户上的知识库文章链接 顾问服务会分两类评估某个问题给用户系统带来的风险： 总体风险：表示问题对用户的系统的影响 变动风险：表示修复措施对用户的系统的影响。例如可能需要重启系统 使用漏洞服务进行安全性评估   漏洞服务会报告对用户的系统有影响的常见的漏洞和风险(CVE)。可以从Vulnerability→CVEs菜单访问该服务： 对于每个CVE，智能分析工具均会提供附加信息，并列出暴露在风险中的系统 可以单击Remediate来创建用于修复的Ansible Playbook 使用合规性服务分析合规性   合规性服务会分析用户的系统，并根据OpenSCAP策略报告系统的合规性水平。OpenSCAP项目会实施一些工具，以便根据一套规则检查系统的合规性。智能分析工具会提供一些规则来对照不同策略（如支付卡行业数据安全标准(PCI DSS)评估用户的系统。 使用补丁服务更新软件包   补丁服务会列出适用于用户的系统的红帽产品公告。该服务还会生成供用户运行的Ansible Playbook，用来更新与适用公告相关联的RPM软件包： 访问特定系统的公告列表，请使用Patch→Systems菜单 单击系统的Apply all applicable advisories，以生成Ansible Playbook 使用偏移服务对系统进行比较   利用偏移服务，可以比较系统或系统历史记录。此项服务可以将系统与类似系统或之前的系统状态进行比较，从而帮用户对该系统进行故障排除。可以从Drift→Comparison菜单访问该服务。 使用策略服务触发警报   利用策略服务，可以创建用于监控系统的规则，并在系统不符合规则时发送警报。每次系统同步其元数据时，智能分析工具都会对规则进行评估。可以从Policies菜单访问该服务。 访问清单和修复Playbook并监控订阅 Inventory页面中提供用户已注册到红帽智能分析工具的系统列表： Last seen列显示各个系统最近一次更新元数据的时间。单击系统名称即可查看其详细信息并直接访问相应系统的顾问服务、漏洞服务、合规性服务和补丁服务 Remediations页面会列出用户创建的用于修复的所有Ansible Playbook。用户可以从该页面下载playbook 使用Subscription Watch页面，可以监控用户的红帽订阅使用情况 练习 "},"05-IBM_Operating_System/06-RHEL学习笔记/11-RHEL-复习与练习.html":{"url":"05-IBM_Operating_System/06-RHEL学习笔记/11-RHEL-复习与练习.html","title":"RHEL-复习与练习","keywords":"","body":"RHEL-复习与练习 "},"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/":{"url":"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/","title":"RHEL-Ansible学习笔记","keywords":"","body":"RHEL-Ansible学习笔记 简介   红帽企业Linux(RHEL)是红帽提供的、受商业支持的企业就绪型Linux发行版。它是开源计算的领先平台，而不仅仅是成熟开源项目的集合。RHEL经过广泛测试，拥有庞大的合作伙伴生态系统、硬件和软件认证、咨询服务、培训以及为期多年的支持和维护保障。   Ansible是一款开源自动化平台。它是一种简单的自动化语言，能够在Ansible Playbook中完美地描述 IT 应用基础架构 官方网站：Red Hat Enterprise Linux 下载评估版本来试用红帽企业Linux：Red Hat Enterprise Linux Server RHEL开发主页：Red Hat Developer RHEL官方下载链接：Download Red Hat Enterprise Linux Ansible模块文档：Ansible Module Ansible官方文档主页：Ansible Documentation Ansible的问题跟踪器及其集成模块，链接为：https://github.com/ansible/ansible/issues 本章节是在官网学习RHEL记录的笔记。 内容 "},"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/01-Ansible-安装Ansible.html":{"url":"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/01-Ansible-安装Ansible.html","title":"Ansible-安装Ansible","keywords":"","body":"Ansible-安装Ansible 官方参考链接： How to download and install Red Hat Ansible Engine Red Hat Ansible Automation Platform安装指南 下载与安装 控制节点 RHEL9下载安装 下载最新的RHEL9.0版本，官方下载链接：Download Red Hat Enterprise Linux 下载完成后配置本地YUM源： [root@localhost ~]# yum repolist Updating Subscription Management repositories. repo id repo name redhat9_app redhat9_app redhat9_os redhat9_os 安装Python   如果是RHEL8，Ansible可以自动使用platform-python软件包，该软件包支持使用Python的系统实用程序。此次使用的是RHEL9，默认是没有了，光盘里面也没有。但是有Python39，暂时不安装。 注册系统 将系统注册到红帽订阅管理工具： [root@localhost ~]# subscription-manager register Registering to: subscription.rhsm.redhat.com:443/subscription Username: Password: The system has been registered with ID: The registered system name is: localhost 订阅仓库管理 查看系统通过订阅获取的仓库： [root@redhat9 ~]# subscription-manager repos --list This system has no repositories available through subscriptions. 查看subscription-manager版本： [root@redhat9 ~]# subscription-manager version server type: Red Hat Subscription Management subscription management server: 4.0.18-3 subscription management rules: 5.41 subscription-manager: 1.29.26-3.el9_0 查看是否有Ansible相关订阅： [root@redhat9 ~]# subscription-manager list --available |grep -i ansible Red Hat Ansible Engine Red Hat Ansible Automation Platform 记住Pool ID将订阅添加到系统： [root@redhat9 ~]# subscription-manager attach --pool=2c9xxxxf82fexxxxx183044cccxxxxxx Successfully attached a subscription for: Red Hat Developer Subscription for Individuals 查看当前仓库： [root@redhat9 ~]# yum repolist Updating Subscription Management repositories. repo id repo name redhat9_app redhat9_app redhat9_os redhat9_os rhel-9-for-x86_64-appstream-rpms Red Hat Enterprise Linux 9 for x86_64 - AppStream (RPMs) rhel-9-for-x86_64-baseos-rpms Red Hat Enterprise Linux 9 for x86_64 - BaseOS (RPMs) 启用Ansible引擎库 启动Ansible相关仓库： [root@redhat9 ~]# subscription-manager repos --enable \\ > ansible-automation-platform-2.2-for-rhel-9-x86_64-rpms Repository 'ansible-automation-platform-2.2-for-rhel-9-x86_64-rpms' is enabled for this system. 然后安装Ansible即可： [root@redhat9 ~]# yum install ansible 安装的RHEL9系统版本里面已经有Ansible了： [root@redhat9 ~]# sudo ansible --version ansible [core 2.12.2] config file = /etc/ansible/ansible.cfg configured module search path = ['/root/.ansible/plugins/modules', '/usr/share /ansible/plugins/modules'] ansible python module location = /usr/lib/python3.9/site-packages/ansible ansible collection location = /root/.ansible/collections:/usr/share/ansible/co llections executable location = /bin/ansible python version = 3.9.10 (main, Feb 9 2022, 00:00:00) [GCC 11.2.1 20220127 (Re d Hat 11.2.1-9)] jinja version = 2.11.3 libyaml = True 调用本地主机上的setup模块，检索ansible_python_version的值： [root@redhat9 ~]# ansible -m setup localhost | grep ansible_python_version \"ansible_python_version\": \"3.9.10\", 受控节点   受管主机不需要安装特殊的代理。Ansible控制节点使用标准的网络协议连接受管主机，从而确保系统处于指定的状态。受管主机可能要满足一些要求： Linux和UNIX受管主机需要安装有Python2（版本2.6或以上）或Python3（版本3.5或以上），这样才能运行大部分的模块 对于RHEL8，可以依靠platform-python软件包。也可以启用并安装python36应用流（或 python27应用流） 我采用RHEL8的受控节点，platform-python信息如下： [root@redhat8 ~]# yum list installed platform-python Updating Subscription Management repositories. Installed Packages platform-python.x86_64 3.6.8-1.el8 @anaconda 添加互信 添加用户 控制节点和受控节点上都添加ansible用户： [root@redhat8 ~]# useradd ansible [root@redhat8 ~]# cat /etc/passwd |grep ansible ansible:x:1011:1011::/home/ansible:/bin/bash 可以设置密码： [root@redhat8 ~]# passwd ansible Changing password for user ansible. New password: Retype new password: passwd: all authentication tokens updated successfully. 用户设置为可以ssh访问。 添加host表 在控制节点和受控节点上都添加对方信息，示例： [ansible@redhat9 ~]$ cat /etc/hosts 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 ::1 localhost localhost.localdomain localhost6 localhost6.localdomain6 192.168.100.133 redhat9 192.168.100.130 redhat8 添加互信   如果是单一现有受管主机，可以在受管主机上安装公钥，并使用ssh-copy-id命令在本地的~/.ssh/known_hosts文件中填充其主机密钥，如下所示： [ansible@redhat8 ~]$ ssh-keygen -t rsa Generating public/private rsa key pair. Enter file in which to save the key (/home/ansible/.ssh/id_rsa): Created directory '/home/ansible/.ssh'. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/ansible/.ssh/id_rsa. Your public key has been saved in /home/ansible/.ssh/id_rsa.pub. The key fingerprint is: ...output omitted... 将密钥拷贝到对端系统： [ansible@redhat8 ~]$ ssh-copy-id ansible@redhat9 /usr/bin/ssh-copy-id: INFO: Source of key(s) to be installed: \"/home/ansible/.ssh/id_rsa.pub\" The authenticity of host 'redhat9 (192.168.100.133)' can't be established. ECDSA key fingerprint is SHA256:DCK9bY2lCTvdQooqufMRIHemI2vxLNT2knhj1fKIyY0. Are you sure you want to continue connecting (yes/no)? yes /usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed /usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys ansible@redhat9's password: Number of key(s) added: 1 Now try logging into the machine, with: \"ssh 'ansible@redhat9'\" and check to make sure that only the key(s) you wanted were added. 验证是否可以： [ansible@redhat8 ~]$ ssh ansible@redhat9 Register this system with Red Hat Insights: insights-client --register Create an account or view all your systems at https://red.ht/insights-dashboard Last login: Mon Sep 5 15:16:08 2022 from 192.168.100.1 [ansible@redhat9 ~]$ 在另外一个节点也执行一遍，就可以互相免密访问了。查看known_hosts示例： [ansible@redhat9 ~]$ cat .ssh/known_hosts redhat8 ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AbsjHS25kvfAWcZ3KmZVXQ/WXCT4V5m 192.168.100.131 ssh-ed25519 AAAAC3NzaC1lZDI1NTE5PIXbsjHS25kvfAWcZ3KmZjVXQ/WXCT4 待补充 "},"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/02-Ansible-实施Playbook.html":{"url":"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/02-Ansible-实施Playbook.html","title":"Ansible-实施Playbook","keywords":"","body":"实施Ansible Playbook 定义清单   清单定义Ansible将要管理的一批主机，这些主机也可以分配到组中，组可以包含子组，主机也可以是多个组的成员。清单还可以设置应用到它所定义的主机和组的变量。可以通过两种方式定义主机清单： 静态主机清单可以通过文本文件来定义 动态主机清单可以根据需要使用外部信息提供程序通过脚本或其他程序来生成 静态清单 静态清单指定受管主机   可以使用多种不同的格式编写静态清单，包括INI样式或YAML。INI样式最简单的静态清单文件是受管主机的主机名或IP地址的列表，每行一个： 192.168.100.131 web.big1000.com db2.big1000.com 示例主机清单定义了多个主机组，并且主机可以在多个组中： [webservers] web.big1000.com ebook.big1000.com [db-servers] db2.big1000.com oracle.big1000.com 192.168.100.130 [prod-servers] ebook.big1000.com db2.big1000.com [development] 192.168.100.131 说明： ansible all --list-hosts中all主机组含有清单中明确列出的每一个主机 ansible ungrouped --list-hosts中ungrouped主机组含有清单中明确列出、但不属于任何其他组的每一个主机 定义嵌套组   Ansible主机清单可以包含由多个主机组构成的组。这通过创建后缀为:children的主机组名称来实现。示例创建名为prod-servers的新组，它包含来自webservers和db-servers组的所有主机： [webservers] web.big1000.com ebook.big1000.com [db-servers] db2.big1000.com oracle.big1000.com 192.168.100.130 [prod-servers:children] webservers db-servers   一个组可以同时包含受管主机和子组作为其成员。例如，在上面的清单中，可以添加一个拥有自己的受管主机列表的[prod-servers]部分。这一列表中的主机将与north-america组从其子组中继承的其他主机合并。 简化主机规格   如果主机过多，并且有明显规律可循，可以通过指定主机名称或IP地址的范围来简化Ansible主机清单。可以指定数字或字母范围。语法如下所示： [START:END] 范围匹配从START到END(包含)的所有值。示例： 192.168.[4:7].[0:255]匹配192.168.4.0/22网络中的所有IPv4地址(192.168.4.0到192.168.7.255) web[01:10].big1000.com匹配名为web01.big1000.com到web10.big1000.com的所有主机(如果数字范围中包含前置零，其模式中会使用它们，所以不会匹配web1) [a:c].big1000.com匹配名为a.big100.com、b.big100.com和c.big100.com的主机 2001:db8::[a:f]匹配从2001:db8::a到2001:db8::f的所有IPv6地址 验证清单 验证主机redhat8是否在清单中： [root@redhat9 ~]# ansible redhat8 --list-hosts hosts (1): redhat8 列出组testhosts中的所有主机： [root@redhat9 ~]# ansible testhosts --list-hosts hosts (2): redhat8 192.168.100.130   如果清单中含有名称相同的主机和主机组，ansible命令将显示警告并以主机作为其目标。主机组则被忽略。应确保主机组不使用与清单中主机相同的名称。 覆盖清单的位置   /etc/ansible/hosts文件是系统的默认静态清单文件。通常不使用该文件，而是在Ansible配置文件中为清单文件定义一个不同的位置。 在清单中定义变量   可以在主机清单文件中指定playbook使用的变量值。这些变量仅应用到特定的主机或主机组。通常，最好在特殊目录中定义这些库存变量，而不要直接在清单文件中定义。 动态清单   可以使用外部数据库提供的信息动态生成Ansible清单信息。开源社区编写了许多可从上游 Ansible项目获取的动态清单脚本。 管理Ansible配置文件 配置Ansible Ansible从控制节点上多个可能的位置之一选择其配置文件： /etc/ansible/ansible.cfg：ansible软件包的此位置会有一个基础配置文件。如果找不到其他配置文件，则使用此文件 ~/.ansible.cfg：Ansible在用户的主目录中查找.ansible.cfg文件。如果存在此配置并且当前工作目录中也没有ansible.cfg文件，则使用此配置取代/etc/ansible/ansible.cfg ./ansible.cfg：如果执行ansible命令的目录中存在ansible.cfg文件，则使用它，而不使用全局文件或用户的个人文件   推荐的做法是在要运行Ansible命令的目录中创建ansible.cfg文件。此目录中也将包含任何供用户的Ansible项目使用的文件，如清单和playbook。这是用于Ansible 配置文件的最常用位置。在实践中，很少会使用~/.ansible.cfg或/etc/ansible/ansible.cfg文件。  可以通过将不同的配置文件放在不同的目录中，然后从适当目录执行Ansible命令，以此利用配置文件；随着配置文件数量的增加，这种方法难以管理。可以通过ANSIBLE_CONFIG环境变量定义配置文件的位置，Ansible将使用变量所指定的配置文件，而不用上面提及的任何配置文件。 配置文件优先级   配置文件的搜索顺序与上述列表相反。位于搜索顺序中的第一个文件是Ansible选择的文件。Ansible仅使用它找到的第一个文件中的配置设置。 ANSIBLE_CONFIG环境变量指定的任何文件都会覆盖所有其他配置文件 如果没有设置该变量，则接下来检查运行ansible命令的目录中是否有ansible.cfg文件 如果不存在上述文件，则检查用户的主目录中是否有.ansible.cfg文件 只有在找不到其他配置文件时，才使用全局/etc/ansible/ansible.cfg文件 如果/etc/ansible/ansible.cfg配置文件不存在，Ansible包含它使用的默认值   可以运行ansible --version命令来清楚地确认所安装的Ansible版本，以及正在使用的配置文件。命令示例如下： [root@redhat9 ~]# ansible --version ansible [core 2.12.2] config file = /etc/ansible/ansible.cfg ...output omitted... 执行Ansible命令时使用-v选项是显示活动的Ansible配置文件的另一种方式： [root@redhat9 ~]# ansible servers --list-hosts -v Using /etc/ansible/ansible.cfg as config file ...output omitted... 管理配置文件中的设置   Ansible配置文件由几个部分组成，每一部分含有以键值对形式定义的设置。部分的标题以方括号括起。对于基本操作，使用以下两部分： [defaults]部分设置Ansible操作的默认值 [privilege_escalation]配置Ansible如何在受管主机上执行特权升级 例如，下面是典型的ansible.cfg文件： [defaults] inventory = ./inventory remote_user = user ask_pass = false [privilege_escalation] become = true become_method = sudo become_user = root become_ask_pass = false 此文件中的指令如下表： 指令 描述 inventory 指定清单文件的路径 remote_user 要在受管主机上登录的用户的名称。如果未指定，则使用当前用户的名称 ask_pass 是否提示输入SSH密码。如果使用SSH公钥身份验证，则可以是false become 连接后是否自动在受管主机上切换用户(通常切换为root)。也可以通过play来指定 become_method 如何切换用户(通常为sudo，sudo默认设置，也可选择su) become_user 要在受管主机上切换到的用户(通常是root，root是默认值) become_ask_pass 是否需要为become_method提示输入密码。默认为false 配置连接   Ansible需要知道如何与其受管主机通信。更改配置文件的一个最常见原因是为了控制Ansible使用什么方法和用户来管理受管主机。需要的一些信息包括： 列出受管主机和主机组的清单的位置 要使用哪一种连接协议来与受管主机通信(默认为SSH)，以及是否需要非标准网络端口来连接服务器 要在受管主机上使用哪一远程用户；可以是root用户或者某一非特权用户 如果远程用户为非特权用户，Ansible需要知道它是否应尝试将特权升级为root以及如何进行升级(如使用sudo) 是否提示输入SSH密码或sudo密码以进行登录或获取特权 清单位置   在[defaults]部分中，inventory指令可以直接指向某一静态清单文件，或者指向含有多个静态清单文件和动态清单脚本的某一目录。 连接设置 连接设置： 默认情况下，Ansible使用SSH协议连接受管主机。控制Ansible如何连接受管主机的最重要参数在[defaults]部分中设置。 默认情况下，Ansible尝试连接受管主机时使用的用户名与运行Ansible命令的本地用户相同。若要指定不同的远程用户，将remote_user参数设置为该用户名 如果为运行Ansible的本地用户配置了SSH私钥，使得它们能够在受管主机上进行远程用户的身份验证，则 Ansible将自动登录。如果不是这种情况，可以通过设置指令ask_pass = true，将Ansible配置为提示本地用户输入由远程用户使用的密码 如果在使用一个Linux控制节点，并对受管主机使用OpenSSH，如果可以使用密码以远程用户身份登录，那么或许可以设置基于SSH密钥的身份验证，从而能够设置ask_pass = false 第一步是确保在~/.ssh中为控制节点上的用户配置了SSH密钥对。可以运行ssh-keygen命令来实现这个目标 升级特权   鉴于安全性和审计原因，Ansible可能需要先以非特权用户身份连接远程主机，然后再通过特权升级获得root用户身份的管理权限。这可以在Ansible配置文件的[privilege_escalation]部分中设置。 要默认启用特权升级，可在配置文件中设置指令become = true。即使默认为该设置，也可以在运行临时命令或Ansible Playbook时通过各种方式覆盖它 become_method指令指定如何升级特权。有多个选项可用，默认为sudo become_user指令指定要升级到的用户，默认为root 如果所选的become_method机制要求用户输入密码才能升级特权，可以在配置文件中设置become_ask_pass = true指令   在RHEL7上，/etc/sudoers的默认配置允许wheel组中的所有用户在输入密码后使用sudo成为root用户。若要让用户（示例中为ansible）在不输入密码前提下使用sudo成为root，一种办法是将含有适当指令的文件安装到/etc/sudoers.d目录（归root 所有，八进制权限为0400）： ## password-less sudo for Ansible user ansible ALL=(ALL) NOPASSWD:ALL   示例ansible.cfg文件假定用户可以通过基于SSH密钥的身份验证以ansible用户身份连接受管主机，并且ansible可以使用sudo以root用户身份运行命令而不必输入密码： [defaults] inventory = ./inventory remote_user = ansible ask_pass = false [privilege_escalation] become = true become_method = sudo become_user = root become_ask_pass = false 非SSH连接   默认情况下，Ansible用于连接受管主机的协议设置为smart，它会确定使用SSH的最高效方式。可以通过多种方式将其设置为其他的值。  例如，默认使用SSH的规则有一个例外。如果用户目录中没有localhost，Ansible将设置一个隐式localhost条目以允许运行以localhost为目标的临时命令和playbook。这一特殊清单条目不包括在all或ungrouped主机组中。此外，Ansible不使用smart SSH连接类型，而是利用默认的特殊local连接类型来进行连接。 [root@redhat9 ~]# ansible localhost --list-hosts hosts (1): localhost   local连接类型忽略remote_user设置，并且直接在本地系统上运行命令。如果使用了特权升级，它会在运行 sudo时使用运行Ansible命令的用户帐户，而不是remote_user。如果这两个用户具有不同的sudo特权，这可能会导致混淆。 如果要确保像其他受管主机一样使用SSH连接localhost，一种方法是在清单中列出它。但是，这会将它包含在 all和ungrouped组中，可能不希望如此。 另一种办法是更改用于连接localhost的协议。执行此操作的最好方法是为localhost设置 ansible_connection主机变量。为此，要在运行Ansible命令的目录中创建host_vars子目录。在该子目录中，创建名为localhost的文件，其应含有ansible_connection: smart这一行。这将确保对localhost使用smart (SSH)连接协议，而非local。 也可以通过另一种变通办法来使用它。如果清单中列有127.0.0.1，则默认情况下，将使用smart来连接它。也可以创建一个含有ansible_connection: local这一行的host_vars/127.0.0.1文件，它会改为使用local。配置文件注释 Ansible配置文件允许使用两种注释字符：井号或编号符号(#)以及分号(;)。 位于行开头的编号符号会注释掉整行。它不能和指令位于同一行中 分号字符可以注释掉所在行中其右侧的所有内容。它可以和指令位于同一行中，只要该指令在其左侧 示例练习 创建目录： [root@redhat9 ~]# mkdir ~/deploy-manage [root@redhat9 ~]# cd ~/deploy-manage [root@redhat9 deploy-manage]# 编辑ansible.cfg文件，内容如下： [defaults] inventory = ./inventory [privilege_escalation] become = true become_method = sudo become_user = root become_ask_pass = true 编辑inventory文件，内容如下： [myself] localhost [redhata] redhat8a [redhatb] redhat8b [redhat:children] redhata redhatb 运行ansible --list-hosts命令，以验证是否提示输入sudo密码： [root@redhat9 deploy-manage]# ansible redhatb --list-hosts BECOME password: hosts (1): redhat8b 运行临时命令 使用Ansible运行临时命令 运行临时命令 使用ansible命令来运行临时命令： ansible host-pattern -m module [-a 'module arguments'] [-i inventory] 参数说明： host-pattern参数用于指定应在其上运行临时命令的受管主机： 可以是清单中的特定受管主机或主机组 可以与--list-hosts选项结合使用，此选项显示通过特定主机模式匹配的主机 可以使用-i选项来指定要使用的其他清单位置，取代默认位置 -m选项将Ansible应在目标主机上运行的module的名称作为参数： 模块是为了实施任务而执行的小程序 一些模块不需要额外的信息，但其他模块需要使用额外参数来指定其操作详情 -a选项以带引号字符串形式取这些参数的列表   一种最简单的临时命令是使用ping模块。此模块不执行ICMP ping，而是检查能否在受管主机上运行基于Python的模块。示例临时命令确定清单中的所有受管主机能否运行标准的模块： [ansible@redhat9 ~]$ ansible all -m ping 192.168.100.131 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/libexec/platform-python\" }, \"changed\": false, \"ping\": \"pong\" } redhat8 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/libexec/platform-python\" }, \"changed\": false, \"ping\": \"pong\" } 通过模块来执行任务   模块是临时命令用于完成任务的工具。Ansible提供了数百个能够完成不同任务的模块。命令ansible-doc -l可列出系统上安装的所有模块。可以使用ansible-doc来按照名称查看特定模块的文档，再查找关于模块将取什么参数作为选项的信息。示例显示ping模块的文档： [ansible@redhat9 ~]$ ansible-doc ping > ANSIBLE.BUILTIN.PING (/usr/lib/python3.9/site-packages/ansible/modules/pin> ...output omitted... ADDED IN: historical OPTIONS (= is mandatory): - data Data to return for the `ping' return value. If this parameter is set to `crash', the module will cause an exception. [Default: pong] type: str ...output omitted... Ansible模块各种类型： 文件模块： copy：将本地文件复制到受管主机 file：设置文件的权限和其他属性 lineinfile：确保特定行是否在文件中 synchronize：使用rsync同步内容 软件包模块： package：使用操作系统本机的自动检测软件包管理器管理软件包 yum：使用YUM软件包管理器管理软件包 apt：使用APT软件包管理器管理软件包 dnf：使用DNF软件包管理器管理软件包 gem：管理Ruby gem pip：从PyPI管理Python软件包 系统模块： firewalld：使用firewalld管理任意端口和服务 reboot：重新启动计算机 service：管理服务 user：添加、删除和管理用户帐户 Net Tools模块 get_url：通过HTTP、HTTPS或FTP下载文件 nmcli：管理网络 uri：与Web服务交互 大部分模块会取用参数。可在模块的文档中找到可用于该模块的参数列表： 临时命令可以通过-a选项向模块传递参数 无需参数时，可以从临时命令中省略-a选项 如果需要指定多个参数，以引号括起的空格分隔列表形式提供 示例临时命令使用user模块来确保huang用户存在于redhat8上并且其UID为1000： [ansible@redhat9 ~]$ ansible -m user -a 'name=huang uid=1000 state=present' redhat8 redhat8 | SUCCESS => { \"ansible_facts\": { \"discovered_interpreter_python\": \"/usr/libexec/platform-python\" }, \"append\": false, \"changed\": false, \"comment\": \"huang\", \"group\": 1000, \"home\": \"/home/huang\", \"move_home\": false, \"name\": \"huang\", \"shell\": \"/bin/bash\", \"state\": \"present\", \"uid\": 1000 }   大多数模块为idempotent，这表示它们可以安全地多次运行；如果系统已处于正确的状态，它们不会进行任何操作。例如再次运行前面的临时命令，应该不会报告任何更改。 command模块   command模块允许管理员在受管主机的命令行中运行任意命令。运行的命令通过-a选项指定为该模块的参数。示例对由testhosts]主机模式引用的受管主机运行hostname命令： [ansible@redhat9 ~]$ ansible testhosts -m command -a /usr/bin/hostname 192.168.100.131 | CHANGED | rc=0 >> redhat8 redhat8 | CHANGED | rc=0 >> redhat8 示例临时命令为每个受管主机返回两行输出： 第一行是状态报告，显示对其运行该临时操作的受管主机名称及操作的结果 第二行是使用Ansible command模块远程执行的命令的输出 使用-o选项以单行格式显示Ansible临时命令的输出： [ansible@redhat9 ~]$ ansible testhosts -m command -a /usr/bin/hostname -o 192.168.100.131 | CHANGED | rc=0 | (stdout) redhat8 redhat8 | CHANGED | rc=0 | (stdout) redhat8 command模块注意事项： command模块对受管主机执行的远程命令不是由受管主机上的shell处理。因此无法访问shell环境变量，也不能执行重定向和传送等shell操作 如果临时命令没有指定哪个模块与-m选项一起使用，Ansible将默认使用command模块 shell模块   在命令需要shell处理的情形中，可以使用shell模块。与command模块类似，可以在临时命令中将要执行的命令作为参数传递给该模块： 与command模块不同的是，这些命令将通过受管主机上的shell进行处理。因此，可以访问shell环境变量，也可使用重定向和传送等shell操作   示例command模块和shell模块的区别。尝试使用这两个模块执行内建的Bash命令set，只有使用shell模块时才会成功： [ansible@redhat9 ~]$ ansible redhat8 -m command -a set redhat8 | FAILED | rc=2 >> [Errno 2] No such file or directory: b'set': b'set' [ansible@redhat9 ~]$ ansible redhat8 -m shell -a set redhat8 | CHANGED | rc=0 >> BASH=/bin/sh ...output omitted... raw模块   command和shell模块都要求受管主机上安装正常工作的Python。第三个模块是raw，可以绕过模块子系统，直接使用远程shell运行命令： 在管理无法安装Python的系统(如网络路由器)时，可以利用raw模块 也可用于将Python安装到主机上 三个模块注意事项 在大多数情形中，建议避免使用command、shell和raw这三个运行命令模块： 其他模块大部分都是幂等的，可以自动进行更改跟踪： 可以用于测试系统的状态，在这些系统已处于正确的状态时不执行任何操作 相反，以幂等方式使用运行命令模块要复杂得多。依靠它们，更难以确信再次运行临时命令或playbook 不会造成意外的失败 当shell或command模块运行时，通常会基于它是否认为影响了计算机状态而报告CHANGED状态 有时候运行命令模块也是解决问题的好办法。如需使用，建议最好先尝试使用 command模块，只有在需要shell或raw模块的特殊功能时才利用它们 配置临时命令的连接   受管主机连接和特权升级的指令可以在Ansible配置文件中配置，也可使用临时命令中的选项来定义。使用临时命令中的选项定义时，它们将优先于Ansible配置文件中配置的指令。下表显示了与各项配置文件指令类同的命令行选项。 配置文件指令 命令行选项 inventory -i remote_user -u become --become, -b become_method --become-method become_user --become-user become_ask_pass --ask-become-pass, -K 可以通过查询ansible --help的输出来确定其当前定义的值： [ansible@redhat9 ~]$ ansible --help ...output omitted... -c CONNECTION, --connection CONNECTION connection type to use (default=smart) -u REMOTE_USER, --user REMOTE_USER connect as this user (default=None) Ansible模块文档：Ansible Module 编写和运行Playbook Ansible Playbook说明   任务是指应用模块来执行特定工作单元。 play是一系列任务，按顺序应用于从清单中选择的一台或多台主机。playbook是一个文本文件，其中包含由一个或多个按特定顺序运行的play组成的列表。 Play可以让用户将一系列冗长而复杂的手动管理任务转变为可轻松重复的例程，并且具有可预测的成功成果 在playbook中，您可以将play内的任务序列保存为人类可读并可立即运行的形式 根据任务的编写方式，任务本身记录了部署应用或基础架构所需的步骤 格式化Ansible Playbook   临时命令ansible -m user -a 'name=huang uid=1000 state=present' redhat8可以重新编写为一个单任务play并保存在playbook中。生成的playbook如下： --- - name: Configure important user consistently hosts: redhat8 tasks: - name: huang exists with UID 1000 user: name: huang uid: 1000 state: present   Playbook是以YAML格式编写的文本文件，通常使用扩展名yml保存。Playbook使用空格字符(不允许使用制表符)缩进来表示其数据结构。YAML对用于缩进的空格数量没有严格的要求，但有两个基本的规则： 处于层次结构中同一级别的数据元素(例如同一列表中的项目)必须具有相同的缩进量 如果项目属于其他项目的子项，其缩进量必须大于父项   Playbook开头的一行由三个破折号---组成，这是文档开始标记。其末尾可能使用三个圆点...作为文档结束标记，通常会省略。在这两个标记之间，会以一个play列表的形式来定义playbook。YAML列表中的项目以一个破折号加空格开头。示例： - Thor - America Captain - Thanos   Play本身是一个键值对集合。同一play中的键应当使用相同的缩进量。下面示例显示了具有三个键的YAML代码片段。前两个键具有简单的值。第三个将含有三个项目的列表作为值。示例： Company: Marvel Alliance: The Avengers superhero: - Thor - America Captain - Iron Man 生成的playbook详细说明： 原始示例play有三个键：name、hosts和tasks，这些键都有相同的缩进 play的第一行开头是破折号加空格(表示该play是列表中的第一项)，而后是第一个键，即name属性： name键将一个任意字符串作为标签与该play关联。示例中标识了该play的用途：Configure important user consistently name键是可选的，但建议使用，有助于记录playbook。在playbook中包含多个play时特别有用 Play中的第二个键是hosts属性，指定对其运行play中的任务的主机。与用于ansible命令的参数相似，hosts属性将主机模式取为值，如清单中受管主机或组的名称 Play中的最后一个键是tasks属性，其值指定要为该play运行的任务的列表。本例中只有一项任务，该任务使用特定参数运行user模块(以确保用户huang存在并且具有UID1000) 作为play中的一部分，tasks属性按顺序实际列出要在受管主机上运行的任务。列表中各项任务本身是一个键值对集合。示例中，play中的唯一任务含有两个键： name是记录任务用途的可选标签。建议命名所有任务，从而帮助记录自动流程中每一步的用途 user是要为这个任务运行的模块。其参数作为一组键值对传递，它们是模块的子项(name、uid和 state)   playbook中play和任务列出的顺序很重要，Ansible会按照顺序运行它们。下面示例为含有多项任务的tasks属性的示例，该示例使用service模块确保为多个网络服务启用在引导时启动： tasks: - name: web server is enabled service: name: httpd enabled: true - name: NTP server is enabled service: name: chronyd enabled: true - name: Postfix is enabled service: name: postfix enabled: true 运行Playbook   ansible-playbook命令可用于运行playbook。该命令在控制节点上执行，要运行的playbook的名称则作为参数传递。示例如下： [ansible@redhat9 ~]$ ansible-playbook test1.yml PLAY [Configure important user consistently] *********************************** TASK [Gathering Facts] ********************************************************* ok: [redhat8] TASK [huang exists with UID 1000] ********************************************** ok: [redhat8] PLAY RECAP ********************************************************************* redhat8 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 运行playbook说明： 在运行playbook时，将生成输出来显示所执行的play和任务。输出中也会报告执行的每一项任务的结果 在运行playbook时，屏幕中会显示每个play和任务的name键的值 Gathering Facts任务是一项特别的任务，setup模块通常在play启动时自动运行这项任务 对于含有多个play和任务的playbook，设置name属性后可以更加轻松地监控playbook执行的进展 通常而言，Ansible playbook中的任务是幂等的，而且能够安全地多次运行playbook。如果目标受管主机已处于正确的状态，则不应进行任何更改 提高输出的详细程度   ansible-playbook命令提供的默认输出不提供详细的任务执行信息。ansible-playbook -v命令提供了额外的信息，总共有四个级别。具体说明如下表： 选项 描述 -v 显示任务结果 -vv 任务结果和任务配置都会显示 -vvv 包含关于与受管主机连接的信息 -vvvv 增加了连接插件相关的额外详细程度选项，包括受管主机上用于执行脚本的用户，以及所执行的脚本 语法验证   在执行playbook之前，最好要进行验证，确保其内容的语法正确无误。ansible-playbook命令中 --syntax-check选项可用于验证playbook的语法。验证成功示例如下： [ansible@redhat9 ~]$ ansible-playbook --syntax-check test1.yml playbook: test1.yml 执行空运行   使用-C选项对playbook执行空运行。这会使Ansible报告在执行该playbook时将会发生什么更改，但不会对受管主机进行任何实际的更改。示例如下： [ansible@redhat9 ~]$ ansible-playbook -C site.yml PLAY [Install and start Apache HTTPD] ****************************************************************************** TASK [Gathering Facts] ****************************************************************************** ok: [redhat8] TASK [httpd package is present] ******************************************************************************* ok: [redhat8] TASK [httpd is started] ******************************************************************************* changed: [redhat8] PLAY RECAP ******************************************************************** redhat8 : ok=3 changed=1 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0   演示了一个playbook的空运行，它包含单项任务，可确保在受管主机上安装了最新版本的 httpd软件包。该空运行报告此任务会对受管主机产生的更改。 实施多个Play 编写多个Play   Playbook是一个YAML文件，由一个或多个play组成的列表。play按顺序列出了要对清单中的选定主机执行的任务。因此，如果一个playbook中含有多个play，每个play可以将其任务应用到单独的一组主机。 在编排可能涉及对不同主机执行不同任务的复杂部署时很方便。可以对一组主机运行一个play，完成后再对另一组主机运行另一个play Playbook中的各个play编写为playbook中的顶级列表项。各个play是含有常用play关键字的列表项   示例含有两个play的简单playbook。第一个play针对redhat8运行，第二个play则针对192.168.100.131运行： --- # This is a simple playbook with two plays - name: first play hosts: redhat8 tasks: - name: first task yum: name: httpd status: present - name: second task service: name: httpd enabled: true - name: second play hosts: 192.168.100.131 tasks: - name: first task service: name: sshd enabled: true Play中的远程用户和特权升级   Play可以将不同的远程用户或特权升级设置用于play，取代配置文件中指定的默认设置。这些都在play本身中与hosts或tasks关键字相同的级别上设置。 用户属性   Playbook中的任务与临时命令相同，用于任务执行的用户帐户取决于Ansible配置文件/etc/ansible/ansible.cfg中的不同关键字。运行任务的用户可以通过remote_user关键字来定义。如果启用了特权升级，become_user等其他关键字也会发生作用。可以在play中使用remote_user关键字来覆盖Ansible配置中定义的远程用户： remote_user: remoteuser 特权升级属性   可以提供额外的关键字，从而在playbook内定义特权升级参数。become布尔值关键字可用于启用或禁用特权升级，无论它在Ansible配置文件中的定义为何。可以取yes或true值来启用特权升级，或者取no或false值来禁用它： become: true   如果启用了特权升级，则可以使用become_method关键字来定义特定play期间要使用的特权升级方法。示例指定sudo用于特权升级： become_method: sudo   启用了特权升级时，become_user关键字可定义特定play上下文内要用于特权升级的用户帐户。示例如下： become_user: privileged_user 示例在play中使用这些关键字： - name: /etc/hosts is up to date hosts: redhat8 remote_user: ansible become: yes tasks: - name: redhat9 in /etc/hosts lineinfile: path: /etc/hosts line: '192.168.100.133 redhat9 server' state: present 查找用于任务的模块 模块文档   Ansible随附打包的大量模块为管理员提供了许多用于常见管理任务的工具。使用ansible-doc命令来查找关于本地系统上安装的模块的信息。使用ansible-doc -l命令查看控制节点上可用模块的列表，将显示模块名称列表以及其功能的概要。示例如下： [ansible@redhat9 ~]$ ansible-doc -l apt Manages apt-packages apt_key Add or remove an apt key apt_repository Add and remove APT repositories assemble Assemble configuration files from fragments ...output omitted...   使用ansible-doc [模块名称]命令来显示模块的详细文档。与Ansible文档网站一样，该命令提供模块功能的概要、其不同选项的详细信息，以及示例。命令示例如下： [ansible@redhat9 ~]$ ansible-doc git > ANSIBLE.BUILTIN.GIT (/usr/lib/python3.9/site-packages/ansible/modules/git.py) Manage `git' checkouts of repositories to deploy files or software. ADDED IN: version 0.0.1 of ansible-core OPTIONS (= is mandatory): - accept_hostkey If `yes', ensure that \"-o StrictHostKeyChecking=no\" is present as an ssh option. [Default: no] type: bool added in: version 1.5 of ansible-core ...output omitted...   ansible-doc命令的-s选项会生成示例输出，可以充当如何在playbook中使用特定模块的示范。输出中包含的注释，提醒管理员各个选项的用法。示例如下： [ansible@redhat9 ~]$ ansible-doc -s git - name: Deploy software (or files) from git checkouts git: accept_hostkey: # If `yes', ...... accept_newhostkey: # As of OpenSSH 7.5, ...... archive: # Specify archive file path with extension...... archive_prefix: # Specify a prefix to add to each file path...... bare: # If `yes', repository will be created ...... clone: # If `no', do not clone the repository even ...... ...output omitted... 模块维护   Ansible随附了大量模块，它们可用于执行许多任务。这在该模块的 ansible-doc输出末尾的METADATA部分中指明上游Ansible社区中维护该模块的人。status字段记录模块的开发状态： stableinterface：模块的关键字稳定，将尽力确保不删除关键字或更改其含义 preview：模块处于技术预览阶段，可能不稳定，其关键字可能会更改，或者它可能需要本身会受到不兼容更改的库或Web服务 deprecated：模块已被弃用，未来某一发行版中将不再提供 removed：模块已从发行版中移除，但因文档需要存在存根，以帮助之前的用户迁移到新的模块 supported_by字段记录上游Ansible社区中维护该模块的人。可能的值包括： core：由上游核心Ansible开发人员维护，始终随Ansible提供 curated：模块由社区中的合作伙伴或公司提交并维护 community：模块不受到核心上游开发人员、合作伙伴或公司的支持，完全由一般开源社区维护   可以自己编写私有的模块，或者从第三方获取模块。Ansible会在ANSIBLE_LIBRARY环境变量指定的位置查找自定义模块；未设置此变量时由当前Ansible配置文件中的library关键字指定。Ansible也在相对于当前运行的playbook的./library目录中搜索自定义模块。示例： library = /home/ansible/my_modules 相关文档参考： 有关编写方法的文档链接：Ansible Modules 上游Ansible社区有用于Ansible的问题跟踪器及其集成模块，链接为：https://github.com/ansible/ansible/issues 注意事项   使用ansible-doc命令可以查找和了解如何为用户的任务使用模块。command、shell和raw模块的用法可能看似简单，应尽量避免在playbook中使用它们。因为它们可以取用任意命令，因此使用这些模块时很容易写出非幂等的playbook。示例如下： - name: Non-idempotent approach with shell module shell: echo \"nameserver 192.168.100.1\" > /etc/resolv.conf 示例说明； 示例为使用shell模块的任务为非幂等 每次运行play时，它都会重写/etc/resolv.conf，即使它已经包含了行nameserver 192.168.100.1   可以通过多种方式编写以幂等方式使用shell模块的任务，而且有时候进行这些更改并使用 shell是最佳的做法。使用copy模块是更快的方案。示例如果/etc/resolv.conf文件已包含正确的内容，则不会重写该文件： - name: Idempotent approach with copy module copy: dest: /etc/resolv.conf content: \"nameserver 192.168.100.1\\n\"   copy模块可以测试来了解是否达到了需要的状态，如果已达到，则不进行任何更改。shell模块容许非常大的灵活性，但需要注意，确保它以幂等方式运行。幂等的playbook可以重复运行，确保系统处于特定的状态，而不会破坏状态已经正确的系统。 Playbook语法变化 YAML注释   注释可以用于提高可读性。在YAML中，编号或井号符号#右侧的所有内容都是注释。如果注释的左侧有内容，请在该编号符号的前面加一个空格。示例： # This is a YAML comment - Name: Thor # This is also a YAML comment YAML字符串   YAML中的字符串通常不需要放在引号里，即使字符串中包含空格。字符串可以用双引号或单引号括起。三个示例分别如下： this is a string 'this is another string' \"this is yet another a string\" 编写多行字符串一种方式是使用竖线|字符表示要保留字符串中的换行字符： include_newlines: | Example Company 123 Main Street Atlanta, GA 30303   编写多行字符串，也可以使用大于号>字符来表示换行字符转换成空格并且行内的引导空白将被删除。这种方法通常用于将很长的字符串在空格字符处断行，使它们跨占多行来提高可读性。示例： fold_newlines: > This is an example of a long string, that will become a single sentence once folded. YAML字典 以缩进块的形式编写的键值对集合，示例： name: America Captain from: New York power: 9999 字典也可以使用以花括号括起的内联块格式编写，示例： { name: Wonder Woman,from: Amazon,power: 9998} YAML列表 使用普通单破折号语法编写的列表： hosts: - hosta - hostb - hostc 也有以方括号括起的内联格式： superhero: [Wonder Woman, Amazon, 9998] 过时的“键=值”Playbook简写   某些playbook可能使用较旧的简写方法，通过将模块的键值对放在与模块名称相同的行上来定义任务。示例： tasks: - name: shorthand form service: name=httpd enabled=true state=started 通常避免简写，使用下面格式： tasks: - name: normal form service: name: httpd enabled: true state: started "},"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/03-Ansible-变量管理等.html":{"url":"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/03-Ansible-变量管理等.html","title":"Ansible-变量管理等","keywords":"","body":"Ansible-变量&机密&事实管理 管理变量 Ansible变量   Ansible支持利用变量来存储值，并在Ansible项目的所有文件中重复使用这些值。这可以简化项目的创建和维护，并减少错误的数量。通过变量，可以轻松地在Ansible项目中管理给定环境的动态值。变量可能包含下面这些值： 要创建的用户 要安装的软件包 要重新启动的服务 要删除的文件 要从互联网检索的存档 命名变量 变量的名称必须以字母开头，并且只能含有字母、数字和下划线。示例如下表： 无效的变量名称 有效的变量名称 db2 server db2_server remote.file remote_file 1st file file_1 or file1 remoteserver$1 remote_server_1 or remote_server1 定义变量   可在Ansible项目中的多个位置定义变量。如果在两个位置设置了同名变量，并且变量值不同，则通过优先级来决定要使用哪个值。 可以设置会影响一组主机的变量，也可以设置只会影响个别主机的变量 有些变量是Ansible可以根据系统配置来设置的事实 有些变量则可在playbook中设置，然后影响该playbook中的一个play，或者仅影响该play中的一项任务 可通过--extra-vars或-e选项并指定变量值来在ansible-playbook命令行上设置额外变量 ，这些值将覆盖相应变量名称的所有其他值 定义变量的方法如下，按优先级从低到高排列： 在清单中定义的组变量 在清单或Playbook所在目录的group_vars子目录中定义的组变量 在清单中定义的主机变量 在清单或Playbook所在目录的host_vars子目录中定义的主机变量 在运行时中发现的主机事实 (vars和vars_files)playbook中的Play变量 任务变量 在命令行中定义的额外变量   建议选择全局唯一的变量名称，以避免考虑优先级规则。如果在多个级别上定义了相同名称的变量，则采用优先级别最高的变量。更详细、更精准的变量优先级说明，见Ansible文档：Variable precedence: Where should I put a variable? Playbook中的变量 Playbook中定义变量   编写playbook时，可以定义自己的变量，然后在任务中调用这些值。Playbook变量可以通过多种方式定义。一种常见方式是将变量放在playbook开头的vars块中： - hosts: all vars: user: huang home: /home/huang   也可以在外部文件中定义playbook变量，使用vars_files指令，后面跟上相对于playbook位置的外部变量文件名称列表： - hosts: all vars_files: - vars/users.yml 可以使用YAML格式在这些文件中定义playbook变量，示例： user: huang home: /home/huang 在Playbook中使用变量   声明变量后，若需要使用，可以将变量名称放在双花括号{{ }}内。在任务执行时，Ansible会将变量替换为其值。示例： vars: user: huang tasks: # This line will read: Creates the user joe - name: Creates the user {{ user }} user: # This line will create the user named Joe name: \"{{ user }}\"   当变量用作开始一个值的第一元素时，必须使用引号。这可以防止Ansible将变量引用视为YMAL 字典的开头。如果缺少引号，将显示下列消息： yum: name: {{ service }} ^ here We could be wrong, but this one looks like it might be an issue with missing quotes. Always quote template expression brackets when they start a value. For instance: with_items: - {{ foo }} Should be written as: with_items: - \"{{ foo }}\" 主机变量和组变量 直接应用于主机的清单变量分为两大类： 主机变量，应用于特定主机 组变量，应用于一个主机组或一组主机组中的所有主机 主机变量优先于组变量，但playbook中定义的变量的优先级比这两者更高   若要定义主机变量和组变量，一种方法是直接在清单文件中定义。这种方法比较老，不容易使用，它将主机和主机组的所有清单信息和变量设置都放在了一个文件中。 定义web1.big1000.com的ansible_user主机变量： [servers] web1.big1000.com ansible_user=ansible 定义servers主机组的user组变量： [servers] web1.big1000.com web2.big1000.com [servers:vars] user=ansible 定义servers组的user组变量，该组由两个主机组组成，每个主机组有两个服务器： [servers1] web1.big1000.com web2.big1000.com [servers2] db2.big1000.com oracle.big1000.com [servers:children] servers1 servers2 [servers:vars] user=ansible 使用目录填充主机和组变量   定义主机和主机组的变量的首选做法是在与清单文件或playbook相同的工作目录中，创建 group_vars和host_vars两个目录。 这两个目录分别包含用于定义组变量和主机变量的文件 建议使用host_vars和group_vars目录定义清单变量，而不直接在清单文件中定义它们   为了定义用于servers组的组变量，需要创建名为group_vars/servers的YAML文件，然后该文件的内容将使用与playbook相同的语法将变量设置为值： user: ansible   为了定义用于特定主机的主机变量，在host_vars目录中创建名称与主机匹配的文件来存放主机变量。例如需要管理两个数据中心，并在~/project/inventory清单文件中定义数据中心主机： [ansible@redhat9 ~]$ cat ~/project/inventory [datacenter1] web1.big1000.com web2.big1000.com [datacenter2] web3.big1000.com web4.big1000.com [datacenters:children] datacenter1 datacenter2 如需为两个数据中心的所有服务器定义一个通用值，可以为datacenters主机组设置一个组变量： [ansible@redhat9 ~]$ cat ~/project/group_vars/datacenters package: httpd 如果要为每个数据中心定义不同的值，可以为每个数据中心主机组设置组变量： [ansible@redhat9 ~]$ cat ~/project/group_vars/datacenter1 package: httpd [ansible@redhat9 ~]$ cat ~/project/group_vars/datacenter2 package: apache 如果要为每一数据中心的各个主机定义不同的值，则在单独的主机变量文件中定义变量： [ansible@redhat9 host_vars]$ cat web1.big1000.com package: httpd [ansible@redhat9 host_vars]$ cat web2.big1000.com package: apache [ansible@redhat9 host_vars]$ cat web3.big1000.com package: oracle-server [ansible@redhat9 host_vars]$ cat web4.big1000.com package: db2-server 示例项目project的目录结构如果包含上面的所有示例文件： [ansible@redhat9 ~]$ tree project project ├── ansible.cfg ├── group_vars │ ├── datacenter1 │ ├── datacenter2 │ └── datacenters ├── host_vars │ ├── web1.big1000.com │ ├── web2.big1000.com │ ├── web3.big1000.com │ └── web4.big1000.com ├── inventory └── playbook.yml 2 directories, 10 files 注意事项： Ansible会查找与清单和playbook相对的host_vars和group_vars子目录 如果清单和playbook恰好在同一目录中，则比较简单，Ansible可以在相应目录中查找这两个子目录 如果清单和playbook在不同目录中，则Ansible需要从两个位置查找host_vars和group_vars子目录。playbook子目录的优先级更高 从命令行覆盖变量   清单变量可被playbook中设置的变量覆盖，这两种变量又可通过在命令行中传递参数到 ansible或ansible-playbook命令来覆盖。在命令行上设置的变量称为额外变量。当需要覆盖一次性运行的 playbook的变量的已定义值时，额外变量非常有用。例如： [ansible@redhat9 ~]$ ansible-playbook main.yml -e \"package=apache\" 使用数组作为变量   除了将与同一元素相关的配置数据(软件包列表、服务列表和用户列表等)分配到多个变量外，管理员也可以使用数组。好处在于，数组是可以浏览的。例如有下列代码片段： user1_first_name: Bob user1_last_name: Jones user1_home_dir: /users/bjones user2_first_name: Anne user2_last_name: Cook user2_home_dir: /users/acook 可以改写成名为users的数组： users: bjones: first_name: Bob last_name: Jones home_dir: /users/bjones acook: first_name: Anne last_name: Cook home_dir: /users/acook 可以使用以下变量来访问用户数据： # Returns 'Bob' users.bjones.first_name # Returns '/users/acook' users.acook.home_dir 由于变量被定义为Python字典，因此可以使用替代语法： # Returns 'Bob' users['bjones']['first_name'] # Returns '/users/acook' users['acook']['home_dir'] 注意事项： 如果键名称与Python方法或属性的名称(如discard、copy和add等)相同，点表示法可能会造成问题。使用方括号表示法有助于避免冲突和错误 两种语法都有效，但为了方便故障排除，建议在任何给定Ansible项目的所有文件中一致地采用一种语法 使用已注册变量捕获命令输出   可以使用register语句捕获命令输出。输出保存在一个临时变量中，稍后在playbook中可用于调试用途或者达成其他目的，例如基于命令输出的特定配置。示例playbook如何为调试用途捕获命令输出： --- - name: Installs a package and prints the result hosts: redhat8 tasks: - name: Install the package yum: name: httpd state: installed register: install_result - debug: var: install_result   在运行playbook时，debug模块用于将install_result注册变量的值转储到终端。上面playbook运行结果示例如下： [ansible@redhat9 ~]$ ansible-playbook test2.yml PLAY [Installs a package and prints the result] ************** TASK [Gathering Facts] ************************************** ok: [redhat8] TASK [Install the package] ********************************* ok: [redhat8] TASK [debug] ******************************************** ok: [redhat8] => { \"install_result\": { \"changed\": false, \"failed\": false, \"msg\": \"Nothing to do\", \"rc\": 0, \"results\": [] } } PLAY RECAP ******************************************* redhat8 : ok=3 changed=0 unreachabl e=0 failed=0 skipped=0 rescued=0 ignored=0 管理机密 Ansible Vault   Ansible可能需要访问密码或API密钥等敏感数据，以便能配置受管主机。使用Ansible随附的 Ansible Vault可以加密和解密任何由Ansible使用的结构化数据文件。 使用Ansible Vault，可通过ansible-vault命令行工具创建、编辑、加密、解密和查看文件 Ansible Vault可以加密任何由Ansible使用的结构化数据文件： 可能包括清单变量、playbook中含有的变量文件、在执行playbook时作为参数传递的变量文件 或者Ansible角色中定义的变量 Ansible Vault并不实施自有的加密函数，而是使用外部Python工具集。文件通过利用AES256的对称加密(将密码用作机密密钥)加以保护 创建加密的文件   要创建新的加密文件，可使用ansible-vault create filename命令。该命令将提示输入新的vault密码，然后利用默认编辑器vi打开文件。可以设置和导出EDITOR环境变量，将默认编辑器设为nano，可设为export EDITOR=nano。 [ansible@redhat9 ~]$ ansible-vault create secret.yml New Vault password: Confirm New Vault password:   可以使用vault密码文件来存储vault密码，而不是通过标准输入途径输入vault密码。需要使用文件权限和其他方式来严密保护该文件： [ansible@redhat9 ~]$ ansible-vault create --vault-password-file=vault-pass secret.yml 查看加密的文件   可以使用ansible-vault view filename命令查看Ansible Vault加密的文件，而不必打开它进行编辑。示例如下： [ansible@redhat9 ~]$ ansible-vault view secret1.yml Vault password: 编辑现有的加密文件   ansible-vault edit filename命令可以编辑现有的加密文件。此命令将文件解密为一个临时文件，并允许编辑该文件。保存时，它将复制其内容并删除临时文件： [ansible@redhat9 ~]$ ansible-vault edit secret.yml Vault password:   edit子命令始终重写文件，因此只应在进行更改时使用它。这在文件保管在版本控制下时有影响。要查看文件的内容而不进行更改，始终应使用view子命令。 加密现有的文件   使用ansible-vault encrypt filename命令加密已存在的文件。此命令可取多个欲加密文件的名称作为参数。示例： [ansible@redhat9 ~]$ ansible-vault encrypt secret2.yml secret3.yml New Vault password: Confirm New Vault password: Encryption successful   可以用--output=OUTPUT_FILE选项，可将加密文件保存为新的名称。只能通过--output选项使用一个输入文件。 解密现有的文件   可以通过ansible-vault decrypt filename命令对现有加密文件永久解密。在解密单个文件时，可使用--output选项以其他名称保存解密的文件。示例如下： [ansible@redhat9 ~]$ ansible-vault decrypt secret2.yml Vault password: Decryption successful 更改加密文件的密码   使用ansible-vault rekey filename命令更改加密文件的密码。此命令可一次性更新多个数据文件的密钥。它将提示提供原始密码和新密码。示例如下： [ansible@redhat9 ~]$ ansible-vault rekey secret3.yml Vault password: New Vault password: Confirm New Vault password: Rekey successful 在使用vault密码文件时，使用--new-vault-password-file选项： [ansible@redhat9 ~]$ ansible-vault rekey \\ > --new-vault-password-file=NEW_VAULT_PASSWORD_FILE secret.yml Playbook和Ansible Vault   要运行可访问通过Ansible Vault加密的文件的playbook，需要向ansible-playbook命令提供加密密码。如果不提供密码，playbook将返回错误，示例如下： ERROR: A vault password must be specified to decrypt vars/xxxx.yml 为playbook提供vault密码，使用--vault-id选项。例如，要以交互方式提供vault密码，使用下例中所示的--vault-id @prompt： [ansible@redhat9 ~]$ ansible-playbook --vault-id @prompt site.yml Vault password (default): ...output omitted... 更多密码提供方式： 使用的Ansible版本是2.4之前的，则需要使用--ask-vault-pass选项以交互方式提供vault密码。如果playbook使用的所有vault加密文件都使用同一密码加密，则仍可使用该选项 也可使用--vault-password-file选项指定以纯文本存储加密密码的文件。密码应当在该文件中存储为一行字符串。由于该文件包含敏感的纯文本密码，因此务必要通过文件权限和其他安全措施对其加以保护。命令示例： [ansible@redhat9 ~]$ ansible-playbook \\ >--vault-password-file=vault-pw-file site.yml 也可以使用ANSIBLE_VAULT_PASSWORD_FILE环境变量，指定密码文件的默认位置   从Ansible 2.4开始，可以通过ansible-playbook使用多个Ansible Vault密码。要使用多个密码，请将多个--vault-id或--vault-password-file选项传递给ansible-playbook命令。示例如下： [ansible@redhat9 ~]$ ansible-playbook \\ > --vault-id one@prompt --vault-id two@prompt site.yml Vault password (one): Vault password (two): ...output omitted... 示例说明： @prompt前面的vault ID one和two可以是任何字符，甚至可以完全省略它们 如果在使用ansible-vault命令加密文件时使用--vault-id id选项，则在运行ansible-playbook时，将最先尝试匹配ID的密码。如果不匹配，接下来将尝试您提供的其他密码 没有ID的vault ID @prompt实际上是default@prompt的简写，这意味着提示输入vault ID default的密码 变量文件管理的推荐做法   若要简化管理，务必要设置Ansible项目，使敏感变量和所有其他变量保存在相互独立的文件中。然后，包含敏感变量的文件可通过ansible-vault命令进行保护。管理组变量和主机变量的首选方式是在 playbook级别上创建目录： group_vars目录通常包含名称与它们所应用的主机组匹配的变量文件 host_vars目录通常包含名称与它们所应用的受管主机名称匹配的变量文件   除了使用group_vars或host_vars中的文件外，也可对每一主机组或受管主机使用目录。这些目录而后可包含多个变量文件，它们都由该主机组或受管主机使用。例如playbook.yml的项目目录： . ├── ansible.cfg ├── group_vars │ └── webservers │ └── vars ├── host_vars │ └── demo.example.com │ ├── vars │ └── vault ├── inventory └── playbook.yml 示例项目目录说明： 在playbook.yml的以下项目目录中，webservers主机组的成员将使用group_vars/webservers/vars文件中的变量 而demo.example.com将使用host_vars/demo.example.com/vars和host_vars/demo.example.com/vault中的变量 示例中，host_vars/demo.example.com目录内使用的文件名没有什么特别之处。该目录可以包含更多文件，一些由Ansible Vault加密，另一些则不加密： 在这种情景中，其好处在于用于demo.example.com的大部分变量可以放在vars文件中，敏感变量则可单独放在vault文件中保密 然后，管理员可以使用ansible-vault加密vault文件，而将vars文件保留为纯文本   如果在playbook中使用多个vault密码，确保为每个加密文件分配一个vault ID，并在运行playbook时输入具有该vault ID的匹配密码。 管理事实 Ansible事实   Ansible事实是Ansible在受管主机上自动检测到的变量。事实中含有与主机相关的信息，可以像 play中的常规变量、条件、循环或依赖于从受管主机收集的值的任何其他语句那样使用。事实可能包括： 主机名称 内核版本 网络接口 IP 地址 操作系统版本 各种环境变量 CPU 数量 提供的或可用的内存 可用磁盘空间 借助事实，可以方便地检索受管主机的状态，并根据该状态确定要执行的操作。例如： 可以根据含有受管主机当前内核版本的事实运行条件任务，以此来重新启动服务器 可以根据通过事实报告的可用内存来自定义MySQL配置文件 可以根据事实的值设置配置文件中使用的IPv4地址   通常，每个play在执行第一个任务之前会先自动运行setup模块来收集事实。在Ansible 2.3中为Gathering Facts任务，在更早版本的中为setup。默认情况下，无需具有在play中运行setup的任务，通常会自动运行。  查看为受管主机收集的事实的一种方式是运行一个收集事实并使用debug模块显示ansible_facts变量值的简短playbook。示例playbook如下： - name: Fact dump hosts: redhat8 tasks: - name: Print all facts debug: var: ansible_facts 运行结果示例如下： [ansible@redhat9 ~]$ ansible-playbook setup.yml PLAY [Fact dump] ************************************************************ TASK [Gathering Facts] ************************************************************ ok: [redhat8] TASK [Print all facts] ************************************************************ ok: [redhat8] => { \"ansible_facts\": { \"all_ipv4_addresses\": [ \"192.168.100.130\", \"192.168.100.131\" ], \"all_ipv6_addresses\": [ \"fe80::bcd7:31a:c4ac:9c09\" ], \"architecture\": \"x86_64\", \"bios_date\": \"07/29/2019\", ...output omitted... \"virtualization_type\": \"VMware\" } } PLAY RECAP ************************************************************** redhat8 : ok=2 changed=0 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0   Playbook以JSON格式显示ansible_facts变量的内容，作为变量的散列/字典。可以浏览输出来查看收集了哪些事实，并查找可能要在play中使用的事实。下表是可能从受管节点收集的并可在playbook中使用的一些事实： 事实 变量 短主机名 ansible_facts['主机名称'] 完全限定的域名 ansible_facts['fqdn'] 主要IPv4地址(基于路由) ansible_facts['default_ipv4']['address'] 所有网络接口的名称列表 ansible_facts['interfaces'] /dev/vda1磁盘分区的大小 ansible_facts['devices']['vda']['partitions']['vda1']['size'] DNS服务器列表 ansible_facts['dns']['nameservers'] 当前运行的内核的版本 ansible_facts['kernel'] 如果变量的值为散列/字典，则可使用两种语法来检索该值。从上表中举两例： ansible_facts['default_ipv4']['address']也可写成ansible_facts.default_ipv4.address ansible_facts['dns']['nameservers']也可写成ansible_facts.dns.nameservers 在playbook中使用事实时，Ansible将事实的变量名动态替换为对应的值： --- - hosts: all tasks: - name: Prints various Ansible facts debug: msg: > The default IPv4 address of {{ ansible_facts.fqdn }} is {{ ansible_facts.default_ipv4.address }}   下面示例演示了Ansible如何查询受管节点，并且动态使用系统信息来更新变量。也可使用事实来创建符合特定标准的动态主机组： PLAY *********************************************************************** TASK [Gathering Facts] ***************************************************** ok: [demo1.example.com] TASK [Prints various Ansible facts] **************************************** ok: [demo1.example.com] => { \"msg\": \"The default IPv4 address of demo1.example.com is 172.25.250.10\" } PLAY RECAP ***************************************************************** demo1.example.com : ok=2 changed=0 unreachable=0 failed=0 Ansible事实作为变量注入   在Ansible2.5之前，事实是作为前缀为字符串ansible_的单个变量注入，而不是作为ansible_facts变量的一部分注入。例如ansible_facts['distribution']事实可以称为ansible_distribution。  较旧的playbook仍然使用作为变量注入的事实，而不是在ansible_facts变量下创建命名空间的新语法。可以使用临时命令来运行setup模块，以此形式显示所有事实的值。以下示例中使用一个临时命令在受管主机redhat8上运行setup模块： [ansible@redhat9 ~]$ ansible redhat8 -m setup redhat8 | SUCCESS => { \"ansible_facts\": { \"ansible_all_ipv4_addresses\": [ \"192.168.100.130\", \"192.168.100.131\" ], \"ansible_all_ipv6_addresses\": [ \"fe80::bcd7:31a:c4ac:9c09\" ], \"ansible_apparmor\": { \"status\": \"disabled\" }, ...output omitted... }, \"changed\": false } 旧的和新的事实名称对比如下表： ansible_facts形式 旧事实变量形式 ansible_facts['主机名称'] ansible_hostname ansible_facts['fqdn'] ansible_fqdn ansible_facts['default_ipv4']['address'] ansible_default_ipv4['address'] ansible_facts['interfaces'] ansible_interfaces ansible_facts['devices']['vda']['partitions']['vda1']['size'] ansible_devices['vda']['partitions']['vda1']['size'] ansible_facts['dns']['nameservers'] ansible_dns['nameservers'] ansible_facts['kernel'] ansible_kernel   目前Ansible同时识别新的事实命名系统和旧的命名系统。将Ansible配置文件的[default]部分中的 inject_facts_as_vars参数设置为false，可关闭旧命名系统。默认设置目前为true。如果更改为false，尝试通过旧命名空间引用事实将导致以下错误： ...output omitted... TASK [Show me the facts] ************************************************* fatal: [demo.example.com]: FAILED! => {\"msg\": \"The task includes an option with an undefined variable. The error was: 'ansible_distribution' is undefined\\n\\nThe error appears to have been in '/home/student/demo/playbook.yml': line 5, column 7, but may\\nbe elsewhere in the file depending on the exact syntax problem.\\n\\nThe offending line appears to be:\\n\\n tasks:\\n - name: Show me the facts\\n ^ here\\n\"} ...output omitted... 关闭事实收集 不想为play收集事实的原因可能有： 不准备使用任何事实，并且希望加快play速度或减小play在受管主机上造成的负载 受管主机因为某种原因而无法运行setup模块，或者需要安装一些必备软件后再收集事实 为play禁用事实收集可将gather_facts关键字设为no： --- - name: This play gathers no facts automatically hosts: large_farm gather_facts: no   即使play设置了gather_facts: no，也可以随时使用setup模块的任务来手动收集事实。示例如下： tasks: - name: Manually gather facts setup: ...output omitted... 创建自定义事实   管理员可以创建自定义事实，将其本地存储在每个受管主机上。这些事实整合到setup模块在受管主机上运行时收集的标准事实列表中。它们让受管主机能够向Ansible提供任意变量，以用于调整play的行为。 自定义事实可以在静态文件中定义，格式可为INI文件或采用JSON。它们也可以是生成JSON输出的可执行脚本 借助自定义事实，管理员可以为受管主机定义特定的值，供play用于填充配置文件或有条件地运行任务。动态自定义事实允许在play运行时以编程方式确定这些事实的值，甚至还可以确定提供哪些事实 默认情况下，setup模块从各受管主机的/etc/ansible/facts.d目录下的文件和脚本中加载自定义事实： 各个文件或脚本的名称必须以.fact结尾才能被使用 动态自定义事实脚本必须输出JSON格式的事实，而且必须是可执行文件   示例采用INI格式编写的静态自定义事实文件。INI格式的自定义事实文件包含由一个部分定义的顶层值，后跟用于待定义的事实的键值对： [packages] web_package = httpd db_package = mariadb-server [users] user1 = huang user2 = ansible   也以JSON格式提供同样事实。以下JSON事实等同于以上示例中INI格式指定的事实。JSON数据可以存储在静态文本文件中，或者通过可执行脚本输出到标准输出： { \"packages\": { \"web_package\": \"httpd\", \"db_package\": \"mariadb-server\" }, \"users\": { \"user1\": \"huang\", \"user2\": \"ansible\" } }   自定义事实由setup模块存储在ansible_facts['ansible_local']变量中。事实按照定义它们的文件的名称来整理。例如，假设前面的自定义事实由受管主机上保存为/etc/ansible/facts.d/custom.fact的文件生成。这时，ansible_facts['ansible_local']['custom']['users']['user1']的值为huang。可以利用临时命令在受管主机上运行setup模块来检查自定义事实的结构，官方示例： [user@demo ~]$ ansible demo1.example.com -m setup demo1.example.com | SUCCESS => { \"ansible_facts\": { ...output omitted... \"ansible_local\": { \"custom\": { \"packages\": { \"db_package\": \"mariadb-server\", \"web_package\": \"httpd\" }, \"users\": { \"user1\": \"joe\", \"user2\": \"jane\" } } }, ...output omitted... }, \"changed\": false } 自定义事实的使用方式与playbook中的默认事实相同，官方示例： [user@demo ~]$ cat playbook.yml --- - hosts: all tasks: - name: Prints various Ansible facts debug: msg: > The package to install on {{ ansible_facts['fqdn'] }} is {{ ansible_facts['ansible_local']['custom']['packages']['web_package'] }} [user@demo ~]$ ansible-playbook playbook.yml PLAY *********************************************************************** TASK [Gathering Facts] ***************************************************** ok: [demo1.example.com] TASK [Prints various Ansible facts] **************************************** ok: [demo1.example.com] => { \"msg\": \"The package to install on demo1.example.com is httpd\" } PLAY RECAP ***************************************************************** demo1.example.com : ok=2 changed=0 unreachable=0 failed=0 使用魔法变量   一些变量并非事实或通过setup模块配置，但也由Ansible自动设置。这些魔法变量也可用于获取与特定受管主机相关的信息。最常用的有四个： hostvars：包含受管主机的变量，可以用于获取另一台受管主机的变量的值。如果还没有为受管主机收集事实，则它不会包含该主机的事实 group_names：列出当前受管主机所属的所有组 groups：列出清单中的所有组和主机 inventory_hostname：包含清单中配置的当前受管主机的主机名称。这可能因为各种原因而与事实报告的主机名称不同   另外还有许多其他的魔法变量。有关更多信息参考Variable precedence: Where should I put a variable?。深入了解它们的值，可以使用debug模块报告特定主机的hostvars变量的内容： [ansible@redhat9 ~]$ ansible localhost -m debug -a 'var=hostvars[\"localhost\"]' localhost | SUCCESS => { \"hostvars[\\\"localhost\\\"]\": { \"ansible_check_mode\": false, \"ansible_config_file\": \"/home/ansible/ansible.cfg\", \"ansible_connection\": \"local\", \"ansible_diff_mode\": false, \"ansible_facts\": {}, \"ansible_forks\": 5, \"ansible_inventory_sources\": [ \"/home/ansible/inventory\" ], \"ansible_playbook_python\": \"/usr/bin/python3.9\", \"ansible_python_interpreter\": \"/usr/bin/python3.9\", \"ansible_verbosity\": 0, \"ansible_version\": { \"full\": \"2.12.2\", \"major\": 2, \"minor\": 12, \"revision\": 2, \"string\": \"2.12.2\" }, \"group_names\": [], \"groups\": { \"all\": [ \"redhat8\", \"192.168.100.131\" ], \"testhosts\": [ \"redhat8\", \"192.168.100.131\" ], \"ungrouped\": [] }, \"inventory_hostname\": \"localhost\", \"inventory_hostname_short\": \"localhost\", \"omit\": \"__omit_place_holder__b264b0e13db6af9e4a57204f1d159fb7d8e2eb95\", \"playbook_dir\": \"/home/ansible\" } } "},"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/04-Ansible-任务控制.html":{"url":"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/04-Ansible-任务控制.html","title":"Ansible-任务控制","keywords":"","body":"Ansible-任务控制 编写循环和条件任务 利用循环迭代任务   Ansible支持使用loop关键字对一组项目迭代任务。可以配置循环以利用列表中的各个项目、列表中各个文件的内容、生成的数字序列或更为复杂的结构来重复任务。 简单循环   简单循环对一组项目迭代任务。loop关键字添加到任务中，将应对其迭代任务的项目列表取为值。循环变量item保存每个迭代过程中使用的值。以下代码片段使用两次service模块来确保两个网络服务处于运行状态： - name: Postfix is running service: name: postfix state: started - name: Dovecot is running service: name: dovecot state: started 这两个任务可以重新编写为使用一个简单循环： - name: Postfix and Dovecot are running service: name: \"{{ item }}\" state: started loop: - postfix - dovecot   可以通过一个变量提供loop所使用的列表。下面示例中，变量mail_services含有需要处于运行状态的服务的列表： vars: mail_services: - postfix - dovecot tasks: - name: Postfix and Dovecot are running service: name: \"{{ item }}\" state: started loop: \"{{ mail_services }}\" 循环散列或字典列表   loop列表不需要是简单值列表。下面示例中，列表中的每个项实际上是散列或字典。示例中的每个散列或字典具有两个键，即name和groups，当前item循环变量中每个键的值可以分别通过item.name和item.groups变量来检索。 - name: Users exist and are in the correct groups user: name: \"{{ item.name }}\" state: present groups: \"{{ item.groups }}\" loop: - name: ansible groups: wheel - name: huang groups: root 任务的结果是用户ansible存在且为组wheel的成员，并且用户huang存在且为组root的成员。 较早样式的循环关键字 "},"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/20-Ansible-常见问题.html":{"url":"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/20-Ansible-常见问题.html","title":"Ansible-常见问题","keywords":"","body":"Ansible-常见问题 权限问题 提示需要root用户 运行ansible-playbook报错示例如下： [ansible@redhat9 ~]$ ansible-playbook -C site.yml PLAY [Install and start Apache HTTPD] *************************************************************************************** TASK [Gathering Facts] *************************************************************************************** ok: [redhat8] TASK [httpd package is present] *************************************************************************************** fatal: [redhat8]: FAILED! => {\"changed\": false, \"msg\": \"This command has to be run under the root user.\", \"results\": []} PLAY RECAP **************************************************************************************** redhat8 : ok=1 changed=0 unreachable=0 failed=1 skipped=0 rescued=0 ignored=0   没有root权限，用户也不能使用sudo，在ansible.cfg文件中become相关项，检查配置文件。通常配置如下所示： [privilege_escalation] become = true become_method = sudo become_user = root become_ask_pass = false 提示没有权限 报错示例如下： [ansible@redhat9 ~]$ ansible-playbook -C site.yml PLAY [Install and start Apache HTTPD] **************************************************************************************** TASK [Gathering Facts] ******************************************************************************************************* fatal: [redhat8]: UNREACHABLE! => {\"changed\": false, \"msg\": \"Failed to connect to the host via ssh: user@redhat8: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\", \"unreachable\": true} PLAY RECAP ******************************************************************************************************************* redhat8 : ok=0 changed=0 unreachable=1 failed=0 skipped=0 rescued=0 ignored=0 运行ping模块同样报错： [ansible@redhat9 ~]$ ansible redhat8 -m ping redhat8 | UNREACHABLE! => { \"changed\": false, \"msg\": \"Failed to connect to the host via ssh: user@redhat8: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\", \"unreachable\": true }   用户没有做ssh验证，或者是做了，但是在ansible.cfg文件中remote_user =项的用户写错了，检查ssh验证，检查配置文件。 待补充 "},"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/21-Ansible-官方实例参考.html":{"url":"05-IBM_Operating_System/07-RHEL-Ansible学习笔记/21-Ansible-官方实例参考.html","title":"Ansible-官方实例参考","keywords":"","body":"Ansible-官方实例参考 常用软件安装 Apache Web服务安装   安装Apache Web服务器并开启相关的端口以使其服务可被访问。Playbook查询Web服务器以确认其已设好并在运行。创建playbook并在vars部分中定义以下变量： 变量 描述 web_pkg 要安装的 Web 服务器软件包 firewall_pkg 要安装的防火墙软件包 web_service 要管理的 Web 服务 firewall_service 要管理的防火墙服务 python_pkg uri 模块所需的软件包 rule 要打开的服务 完整playbook内容参考如下： --- - name: Deploy and start Apache HTTPD service hosts: webserver vars: web_pkg: httpd firewall_pkg: firewalld web_service: httpd firewall_service: firewalld python_pkg: python3-PyMySQL rule: http tasks: - name: Required packages are installed and up to date yum: name: - \"{{ web_pkg }}\" - \"{{ firewall_pkg }}\" - \"{{ python_pkg }}\" state: latest - name: The {{ firewall_service }} service is started and enabled service: name: \"{{ firewall_service }}\" enabled: true state: started - name: The {{ web_service }} service is started and enabled service: name: \"{{ web_service }}\" enabled: true state: started - name: Web content is in place copy: content: \"Example web content\" dest: /var/www/html/index.html - name: The firewall port for {{ rule }} is open firewalld: service: \"{{ rule }}\" permanent: true immediate: true state: enabled - name: Verify the Apache service hosts: localhost become: false tasks: - name: Ensure the webserver is reachable uri: url: http://servera.lab.example.com status_code: 200 待补充 "},"06-IBM_Database&Middleware&Other/":{"url":"06-IBM_Database&Middleware&Other/","title":"IBM_Database&Middleware&Other","keywords":"","body":"IBM_Database&Middleware&Other 简介 IBM 软件产品有DB2、Lotus、Rational、Tivoli、WebSphere五大系列。 官方链接https://www.ibm.com/cn-zh/products/software IBM支持 7*24小时呼叫中心：400-810-1818转5004 IBM 用户支持中心：产品下载和更新、打开和查看案例、产品通知以及支持指南，官方连接： IBM 支持团队 在线支持指南： 高效快速获得IBM售后技术支持 IBM 软件技术支持微信公众号：ibmsupport 内容 DB2_Database Websphere_Application_Server Websphere_MQ Flienet Cognos "},"06-IBM_Database&Middleware&Other/01-DB2_Database/":{"url":"06-IBM_Database&Middleware&Other/01-DB2_Database/","title":"DB2_Database","keywords":"","body":"Db2_Database 简介   IBM Db2® Database是一款关系型数据库，可为事务型工作负载提供高级数据管理和分析功能。该运营数据库旨在提供高性能、切实可行的洞察、数据可用性和可靠性，并且在 Linux、Unix 和 Windows 操作系统上均受支持。 官方网站：IBM Db2 Database IBM Db2支持社区：IBM Db2技术支持 内容 DB2-数据收集 DB2-常见SQL_messages DB2-数据库其它故障 DB2-数据库相关说明 DB2-常用操作或命令 "},"06-IBM_Database&Middleware&Other/01-DB2_Database/01-DB2-数据收集.html":{"url":"06-IBM_Database&Middleware&Other/01-DB2_Database/01-DB2-数据收集.html","title":"DB2-数据收集","keywords":"","body":"DB2-数据收集 DB2 Database出现故障时候很可能涉及到业务，及时收集相应的日志给IBM DB2数据库工程师可以准确分析出问题原因，有助于尽快解决业务问题。 通常分析DB2问题时候，IBM support需要db2diag.log和db2support.zip两个数据。 db2diag.log 各个系统存放路径有所差别，并且用户可以自定义。 AIX和Linux系统 db2diag.log的路径可以自定义，在系统参数DIAGPATH中 AIX和Linux默认存放目录是：/sqllib/db2dump/db2diag.log Windows系统 Windows系统在C:\\Documents and Settings\\All Users\\Application Data\\IBM\\DB2\\\\ 可以通过命令db2set -all找到DB2INSTPROF，在对应目录下查找即可。 命令db2diag 命令db2diag可以读取的db2diag.log中的内容,示例： #显示所有critical错误消息 db2diag -level critical #显示最近三天记录的severe错误 db2diag -gi \"level=severe\" -H 3d #查看db2diag.log文件的增长 db2diag -f db2diag.log #从所有db2diag.log文件中读取最后10行 db2diag -lastlines 10 #显示最后100行中所有级别为Error的记录 db2diag -g level=Error -lastlines 100 命令db2diag更多用法可以参照官方介绍：DB2 db2diag命令介绍 db2support.zip 此数据通过db2support命令进行收集，收集条件： 运行db2support之前确保数据库是激活状态 具有SYSADM权限的用户（例如实例所有者） 一般情况下收集的格式如下： #其它有权限用户 db2support -d -s #实例用户目录 db2support . -d -s #如果是pureScale环境 db2support . -d DBname -ps 生成的db2support.zip文件如果为指定，就存放在当前目录。 命令db2support用法很多，不通参数收集的内容有差别，如果IBM support指定了相关参数进行收集，请按照IBM support提供命令进行收集。 命令db2support更多用法可以参照官方介绍：DB2 db2support命令介绍 针对性数据收集 语句执行慢   SQL语句执行慢时候，建议对SQL里面的表都跑下统计信息，看看执行计划是否改变，如果没有改变，把SQL放到文件sql.txt里面，以英文的分号\";\" 结尾, 然后在sql.txt相同目录下，收集db2support: db2support . -d -cl 1 -sf sql.txt -o db2support_cl0.zip 待补充 "},"06-IBM_Database&Middleware&Other/01-DB2_Database/02-DB2-常见SQL_messages.html":{"url":"06-IBM_Database&Middleware&Other/01-DB2_Database/02-DB2-常见SQL_messages.html","title":"DB2-常见SQL_messages","keywords":"","body":"DB2-常见问题 记录一些日常运维过程中遇到的SQL messages，方便查阅。IBM 官方SQL messages说明网站：IBM DB2 11.1 SQL messages DB2 connect常见SQL 官方参考链接：DB2 Connect 常见问题 SQL6048N   在使用db2start命令启动DB2的时候报错SQL6048N，一般是hosts表有问题，检查下/etc/hosts，注意大小写。此情况通常出现在数据库在新的操作系统上启动时候发生。当然还可能是其它原因，IBM官方详细描述：db2start failing with SQL6048N error SQL5043N db2start命令启动DB2的时候报错SQL5043N,示例： SQL5043N Support for one or more communications protocols specified in the DB2COMM environment variable failed to start successfully. However, core database manager functionality started successfully. Explanation This message can be returned for the following types of reasons: Communication subsystem 原因：  通常是未定义DB2COMM概要文件变量，或者该变量未正确定义。该问题通常是DB2COMM变量与数据库管理器配置中定义的名称（例如，svcename或nname）之间不匹配的结果。 首先查看db2set： $ db2set -all 如果DB2COMM未配置则配置： $ db2set DB2COMM=TCPIP 需要重启实例生效，如果上面设置了，查看svcname设置： $ db2 get dbm cfg | grep -i svc 如果SVCNAME未设置，设置即可，然后重启数据库。 官方参考链接：DB2 Connect 常见问题 其他SQL SQL0912N 官方说明：DB2 10.5 SQL0912N 由于没有足够的内存用于锁定请求，因此已达到数据库的最大锁定数量。出现此错误时候可能会导致应用批处理失败，在db2diag.log出现大量错误，错误示例如下： 2020-09-10-08.46.12.137491+480 I3480316188A583 LEVEL: Error PID : 20119590 TID : 21562 PROC : db2sysc 0 INSTANCE: ftpinst NODE : 000 DB : testDB APPHDL : 0-35376 APPID: *LOCAL.ftpinst.200910004557 AUTHID : FTPUSR HOSTNAME: testDB1 EDUID : 21562 EDUNAME: db2agent (FTPDB) 0 FUNCTION: DB2 UDB, catalog services, sqlrlNonRestartCheckIndex, probe:100 RETCODE : ZRC=0x8510000A=-2062548982=SQLP_LFUL \"Lock list full - SQL0912 Reason code 1\" DIA8310C Lock list was full. 根据不同的Reason code选择解决方法： Reason code 1：增加LOCKLIST数据库配置参数，该参数管理分配给本地锁管理器的锁内存 Reason code 2：增加CF_LOCK_SZ数据库配置参数，该参数管理分配给全局锁管理器的锁内存 关于LOCKLIST官方说明:DB2 LOCKLIST SQL20048N 官方说明：DB2 SQL20048N 示例故障现象和报错： 某系统每晚22:00跑定时任务存储过程生成报表数据，但每月的6-7号晚上跑存储过程都会失败，导致报表数据为空。经查，是调用存储过程QU_REPORT_DATA_LEVEL_TWO()时候报错，错误信息为：Error: SQLCODE=-20448,SQLSTATE=22007, SQLERRMC=;hh24:mi:ss,DRIVER=4.0.100。 解决方法：  报错DB2版本是9.5FP10，使用JDBC版本是4.0.100，此JDBC版本是DDB9.5 FP0GA版本时候发布的，建议下载9.5FP10对应的最新版本的JDBC。同理其它版本有类似不匹配问题建议使用对应版本。 IBM DB2 JDBC Driver版本和下载：https://www.ibm.com/support/pages/node/382667 SQL0727N 官方说明：DB2 SQL0727N 描述：隐式系统操作类型action-type期间发生错误。返回的错误信息包括SQLCODEsqlcode，SQLSTATE sqlstate和消息令牌token-list。   在执行一个操作的时候，因为触发了一个内部操作，然而在执行这个内部操作的时候失败了 所以根据客户实际的报错，根据action type和具体的code去判断引起的原因，报错示例： $ db2 rebind package SQL0727N An error occurred during implicit system action type \"3\" Information returned for the error includes SQLCODE \"-117\",SQLSTATE \"42802\" and massage tokens \"\". LINE NUMBER=664. SQLSTATE=56098 在报错示例中可以看到action type为3：implicit revalidation of an object，SQLCODE为\"-117\",SQLSTATE为\"42802\"，初步判断是SQL0117N引起的，SQL0117N详细描述单独说明。 SQL0117N 官方说明：DB2 SQL0117N 描述：赋值数目与指定的或隐含的列数或变量数不一样，将无法处理该语句。 在下列情况下，值的数目可能会不同： 在INSERT语句值列表中的插入值的数目与指定的或隐含的列数不相同。如果未指定任何列列表，那么会隐含包括表（隐式隐藏的表除外）或视图中所有列的列列表。 在SET语句或UPDATE语句的SET子句中，赋值符号右侧的值数目与左侧的列数或变量数不匹配。 解决方法： 更正该语句以便为每一个指定的或隐含的列或变量指定一个值。 sqlcode：-117 sqlstate：42802 SQL1224N 官方说明：Db2 11.1 SQL1000 - SQL1249 描述：由于数据库管理器发生了错误或者被强制中断，从而无法接受新的请求，已终止正在处理的所有请求或者已终止所指定的请求。 可能原因： 客户机/服务器配置问题 数据库管理器代理程序不可用 此用户标识没有足够的权限 数据库目录冲突 达到已配置的数据库限制或系统资源限制 所请求的功能不受支持 在新添加的成员上激活数据库 用户响应： 仅限于联合环境：确定是联合数据源返回了错误还是联合数据库服务器返回了错误 确保客户机/服务器配置正确 确保数据库管理器已启动并处于运行状态 确保此用户标识有权执行下列操作： 消除任何数据库目录冲突   在DB2 pureScale环境中，如果已添加新成员，那么必须先等待激活操作完成，然后才能从新成员中打开后续数据库连接。否则，请从另一个现有成员进行连接 sqlcode：-1224 sqlstate：55032 待补充 "},"06-IBM_Database&Middleware&Other/01-DB2_Database/03-DB2-数据库其它问题.html":{"url":"06-IBM_Database&Middleware&Other/01-DB2_Database/03-DB2-数据库其它问题.html","title":"DB2-数据库其它问题","keywords":"","body":"DB2-数据库故障 记录一些日常运维过程中遇到的一些数据库故障，方便查阅。 db2start时引发操作系统EEXIST错误 在使用db2start启动数据库时候，db2diag.log中有如下错误信息， 2011-12-14-18.01.38.656079+120 E32782E328 LEVEL: Error (OS) PID : 26310 TID : 46912685380880PROC : db2star2 INSTANCE: tamdbi02 NODE : 000 FUNCTION: DB2 UDB, SQO Memory Management, sqloMemCreateSingleSegment, probe:100 CALLED : OS, -, shmget OSERR: EEXIST (17)   这是在DB2数据库正在运行时发出db2start时候产生报错，可能是db2之前未正确停止（IPC剩余资源），或者启动了两次（自动启动和手动启动）。解决方法（依次运行）： db2stop force ipclean -a db2start IBM官方说明：OS error EEXIST was thrown when db2start was issued in a single node environment. 数据库异常终止 现象：DB2数据库异常终止，手动重启恢复。db2diag.log中报错示例： 2018-02-06-17.53.07.475000+480 E13871146F536 LEVEL: Warning PID : 20632 TID : 20100 PROC : db2syscs.exe INSTANCE: DB2 NODE : 000 DB : TESTDB APPHDL : 0-17775 APPID: 10.9.100.211.62501.180206095310 AUTHID : DB2ADMIN HOSTNAME: NEWTEST EDUID : 20100 EDUNAME: db2agent (TESTDB) 0 FUNCTION: DB2 UDB, runtime interpreter, sqlriPEXInitHashTable, probe:3848 MESSAGE : Partial Early Aggregation/Distinct running with reduced memory 故障原因：Partial Aggregation operators (PED, PEA) 可能因为访问了无效的内存或内存故障导致DB2异常终止。发生这种情况是由于在指定的内存范围结束时发生下列任何一种情况: SQL 语句在最初编译的时候SORTHEAP动态减少，比如在一个STMM的环境中自动调SORTHEAP； 对操作员可用的sort reservation由于节流而减少，即总sort reservation正在接近或超过SHEAPTHRES_SHR。 临时解决方法：按照以下禁用部分aggregation： db2set DB2_REDUCED_OPTIMIZATION=\"NO_PEA,NO_PED\" recycle the instance 这是通过内部注册表变量设置来解决此问题，在升级包含此修复的Fix包前此设置必须清掉此设置： db2set DB2_REDUCED_OPTIMIZATION= recycle the instance 永久性解决方法：升级修复此问题，修复此问题版本：DB2 10.5 FP7，升级到此版本或更新版本 IBM官方补丁：http://www-01.ibm.com/support/docview.wss?uid=swg24044110 导出表定义、存储过程不完整   当使用db2look命令导出存储过程时候，没有返回错误信息，但返回得结果里面少了一部分存储过程的定义，命令示例如下： $db2look -d -e -dp -o db2look_tale.ddl 可以先通过检索syscat.PROCEDURES系统目录表，看对应的存储过程是否存在: db2 \"select * from syscat.PROCEDURES where PROCNAME ='?'\"   导出存储过程结构，可以尝试从​SYSCAT.PROCEDURES导出(此方法的缺陷是当text>32767时，导出的该条存储过程是不完整的): DB2 SELECT CHAR(ROUTINESCHEMA,20), CHAR(ROUTINENAME,20), TEXT FROM SYSCAT.ROUTINES > 还可以使用export导出: db2 \"EXPORT TO procudure.del OF del lobs to sp.del MODIFIED BY LOBSINFILE SELECT 'SET CURRENT SCHEMA '||rtrim(procschema)||'@'||chr(10)||'SET CURRENT PATH = SYSIBM,SYSFUN,SYSPROC,'||rtrim(procschema)||' @'||chr(10)||text||chr(10)||'@'||chr(10) FROM syscat.procedures ORDER BY create_time ; \"​ 可以用指定schema name和proc name即可以导出存储过程的DDL信息: db2 GET ROUTINE INTO FROM PROCEDURE . 示例： db2 GET ROUTINE INTO routine.txt FROM PROCEDURE XCRSUSR.HOLD_ERR_CORP_LIST   在导出时使用db2look -wrap选项还是达不到预期效果，最后在查看原始的创建PL/SQL package的语句后，使用下面命令解决了问题： db2look -d -mod -cor 参数说明： -mod:为每个模块以及在每个模块中定义的所有对象生成DDL语句 -cor:不管语句最初是否包含该子句，都使用CREATE OR REPLACE子句生成DDL语句 官方关于db2look说明：db2look - Db2 statistics and DDL extraction tool command 语句执行慢 现象：有两张表a和b，a表数据量是60万，b表数据量是300万，有一条语句执行比较慢，有一个SQL执行比较慢。   强制Db2走索引，成本是高出很多的，主要的原因是： 两个组合索引都只有两列，那么要评估谓词，Db2走索引只能先index scan然后， 然后通过rid扫表，这个成本较大。 建议1：把select放到t1.sql, 然后跑下db2advis， 看看db2advis是不是对索引定义有优化建议： db2advis -d -i t1.sql -o advis_new.out 建议2：如果1没什么作用，建议把sortheap调到1000，调大sortheap后，Db2会走hsjoin。sortheap调高的时候，sheapthres_shr应该相应也调高。建议​sheapthres_shr调到5000。查看当前heap配置： db2 get db cfg | grep -i sheap 修改配置示例： db2 update db cfg for using SHEAPTHRES_SHR 5000 db2 update db cfg for using SORTHEAP 1000 待补充 "},"06-IBM_Database&Middleware&Other/01-DB2_Database/04-DB2-数据库相关说明.html":{"url":"06-IBM_Database&Middleware&Other/01-DB2_Database/04-DB2-数据库相关说明.html","title":"DB2-数据库相关说明","keywords":"","body":"DB2-数据库相关说明 记录一些日常运维过程中遇到的DB2数据库参数、配置及一些事件的说明。 db2diag.log中事件说明 AgentBreathingPoint 在db2diag.log中记录的事件示例如下： 2018-05-28-14.34.10.316021+480 I24270A2398 LEVEL: Warning PID : 6226260 TID : 32997 PROC : db2sysc 0 INSTANCE: testminst NODE : 000 DB : TESTMDB APPHDL : 0-31708 APPID: 10.1.16.19.55805.190603233117 AUTHID : ESBMDATA HOSTNAME: TESTDB2 EDUID : 32997 EDUNAME: db2agent (ESBMDB) 0 FUNCTION: DB2 UDB, base sys utilities, sqeAgent::AgentBreathingPoint, probe:16 CALLSTCK: (Static functions may not be resolved correctly, as they are resolved to the nearest symbol) [0] 0x0900000020C3DC88 AgentBreathingPoint__8sqeAgentFi + 0x3D8 [1] 0x090000002095DAA4 sqlplWaitOnWP__FCP9sqeBsuEduCP14SQLP_LOCK_INFOCP8SQLP_LRBCP15SQLP_LTRN_CHAINCbN25 + 0x35B8 [2] 0x090000002066EC84 sqlplrq__FP9sqeBsuEduP14SQLP_LOCK_INFO + 0x7F4 [3] 0x0900000020671880 sqlplrq__FP9sqeBsuEduP14SQLP_LOCK_INFO + 0x18C4 [4] 0x09000000208E8B3C sqldReadNorm__FP13SQLD_DFM_WORKl + 0xC58 说明：It is a db2 mechanism called 'agent breathing' which is used to detect if application/client connection is gone abnormally. This mechanism can be seen in many functions. If user saw this error message, it would mean either the tcpip layer closed the connection due to some timeout setting or the application/client process is gone without calling close connection function. 官方说明：What does \"AgentBreathingPoint\" error mean in db2? DB2数据库配置参数 遇到的一些数据库配置参数简单说明。 LOCKLIST   此参数指示分配给锁定列表的存储量。每个数据库有一个锁定列表，锁定列表包含由同时连接至数据库的所有应用程序挂起的锁定。查看命令及示例： $ db2 get db cfg for |grep -i locklist Max storage for lock list (4KB) (LOCKLIST) = 4096 关于LOCKLIST官方说明:DB2 LOCKLIST 返回状态码   在shell中，可以使用变量$?来获取上一条命令退出状态码。在db2中，可以使用GET DIAGNOSTICS语句，语句用于获取当前的执行环境信息，包括有关先前执行的SQL语句（GET DIAGNOSTICS语句除外）的信息。SQLCA中也提供了一些可通过GET DIAGNOSTICS语句获得的信息。数据类型如下表所示： 信息类型 项目 数据类型 Statement information DB2_RETURN_STATUS INTEGER Statement information DB2_SQL_NESTING_LEVEL INTEGER Statement information ROW_COUNT DECIMAL(31,0) Condition information DB2_TOKEN_STRING VARCHAR(1000) Condition information MESSAGE_TEXT VARCHAR(32672) 用法及示例参考官方文档：GET DIAGNOSTICS statement 索引相关 索引选择不正确   如果存在正确索引，优化器没有选择，不需要手工干预，一般通过更新统计信息，优化器会基于cost原则来选择： db2 runstats on table tabname with distribution and indexes all 手工干预优化器 可以通过optimization guidelines方式干预优化器来使用不同索引。官方参考文档：Access plan and query optimization guidelines 查看优化器生成执行计划 可以通过dbexfmt命令来看access plan,示例： db2 -tvf ~/sqllib/misc/EXPLAIN.DDL db2 connect to DBNAME db2 \"set current explain mode explain db2 -tvf t.sq db2 \"set current explain mode no\" db2exfmt -d DBNAME -g TIC -w -1 -n % -s % -# 0 -o explain.txt 待补充 "},"06-IBM_Database&Middleware&Other/01-DB2_Database/05-DB2-常用操作或命令.html":{"url":"06-IBM_Database&Middleware&Other/01-DB2_Database/05-DB2-常用操作或命令.html","title":"DB2-常用操作或命令","keywords":"","body":""},"06-IBM_Database&Middleware&Other/02-Websphere_Application_Server/":{"url":"06-IBM_Database&Middleware&Other/02-Websphere_Application_Server/","title":"Websphere_Application_Server","keywords":"","body":"Websphere_Application_Server 简介   IBM Websphere_Application_Server是一种高性能的Java应用服务器，可用于构建、运行、集成、保护和管理内部部署和/或外部部署的动态云和Web应用。它不仅能够确保高性能和灵活性，还提供多种开放标准编程模型选项，旨在最大程度提高开发人员的生产力。它可提供灵活先进的性能、冗余和编程模型。 官方网站：IBM WebSphere Application Server 内容 WAS-数据收集 WAS-常见问题处理 WAS-其它报错处理 WAS-故障处理实例 "},"06-IBM_Database&Middleware&Other/02-Websphere_Application_Server/01-WAS-数据收集.html":{"url":"06-IBM_Database&Middleware&Other/02-Websphere_Application_Server/01-WAS-数据收集.html","title":"WAS-数据收集","keywords":"","body":"WAS-日志收集   WAS作为中间件，如果出现问题，很可能涉及到业务，故障原因除WAS本身，还可能涉及到操作系统和应用，根据WAS不同的故障现象，收集相应的日志给IBM WAS工程师可以尽快并且准确分析出问题原因，有助于尽快解决业务问题。 主要分为以下几种情况： 线程挂起 Java堆内存溢出 hang or high CPU问题 crash宕机 线程挂起_收集数据   当WAS线程挂起的时候，需要收集数据有javacore、垃圾回收日志、目录/logs下所有日志以及网络端口信息。 javacore 一定要在故障发生时收集 收集用途： 查看线程信息 监控锁信息 AIX & Linux平台收集方法如下： 生成三个javacore，每两个间隔两分钟执行一次： #查看WAS java 进程id ps -ef |grep java #手动生成三个javacore kill -3 如果没有自定义过，生成日志默认存放在/javacore*。 垃圾回收日志 即native_stderr.log，需要手动启动，收集用途： 垃圾回收效率 有没有OutOfMemoryError及其它JVM异常 目录/logs下所有日志 收集用途： 运行时日志：SystemOut.log,SystemErr.log ffdc日志 端口信息 收集用途： 查看端口使用情况 收集运行命令netstat -an >netstat.txt Java堆内存溢出_收集数据   当出现Java堆内存溢出的时候，需要收集数据有heapdump、垃圾回收日志、javacore文件、目录/logs下的其它日志和server.xml文件 堆内存转储heapdump文件 收集用途： 分析堆内存的具体使用情况 默认生成在下 垃圾回收日志 即native_stderr.log，需要手动启动，收集用途： 分析出现内存溢出的过程 确认触发内存溢出的直接原因 评估垃圾回收性能，找出合适的GC策略和调优参数 Java线程转储javacore文件 在Java内存溢出问题中自动生成，收集用途： Java线程信息、环境变量及Java变量设置，类加载信息 查看java.lang.OutOfMemoryError 其它日志 目录/logs下的其它日志和server.xml文件 hang or high CPU问题数据收集 如果在使用WAS的过程中遇到性能，挂起或高CPU问题,可能原因有： 操作系统CPU资源不足 垃圾回收消耗大量CPU资源 应用程序出现死循环/复杂递归调用 配置不恰当 可以通过下面方法收集诊断和解决问题所需的数据。 AIX系统收集方法 IBM提供了一个脚本去收集，脚本名称：aixperf.sh 需要用root用户执行，并且确保有执行权限，脚本收集信息如下： aixperf_RESULTS.tar.gz 三个javacore 目录/logs下所有 官方链接： AIX系统中WAS性能问题 Linux系统收集方法 IBM同样提供了一个脚本去收集，脚本名称：linperf.sh 需要用root用户执行，并且确保有执行权限，脚本收集信息如下： linperf_RESULTS.tar.gz 三个javacore 目录/logs下所有 官方链接： Linux系统中WAS性能问题 Windows系统收集方法 官方链接： Windows系统中WAS性能问题 crash宕机_收集数据   crash是应用程序服务器因为软件的原因进程意外终止；crash和线程挂起的区别是crash时候进程不在了，线程挂起进程还在，一般出现此故障原因： 垃圾回收异常 JIT(Just-In-Time)异常 应用程序访问了错误的内存地址 本地内存溢出 栈指针超出了线程栈的限制 JNI(Java Native Interface)调用异常 主要需要收集 javacore，通常自动生成 目录/logs下所有日志 运行时日志：SystemOut.log,;SystemErr.log JVM日志：native_stderr.log;native_stdout.log ffdc日志 系统core文件：目录下；系统/tmp目录下；目录下 操作系统数据收集 AIX 系统需要收集信息如下： errpt信息：记录系统事件和系统报错 dbx输出：提供native堆栈信息 Linux 系统需要收集信息如下： gdb输出 libsgrabber Installation Manager数据收集 Installation Manager图形（GUI）界面收集数据 步骤如下： 启动Installation Manager 在菜单栏中，转到“Help”，然后选择“Export data for problem analysis” 在“ Export Data”窗口中，选择名称和位置以保存包含问题分析数据的.zip文件 单击“OK”，然后退出安装管理器   如果是第一次在Linux上安装Installation Manager，或者在Linux上升级Installation Manager的现有版本，请运行以下命令。此命令旨在单行显示： rpm -qa --qf \"%-20{NAME} %-10{VERSION} %-10{RELEASE} %-10{ARCH}\\n\" >/tmp/rpmlist.txt   将以下文件组收集到单个zip或tar文件中，然后将它们发送给IBM进行进一步分析: 从Installation Manager生成的.zip文件 WAS_HOME/logs中的所有文件（如果存在“ logs”目录） 静默响应文件（如果使用响应文件安装产品） 如果适用于您的方案，则在先前步骤中生成的/tmp/rpmlist.txt文件 （可选）收集下面“可选其它数据”部分中列出的信息 Installation Manager命令行（imcl）界面收集数据 步骤如下： 浏览至安装Installation Manager的位置中的eclipse/tools子目录 运行imcl命令将数据导出到选择的文件中（文件名使用“ .zip”扩展名）： Windows: imcl.exe exportInstallData UNIX and Linux: ./imcl exportInstallData z/OS: ./imcl exportInstallData 剩下步骤同上，需要传送给IBM的数据信息也是同上。 在z/OS上收集Installation Manager的数据 使用imcl实用程序为z/OS上的Installation Manager收集数据，见上面描述。 可选其它数据   安装程序将写入一些其它数据，这些数据可能有助于验证安装是否完成，收集方法和步骤如下： 收集以下两个文件： WAS_HOME/properties/version/installed.xml WAS_HOME/properties/version/history.xml 收集.was.installlocation.registry文件，位置会有所不同，取决于运行的操作系统的用户： 管理员或root用户 AIX：/usr/.ibm HP-UX, Linux, Solaris：/opt/.ibm Windows：Windows directory 非管理员或非root用户 AIX, HP-UX, Linux, Solaris：/.ibm Windows：\\.ibm 当Installation Manager无法自动收集数据时手动收集   如果Installation Manager发生故障并且无法生成用于问题分析的数据，那么可以手动收集问题分析所需的文件。找到Installation Manager的Agent Data directory，然后压缩该目录的全部内容,建议使用zip格式。  注意，Agent Data directory与安装Installation Manager的位置不同。具体取决于您是以管理员身份（根用户），非管理员用户身份（非root用户）还是以组模式安装。如果不知道具体目录，可以参考官方文档：default Agent Data location for Installation Manager 官方参考 官方参考链接：MustGather:Installation Manager issues for installing and updating WebSphere Application Server V8.0, V8.5, and V9.0 类加载问题 收集步骤：1) 使用以下跟踪字符串启用和收集Application Server traces： com.ibm.ws.classloader.*=all Static trace: 登录到管理控制台 在左侧面板中，展开Troubleshooting,单击Logs and Trace 选择要跟踪的应用程序服务器，然后在下一页上单击Diagnostic Trace链接 选择Configuration选项卡。 在Trace Output下，选择File单选按钮并指定File Name。另外，将Maximum file size增加到100 MB，并将Maximum number of historical files增加到10 选择Basic (Compatible) Trace Output Format,除非IBM支持人员另有说明 在同一面板上，单击右侧面板上Additional Properties下的Change Log Detail Levels 在Configuration tab选项卡下，通过输入特定于您要为其收集数据的MustGather文档的跟踪字符串来指定Trace Specification 单击Apply和OK,然后Save配置（选择Synchronize changes with Nodes选项） 重新启动服务器以开始tracing Dynamic trace: 登录到管理控制台 在左侧面板中，展开Troubleshooting,单击Logs and Trace 选择要跟踪的应用程序服务器，然后在下一页上单击Diagnostic Trace链接 选择Runtime选项卡（服务器应已启动并正在运行，此选项卡才能显示） 在Trace Output下，选择File单选按钮并指定File Name。另外，将Maximum file size增加到100 MB，并将Maximum number of historical files增加到10 重要提示：如果不希望此设置成为永久设置，不要选择Save Runtime Changes to Configuration as well 在同一面板上，单击右侧面板上Additional Properties下的Change Log Detail Levels 选择Runtime选项卡 在Trace Specification下，输入要为其收集数据的特定MustGather的跟踪字符串 单击Apply和OK,然后Save配置（选择Synchronize changes with Nodes选项） 服务器不需要重新启动 Stopping trace: 在适当的跟踪选项卡（Configuration and/or Runtime）中，从Trace Specification中删除跟踪字符串 单击Apply和OK,然后Save配置（选择Synchronize changes with Nodes选项） 2) 通过管理控制台启用Java™虚拟机（JVM）类加载器跟踪: 选择Servers，选择Application servers，然后选择要配置的服务器 在Server Infrastructure部分中，打开ava and Process Management，然后选择Process Definition 在Additional Properties下，选择Java Virtual Machine 选中Verbose class loading复选框。 将以下字符串添加到Generic JVM arguments field字段中：Dws.ext.debug = true -Dws.osgi.debug 单击OK 3) 保存更改,停止服务器;4) 清除JVM和OSGi类缓存,有关更多详细信息，请参阅如何清除WebSphere类高速缓存;5) 备份和删除此WebSphere进程的所有WebSphere日志文件（SystemOut .log，SystemErr .log，native_stderr.log，native_stdout.log，startServer.log，stopServer.log和trace.log）。 日志文件位于以下目录中： / logs / server_name / * 清除所有WebSphere Application Server FFDC日志。FFDC文件位于以下目录中： / profile_name / logs / ffdc / * 注意：如果已配置为将FFDC日志文件写入其他位置，请相应地清除它们。 6 )重新启动服务器,重现该问题。确保在WebSphere日志（SystemOut.log）和跟踪文件（trace.log）中生成了类加载器异常 7 )针对问题概要文件运行收集器工具: Gathering information with the collector tool - V8.5 Gathering information with the collector tool - V9.0 参考链接 官方参考链接： Classloader problems for WebSphere Application Server Setting up a trace in WebSphere Application Server How to clear the WebSphere class caches "},"06-IBM_Database&Middleware&Other/02-Websphere_Application_Server/02-WAS-常见问题处理.html":{"url":"06-IBM_Database&Middleware&Other/02-Websphere_Application_Server/02-WAS-常见问题处理.html","title":"WAS-常见问题处理","keywords":"","body":"WAS-常见问题处理 WAS常见问题有两类，配置相关问题和性能相关问题。 内存溢出问题 WAS使用的内存类型 Jave堆内存(Java heap)： 存放Java对象的内存空间 通过-Xms(初始堆大小)和-Xmx(最大堆大小)设置，并在运行过程中由JVM动态调整 本地内存(native memory): JavaD对象职位使用的一些内存 不能手动设置，等于进程可以总内存减去Java最大堆内存 64位的WAS环境寻址空间非常大，本地内存理论上也可以设置很大 32位的WAS： AIX:2.75G-Xmx(Xmx Linux:3G-Xmx Windows:2G-Xmx Java堆内存溢出分类 大对象分配： 大于64KB即为大对象 可添加JVM参数找出大对象：-Xdump:stack:events=allocation,filter=#5m 堆内存耗尽： 内存泄漏 内存使用量短时间内达到最大值（如很大的数据库查询结果集） 堆内存碎片化（主要是V6及以前版本，几乎没有在使用的）： pinned objedts不可移动的对象 查看堆内存使用量 查看方法：登录到WAS管理控制台-->监控和调整-->性能查看器-->当前活动-->(服务器名称)-->性能模块看到的内存使用量的曲线图一半两种状态： 锯齿状，说明比较稳定，是正常情况 持续增长或指数增长型，当增长到最大堆后，将无法分配新的内存，就会出现内存溢出。 需要收集的数据 收集数据方法参考上一篇文章：WAS-数据收集 本地内存溢出 常见原因及建议： 最大堆设置过大：减小最大堆 java.lang.TreadLocal泄露本地内存：设置WebContainer线程池最大值等于最小值 AIO:DirectByteBurrer泄露本地内存：设置WebContainer定制属性：com.ibm.ws.webcontainer.channelwritety pe=sync JIT(Just-In-Time)编辑器内存泄露：禁用JIT Classloader及其它JNI调用内存泄露：分析系统core文件 现象： 通常不会生成heapdump，生成系统core，然后导致crash 64位环境可能表现为WAS进程的总内存不断增大 官方介绍链接： Native Memory Issues on Linux Native Memory Issues on AIX WAS响应慢&线程挂起&CPU高 WAS响应慢&线程挂起 一般情况下WAS响应慢原因： HTTP服务器和插件导致 Java堆内存配置不合理 数据连接池问题 WebContainer线程池 网络质量问题 数据库性能问题 线程挂起是JVM不再响应客户端请求的一种状态，现象可表现为： WAS访问端口(9080)连接数高 应用程序首页无法打开 SystemOut.log日志中出现WSVR0605W 可能导致线程挂起的原因： 线程死锁：A线程等待B线程正在使用的某个资源，同时B线程也在等待A线程正在使用的某个资源 应用程序代码问题：部分代码效率不高，在业务压力大的时候称为性能瓶颈 线程池和&或数据源配置不合理 数据库和&或其它后天系统存在性能问题 垃圾回收效率低下，GC开销过大 系统物理资源瓶颈：物理内存不足，换页空间使用率高，I/O过高 高CPU问题 造成WAS高CPU的主要原因和分析思路： 垃圾回收消耗大量CPU资源： 通过tprof/top定位问题 分析垃圾回收日志找出消耗资源的原因 通过-Xgcpolicy设置合适的垃圾回收策略 调整其它垃圾回收相关的JVM参数 应用程序出现死循环，复杂递归调用或消耗资源的操作： 通过tprof/top定位问题线程 对应到javacore里找到问题线程的Java堆栈信息，将此堆栈信息提供给程序开发任意，继续排查程序问题 配置不恰当： 单个线程消耗的CPU都不高 垃圾回收基本正常 线程数量很多 系统CPU资源不够： 物理CPU个数太少 CPU出现排队等待现象(vmstat) 需要收集的数据 收集数据方法参考上一篇文章：WAS-数据收集 官方介绍链接： Performance,hang,orhigh CPU issues with WAS on AIX Performance,hang,orhigh CPU issues with WAS on Linux Performance,hang,or high CPU issues on Windows WAS carsh(宕机) 应用程序服务器因为软件方便的原因进程意外终止的一种故障。carsh和线程挂起的区别：carsh进程不在，线程挂起进程还在。 WAS carsh常见原因： Segmentation Violation：应用程序访问了错误的内存地址 Native Stack Overflow：栈指针超出线程栈的限制 本地内存溢出：OutOfMemortError,无法使用malloc方法分配到内存 垃圾回收异常： 垃圾回收的过程中出现异常 垃圾回收后出现异常，说明可能存储内存故障 JIT(Just-In-Time)异常： 编译过程中出现异常 编译输出的本地代码异常，导致WAS执行时出错 JNI(Java Native Interface)调用异常 程序中调用到了本地库文件，或程序中的第三方代码使用了本地库文件，如JDBC驱动，MQ库文件，CM库文件 需要收集的数据 收集数据方法参考上一篇文章：WAS-数据收集 Installation Manager issues 使用Installation Manager安装和更新WAS的问题。官方参考链接：Troubleshooting : IBM Installation Manager and WebSphere Application Server Installation Common Issues "},"06-IBM_Database&Middleware&Other/02-Websphere_Application_Server/03-WAS-其它报错处理.html":{"url":"06-IBM_Database&Middleware&Other/02-Websphere_Application_Server/03-WAS-其它报错处理.html","title":"WAS-其它报错处理","keywords":"","body":"WAS-其它报错处理 遇到的一些报错的处理过程。 WAS启动问题 启动WAS agent时候报错 报错代码：JVMJ9TI001E和JVMJ9VM015W，示例： JVMJ9TI001E Agent library am_ibm_16 could not be opened (Could not load module . System error: No such file or directory) JVMJ9VM015W Initialization error for library j9jvmti29(-3): JVMJ9VM009E J9VMDllMain failed 原因：This is caused due to incorrect permissions or missing libraries in the toolkit dir. IBM官方说明：WAS agent fails with \"JVMJ9TI001E Agent library am_ibm_16 could not be opened errors\" when starting. WAS server启动时报错 SystemOut.log里面事件示例： [21-1-7 19:45:10:458 CST] 0000006c wtp E org.eclipse.jst.j2ee.commonarchivecore.internal.strategy.DirectoryLoadStrategyImpl addFileFromBinariesDirectory Failed to open archive [ WEB-INF/lib/poi-3.11.jar ] [21-1-7 19:45:10:460 CST] 0000006c wtp W org.eclipse.jst.j2ee.commonarchivecore.internal.impl.CommonarchiveFactoryImpl openNestedArchive An error occurred while opening a nested archive: error in opening zip file [21-1-7 19:45:10:461 CST] 0000006c wtp W org.eclipse.jst.j2ee.commonarchivecore.internal.impl.CommonarchiveFactoryImpl openNestedArchive Base exception java.util.zip.ZipException: error in opening zip file at java.util.zip.ZipFile.open(Native Method) at java.util.zip.ZipFile.(ZipFile.java:150) at java.util.zip.ZipFile.(ZipFile.java:166) ... 停止服务器并确认没有java进程后先清除一下缓存，删除下面示例目录中文件: /home/wasusr/IAMServer01/temp/* /home/wasusr/IAMServer01/wstemp/* /home/wasusr/IAMServer01/configuration/* /home/wasusr/IAMServer01/servers/BIMServer01/* 执行脚本： /home/wasusr/IAMServer01/bin/osgiCfgInit.sh /home/wasusr/IAMServer01/bin/clearClassCache.sh 然后再启动WAS。 SystemOut.log里如果还有如下报错： Caused by: java.io.FileNotFoundException: /home/wasusr/IAMServer01/logs/ffdc/BIMServer01_exception.log (打开的文件过多) 代表当前OS的ulimit参数里nofiles值比较低，例如1024,建议增大至8096 (如果使用ulimit命令设置重新启动后会失效，查看修改/etc/limits文件) 如果启动server还有错，收集新的SystemErr.log和SystemOut.log，以及下面内容： ulimit -a > ulimit.txt ls /home/wasusr/IBM/WebSphere/AppServer > ls.txt 待补充 "},"06-IBM_Database&Middleware&Other/02-Websphere_Application_Server/04-WAS-故障处理实例.html":{"url":"06-IBM_Database&Middleware&Other/02-Websphere_Application_Server/04-WAS-故障处理实例.html","title":"WAS-故障处理实例","keywords":"","body":"WAS-故障处理实例 记录几个故障处理实例。 Out Of Memory 发生内存溢出后，根据之前说明收集相应的数据。 示例一：Java堆OOM   分析javacore，从javacore里看到Java堆已经扩展到最大堆4G，只剩11m，几乎用尽，此种类型属于Java堆OOM，javacore里面信息示例： /javacore.20210108.200305.7955.0003.txt | 8,022,601 bytes Server Name: fxqapp02Node01Cell\\fxqapp02Node01\\server1 Dump Event \"systhrow\" (00040000) Detail \"java/lang/OutOfMemoryError\" \"Java heap space\" received JRE 1.7.0 Linux amd64-64 build 20130421_145945 (pxa6470sr4fp1ifix-20130423_02(SR4 FP1+IV38579+IV38399+IV40208) ) OS Level : Linux 2.6.32-573.26.1.el6.x86_64 How Many : 8 -Xms512m -Xmx4096m -verbose:class,gc -verbose:jni Total memory free: 11,826,296 (0x0000000000B47478) = 11M Total memory in use: 4,283,075,464 (0x00000000FF4A8B88) = 4085M Total memory: 4,294,901,760 (0x00000000FFFF0000) = 4096M 分析heapdump​，可以看到内存使用情况，示例如下： Problem Suspect 1 One instance of \"org.apache.ibatis.executor.result.DefaultResultHandler\" occupies 3,513,427,680 (87.77%) bytes. The memory is accumulated in one instance of \"java.lang.Object[]\". Class Name | Shallow Heap | Retained Heap | Percentage ----------------------------------------------------------------------------------------------------------------------- org.apache.ibatis.executor.result.DefaultResultHandler @ 0x352e55c0 Unknown| 16 | 3,513,427,680 | 87.77% '- java.util.ArrayList @ 0x352e7bd0 | 24 | 3,513,427,664 | 87.77% '- java.lang.Object[1215487] @ 0xb5e7e830 | 4,861,968 | 3,513,427,640 | 87.77% |- java.util.HashMap @ 0x9466a448 | 48 | 3,120 | 0.00% |- java.util.HashMap @ 0x66296e10 | 48 | 3,104 | 0.00% |- java.util.HashMap @ 0x66296e40 | 48 | 3,104 | 0.00% |- java.util.HashMap @ 0x946592b8 | 48 | 3,104 | 0.00% |- java.util.HashMap @ 0x94669458 | 48 | 3,104 | 0.00% ...... |- java.util.HashMap @ 0x946694e8 | 48 | 3,072 | 0.00% '- Total: 25 of 1,166,800 entries; 1,166,775 more | | | ----------------------------------------------------------------------------------------------------------------------- Javacore里看到有多个线程有类似的堆栈，例如：​ ===== 3XMTHREADINFO \"WebContainer : 9\" J9VMThread:0x00000000054B9200, j9thread_t:0x00007F516C0D11E0, java/lang/Thread:0x00000000129862D0, state:R, prio=5 3XMTHREADINFO3 Java callstack: 4XESTACKTRACE at java/net/SocketInputStream.socketRead0(Native Method) 4XESTACKTRACE at java/net/SocketInputStream.read(SocketInputStream.java:161(Compiled Code)) 4XESTACKTRACE at java/net/SocketInputStream.read(SocketInputStream.java:132(Compiled Code)) 4XESTACKTRACE at oracle/net/ns/Packet.receive(Bytecode PC:31(Compiled Code)) 4XESTACKTRACE at oracle/net/ns/DataPacket.receive(Bytecode PC:1(Compiled Code)) 4XESTACKTRACE at oracle/net/ns/NetInputStream.getNextPacket(Bytecode PC:48(Compiled Code)) ......   在上面示例中，从heapdump分析结果来看是ibatis​相关\"org.apache.ibatis.executor.result.DefaultResultHandler\"里保存了大量的对象，占用较多内存，需要应用检查此对象为何占用内存比较多。  遇到oom之后，Java的垃圾回收会尝试回收不使用的对象，释放资源；如果对象不再使用，可以被回收，有足够的资源来进行新对象的分配就可以恢复；但是如果Java堆里面的对象都是被占用的，那么垃圾回收是不会释放这些资源，​结果就是频繁的global gc，性能会比较差，server无法响应请求，可以查看垃圾回收日志查看使用曲线。​  出现oom的时候数据库和网络方面是否正常？如果这么大的对象都是正常需求，比如高业务请求时需要申请这么多对象，那么可以通过增加server，或者增加Java堆大小的方式来规避oom。​  另外，如果开启了开启了class 和jni的trace，如果在生成环境，并且问题已经解决，建议关闭，对性能会有一定的影响。​ 待补充 "},"06-IBM_Database&Middleware&Other/03-Websphere_MQ/":{"url":"06-IBM_Database&Middleware&Other/03-Websphere_MQ/","title":"Websphere_MQ","keywords":"","body":"Websphere_MQ 简介   IBM MQ 是一款企业级消息传递解决方案，能够安全、可靠地连接多个平台的应用、系统、服务及文件。MQ 能够通过队列系统，在这些作业点之间传输数据，确保在网络或应用出现故障时，实现稳定交付。 官方网站：IBM MQ 内容 MQ-数据收集 MQ-连接通道问题 "},"06-IBM_Database&Middleware&Other/03-Websphere_MQ/01-MQ-数据收集.html":{"url":"06-IBM_Database&Middleware&Other/03-Websphere_MQ/01-MQ-数据收集.html","title":"MQ-数据收集","keywords":"","body":"MQ-数据收集 MQ错误日志存放在一个固定的目录，通常MQ出问题去里面查看错误代码，在诊断MQ故障过程中，只有此错误日志是不够的，还有很多日志需要收集。 错误日志目录 在安装MQ 时候就会自动创建errors目录，包含三个错误日志文件： AMQERR01.LOG AMQERR02.LOG AMQERR03.LOG 知道队列管理器名称 Unix 和Linux系统：/var/mqm/qmgrs//errors Windows系统：\\QMGRS\\\\ERRORS\\AMQERR01.LOG 队列管理器名称未知 Unix 和Linux系统：/var/mqm/errors Windows系统：\\@SYSTEM\\ERRORS\\AMQERR01.LOG 有条件可以通过命令dspmq查看队列管理器名称，查看所有示例： dspmq -o all 客户端应用程序发生错误,客户端上目录 Unix 和Linux系统：/var/mqm/errors Windows系统：\\ERRORS\\AMQERR01.LOG IBM i 上日志目录 队列管理器可用：/QIBM/UserData/mqm/qmgrs//errors 队列管理器不可用：/QIBM/UserData/mqm/errors AS400系统上查看可用用程序EDTF: EDTF '/QIBM/UserData/mqm/errors' 故障数据收集 发生故障时候，特别是比较复杂故障，上面的日志信息是不够的，需要收集完整的MQ故障诊断信息。 IBM MQ中使用runmqras命令来收集IMQ故障诊断信息，然后给IBM MQ支持工程师，可以准确判断故障原因。 注意： 命令runmqras需要的Java7或更高版本的Java运行时环境（JRE）才能运行 命令runmqras不会收集队列中消息中包含的用户信息。 默认情况下，runmqras收集以下信息： IBM MQ FDC文件 错误日志（来自所有队列管理器以及机器范围的IBM MQ错误日志） 产品版本控制，状态信息以及其他各种操作系统命令的输出。 收集方法如下： runmqras -qmlist -section defs 会生成一个以runmqras开头的.zip文件，拷贝出来发送给IBM 支持中心工程师即可。 如果IBM工程师需要更多信息参照IBM MQ工程师给的命令参数进行收集。 命令runmqras更多用法可以参照官方介绍：MQ runmqras命令介绍 "},"06-IBM_Database&Middleware&Other/03-Websphere_MQ/02-MQ-连接通道问题.html":{"url":"06-IBM_Database&Middleware&Other/03-Websphere_MQ/02-MQ-连接通道问题.html","title":"MQ-连接通道问题","keywords":"","body":"MQ-连接通道问题 MQ作为消息传递中间件，channel是重要的组件，出现问题了也直接影响应用。 通道基本操作 常用关于通道MQSC命令： 命令 描述 DISPLAY CHANNEL (*) 显示所有通道 DISPLAY CHANNEL (ChannelName) 显示某一通道 START CHANNEL(ChannelName) 启动某一通道 STOP CHANNEL(ChannelName) 停止某一通道 更多MQSC命令：使用MQSC命令管理MQ 对于查看连接数，可以在操作系统上使用如下方法： netstat -an | grep 1414 >1 wc -l 1 通道连接问题 报错示例 服务器端报错示例： AMQ9999:Channel 'Channel name' to host 'hostnamne(ip address)' ended abnormally. AMQ9513:Maximun number of channels reached. host端报错示例： AMQ9202:Remote host 'hostname(ip address)(7007)' not available,retry later 故障分析 AMQ9202是channel连接问题，可能原因： 侦听器(listener)未运行 inetd.conf中的设置不正确 QMGR没有运行 队列远程服务器的rname或rqmname中的路由信息​​不正确 通道conname或xmitq中的路由信息​​不正确 故障分析分析过程： AMQ9202报错中信息：The return code form TCP/IP is 78(X'4E),The reason for the failure may be that this host cannot reach the destination host。 code 78(X'4E)是连接超时，结合服务端的AMQ9999和AMQ9513报错，问题应该由于连接数超过最大值导致到服务端连接出现异常 连接数达到最大值可能是由于部分通道不停尝试连接，建议检查连接的网络是否有有异常或者通道是否启用。 解决建议 基本建议： 如果确认部分通道未启用：建议关掉这些通道 如果确认所有通道是启用的：建议排查网络是否有问题 MQ参数配置建议：  可以通过增加或者修改部分参数来优化连接数的问题，可以避免一些无效连接导致连接计数值过大。建议在/VAR/MQM/QMGRS/QM_EFSSV2_1041/QM.INI增加或者修改部分参数，建议如下： CHANNELS: MaxChannels=500 MaxActiveChannels=500 AdoptNewMCA=ALL AdoptNewMCACheck=ALL 参数描述如下：MaxChannels和MaxActiveChannels：  分别代表队列管理器允许配置的通道的最大个数和允许同时运行的通道的个数，这对于大并发的Client/Server间通讯尤为重要。 AdoptNewMCA=ALL：  当MQ接收到启动通道的请求，但是同时它发现与该通道对应的amqcrsta的进程已经存在，这时，该进程必须首先被停止，然后，通道才能启动。AdoptNewMCA的作用就是停止这种进程，并且为新的通道启动请求启动一个新的进程。  该属性可以将状态处于running状态的接收端通道强行终止，从而使发送端的通道启动或请求操作得以成功。如果为某一通道指定了AdoptNewMCA的属性，但是新的通道由于\"channel is already running\"而启动失败，则它可以： 新的通道通知之前的通道停止； 如果旧的通道在AdoptNewMCATimeout的时间间隔内没有接受该停止请求，相应的进程(或线程)被kill掉； 如果旧的通道经过步骤2仍未终止，则当第二个AdoptNewMCATimeout时间间隔到达时，MQ终止该通道，同时产生\"channelin use\"的错误。 其它常见问题 其它常见问题可以参考官方说明：常见MQ消息和可能原因 "},"06-IBM_Database&Middleware&Other/04-Filenet/":{"url":"06-IBM_Database&Middleware&Other/04-Filenet/","title":"Filenet","keywords":"","body":""},"06-IBM_Database&Middleware&Other/05-Cognos/":{"url":"06-IBM_Database&Middleware&Other/05-Cognos/","title":"Cognos","keywords":"","body":"Cognos 简介   IBM发布了基于IBM Cognos Analytics的全新全球互动式仪表板，显示新冠病毒在全球范围的传播。公众、研究人员、数据科学家和媒体可以利用这个仪表板，对地区数据进行更深入的分析和过滤。这个仪表板中反映的新冠病毒数据来自各个国家和地方政府以及世界卫生组织：新冠疫情数据仪表盘 官方网站：IBM Cognos Analytics 内容 Cognos-数据收集 Cognos-常见问题 "},"06-IBM_Database&Middleware&Other/05-Cognos/01-Cognos-数据收集.html":{"url":"06-IBM_Database&Middleware&Other/05-Cognos/01-Cognos-数据收集.html","title":"Cognos-数据收集","keywords":"","body":"Cognos-数据收集 Cognos接触不多，目前也就收集过两种日志。 JDBC trace   JDBC(Java DataBase Connectivity)连接数据库出现问题时候，可以抓JDBC trace,可以追踪到一下Cognos发送到oracle端的具体内容信息，JDBC trace更改操作如下:a. 找到并打开cognos/CA11/configuration/xqe.diagnosticlogging.xml文件: b. 将文件中的更改为;c. 如果需要了解驱动程序正在进行哪些方法调用（收集此信息根据IBM工程师建议）：将修改为；d. 修改完成后示例： e. 将更改保存到文件，不需要重新启动（这是Cognos Analytics 11版本说明，有条件的话，还是建议重启Query Service或者整个Cognos去激活这个配置），在进行更改后等待30秒钟，重新问题即可;f. 在Cognos安装目录下的...log/xqe目录中，在故障发生后，将故障点的日志取出。在收集所需的日志文件后，通过还原原始xqe.diagnosticlogging.xml文件来禁用跟踪。 XQE dump日志 收集Cognos的XQE dump日志，，需要更改日志收集策略，方法如下：a. 找到并打开cognos/CA11/configuration/xqe.config.xml文件；b. 找到如下字段： c. 在b中的字段中加入如下字段： Xdump:system:events=systhrow+throwˆfilter=com/ibm/cognos/jdbc/adaptor/sqlexception/SQLCognosInvalidLogonExceptionˆrange=1..1ˆrequest=serial+compact+prepwalk) into the xqe.config.xml d. 最终变成如下字段： e. 修改目的是专门抓去invalid logon信息的，一旦无法登录到数据源错误发生，立马会在...log/xqe文件夹下产生dump，故障发生后取出即可。 "},"06-IBM_Database&Middleware&Other/05-Cognos/02-Cognos-常见问题.html":{"url":"06-IBM_Database&Middleware&Other/05-Cognos/02-Cognos-常见问题.html","title":"Cognos-常见问题","keywords":"","body":"Cognos-常见问题 无法登录到数据源 报表无法查看,检查发现Cognos有报错，报错信息和现场如下： Failure QE-DEF-0285 登录失败。XQE-DS-0006 无法登录到数据源。ORA-28000: the account is locked Failure QE-DEF-0285 登录失败。XQE-DS-0006 无法登录到数据源。ORA-01005: null password given; logon denied 尝试重启Cognos后，Cognos可以正常连接到oracle数据库，报表可以正常查看，但是不定时会出现此报错，再次无法连接oracle数据库， 初步分析过程 初步操作建议： 建议在发生故障时候不重启Cognos，可以单独重启Cognos中的Query Service。如果确认有效，可以在故障发生时候快速恢复，不需要重启整个Cognos耗费比较长时间。重启Query Service步骤： 依次选择：IBM Cognos Administration-->系统-->服务-->查询 选中Query Service右边下三角，然后选中stop immediately先关掉，然后在选中start进行启动 此台Cognos服务采用JDBC (Java DataBase Connectivity,java数据库连接)方式连接到oracle数据库，建议进行JDBC trace，可以追踪到一下Cognos发送到oracle端的具体内容信息，JDBC trace更改操作见Cognos-数据收集 收集Cognos的XQE dump日志，需要更改日志收集策略，方法见Cognos-数据收集 收取日志   在根据上面步骤修改好配置后，当再次发生报表系统使用不了，检查依然是Cognos连接oracle出现报错，故障类型一样，根据IBM Cognos工程师建议，进行如下操作： 重启Query Service，重启后尝试进行连接oracle，测试正常，报表系统正常使用； 通过此操作可以在未准确定位故障前快速进行临时恢复，整个过程不超过1分钟； 在Cognos的...log/xqe目录下取出故障点的JDBC trace日志和XQE dump日志； 将Query Service重启后的结果反馈给IBM Cognos工程师，同时将抓取到的日志上传到IBM专用日志分析服务器给IBM Cognos工程师进行分析。 故障分析和解决   Cognos采用JDBC (Java DataBase Connectivity,java数据库连接)方式进行连接oracle数据库，连接属性配置等都是在JDBC里面配置，根据分析，JDBC驱动问题也会导致此类型报错，建议ojdbc5.jar 换成 ojdbc6.jar（或者ojdbc7.jar），并且对应相应oracle数据库版本。  在示例故障中JDBC版本不匹配导致（数据库版本是11.2.0.4.0，JDBC的驱动版本是11.2.0.3.0），可能是近期用户升级了oracle数据库： 建议在闲暇时段停止Cognos服务，在Cognos连接的oracle（版本11.2.0.4.0）数据库的程序文件中取出了JDBC驱动，替换了Cognos中的JDBC驱动，此目的是为了保证一致性；同时从oracle官网下载11.2.0.4.0版本的JDBC驱动备用，下载地址oracle JDBC 更新驱动后Cognos能正常连接到数据库，但是由于之前故障是间歇性的，故需要进行持续观察，长时间观察后，并没有再次发生故障，报错ORA-01005: null password given; logon denied的问题得到解决。 数据库用户锁死分析和临时解决方法:  报错日志中ORA-28000: the account is locked报错，此报错是因为数据库密码锁死导致。Oracle工程师根据分析是由于Cognos频繁发送无效密码导致。Cognos工程师分析是由于Cognos报错ORA-01005: null password given; logon denied导致；  在操作系统层面Oracle数据库用户密码有重试次数限制，由于Oracle影响其它应用访问此数据库，故可以将此数据库的密码策略临时进行更改（不设重试错误次数被锁限制），避免Cognos连接不上oracle时候持续发生无效密码导致数据被锁。在后续观察中，Cognos出现ORA-01005: null password given; logon denied报错后，数据库用户没有被锁死，临时避免了Cognos连接数据库故障时候锁死用户。 问题解决后建议： 在前面内容中提到的抓取JDBC trace日志和XQE dump日志进行的修改进行还原，因为日志持续增长，服务器存储空间有限； 在JDBC连接问题观察一段时间后不再出现，说明问题解决了，那么可以将oracle用户的密码策略恢复到初始状态; 如果数据库进行了更新，建议同时更新Cognos端的JDBC驱动； 如还有其它平台Cognos在使用，建议检查JDBC版本，尽量和数据库版本保持一致。 其它问题 内容库报错 日志中有内容库的报错时候，建议做一个consistency check，检查内部即可。检查方法连接如下：Creating and running a content store consistency check CAM报错 在日志中有中有CAM的报错，建议重新生成crypto keys，官方参考链接如下：How to Regenerate Cryptographic Keys as of Cognos 缓存清理 清除query service缓存，清除方法如下： 在IBM Cognos Administration管理界面找到配置选项并点开，找到Query Service Caching项； 选中Query Service Caching项，在右下角点击Clear cache选项，清除状态会显示出来。 官方参考链接：Clear everything in the cache "},"06-IBM_Database&Middleware&Other/06-InfoSphere_Data_Replication/":{"url":"06-IBM_Database&Middleware&Other/06-InfoSphere_Data_Replication/","title":"InfoSphere_Data_Replication","keywords":"","body":"InfoSphere_Data_Replication 简介   IBM Data Replication-CDC Replication是一种复制解决方案，可在数据库更改发生时捕获它们并将它们交付到目标数据库、消息队列或ETL解决方案，例如基于IBM Data Replication管理控制台中配置的表映射的IBM DataStage®图形用户界面应用程序。 官方说明及文档主页： IBM InfoSphere Data Replication-About CDC Replication IBM InfoSphere Data Replication documentation 内容 "},"06-IBM_Database&Middleware&Other/06-InfoSphere_Data_Replication/01-CDC-安装与卸载.html":{"url":"06-IBM_Database&Middleware&Other/06-InfoSphere_Data_Replication/01-CDC-安装与卸载.html","title":"CDC-安装与卸载","keywords":"","body":"CDC-安装与卸载 IBM i安装与卸载 官方参考链接： Installing the CDC Replication Engine for Db2 for i version 11.4 11.4.0-Uninstalling the CDC Replication Engine for Db2® for i 安装CDC 系统要求   CDC要求您分配一个端口以与运行管理控制台和其他服务器的客户端工作站进行通信。这些端口必须可以通过防火墙访问。具体说明如下表： 协议 默认端口 IN/OUT 目的 TCP 11111 IN 接受来自管理控制台、访问服务器、命令行实用程序和其他CDC Replication安装的连接作为复制源 UDP 2222 IN 仅当在Access Server 10.2.1及更早版本中启用了自动发现功能时，才需要此端口。该端口侦听来自访问服务器的广播，该服务器检测所有正在运行的CDC Replication安装 TCP 11111 OUT 在管理控制台中添加订阅时，如果订阅使用配置为数据源的数据存储(源数据存储)，那么需要一个TCP端口，以便订阅可以连接到目标数据存储 UDP 10101 OUT Auto-discovery回复在此端口上发送回Access Server。默认开启Auto-discovery 软硬件、磁盘、内存等要求官方参考链接：System requirements for CDC Replication Engine for Db2® for i 用户登录 建议创建专门的用户进行安装，用户要求如下： 需要有权限：*SECADM,*JOBCTL,*ALLOBJ,*SAVSYS,*AUDIT,*IOSYSCFG,*SPLCTL 不要使用D_MIRROR用户 例如创建CDCADMIN用户： CRTUSRPRF USRPRF(CDCADMIN) SPCAUT(*SECADM *JOBCTL *ALLOBJ *SAVSYS *AUDIT *IOSYSCFG *SPLCTL) 安装文件及程序准备 将安装文件通过FTP等传输到系统指定库，例如叫IBMTEMP，然后使用下面命令恢复安装程序： RSTOBJ OBJ(DMCINSTALL) SAVLIB(V11R4M0) DEV(*SAVF) SAVF(IBMTEMP/V11R4M0) RSTLIB(QTEMP) 运行安装程序 运行如下命令开启安装程序： ?QTEMP/DMCINSTALL 按F4进入安装提示屏幕，在选项中输入相关信息： Device Name：用于运行安装程序的Savefile：*SAVF Savefile Name for Product Library Name：V11R4M0，对应Library Name为存放此Savefile的库，即IBMTEMP Savefile Name for Tutorial Name：V11R4M0TUT，对应Library Name为存放此Savefile的库，即IBMTEMP，还可以输入*LIBL以指定列表中的库集 示例如下： Product Installation (DMCINSTALL) Type choices, press Enter. Device name . . . . . . . . . . *SAVF *SAVF Savefile name for product . . . V11R4M0 Name Library Name . . . . . . . . . IBMTEMP Name, *LIBL Savefile name for tutorial . . . V11R4M0TUT Name Library Name . . . . . . . . . IBMTEMP Name, *LIBL 对应命令如下： QTEMP/DMCINSTALL SAVFPROD(IBMTEMP/V11R4M0) SAVFTUTOR(IBMTEMP/V11R4M0TUT) 按Enter继续。 用户Profile选择   上一步执行后，将出现D_MIRROR User Profile Exists的提示屏幕。表明安装程序检测到存在D_MIRROR用户配置文件。此用户配置文件可能存在于先前安装的CDC Replication中。CDC Replication要求为版本11.4正确配置D_MIRROR用户配置文件： F2：保持D_MIRROR用户配置文件不变。如果用户配置文件是在安装以前的CDC Replication版本期间创建的，并且其配置未更改，则用户配置文件对于版本11.4应该仍然有效 F3：取消安装 F4：重新配置D_MIRROR用户配置文件 验证用户配置文件是否配置正确： DSPUSRPRF USRPRF(D_MIRROR) 验证以下参数： Special authority：*JOBCTL Password is NONE：`YES`(密码的使用是可选的) Set password to expired：*NO Message queue：QUSRSYS/D_MIRROR 按Enter继续。 许可协议 屏幕上显示的软件许可协议中的条款，按F2接受并开始安装。然后按Enter继续。 指定产品和教程库 在Product and Tutorial Library屏幕中输入下面信息： Product Library：要安装CDC Replication的库的名称。默认是DMIRROR Tutorial Library：要安装教程表的库的名称（可选），默认是DTUTOR 必须将CDC Replication和教程表安装到不同的库中 Product IASP Device：要安装CDC Replication的IASP设备的名称： 如果要在IASP上安装CDC Replication，请输入IASP设备的名称 如果没有ASP设备，使用默认值*SYSBAS 如果指定了IASP设备的名称，则会出现安装类型屏幕： F(Full product installation)：将CDC Replication产品安装到指定的IASP设备中，并将所需的支持对象(*SBSD``*CLSD和*JOBQ)安装到当前连接到IASP设备的机器的系统ASP上的工作库中 W(Work library only)：仅将所需的支持对象(*SBSD``*CLSD和*JOBQ)安装到连接到IASP设备的机器的系统ASP上的工作库中： 如果已经在连接的IASP设备上安装了CDC Replication的完整产品，请指定此选项 当实现了可切换的IASP环境并需要在Secondary机器上使用另一个工作库副本时，也可以指定此选项 安装程序会自动创建工作库。工作库的名称是产品库的前八个字符加上01。例如，DMIRROR01 如果库存在，则安装程序结束，提示Work library DMIRROR01 already exists! Installation will terminate. 如果指定了现有库的名称，则会出现Existing Library Specified屏幕： 默认产品库是DMIRROR 在Replace Specified Library字段中，指定要安装CDC Replication的库的名称 如果要在指定的产品库中安装CDC Replication，请输入Y，选择Y删除该库的所有现有内容；如果要安装到不同的库中，请输入N，并指定不同库的名称 完成安装   安装程序会创建指定的库并在系统上安装CDC Replication。安装完成后，会生成一条最终消息以指示安装是否成功。如果安装不成功，则会在作业日志中放置错误消息。在再次运行安装程序之前，使用DSPJOBLOG命令来识别错误并采取必要的纠正措施。安装成功消息示例： The product installation is complete.See Installation Guide for post installation activities. 卸载CDC "},"07-Oracle_Database/":{"url":"07-Oracle_Database/","title":"Oracle_Database","keywords":"","body":"Oracel_Database 简介 Oracle Database是Oracle公司的一款关系数据库管理系统。 官方网站主页：https://www.oracle.com/index.html 官方数据库主页：https://www.oracle.com/database/ 内容 "},"07-Oracle_Database/01-Oracle学习笔记/":{"url":"07-Oracle_Database/01-Oracle学习笔记/","title":"Oracle学习笔记","keywords":"","body":"Oracle学习笔记 简介 学习主要教材或链接： 《Oracle DBA 工作笔记 运维、数据迁移与性能调优》，杨键荣编著，中国铁道出版社有限公司 Oracle Database Documentation 内容 "},"07-Oracle_Database/01-Oracle学习笔记/01-Oracle-安装与部署.html":{"url":"07-Oracle_Database/01-Oracle学习笔记/01-Oracle-安装与部署.html","title":"Oracle-安装与部署","keywords":"","body":"Oracle-安装与部署 官方软件下载链接： 甲骨文中国 Oracle软件下载 Oracle yum Oracle public-yum Oracle数据库安装 官方安装guide：Oracle Database 19c Install and Upgrade 配置YUM源 为安装依赖包，配置Oracle的YUM源： [root@redhat8 yum.repos.d]# wget http://public-yum.oracle.com/public-yum-ol7.repo --2022-05-14 13:18:55-- http://public-yum.oracle.com/public-yum-ol7.repo Resolving public-yum.oracle.com (public-yum.oracle.com)... 23.195.249.95, 2600:1409:3000:38b::2a7d, 2600:1409:3000:382::2 a7dConnecting to public-yum.oracle.com (public-yum.oracle.com)|23.195.249.95|:80... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: https://public-yum.oracle.com/public-yum-ol7.repo [following] --2022-05-14 13:18:55-- https://public-yum.oracle.com/public-yum-ol7.repo Connecting to public-yum.oracle.com (public-yum.oracle.com)|23.195.249.95|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 16402 (16K) [text/plain] Saving to: ‘public-yum-ol7.repo’ public-yum-ol7.repo 100%[=================================================>] 16.02K --.-KB/s in 0s 2022-05-14 13:18:57 (128 MB/s) - ‘public-yum-ol7.repo’ saved [16402/16402] Linux系统安装RPM Oracle官网下载的两个RPM： oracle-database-preinstall-19c-1.0-1.el7.x86_64.rpm oracle-database-ee-19c-1.0-1.x86_64.rpm 第一个RPM下载地址：Latest packages for Oracle Linux 7 (x86_64) 预安装RPM 首先安装oracle-database-preinstall-19c-1.0-1.el7.x86_64.rpm，提示： [root@redhat8 Downloads]# rpm -ivh oracle-database-preinstall-19c-1.0-1.el7.x86_64.rpm warning: oracle-database-preinstall-19c-1.0-1.el7.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID ec551f03: NOKEY error: Failed dependencies: compat-libcap1 is needed by oracle-database-preinstall-19c-1.0-1.el7.x86_64 compat-libstdc++-33 is needed by oracle-database-preinstall-19c-1.0-1.el7.x86_64 ksh is needed by oracle-database-preinstall-19c-1.0-1.el7.x86_64 libaio-devel is needed by oracle-database-preinstall-19c-1.0-1.el7.x86_64 libstdc++-devel is needed by oracle-database-preinstall-19c-1.0-1.el7.x86_64 sysstat is needed by oracle-database-preinstall-19c-1.0-1.el7.x86_64 xorg-x11-utils is needed by oracle-database-preinstall-19c-1.0-1.el7.x86_64 根据提示安装依赖包(一条命令解决发现报错，一个一个安装)： [root@redhat8 ~]# yum install compat-libcap1 [root@redhat8 ~]# yum install compat-libstdc++-33 [root@redhat8 ~]# yum install ksh [root@redhat8 ~]# yum install libaio-devel [root@redhat8 ~]# yum install libstdc++-devel [root@redhat8 ~]# yum install sysstat Oracle数据库预安装RPM自动配置Linux，例如用户等： 自动下载和安装安装Oracle Grid Infrastructure和Oracle数据库所需的任何其他RPM包，并解决任何依赖关系 创建一个oracle用户，并为该用户创建oraInventory(oinstall)和OSDBA(dba)组 根据需要，将sysctl.conf设置、系统启动参数和驱动程序参数设置为基于`Oracle数据库预安装RPM程序建议的值 设置硬资源和软资源限制 设置其他推荐参数，具体取决于安装系统环境的内核版本 在Linux x86_64机器的内核中设置numa=off 安装示例如下： [root@redhat8 Downloads]# rpm -ivh oracle-database-preinstall-19c-1.0-1.el7.x86_64.rpm Verifying... ################################# [100%] Preparing... ################################# [100%] Updating / installing... 1:oracle-database-preinstall-19c-1.################################# [100%] RPM包安装Oracle 安装示例： [root@redhat8 ~]# rpm -ivh --nodigest --nofiledigest /tmp/oracle-database-ee-19c-1.0-1.x86_64.rpm 安装报错，研究中...... 安装中出现的问题 依赖包安装问题1 安装依赖包时候提示错误： Curl error (37): Couldn't read a file:// file for file:///etc/pki/rpm-gpg/RPM-GPG-KEY-oracle [Couldn't open file /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle] 解决方法： [root@redhat8 rpm-gpg]# wget http://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol7 -O /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle --2022-05-14 13:29:05-- http://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol7 Resolving public-yum.oracle.com (public-yum.oracle.com)... 23.195.249.95, 2600:1409:3000:38b::2a7d, 2600:1409:3000:382::2 a7dConnecting to public-yum.oracle.com (public-yum.oracle.com)|23.195.249.95|:80... connected. HTTP request sent, awaiting response... 301 Moved Permanently Location: https://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol7 [following] --2022-05-14 13:29:06-- https://public-yum.oracle.com/RPM-GPG-KEY-oracle-ol7 Connecting to public-yum.oracle.com (public-yum.oracle.com)|23.195.249.95|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 1011 [text/plain] Saving to: ‘/etc/pki/rpm-gpg/RPM-GPG-KEY-oracle’ /etc/pki/rpm-gpg/RPM-GPG-KEY-o 100%[=================================================>] 1011 --.-KB/s in 0s 2022-05-14 13:29:07 (13.5 MB/s) - ‘/etc/pki/rpm-gpg/RPM-GPG-KEY-oracle’ saved [1011/1011] 再次安装即可。问题解决参考链接：Couldn't open file /etc/pki/rpm-gpg/RPM-GPG-KEY-oracle error while installing Oracle Pre-install RPM。 依赖包安装问题2 除了libstdc++-devel其他都安装成功，报错： [root@redhat8 ~]# yum install libstdc++-devel Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscription-manager to register. Last metadata expiration check: 0:05:26 ago on Sat 14 May 2022 01:33:49 PM EDT. Error: Problem: cannot install both libstdc++-4.8.5-44.0.3.el7.x86_64 and libstdc++-8.2.1-3.5.el8.x86_64 - package libstdc++-devel-4.8.5-44.0.3.el7.x86_64 requires libstdc++(x86-64) = 4.8.5-44.0.3.el7, but none of the provid ers can be installed - package aspell-12:0.60.6.1-21.el8.x86_64 requires libstdc++.so.6(CXXABI_1.3.9)(64bit), but none of the providers can be installed - cannot install the best candidate for the job - problem with installed package aspell-12:0.60.6.1-21.el8.x86_64 (try to add '--allowerasing' to command line to replace conflicting packages or '--skip-broken' to skip uninstallable pac kages or '--nobest' to use not only best candidate packages) 检查是系统中以及有一个版本： [root@redhat8 Downloads]# rpm -qa |grep libstdc++- compat-libstdc++-33-3.2.3-72.el7.x86_64 libstdc++-8.2.1-3.5.el8.x86_64 使用YUM安装怎么弄都不行，手动安装： [root@redhat8 Downloads]# rpm -ivh libstdc++-devel-8.2.1-3.5.el8.x86_64.rpm warning: libstdc++-devel-8.2.1-3.5.el8.x86_64.rpm: Header V4 RSA/SHA256 Signature, key ID 13d0a55d: NOKEY Verifying... ################################# [100%] Preparing... ################################# [100%] Updating / installing... 1:libstdc++-devel-8.2.1-3.5.el8 ################################# [100%] [root@redhat8 Downloads]# rpm -qa |grep libstdc++- compat-libstdc++-33-3.2.3-72.el7.x86_64 libstdc++-8.2.1-3.5.el8.x86_64 libstdc++-devel-8.2.1-3.5.el8.x86_64 libstdc++-devel下载地址：Libstdc++-devel Download for Linux (rpm, xbps) 安装Oracle报错1 报错如下： [root@redhat8 Downloads]# rpm -ivh oracle-database-ee-19c-1.0-1.x86_64.rpm Verifying... ################################# [100%] Preparing... ################################# [100%] package oracle-database-ee-19c-1.0-1.x86_64 does not verify: no digest 使用--nodigest和--nofiledigest解决： [root@redhat8 ~]# rpm -ivh --nodigest --nofiledigest /tmp/oracle-database-ee-19c-1.0-1.x86_64.rpm 官方参考链接：rpm error \"does not verify: no digest\" 安装RPM报错1 报错示例如下： 'AttachHome' failed. Exception in thread \"main\" java.lang.NullPointerException at oracle.sysman.oii.oiic.OiicBaseInventoryApp.main_helper(OiicBaseInventoryApp.java:706) at oracle.sysman.oii.oiic.OiicAttachHome.main(OiicAttachHome.java:696) [SEVERE] An error occurred while registering the Oracle home. Verify logs in /var/log/oracle-database-ee-19c/results/oraInstall.log and /opt/oracle/oraInventory for more details and try again.warning: %post(oracle-database-ee-19c-1.0-1.x86_64) scriptlet failed, exit status 1 临时输出 [root@redhat8 ~]# rpm -ivh --nodigest --nofiledigest /tmp/oracle-database-ee-19c-1.0-1.x86_64.rpm Preparing... ################################# [100%] Updating / installing... 1:oracle-database-ee-19c-1.0-1 ################################# [100%] Exception java.lang.UnsatisfiedLinkError: /opt/oracle/product/19c/dbhome_1/oui/lib/linux64/liboraInstaller.so: libnsl.so. 1: cannot open shared object file: No such file or directory occurred..java.lang.UnsatisfiedLinkError: /opt/oracle/product/19c/dbhome_1/oui/lib/linux64/liboraInstaller.so: libnsl.so.1: cannot open shared object file: No such file or directory at java.lang.ClassLoader$NativeLibrary.load(Native Method) at java.lang.ClassLoader.loadLibrary0(ClassLoader.java:1941) at java.lang.ClassLoader.loadLibrary(ClassLoader.java:1857) at java.lang.Runtime.loadLibrary0(Runtime.java:870) at java.lang.System.loadLibrary(System.java:1122) at oracle.sysman.oii.oiip.osd.unix.OiipuUnixOps.loadNativeLib(OiipuUnixOps.java:388) at oracle.sysman.oii.oiip.osd.unix.OiipuUnixOps.(OiipuUnixOps.java:130) at oracle.sysman.oii.oiip.oiipg.OiipgEnvironment.getEnv(OiipgEnvironment.java:201) at oracle.sysman.oii.oiix.OiixIniPair.instantiateEnvVars(OiixIniPair.java:299) at oracle.sysman.oii.oiix.OiixIniPair.updateValue(OiixIniPair.java:230) at oracle.sysman.oii.oiix.OiixIniPair.(OiixIniPair.java:148) at oracle.sysman.oii.oiix.OiixIniFile.readFile(OiixIniFile.java:809) at oracle.sysman.oii.oiix.OiixIniFile.readIniFile(OiixIniFile.java:978) at oracle.sysman.oii.oiix.OiixIniFile.getProfileString(OiixIniFile.java:385) at oracle.sysman.oii.oiix.OiixOraparam.getOraparamProfileString(OiixOraparam.java:338) at oracle.sysman.oii.oiix.OiixOraparam.getOraparamProfileString(OiixOraparam.java:296) at oracle.sysman.oii.oiix.OiixOraparam.usePrereqChecker(OiixOraparam.java:416) at oracle.sysman.oii.oiic.OiicSessionContext.setVariables(OiicSessionContext.java:1325) at oracle.sysman.oii.oiic.OiicBaseInventoryApp.execute(OiicBaseInventoryApp.java:771) at oracle.sysman.oii.oiic.OiicBaseInventoryApp.main_helper(OiicBaseInventoryApp.java:690) at oracle.sysman.oii.oiic.OiicDetachHome.main(OiicDetachHome.java:420) 'DetachHome' failed. Exception in thread \"main\" java.lang.NullPointerException at oracle.sysman.oii.oiic.OiicBaseInventoryApp.main_helper(OiicBaseInventoryApp.java:706) at oracle.sysman.oii.oiic.OiicDetachHome.main(OiicDetachHome.java:420) Exception java.lang.NoClassDefFoundError: Could not initialize class oracle.sysman.oii.oiip.osd.unix.OiipuUnixOps occurre d..java.lang.NoClassDefFoundError: Could not initialize class oracle.sysman.oii.oiip.osd.unix.OiipuUnixOps at oracle.sysman.oii.oiip.oiipg.OiipgEnvironment.getEnv(OiipgEnvironment.java:201) at oracle.sysman.oii.oiix.OiixIniPair.instantiateEnvVars(OiixIniPair.java:299) at oracle.sysman.oii.oiix.OiixIniPair.updateValue(OiixIniPair.java:230) at oracle.sysman.oii.oiix.OiixIniPair.(OiixIniPair.java:148) at oracle.sysman.oii.oiix.OiixIniFile.readFile(OiixIniFile.java:809) at oracle.sysman.oii.oiix.OiixIniFile.readIniFile(OiixIniFile.java:978) at oracle.sysman.oii.oiix.OiixIniFile.getProfileString(OiixIniFile.java:385) at oracle.sysman.oii.oiix.OiixOraparam.getOraparamProfileString(OiixOraparam.java:338) at oracle.sysman.oii.oiix.OiixOraparam.getOraparamProfileString(OiixOraparam.java:296) at oracle.sysman.oii.oiix.OiixOraparam.usePrereqChecker(OiixOraparam.java:416) at oracle.sysman.oii.oiic.OiicSessionContext.setVariables(OiicSessionContext.java:1325) at oracle.sysman.oii.oiic.OiicBaseInventoryApp.execute(OiicBaseInventoryApp.java:771) at oracle.sysman.oii.oiic.OiicBaseInventoryApp.main_helper(OiicBaseInventoryApp.java:690) at oracle.sysman.oii.oiic.OiicAttachHome.main(OiicAttachHome.java:696) 'AttachHome' failed. Exception in thread \"main\" java.lang.NullPointerException at oracle.sysman.oii.oiic.OiicBaseInventoryApp.main_helper(OiicBaseInventoryApp.java:706) at oracle.sysman.oii.oiic.OiicAttachHome.main(OiicAttachHome.java:696) [SEVERE] An error occurred while registering the Oracle home. Verify logs in /var/log/oracle-database-ee-19c/results/oraI nstall.log and /opt/oracle/oraInventory for more details and try again.warning: %post(oracle-database-ee-19c-1.0-1.x86_64) scriptlet failed, exit status 1 [root@redhat8 tmp]# rpm -ivh libnsl-2.28-164.el8.x86_64.rpm warning: libnsl-2.28-164.el8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 8483c65d: NOKEY error: Failed dependencies: glibc(x86-64) = 2.28-164.el8 is needed by libnsl-2.28-164.el8.x86_64 [root@redhat8 tmp]# rpm -ivh glibc-2.28-164.el8.x86_64.rpm warning: glibc-2.28-164.el8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 8483c65d: NOKEY error: Failed dependencies: glibc-common = 2.28-164.el8 is needed by glibc-2.28-164.el8.x86_64 glibc-langpack = 2.28-164.el8 is needed by glibc-2.28-164.el8.x86_64 [root@redhat8 tmp]# rpm -qa |grep glibc glibc-devel-2.28-42.el8.x86_64 glibc-2.28-42.el8.x86_64 glibc-headers-2.28-42.el8.x86_64 glibc-common-2.28-42.el8.x86_64 glibc-langpack-en-2.28-42.el8.x86_64 [root@redhat8 tmp]# rpm -qa |grep libnsl libnsl2-1.2.0-2.20180605git4a062cf.el8.x86_64 "},"08-Python/":{"url":"08-Python/","title":"Python","keywords":"","body":"人生苦短，我用Python 简介 Python初学者，目前只有基础学习笔记 内容 Python基础学习笔记 Python内置模块&函数 Python_LeetCode Python_AIX脚本 Python_爬虫 Python_Excel数据分析 Python_Flask Python系统管理&自动化运维笔记 Python_常见问题及注意事项 "},"08-Python/01-Python基础学习笔记/":{"url":"08-Python/01-Python基础学习笔记/","title":"Python基础学习笔记","keywords":"","body":"Python基础学习笔记 简介 Python初学者，本小节是学习基础知识中的做的笔记。 内容 Python学习笔记-基本数据类型 Python学习笔记-变量与运算符 Python学习笔记-循环&分支&条件 Python学习笔记-结构_包&模块 Python学习笔记-函数 Python学习笔记-面向对象 Python学习笔记-正则表达式 Python学习笔记-JSON Python学习笔记-枚举 Python学习笔记-高级语法与应用 Python学习笔记-函数式编程 Python学习笔记-爬虫学习 Python学习笔记-Pythonic "},"08-Python/01-Python基础学习笔记/01-Python学习笔记-基本数据类型.html":{"url":"08-Python/01-Python基础学习笔记/01-Python学习笔记-基本数据类型.html","title":"Python学习笔记-基本数据类型","keywords":"","body":"Python学习笔记-基本数据类型 整型 进制表达： 二进制：0b 八进制：0o 十六进制：0x 进制转换 转换为二进制： >>> bin(10) '0b1010' >>> bin(0o10) '0b1000' >>> bin (0x10) '0b10000' 转换为十进制： >>> int (0b111) 7 >>> int(0o111) 73 >>> int (0x111) 273 转换为八进制: >>> oct (0b11) '0o3' >>> oct (11) '0o13' >>> oct (0x11) '0o21' 转换为十六进制: >>> hex(999) '0x3e7' >>> hex(222) '0xde' >>> hex(0b11) '0x3' 布尔和复数 bool 布尔类型：表示真（Ture)、假(False) complex 表示复数 非空一般被认为True，空值一般被认为是False，除了0，当然None也可以表示Flase >>> int (True) 1 >>> int (False) 0 >>> type (True) >>> type (False) >>> bool (0) False >>> bool (4) True >>> bool (-1) True >>> bool (0) False >>> bool(4) True >>> bool(0x10) True >>> bool(0o0) False >>> bool ('qwer') True >>> bool ('') False >>> bool ([4,2]) True >>> bool ([]) False >>> bool ({2,3}) True >>> bool ({}) False >>> bool (None) False 复数表示用j表示，例如： >>> 49j 49j str字符串 表示方式，单引号、双引号、三引号，数字在使用引号后，类型会发生改变；双引号可以区别英文中的单引号，加反斜杠（转义字符）也可以进行区分： >>> type (10) >>> type ('10') >>> \"hello\" 'hello' >>> type ('hello') >>> \"I'm Iron Man\" \"I'm Iron Man\" >>> type (\"I'm Iron Man\") >>> 'I\\'m Iron Man' \"I'm Iron Man\" 对于比较长的字符，需要换行的话，可以用三引号（三个单引号或者三个双引号都可以）来换行，输出结果中\\n表示回车，输入过程中有敲击回车的动作，反向使用\\n不能显示换行，会认为是字符串一部分，用print函数可以显示换行效果： >>> '''I am Iron Man! I am Iron Man!''' 'I am Iron Man!\\nI am Iron Man!' >>> 'I am Iron Man!\\nI am Iron Man!' 'I am Iron Man!\\nI am Iron Man!' >>> '''I am Iron Man!\\nI am Iron Man!''' 'I am Iron Man!\\nI am Iron Man!' >>> print ('I am Iron Man!\\nI am Iron Man!') I am Iron Man! I am Iron Man! 一定要用单引号也是可以的，在字符串中加入\\ 然后再回车换行即可继续输入： >>> 'I am \\ Iron Man!' 'I am Iron Man!' 转义字符 表示一些特殊的字符： 与语言本身语法有冲突的字符，或者看不见的字符： \\' 单引号 \\n 换行符 \\t 横向制表符 \\r 回车 转义字符也有冲突的时候，例如如下面\\n被当作换行符了，实际上它是目录的一部分，我们可以通过再加\\去区分，或者在字符前加r，加r后，这样表示后面字符这不是一个不通字符，而是一个原始字符串 >>> print ('d:\\normal\\work') d: ormal\\work >>> print ('d:\\\\normal\\work') d:\\normal\\work >>> print (r'd:\\normal\\work') d:\\normal\\work 字符串的基本操作 经常需要对字符串进行操作，例如合并两个字符串或者字符串里面取其中一个字符， 字符串的运算，相加是最简单的，乘以数字会输出两遍，但是字符串乘以字符串是不行的： >>> 'I am '+'Iron Man!' 'I am Iron Man!' >>> 'I am Iron Man!'*2 'I am Iron Man!I am Iron Man!' 字符串的提取单个字符： 从零开始，正数就是从前往后数，负数就是从后往前；字符中有转义字符不算 >>> 'I am Iron Man!'[0] 'I' >>> 'I am Iron Man!'[3] 'm' >>> 'I am Iron Man!'[1] ' ' >>> 'I am Iron Nan!'[-1] '!' >>> 'I\\'m Iron Man!'[2] 'm' 字符串的提取多个字符： 截取到第n位字符，需要输入下一个序号，即n+1,倒数可以用负数，但是负数不能截取到最后一位，冒号后面不输入，就默认截取到最后；冒号前面不输入，就默认从头开始截取： >>> 'I am Iron Man!'[5:14] 'Iron Man!' >>> 'I am Iron Man!'[5:-1] 'Iron Man' >>> 'I am Iron Man!'[5:] 'Iron Man!' 如果字符比较长，只需要最后的几位，不可能从头开始数，可以从后面开始数，然后截取此位数后面的内容： >>> 'I am Iron Man!'[-4:-1] 'Man' >>> 'I am Iron Man!'[-4:] 'Man!' 列表list 例如[1,2,3,4,5];['I', 'am','Iron','Man',1,2,True];以及嵌套列表：[[True,3],[False,2],[3,4]]，查看类型如下： >>> type ([1,2,3,4,5,6]) >>> type (['I','am','Iron','Man',1,2,True]) >>> type ([[True,3],[False,2],[3,4]]) 列表截取，和字符串截取基本一致： >>> ['I','am','Iron','Man','!'][2] 'Iron' >>> ['I','am','Iron','Man','!'][-1] '!' >>> ['I','am','Iron','Man','!'][1:3] ['am', 'Iron'] 列表操作 相加就是合并，但是不能减，乘也只能乘以数字，会重复数组，除法当然不行 >>> ['I','am']+['Iron','Man','!'] ['I', 'am', 'Iron', 'Man', '!'] >>> ['Thanos']*2 ['Thanos', 'Thanos'] 嵌套列表 >>> [['Thanos','Loki'],['Hulk','Thor'],['Captain America']] [['Thanos', 'Loki'], ['Hulk', 'Thor'], ['Captain America']] 元组tuple 例如：(1,2,3,4,5,6);(1,'-2',False,True),元组的操作和列表一样 >>> (1,2,3,4)+(5,6) (1, 2, 3, 4, 5, 6) >>> (1,2,3)*2 (1, 2, 3, 1, 2, 3) >>> (1,'Thanos',True)[1] 'Thanos' >>> type ((1,2,3)) 当单元素的元组的时候，type认为类型不一样，因为python里面括号也表示一个运算符号，例如（1+3）*3，所以单元素的时候会认为是个数学运算符号，单元素在后面加上一个逗号，即可识别为元组： >>> type((1)) >>> type(('Thanos')) >>> type((1,)) >>> type(('Thanos',)) >>> type(()) 序列总结 str list tuple都属于序列，序列里面每一个元素都有一个序号 序列的加减和乘用法都一致，序列的截取元素的方法也一致： >>> 'I am Iron Man!'[3] 'm' >>> ['I','am','Iron','Man','!'][2] 'Iron' >>> (1,'Thanos',True)[1] 'Thanos' 序列切片操作 前面有提到过，用到了两个数字，其实可以多个数字进行切片操作 >>> ['I','am','Iron','Man','!'][1:3] ['am', 'Iron'] >>> 'I am Iron Man!'[0:8:3] 'Imr' 运算符号 in判断某个元素是否在列表或者字符中： >>> 'Thanos' in ['Iron Man','Captain America','Thor','Thanos'] True >>> 'Thanos' in ['Iron Man','Captain America','Thor'] False >>> 'Thanos' not in ['Iron Man','Captain America','Thor','Thanos'] False 序列元素统计 len 序列取最大元素 max 序列取最小元素 min 对于字母也有大小之分，是根据ascll码来排序： >>> len (['Captain America','Thanos','Thor']) 3 >>> max ([1,3,4,6,8]) 8 >>> min ([4,6,8,2,5]) 2 >>> max ('I am Iron Man!') 'r' >>> min ('I am Iron Man!') ' ' >>> min ('Thanos') 'T' ord参数查看ascll码 ： >>> ord ('T') 84 >>> ord ('t') 116 集合set 集合的特点：无序，所以不能用序列的截取和切片方法 集合的定义：{ } 集合的特性：不重复，元素中重复的元素会被忽略 支持操作：len、in、not in、逻辑运算 >>> type({1,'Thanos','Thor',4,9}) >>> {1,1,'Thanos','Thor','Thanos',3,5,3,'Thor'} {1, 3, 5, 'Thanos', 'Thor'} >>> len({1,1,'Thanos','Thor','Thanos',3,5,3,'Thor'}) 5 >>> 'Thanos' in {1,1,'Thanos','Thor','Thanos',3,5,3,'Thor'} True 集合运算 两个集合的差集：- 两个集合的交集：& 寻找两个集合里面共有的元素 两个集合的合集：| 合并两个集合，并且排除重复的元素 >>> {1,'Thanos','Thor','Hukl'}-{'Thanos'} {1, 'Thor', 'Hukl'} >>> {1,'Thanos','Thor','Captain America'}&{'Captain America'} {'Captain America'} >>> {1,'Thanos','Thor','Hulk','Captain America'}|{'Thor','Iron Man','Hulk'} {1, 'Thor', 'Captain America', 'Iron Man', 'Thanos', 'Hulk'} 空集合 用set()来定义一个空的集合 >>> set() set() >>> type (set()) >>> len (set()) 0 >>> {1,'Thanos','Thor'}&{'Captain America'} set() 字典dict 字典也是一种集合,通常有Key 和Value两个关键字 基本定义方式：{key1:value1,key2:value2,key3:value3...} >>> type({'T':'Thanos','1':'11','C':'Captain America','I':'Iron Man'}) 字典的操作 可以通过key来截取字典字段 字典中不能出现重复的key，重复的会被忽略 对于数字 1 和字符'1'会被识别为不同的key key取值必须是不可变的类型：int、str、tuple value取值可以是任意一种数据类型：str、int、folat、list、set、dict >>> {'T':'Thanos','1':'11','C':'Captain America','I':'Iron Man'}['T'] 'Thanos' >>> {'T':'Thanos','C':'Captain America','T':'Thor','I':'Iron Man'}['T'] 'Thor' >>> {'T':'Thanos','C':'Captain America','T':'Thor','I':'Iron Man'} {'T': 'Thor', 'C': 'Captain America', 'I': 'Iron Man'} >>> type ({(1,2):'Thanos','C':'Captain America'}) Python基本数据类型总结 利用一个思维导图进行总结： "},"08-Python/01-Python基础学习笔记/02-Python学习笔记-变量与运算符.html":{"url":"08-Python/01-Python基础学习笔记/02-Python学习笔记-变量与运算符.html","title":"Python学习笔记-变量与运算符","keywords":"","body":"Python学习笔记-变量与运算符 变量 变量定义 定义采用赋值符号：= 变量名命令可以为字母、数字、下划线的组合，但是变量名的首字符不能为数字； 变量名区分大小写； 可以将数字，字符，序列，集合赋值给变量； 系统保留的关键字是不能使用在变量名中，例如and、if、import。虽然type、print可以作为变量名，但是使用会发生冲突，不建议使用： >>> a=['Thanos'];b=['Hulk'] >>> print (a) ['Thanos'] >>> a*2+b+a ['Thanos', 'Thanos', 'Hulk', 'Thanos'] 在赋值中，int 、str、tuple（不可变）类型称为值类型，list 、set、dict（可变）类型称为引用类型 值类型中，改变a的赋值后b的值没有改变 >>> a=1; b=a; a=3 >>> print(b) 1 在引用类型中，更改了列表中的某一个元素，b所赋的值也会发生改变 >>> a=['Thor','Iron Man','Captain America'] >>> b=a;a[0]='Thanos' >>> print(b) ['Thanos', 'Iron Man', 'Captain America'] 两个字符串相加有得到了一个新的字符串，但是不可以像刚才改变list元素一样取改变字符内容，例如： >>> a='I am '; a=a+'Iron Man' >>> print(a) I am Iron Man >>> a[0]='i' Traceback (most recent call last): File \"\", line 1, in a[0]='i' TypeError: 'str' object does not support item assignment tuple和list赋值的区别 id函数可以查看变量内存地址，可以看到将list赋值给a后，改变a的元素，内存地址没变； 当把tuple赋值给a后，里面元素是不可改变的；例如下面修改： >>> a=['Thor','Iron Man','Captain America'] >>> id(a) 2633689218048 >>> a[0]='Thanos' >>> id(a) 2633689218048 >>> a=('Thor','Iron Man','Captain America') >>> a[0]='Thanos' Traceback (most recent call last): File \"\", line 1, in a[0]='Thanos' TypeError: 'tuple' object does not support item assignment 如果想避免修改，建议用tuple去赋值，如果想动态修改，建议用list去赋值。例如下面的增加元素： >>> a=['Thor','Iron Man','Captain America'] >>> a.append('Hulk') >>> print(a) ['Thor', 'Iron Man', 'Captain America', 'Hulk'] >>> a=('Thor','Iron Man','Captain America') >>> a.append('Hulk') Traceback (most recent call last): File \"\", line 1, in a.append('Hulk') AttributeError: 'tuple' object has no attribute 'append' 访问和修改变量中的多维元素 例如下面二维tuple >>> a=('Thor','Iron Man','Captain America',['Thanos','Loki']) >>> print(a[3]) ['Thanos', 'Loki'] >>> a[3][0] 'Thanos' 如果是一维的tuple，不可修改，刚才试过了，但是tuple中二维元素是list，可以修改list中的元素： >>> a=('Thor','Iron Man','Captain America',['Thanos','Loki']) >>> a[0]='THOR' Traceback (most recent call last): File \"\", line 1, in a[0]='THOR' TypeError: 'tuple' object does not support item assignment >>> a[3][0]='THANOS' >>> print(a) ('Thor', 'Iron Man', 'Captain America', ['THANOS', 'Loki']) 运算符 基本算数运算符：+（加） 、-（减）、（乘）、/ （除）、//（整除）、%（求余）、*（次方） 赋值运算符：=、+=、=、/=、%=、*= 比较（关系）运算符：==、!=、>、=、 逻辑运算符：and（与）、or（或）、not（非） 成员运算符：in(是否在)、not in*(是否不在) 身份运算符：is、is not 位运算符：&(按位与)、|(按位或)、^(按位异或)、~(按位取反)、>(右移动) 赋值运算符 a=a+1可以简写成a+=1;b=b-1可以简写成b-=1;b=ba可以简写成b=a;依此类推 >>> a=1; a=a+1 >>> print(a) 2 >>> a=1;a+=1 >>> print(a) 2 比较运算符 两个变量间进行比较，各种数据类型都可以比较，比较后会返回一个bool值。 字符比较会根据ascll码来比较，多个字符依次开始比较： >>> 'Thanos'=='Thanos' True >>> ['Thanos','Loki']!=['Thanos','Loki'] False >>> 'a'>'b' False >>> 'Thanos'>='Thor' False >>> ord('a');ord('b') 97 98 下面示例中a>=1返回True，然后在进行赋值运算，bool类型True可以相当于数字1，故可以进行数学运算： >>> a=1；a+=a>=1 >>> print(a,a>=1) 2 True 逻辑运算符 操作的是类型是bool类型，返回值也是bool类型： >>> True and True;False and True;False or True;not False True False True True 对于int或者float，0被认为是Fales，非0被认为True； 对于str，空值为False，非空的为True； 对于list，空列表为False，非空为True； 对于tuple、set和dict一样遵循这样规则，反馈的不是直接bool值，只需要关注返回的元素代表的是False还是True： >>> 'Thanos'and'Thor';'Thanos'or'Thor';not 'Thaons' 'Thor' 'Thanos' False >>> ['Thanos']or[];[]or['Thor'] ['Thanos'] ['Thor'] 成员运算符 判断元素是否在某个list或者tuple等数据类型中，dict中只对key元素进行判断；返回值是一个bool值： >>> >>> a='Thanos' >>> a in ['Thor','Thanos','Hulk','Captain America'] True >>> a='Thanos';b='T' >>> a in {'T':'Thanos','H':'Hulk','C':'Captain America'} False >>> b in {'T':'Thanos','H':'Hulk','C':'Captain America'} True 身份运算符 判断两个变量取值是否相等，返回值是一个bool值； 和关系运算符==的区别是，==比较的是两个变量的值是否相等，is比较的是两个变量的身份（内存地址id）是否相等： >>> a='Thor';b='Thanos'; >>> a is not b True >>> a=1;b=1.0 >>> a is b;a==b False True 对于序列：str；tuple和list这种有序的数据，必须按照顺序，而对于集合set无序的数据，不在乎顺序： >>> a=['Thanos','Iron Man','Thor'];b=['Iron Man','Thor','Thanos'] >>> a is b;a==b False False >>> a={1,2,3};b={2,1,3} >>> a==b;a is b True False >>> a={'Thanos','Tron Man','Thor'};b={'Thanos','Tron Man','Thor'} >>> a==b;a is b True False >>> id (a) 2633689392064 >>> id (b) 2633689391840 >>> a=('Thanos','Tron Man','Thor');b=('Thanos','Tron Man','Thor') >>> a==b;a is b True True 类型判断 对象三个特征：值、身份、类型 例如判断某个变量是否是字符str，在python也可以用isinstance函数进行判断，也可以多个判断标准，满足一个就行了： >>> a=['Captain America'] >>> type (a)==str False >>> isinstance (a,list) True >>> isinstance(a,(str,float,set,tuple)) False >>> isinstance(a,(str,float,set,tuple,list)) True 位运算符 按位与用图例解释，下图是按位与&的运算方法： 按位或 | 运算就是只要有一个为1，就得到结果为1，所以2和3比较就是3： >>> a=2;b=3 >>> a&b;a|b 2 3 Python变量与运算符总结 同样利用一个思维导图进行总结： "},"08-Python/01-Python基础学习笔记/03-Python学习笔记-循环&分支&条件.html":{"url":"08-Python/01-Python基础学习笔记/03-Python学习笔记-循环&分支&条件.html","title":"Python学习笔记-循环&分支&条件","keywords":"","body":"Python学习笔记-循环&分支&条件 表达式 表达式定义 表达式（Expression）是运算符（operator）和操作数（operand）所构成的序列 >>> >>> a=('Thor')+('Hulk')*2;print(a) ThorHulkHulk >>> a=1;b=2;c=3;print(a+b*c);print(a or b and c) 7 1 在上面的示例中，a+b*c值是7，数学运算的优先级和基本数学运算一致； a or b and c 结果是2，说明系统先运算的b and c然后再运算的or，所以得到了1， 这就涉及到表达式中的运算符的优先级，网上随便找了个表格，优先级如下所示： 运算符说明 Python运算符 优先级 结合性 小括号 ( ) 19 无 索引运算符 x[i] 或 x[i1: i2 [:i3]] 18 左 属性访问 x.attribute 17 左 乘方 ** 16 左 按位取反 ~ 15 右 符号运算符 +（正号）、-（负号） 14 右 乘除 *、/、//、% 13 左 加减 +、- 12 左 位移 >>、 11 左 按位与 & 10 右 按位异或 ^ 9 左 按位或 | 8 左 比较运算符 ==、!=、>、>=、 7 左 is 运算符 is、is not 6 左 in 运算符 in、not in 5 左 逻辑非 not 4 右 逻辑与 and 3 左 逻辑或 or 2 左 逗号运算符 exp1, exp2 1 左 解析器在解析表达式的时候，如果优先级是同级的，解析器会从左到右去解析。在编程中叫左结合，如果有赋值运算’=‘，则变成右结合，先从’=‘右边开始运算，然后再赋值： >>> a=1;b=1;c=a+b;print(c) 2 >>> a='Thanos';b=3;c=3;not a or b+2==c False >>> a='Thanos';b=3;c=3;(not a) or((b+2)==c) False 条件控制语句 Python中一些基础知识 单行注释，在行前面加上#即可 多行注释，在多行前后加上''' python中用缩进来决定代码块，代码尾部也不需要用分号，通过换行来区分。 条件控制语句 即if else语句，解决选择性问题，示例如下： world=False if world: print('The world is True') else: print('The world is Flase') 执行结果： PS D:\\Python\\codefile> python test.py The world is Flase 当然使用表达式也可以，if后面是个bool值即可： T='Thanos';I='Iron man' if T>I: print('The world will end') else: print('The world will be saved') 执行结果： PS D:\\Python\\codefile> python test.py The world will end if else比较常用的就是密码判断，例如如下代码： account = 'root' password = 'abc123' print('Please input account') user_account = input() print('Please input password') user_password = input() if account == user_account: if password == user_password: print('You are login successful!') else: print('The password is wrong! Please try again!') else: print('The account is wrong! Please try again!') 上面代码中，用到input函数，input是python中在命令行中接受用户输入的函数； 在python中，习惯用下划线“_”来隔离变量中的多个单词； 习惯用大写来定义变量，当然小写也可以； 各种运算符前后都建议空格。 正确输入账号密码后执行结果： PS D:\\Python\\codefile> python test.py Please input account root Please input password abc123 You are login successful! 输错密码后执行结果： PS D:\\Python\\codefile> python test.py Please input account root Please input password 123456 The password is wrong! Please try again! 输错用户后执行结果： PS D:\\Python\\codefile> python test.py Please input account python Please input password abc123 The account is wrong! Please try again! if else其它注意事项 上面代码中使用了条件语句的嵌套使用，在实际应用中 if可以单独使用不需要else，但是else不能单独使用； pass是空语句，或者叫占位语句，作用是保持代码结构的完整性，如果没有pass没任何代码，if语句是不能成功执行，当我们确实没有代码写入或者预留后期写入，可以写入pass保持结果完整性： if expression: pass elif函数 elif是if else的简写，不能单独使用，只能在嵌套中代替if else使用，例如下面语句，用到了很多if else，代码行数很多： a = input() if a == 'T': print('Thanos') else: if a == 'C': print('Captain America') else: if a== 'H': print('Hulk') else: print('Iron Man') 我们可以用elif替代，就简洁不少： a = input() if a == 'T': print('Thanos') elif a == 'C': print('Captain America') elif a== 'H': print('Hulk') else: print('Iron Man') 随便输入个C 查看输出结果： PS D:\\Python\\codefile> python test.py C Captain America input输入数字注意，示例下面代码： a = input() if a == 1: print('Thor') elif a == 2: print('Thanos') else: print('Captain America') 输入1，然后查看结果，可以看到并不是预期的结果，怎么输入都是结果都是一样： PS D:\\Python\\codefile> python test.py 1 Captain America 在代码中加入打印a和打印a的类型： a = input() if a == 1: print('Thor') elif a == 2: print('Thanos') else: print('Captain America') print(a) print(type(a)) 然后输入1，查看结果： 1 Captain America 1 可以看到是个字符，所以我们在命令行输入的1会被仍为是个字符，所以不等于数字1， 转换一下类型就可以了： a = input() a = int (a) if a == 1: print('Thor') elif a == 2: print('Thanos') else: print('Captain America') print(type(a)) 输入1再查看结果，得到了预期的几个： PS D:\\Python\\codefile> python test.py 1 Thor 循环语句 while循环 主要用户递归的情况下 结构如下： while expression: pass else: pass while会不停重复判断，如果判断条件是False，则不会执行后面代码，条件一直是True，会出现死循环，例如如下代码会不停输出’I am Thanos‘： THANOS = True while THANOS: print('I am Thanos') 如果不想出现死循环，运行次数是有限的，在while内部代码段中需要有影响条件的语句： counter = 1 while counter 执行输出结果，可以看到到4就结束了： PS D:\\Python\\codefile> python while_for.py 2 3 4 while 除了单独使用，可以和else一起使用，当while后面条件语句返回值是False时候，就会执行else后面的代码. counter = 1 while counter 执行输出结果，可以看到输出到4结束后就执行了打印出End： PS D:\\Python\\codefile> python while_for.py 2 3 4 End for循环 主要用来遍历/循环 序列、集合或者字典 基本结构如下： for target_list in expression_list: pass 示例如下： super_hero = ['Iron Man','Captain America','Hulk'] for x in super_hero: print(x) 运行后可以看到依次打印出了列表中的元素： PS D:\\Python\\codefile> python while_for.py Iron Man Captain America Hulk 当然也可以采用嵌套， 在下面示例中在打印中使用了end函数，默认不设置是end=\"/n\" 这里设置为空字符，可以讲输出结构横向打印出来，之前的都是列排布： super_hero = [['Iron Man ','Captain America '],('Wonder Woman ','Batman')] for a in super_hero: for b in a: print(b,end='') 执行输出结果如下： PS D:\\Python\\codefile> python while_for.py Iron Man Captain America Wonder Woman Batman for循环也是可以和else搭配使用； 当列表里面所有元素都被遍历完之后，就会执行else： super_hero = [['Iron Man ','Captain America '],('Wonder Woman ','Batman')] for a in super_hero: for b in a: print(b,end='') else: print('Super hero is gone!') 执行输出结果如下： PS D:\\Python\\codefile> python while_for.py Iron Man Captain America Wonder Woman Batman Super hero is gone! 跳出循环的方法： 采用break和continue 采用break后，if后面判断条件成立，就立即终止代码，不会继续执行后续循环，包括后面的else内容，例如如下代码： super_hero = ['Iron Man','Captain America','Thor'] for a in super_hero: if a == 'Captain America': break print(a,end='') else: print('End') 执行输出结果如下，可以看到if判断成立后，直接终止整个循环了： PS D:\\Python\\codefile> python while_for.py Iron Man 如果想排除某个元素，但是想继续执行，则可以用continue： super_hero = ['Iron Man','Captain America','Thor'] for a in super_hero: if a == 'Captain America': continue print(a,end='') else: print('End') 执行结果如下，可以看到排除了if判断成立的元素，但是代码继续在执行： PS D:\\Python\\codefile> python while_for.py Iron Man Thor End 在嵌套中，加入break，如果是在内部循环，只会终止内部循环，外部循环继续执行，示例如下： super_hero = [['Iron Man ','Captain America ','Hulk '],('Wonder Woman ','Batman ')] for a in super_hero: for b in a: if b == 'Captain America ': break print(b,end='') else: print('Super hero is gone!') 执行输出结果如下： PS D:\\Python\\codefile> python while_for.py Iron Man Wonder Woman Batman Super hero is gone! 如何在for循环中指定循环次数，例如十次： for a in range(0,10): print(a,end='') 执行输出结果如下： PS D:\\Python\\codefile> python while_for.py 0123456789 可以看到从0开始循环了十次，range函数就是指定一个范围，第一个元素是起始位，第二个元素不是表示结束位，表示是偏移量，就是从零开始有多少个元素。 如果希望生成的数字有间隔，可以加入第三个元素，及步长，设置成2: for a in range(0,10,2): print(a,end='|') 执行输出结果： PS D:\\Python\\codefile> python while_for.py 0|2|4|6|8| 在输出end函数中使用了end='|',表示输出结果以行输出，并且用字符 | 隔开； 如果想递减，同样用range函数，第一个参数大于第二参数即可，第三个参数可以为负数，range（10，0，-2），即可输出10 8 6 4 2。 如果想打印出一大串数字中的奇数，例如1-20： a = range(1,20) for b in range(0,len(a),2): c = a[b] print(c,end=',') 执行输出结果： PS D:\\Python\\codefile> python while_for.py 1,3,5,7,9,11,13,15,17,19, 上面我用for循环方式实现，其实可以直接用切片方式实现： a = range(1,20) b = a[0:len(a):2] print(list(b)) 执行输出结果： PS D:\\Python\\codefile> python while_for.py [1, 3, 5, 7, 9, 11, 13, 15, 17, 19] "},"08-Python/01-Python基础学习笔记/04-Python学习笔记-结构_包&模块.html":{"url":"08-Python/01-Python基础学习笔记/04-Python学习笔记-结构_包&模块.html","title":"Python学习笔记-结构_包&模块","keywords":"","body":"Python学习笔记-结构_包&模块 Python项目的组织结构 对于比较复杂的项目，需要有完整的组织结构来对代码进行分类管理和组织代码: 包：可用理解为文件夹 模块：可以理解为文件 类：函数、变量   一个包下面可以包含多个模块（也可以有子包），一个模块下面可以有多个类（或者函数和变量），一个类下面可以有多个函数和变量 Python项目的组织结构 如下所示Python_1就是包的名字，ifelse.py代表一个模块那么ifelse就是模块的名字:   如果不同的包里面有相同名字的模块，需要区分可以在模块的前面加上包的名字，例如Python1.ifelse，形成了一个路径，这种方法叫命名空间；  如果想让一个文件夹成为一个包，需要在包下面有一个特定的文件：`_init.py`，同样算一个模块，可以空着，也可以编辑代码。这块模块的名字就是包名：Python_1 Python模块的变量引用 import导入方式   一个项目一般是多个包和多个模块之间的相互调用构成的，在其中一个模块里面定义了一个变量，可以在另外一个模块中使用，不需要重复定义，例如在ifelse.py中定义a：   在while_for.py中引用变量a，用import函数，如果ifelse.py 和while_for.py是同一级别，输入模块名即可： 运行输出结果： PS D:\\Python\\codefile\\Python_1> python while_for.py ['Thor', 'Iron Man', 'Wonder Woman', 'Batman'] 如果不是同级别，需要加上完整路径，及包名字，命名规则和之前一样： 运行输出结果和之前一样。  我们在运行过程中，可以看到自动生成了__pycache___包，并且下面有一个pyc文件，是一个二进制文件，是python自动生成的字节码，可以提升python程序运行的效率。  improt导入的是一个模块，不能直接导入一个模块的变量，引入模块变量时候就需要:模块名.变量名 如果模块名特别长或者路径特别长，可以采用如下方法： import other.ifelse as m print(m.a) 运行结果和之前一样，把模块名简化成一个字母。 from导入 结构如下：from module（或者包） import a（可以是变量或者函数，如前面是包，这里也可以是模块） 同样是上面示例，在包Python_1的while_for模块中，从子包other包的模块ifelse模块中引用a： from other.ifelse import a print(a) 执行后输出结果和之前一致。 如果想导入所有的变量，可以用\"*\"来代替： from other.ifelse import * print(a) 执行后输出结果和之前一致。 如果需要导入很多变量，但是也不是需要全部的，可以用__all__（在Python叫模块内置变量，模块内置属性）来指定。在子包other包的模块ifelse中定义如下三个变量， __all__ = ['a','c'] a = ['Thor','Iron Man'] b = ['Wonder Woman','Batman'] c = ['Captain America','Hulk'] 然后在包Python_1的while_for模块中进行引用： from other.ifelse import * print(a) print(b) print(c) 运行输出结果： PS D:\\Python\\codefile\\Python_1> python while_for.py ['Thor', 'Iron Man'] Traceback (most recent call last): File \"while_for.py\", line 78, in print(b) NameError: name 'b' is not defined 可以看到只输出了a的值，并且有报错说b没有定义，报错后后面的代码也不会继续执行了。 如果想全部引用，出了使用*，还可以直接输入，用逗号隔开： from other.ifelse import a,b,c print(a) print(b) print(c) 如果导入的变量特别多，一行写不下，太长了也不好看，可以在末尾加上“\\\"进行代码换行: from other.ifelse import a,b,\\ c print(a) 也可以用括号强制换行,一般推荐这种方式： from other.ifelse import (a,b, c) print(a) __init__作用   基本作用是当一个包被导入的时候，__init__会自动首先执行,例如在子包other的__init__模块中写入如下代码： d = ['Thor','Captain America','Iron Man'] print(d) 然后在主包Python_1的while_for模块中调入子包other模块中a，while_for中代码如下: from other.ifelse import a print(a) 运行输出结果： PS D:\\Python\\codefile\\Python_1> python while_for.py ['Thor', 'Captain America', 'Iron Man'] ['Thor', 'Iron Man'] 可以看到__init__模块中代码会自动首先执行。 __init__应用场景 在__init__模块里面可以通过__all__来决定哪些模块可以被导出。 方便试验，首先在other中新建两个模块code1.py和code2.py： 然后在code1.py里面定义几个变量： a = ['Thanor'] b = ['loki'] code2.py中定义几个变量： c = ['Thor','Hulk'] d = ['Captain America'] 在__init__.py中输入如下代码，意思是只让调用code1中的内容： __all__ = ['code1'] 然后在Python1主包下面建立个模块code_1.py，输入如下代码，即导入所有变量： from other import * print(code1.a) print(code2.d) 运行输出结果： PS D:\\Python\\codefile\\Python_1> python code_1.py ['Thanor'] Traceback (most recent call last): File \"code1.py\", line 3, in print(code2.d) NameError: name 'code2' is not defined 可以看到只输出了code1中的a，而code2认为没有定义。 __init__还可以用作批量导入,在Python1主包下面模块code_1.py中定义如下系统预定模块： import sys import datatime import io print(sys.path)   执行可以打印出系统存储这些模块的路径。如果Python1下面很多模块需要引用这写系统预定模块，每个都写就很不方便，那么可以在子包other中的__init__模块中输入导入代码： import sys import datatime import io   然后再Python1主包下面模块code1.py调用other包中的元素，就会先执行other下的`_init`模块中的内容： import other print(other.sys.path) 路径也是要写全，执行后输出结果就和刚才一样，这种一般用在很多个模块导入操作。   包和模块是不会重复导入的。也不建议循环引用，例如other包中code1.py中应用 code2.py中的变量，然后再code2.py中引入 code1.py的变量 Python中导入一个模块，就会执行导入模块中的代码： 例如在code_1.py中输入定义变量和打印操作： a = ['Wonder Woman','Batman'] print(a) 然后在code_2.py中只导入模块code1.py，不作打印操作： import code1 运行code_2.py执行结果如下： PS D:\\Python\\codefile\\Python_1\\other> python code2.py ['Wonder Woman', 'Batman'] 可以看到还是有打印输出内容，说明执行了code1.py中的内容。 上面示例中code_2.py相当于一个入口文件，通常一个应用程序中只有一个入口文件。 "},"08-Python/01-Python基础学习笔记/05-Python学习笔记-函数.html":{"url":"08-Python/01-Python基础学习笔记/05-Python学习笔记-函数.html","title":"Python学习笔记-函数","keywords":"","body":"Python学习笔记-函数 函数简介 函数特性：功能性、避免编写重复的代码 之前用到过很多函数，例如print等 Python中定义了很多函数，例如round，保留小数位，并且四舍五入。 新的学习内容，为了区分，建立一个新的包：function。并在包下面建立新的模块module1.py 示例下round函数： a = 1.2328364 b = round(a,3) print(b) 执行后输出结果： PS D:\\Python\\codefile\\function> python module1.py 1.233 可以看到结果中保留了三位有效小数位，并且进行了四舍五入运算。 如何快速查看Python中各类函数的功能 首先在windows下进入phthon的idle，使用help命令去查看详细介绍，格式：help(function)： PS D:\\Python\\codefile\\function> python Python 3.8.3 (tags/v3.8.3:6f8c832, May 13 2020, 22:37:02) [MSC v.1924 64 bit (AMD64)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> help(round) Help on built-in function round in module builtins: round(number, ndigits=None) Round a number to a given precision in decimal digits. The return value is an integer if ndigits is omitted or None. Otherwise the return value has the same type as the number. ndigits may be negative. >>> 函数的结构 在Python中，用def定义函数，格式如下： def funcname(parameter_list): pass funcname：自动义函数名 parameter_list ：参数列表，需要用括号括起来 pass：空语句，占位语句，可以编写任意代码 参数列表可以没有 在函数体中可以使用return返回结果，结果用value表示，如果函数体没有return，那么Python默认返回的是None 函数的编写 定义一个自定义函数后，调用必须在定义后面 例如实现如下两个功能：两个数字或字符相加 def add(a,b): result = a + b return result a = add ('Thanos','Loki') print(a) 执行输出结果如下： PS D:\\Python\\codefile\\function> python module1.py ThanosLoki 打印输入的参数： 定义如下函数，函数中调用了系统print函数，在print函数不需要使用return，因为已经打印了，不需要返回结果： def print(code): print(code) 可以看到我们定义的和系统print函数名字一样，这样会不停自己调用自己，执行会报错。 原因在于我们定义了一个和Python内置函数同名，所以一般命令不要和内置函数冲突，换个名字然后调用定义的函数： def print_input(code): print(code) print_input('Captain America') 执行输出结果： PS D:\\Python\\codefile\\function> python module1.py Captain America 把刚才两个示例合在一起： def add(a,b): result = a + b return result def print_input(code): print(code) a = add ('Thanos','Loki') b = print_input('Captain America') print(a,b) 执行输出结果： PS D:\\Python\\codefile\\function> python module1.py Captain America ThanosLoki None 可以看到先打印出了b，然后打印a，并且没有换行打印出None，这和Python执行顺序有关， 执行到给a赋值的时候，把结算结果赋值给a，但是目前并没有执行打印操作，继续执行给b赋值，在给b赋值的表达式中，调用了print_input函数，而print_input函数中调用了print函数，有打印操作，所以就先打印出了b的值，然后执行print(a,b)，所以接着就换行打印出了a的值，print(a,b)打印出结果不会换行，所以不换行接着打印b，由于print_code内部是没有return，会把函数的结果设置成None，所以print(a,b)打印出来是：ThanosLoki None 关于return 一般函数内部代码执行到reture，后面的代码是不会执行。return返回结果没有限制，可以返回字符串，也可以返回元组等，可以返回一个函数。 返回值也可以是多个，用逗号隔开即可 def damage(Thanos,Thor): damage1 = Thanos * 2 damage2 = Thor *3 + 2 return damage1,damage2 damages = damage(1,2) print(type(damages)) print(damages) damages1,damages2 = damage(1,2) print(damages1,damages2) 执行输出结果 PS D:\\Python\\codefile\\function> python module1.py (2, 8) 2 8 可以看到途中打印了两种输出结果，第一种方法damages输出类型是个元组，打印出来也是个元组； 第二种用两个变量接收了函数的两个返回结果，用返回结果实际意义来表示，这种方法叫序列解包。 一般建议用第二种方法。 序列解包 之前经常需要定义多个变量，例如a=1;b=2;c=3，可以简写成a,b,c=1,2,3。这样就比较简洁直观。 如果是a=1;b=1;c=1，则可以携程a=b=c=1; 可以用一个变量接收多个数值：例如d = 1,2,3 d = 1,2,3 print(type(d)) a,b,c = d print(a) 执行结果如下： PS D:\\Python\\codefile\\function> python module1.py 1 示例中可以给d赋值多个数值，类型输出位tuple，是个序列，代码中用a,b,c桑格值对d进行了序列解包，所以打印出a的值就是1。 序列解包的元素要相等,例如刚才的示例，d有三个元素，我们也需要定义三个变量去序列解包。 函数的参数 以下面代码为例，解释参数类型。 必须参数（形式参数，实际参数）：在函数参数列表定义的参数（Thanos，Thor）是必须传递的，也就是调用函数的时候，必须给Thanos，Thor进行赋值； 形式参数：Thanos和Thor即形式参数； 实际参数：在函数调用过程中往函数的参数列表中给参数传递的实际取值，即下面代码中的1和2； def damage(Thanos,Thor): damage1 = Thanos * 2 damage2 = Thor *3 + 2 return damage1,damage2 damages = damage(1,2) print(type(damages)) print(damages) damages1,damages2 = damage(1,2) print(damages1,damages2) 关键字参数：就是调用的时候，明确指定给的参数值，不用在乎序列，指定赋值，例如在上面的代码进行如下调用： damages = damage(Thor=1,Thanos=2) 默认参数： 例如如下代码： def print_self_introduction(name,home,want,dream): print('I am '+ name) print('I am come form ' + home) print('I want ' + want) print('I will '+ dream) print_self_introduction('Thanos','Titan','Power','Balance the universe') 执行输出结果如下： PS D:\\Python\\codefile\\function> python module1.py I am Thanos I am come form Titan I want Power I will Balance the universe 可以看到在调用定义函数后依次打印出来了，但是如果我要打印很多人的信息，他们就name和home不一样，其它都一样，如果特别多，每个这样调用肯定很复杂。 可以通过修改函数的定义，在形式参数那里预先进行定义，没有默认参数的必须传递是个实际参数；当然如果不想用默认的，只需要更改下就行了： def print_self_introduction(name,home='Earth',want='Power',dream='save the world'): print('I am '+ name) print('I am come form ' + home) print('I want ' + want) print('I will '+ dream) print_self_introduction('Iron Man','Earth','Power','save the world') print('~~~~~~~~~~~~~~~~~~~~~~~~~~~') print_self_introduction('Batman') print('~~~~~~~~~~~~~~~~~~~~~~~~~~~') print_self_introduction('Thor','Asgard') 执行输出结果如下： PS D:\\Python\\codefile\\function> python module1.py I am Iron Man I am come form Earth I want Power I will save the world ~~~~~~~~~~~~~~~~~~~~~~~~~~~ I am Batman I am come form Earth I want Power I will save the world ~~~~~~~~~~~~~~~~~~~~~~~~~~~ I am Thor I am come form Asgard I want Power I will save the world 非默认参数不能放到默认参数后面，也就是必须传递的形式参数不能在默认的形式参数后面。 如果有一个name相同，但是其中一个形式参数不想用默认的，则可以在实际参数中使用关键字参数，关键字参数不在乎顺序： def print_self_introduction(name,home='Earth',want='Power',dream='save the world'): print('I am '+ name) print('I am come form ' + home) print('I want ' + want) print('I will '+ dream) print_self_introduction('Ultron',dream='destroy the world') 执行输出结果如下： PS D:\\Python\\codefile\\function> python module1.py I am Ultron I am come form Earth I want Power I will destroy the world "},"08-Python/01-Python基础学习笔记/06-Python学习笔记-面向对象.html":{"url":"08-Python/01-Python基础学习笔记/06-Python学习笔记-面向对象.html","title":"Python学习笔记-面向对象","keywords":"","body":"Python学习笔记-面向对象 最核心的内容：类，对象 类 类是现实世界或思维世界中的实体在计算机中的反映，它将数据以及这些数据上的操作封装在一起。 类的基本作用是去封装一系列的函数和一系列的变量 在Python中用关键字class来定义一个类 类的格式如下： class classname(object): pass classname：定义类的名字建议第一个字母大写，如果类由两个单词组成，不建议用下划线来连接，建议两个单词首字母大写。 object：类的参数 pass：空语句，占位语句，可以编写任意代码。可以定义若干个变量，还可以定义函数。 新建一个包object，新建一个模块module_1.py，在此模块中进行示例： class SuperHero(): name = 'Thor' form ='Asgard' def print_hero(self): print('My name is ' + self.name) print('I am come form ' + self.form) superhero = SuperHero() superhero.print_hero() 运行输出结果： PS D:\\Python\\codefile\\object> python module_1.py My name is Thor I am come form Asgard 注意事项 要使用类，就需要将类实例化，实例中superhero=SuperHero()就是将类实例化操作； 在类中的函数，模块参数必须加上self，在函数中调用类中的变量，需要加上路径，例如示例中self.name； 运行和调用类需要放在类的外部，在类内部调用函数会报错。 在其它模块调用类 新建一个module_2.py，在里面调用module_1.py中的类，先封装module_1.py实例化和调用的操作，然后在module_2中输入如下代码： from module_1 import SuperHero superhero = SuperHero() superhero.print_hero() 运行输出结果： PS D:\\Python\\codefile\\object> python module_2.py My name is Thor I am come form Asgard 在Python中，这种调用类中的函数通常叫调用类中的方法： 格式如下： class classname(object): pass def funcname(self, parameter_list): pass 类与对象 类进行实例化之后，就变成了一个具体的对象； 类就像一个模板，通过模板可以产生很多对象； 上面示例中，superhero = SuperHero()就是进行了实例化，superhero就是一个对象，还可以继续实例化，例如superhero1 = SuperHero()，当然我们得到superhero1输出结果会跟superhero一样，但是他们是两个不同的对象，在计算机中的内存地址也不一样。 class SuperHero(): name = 'Thor' form = 'Asgard' def print_hero(self): print('My name is '+ self.name) print('I am come form ' +self.name) superhero = SuperHero() superhero1 = SuperHero() superhero.print_hero() superhero1.print_hero() 构造函数 如何向类传递不同的参数，从而生成不同的对象，需要在类的内部定义一个特殊的函数，叫构造函数： 格式如下： class classname(object): pass def __init__(self): pass 函数名是固定的：init，函数的形式参数也必须有一个参数，可以自定义，一般建议用：self； 构造函数的调用是自动进行的，当进行实例化时候，会自动调用，当然用户也可以手动调用，但是实际很少这样做； 构造函数，不能随便return一个除None的值。 初始化对象的属性，下面示例中name = name就是初始化对象的属性； superhero = SuperHero('Thor','Asgard')就是给类传递参数： class SuperHero(): name = '' home = '' def __init__(self,name,home): name = name home = home superhero = SuperHero('Thor','Asgard') print(superhero.name) 执行输出结果如下： PS D:\\Python\\codefile\\object> python module_2.py 可以看到是一个空字符，说明上面的代码有问题，得不到我们想要的结果，其实打印出来的是类变量，即name=''。 在函数中，如果在函数中定义了一个和全局变量同名的局部变量，局部变量不会覆盖全局变量。 在类中，需要理解两个变量：类变量，实例变量 类变量与实例变量 类变量只是和类关联，实例变量和对象相关联的 下面面示例中，name='Iron Man'就是类变量，在self.name = name 就是实例变量，superhero1 = SuperHero('Thor','Asgard')就是给实例变量传递参数， class SuperHero(): name = 'Iron Man' home = 'Earth' def __init__(self,name,home): self.name = name self.home = home superhero1 = SuperHero('Thor','Asgard') superhero2 = SuperHero('Batman','Earth') print(superhero1.name) print(superhero2.name) print(SuperHero.name) print(superhero1.__dict__) 执行后输出结果： PS D:\\Python\\codefile\\object> python module_1.py Thor Batman Iron Man {'name': 'Thor', 'home': 'Asgard'} 可以看到superhero1.name 和superhero2.name值不一样，同样和类SuperHero.name值不一样，对于类变量，只和类相关，不受实例变量影响。 再回到之前打印为空字符的那断程序，其实打印出来的是类变量，即name=''，如果尝试访问一个实例变量，Python首先会在对象的实例变量中查找，如果没有，Python会继续在类变量中寻找。在构造函数中，name = name 没有给实例变量进行赋值，需要通过self.name = name 才是给实例变量进行了赋值。 Python中有一个变量：dict，输出结果是个字典。可以通过superhero1.dict，查看对象superhero1中保存的所有相关的变量 上面示例中可以print(SuperHero.dict)打印所有类中的变量： 输出结果如下： PS D:\\Python\\codefile\\object>python module_1.py {'__module__': '__main__', 'name': 'Iron Man', 'home': 'Earth', '__init__': , '__dict__': , '__weakref__': , '__doc__': None} self与实例方法 self只和对象有关，和类无关。谁调用了它的方法，那么self就指代的是谁 如果在类中定义一个方法，如果是一个实例方法，必须在方法参数列表中固定一个参数：self（也可以用其它的，但是一般建议用self），当调用实例方法时候，不需要传入self来赋值。 实例方法和构造函数的区别在于调用方式不一样，调用构造函数通过类去调用，调用实例方法是通过对象调用； 实例方法主要作用描述类的行为，构造函数用来初始化类的各种特征。 在实例方法中访问实例变量 下面示例中，print（self.name)就是在示例方法中访问示例变量，当然示例中是个构造函数，在此和实例变量是一样的： class SuperHero(): name = '' home = '' def __init__(self,name,home): self.name = name self.home = home print(self.name) 当然，用print(name)打印出来的结果会和上面结果一样，但是如果我们将参数名字修改下，结果就不一样了： class SuperHero(): name = '' home = '' def __init__(self,name1,home): self.name = name1 self.home = home print(self.name) print(name) superhero1=SuperHero('Thor','Asgard') 执行后输出结果： PS D:\\Python\\codefile\\object> python module_1.py Thor Traceback (most recent call last): File \"module_1.py\", line 55, in superhero1=SuperHero('Thor','Asgard') File \"module_1.py\", line 52, in __init__ self.name = name NameError: name 'name' is not defined 可以看到报错了，找不到name，print(self.name)读取了对象的实例变量，第二个print(name)读取的是形式参数的name，而此时我们形式参数是name1，所以找不到了。 在实例方法中访问类变量 方法一： 在之前的示例中，在类的外部，调用过类变量：print(SuperHero.name)，在类的内部也可以这样使用， 方法二： 通过self访问，Python中内置class指代的当前的类： class SuperHero(): name = 'Thor' home = 'Asgard' def __init__(self,name,home): self.name = name self.home = home print(self.__class__.name) superhero = SuperHero('Batman','Earth') print(SuperHero.name) print(superhero.name) 执行后输出结果： PS D:\\Python\\codefile\\object> python module_1.py Thor Thor Batman 可以看到打印了三次，第一次是实例方法中调用类变量打印输出结果，第二次是在类外部调用类变量打印出来的，第三次是调用对象中的变量打印出来结果。 在实例方法中操作类变量 例如我们要操作类变量sum1 class SuperHero(): sum1 = 0 name = '' home = '' def __init__(self,name,home): self.name = name self.name = home self.__class__.sum1 += 1 print('The number of superheroes is '+ str(self.__class__.sum1)) superhero1 = SuperHero('Captain America','Earth') superhero2 = SuperHero('Wonder Woman','Earth') 执行输出结果： PS D:\\Python\\codefile\\object> python module_1.py The number of superheroes is 1 The number of superheroes is 2 也可以在在其它实例方法中实现对sum1的操作，输出结果和上面一致： class SuperHero(): sum1 = 0 name = '' home = '' def __init__(self,name,home): self.name = name self.name = home def print_superhero(self): self.__class__.sum1 += 1 print('The number of superheroes is '+ str(self.__class__.sum1)) superhero1 = SuperHero('Captain America','Earth') superhero1.print_superhero() superhero2 = SuperHero('Wonder Woman','Earth') superhero1.print_superhero() 类方法 chassmethod 和类有关，和对象没关系 在一个函数的前一行加上@classmethod，就表示下面的方法是个类方法，@是装饰器，后面会学到； 在类方法中，参数名字建议使用：cls，可以使用其它的，但是建议用cls： 在类方法中，参数名字建议使用：cls，可以使用其它的，但是建议用cls： class SuperHero(): sum1 = 0 name = '' home = '' def __init__(self,name,home): self.name = name self.name = home self.__class__.sum1 += 1 print('The number of superheroes is '+ str(self.__class__.sum1)) @classmethod def sum_hero(cls): cls.sum1 += 1 print('The number of superheroes is '+ str(cls.sum1)) superhero1 = SuperHero('Captain America','Earth') SuperHero.sum_hero() superhero2 = SuperHero('Wonder Woman','Earth') SuperHero.sum_hero() 执行输出结果： PS D:\\Python\\codefile\\object> python module_1.py The number of superheroes is 1 The number of superheroes is 2 The number of superheroes is 3 The number of superheroes is 4 因为我在构造函数中也调用并操作了类变量，在类方法中也调用了类变量进行操作，所以输出结果计数到4。 操作一个和对象无关的变量，一般建议使用类方法进行操作。 在上面的示例中，使用类SuperHero.sum_hero()调用了类方法，也可以用对象superhero1.sum_hero()也是可以调用，但是不建议这样做，一般用类调用。 静态方法 staticmethod 不需要默认传入一个指定的参数值； 同样需要在前面加上装饰器@staticmethod，格式如下： @staticmethod def funcname(parameter_list): pass 示例如下： class SuperHero(): sum1 = 0 name = '' home = '' def __init__(self,name,home): self.name = name self.name = name @classmethod def sum_hero(cls): cls.sum1 += 1 print('The number of superheroes is '+ str(cls.sum1)) @staticmethod def add_hero(a,b): print(SuperHero.sum1) print('Avengers members have '+ a +' and ' + b) superhero1 = SuperHero('Captain America','Earth') SuperHero.sum_hero() SuperHero.add_hero('Thor','Hulk') superhero1.add_hero('Thor','Hulk') 执行后输出结果： PS D:\\Python\\codefile\\object> python module_1.py The number of superheroes is 1 1 Avengers members have Thor and Hulk 1 Avengers members have Thor and Hulk 在上面的示例中，在静态方法中用print(SuperHero.sum1)访问了类变量，说明是可以访问的，同时调用也使用了SuperHero.add_hero('Thor','Hulk')和superhero1.add_hero('Thor','Hulk')两种方法，但是我们一般建议用前者。 那么，在静态方法和类方法中，能访问实例变量吗？ 直接调用会报错。 静态方法和普通的函数差不多，使用比较少，用静态方法一般都可以用类方法。 静态方法调用类变量一般要加上类名字，而类方法只需要cls加变量就可以了。 成员可见性 即Python类下面变量和方法的可见性 Python类下的变量和方法都可以在内部和外部调用的，例如上面示例中superhero1.add_hero('Thor','Hulk')就是外部调用，放到类中的某一个方法里面调用，就是内部调用。 但是这样不安全，有时候不一定需要随便让调用，例如不想在外部调用去更改。 例如如下示例，在方法内部定义了一个变量power，superhero1.power = -99就是在外部调用并赋值： class SuperHero(): sum1 = 0 name = '' home = '' def __init__(self,name,home): self.name = name self.home = home self.power = 0 superhero1 = SuperHero('Captain America','Earth') superhero1.power = 99 print(superhero1.name + '\\'s power is '+ str(superhero1.power)) 运行后输出结果： PS D:\\Python\\codefile\\object> python module_1.py Captain America's power is -99 这样会操作类的数据不安全，这种在类外部直接操作变量给变量赋值不推荐，推荐在内部的类进行操作，并且用传递方式进行赋值，需要在类里面定义一个方法hero_power，然后再里面对pwer进行赋； 示例中 self.power = power也是在类的方法中调用类的内部变量，之前已经在构造函数中对power赋值了一个初始值： class SuperHero(): sum1 = 0 name = '' home = '' def __init__(self,name,home): self.name = name self.home = home self.power = 0 def hero_power(self,power): self.power = power print(self.name + '\\'s power is '+ str(self.power)) superhero1 = SuperHero('Captain America','Earth') superhero1.hero_power(95) 运行后输出结果： PS D:\\Python\\codefile\\object> python module_1.py Captain America's power is 95 通过方法做数据操作比直接对数据修改安全点，直接对数据修改可以随便改，而在方法里面，可以对数据进行限制，在方法hero_power中加入限制条件: class SuperHero(): sum1 = 0 name = '' home = '' def __init__(self,name,home): self.name = name self.home = home self.power = 0 def hero_power(self,power): if power 运行后输出结果： PS D:\\Python\\codefile\\object> python module_1.py Just kidding, how is it possible? 可以看到输入负数后不可以了，当然上面示例中的if语句还可以这样写，只要是负数，就直接归零然后继续执行后面操作： 同样给-99，输出结果就返回的是0，注意缩进： def hero_power(self,power): if power 运行输出结果： PS D:\\Python\\codefile\\object> python module_1.py Captain America's power is 0 或者这样写，但是这样return的结果不会打印出来，是负数就不会有输出，需要在类外部将结果赋值到一个变量再打印，还是感觉第一种最简单了： class SuperHero(): sum1 = 0 name = '' home = '' def __init__(self,name,home): self.name = name self.home = home self.power = 0 def hero_power(self,power): if power 运行后输出结果： PS D:\\Python\\codefile\\object> python module_1.py Just kidding, how is it possible? 如果给成99，运行后输出结果如下： PS D:\\Python\\codefile\\object> python module_1.py Captain America's power is 99 None if还是会执行，返回值是个空值，所以superhero1_power值是None，综合还是第一种方法最好。 虽然这样限制了，但是在类的外部还是可以进行赋值，如果需要阻止在类的外部对实例变量进行赋值或者访问，这就涉及到成员可见性。 成员可见性有两种属性： 公开的：public，私有的：private 将一个方法变成私有的，可以在方法前面加入双下划线，例如： def hero_power(self,power): hero_power就是一个私有的了，不能在类的外部进行调用了；构造函数除外，在python中，前后都有双下划线都不认为是私有的： class SuperHero(): sum1 = 0 name = '' home = '' def __init__(self,name,home): self.name = name self.home = home self.power = 0 def __hero_power(self,power): if power 运行后可以看到报错了： PS D:\\Python\\codefile\\object> python module_1.py Traceback (most recent call last): File \"module_1.py\", line 231, in superhero1.__hero_power(99) AttributeError: 'SuperHero' object has no attribute '__hero_power' 对于实例变量变成私有的也是一样，在前面加双下划线： class SuperHero(): sum1 = 0 name = '' home = '' def __init__(self,name,home): self.name = name self.home = home self.__power = 0 def hero_power(self,power): if power 运行后输出结果如下： PS D:\\Python\\codefile\\object> python module_1.py Captain America's power is 99 {'name': 'Captain America', 'home': 'Earth', '_SuperHero__power': 99} -1 {'name': 'Captain America', 'home': 'Earth', '_SuperHero__power': 99, '__power': -1} Traceback (most recent call last): File \"module_1.py\", line 253, in print(superhero2.__power) AttributeError: 'SuperHero' object has no attribute '__power' 可以看到调用superhero1.hero_power(99)后有输出结果，即第一行； 在类的外部给调用私有变量并赋值，superhero1.power = -1，打印后也有输出结果； 而直接调用并打印superhero2.power却报错了。 这是由于Python语言的动态性， superhero1.power = -1相当于给superhero1添加了一个新的属性，上面示例中在此前后都用print(superhero1.dict__)查看了成员列表，可以看到明显的变化，多了一个成员； 在成员列表中有一个_SuperHeropower，这是我们设置的私有变量：self.power ，Python中会将此私有变量存储为此形式；__power就是在类外面动态添加的。 面向对象三大特征 继承性 避免定义重复的变量和方法 一般建议一个文件定义一个类 示例在module_1中定义一个类： class Hero(): sum = 0 def __init__(self,name,home): self.name = name self.home = home def get_home(self): print(self.home) 然后在module中去调用： from module_1 import Hero class SuperHero(Hero): def print_hero(self): self.sum += 1 print('My name is '+ self.name) print('I am come form ' +self.home) print('The number of superheroes is '+ str(self.sum)) superhero1 = SuperHero('Captain America','Earth') superhero1.print_hero() superhero1.get_home() 运行后输出结果如下： PS D:\\Python\\codefile\\object> python module_2.py My name is Captain America I am come form Earth The number of superheroes is 1 Earth 可以看到module_2调用了module_1中的类和变量，SuperHero是Hero的子类，SuperHero继承了Hero的实例变量和方法。 有些子类需要有自己的变量，例如上面示例中module2子类中需要加入实例变量dream，在子类中的构造函数需要接受三个参数，除新增的，还需要父类里面的参数，调用的时候也需要 在够着函数中进行调用：Hero._init(self,name,home),self必须要，不然会报错。 示例代码如下： from module_1 import Hero class SuperHero(Hero): def __init__(self,dream,name,home): self.dream = dream Hero.__init__(self,name,home) def print_hero(self): self.sum += 1 print('My name is '+ self.name) print('I am come form ' +self.home) print('I will '+ self.dream) print('The number of superheroes is '+ str(self.sum)) superhero1 = SuperHero('save the world','Captain America','Earth') superhero1.print_hero() 运行后输出结果如下： PS D:\\Python\\codefile\\object> python module_2.py My name is Captain America I am come form Earth I will save the world The number of superheroes is 1 这种方式不推荐，如果此子类不要继承另外个父类，不继承现有的了，那么所有父类的名称都需要更换掉，如果特别多的话，会比较麻烦。 下面介绍第二种调用构造函数方式：super(SuperHero,self).init(name,home)，super在Python中代表父类的关键字，相比上面的方法，推荐使用此方法；如果改了父类，只需要更改子类定义参数中父类的名字就行了，代码里面不需要更改，示例代码如下： from module_1 import Hero class SuperHero(Hero): def __init__(self,dream,name,home): self.dream = dream super(SuperHero,self).__init__(name,home) def print_hero(self): self.sum += 1 print('My name is '+ self.name) print('I am come form ' +self.home) print('I will '+ self.dream) print('The number of superheroes is '+ str(self.sum)) superhero1 = SuperHero('save the world','Captain America','Earth') superhero1.print_hero() 运行后输出结果如下： PS D:\\Python\\codefile\\object> python module_2.py My name is Captain America I am come form Earth I will save the world The number of superheroes is 1 如果子类的方法和父类的方法同名了，Python优先调用子类的方法，如果需要调用父类的，则可以用super去调用，格式跟之前示例一样。 在Python中类是可以多继承的，目前学习只是单继承，用一个思维导图来总结目前学习的类的继承： 类与对象总结 利用一个思维导图进行总结： "},"08-Python/01-Python基础学习笔记/07-Python学习笔记-正则表达式.html":{"url":"08-Python/01-Python基础学习笔记/07-Python学习笔记-正则表达式.html","title":"Python学习笔记-正则表达式","keywords":"","body":"Python学习笔记-正则表达式 正则表达式是一个特殊的字符序列，一个字符串是否与我们所设定的字符序列相匹配 可以实现快速检索文本，实现一些替换文本的操作。 例如： 检查一串数字是否是电话号码； 检测一个字符串是否符合email； 把一个文件里指定的单词替换为另外一个单词。 新的学习内容，在vccode中新建一个包expression，在包下新建一个模块module_1.py开始新代码的学习和编写。 元字符 Python有个内置函数，index可以去查找字符串并判断，也可以用之前学过的in，例如在下面字符中找出神奇女侠： a= 'Thor|Hulk|Captain America|Wonder Woman|Iron Man' print(a.index('Wonder Woman')>-1) print('Wonder Woman' in a) 运行后输出结果如下，可以看到都返回了一个True，说明a中有神奇女侠： PS D:\\Python\\codefile\\expression> python module_1.py True True 用正式表达式也可以解决上面的问题。 Python有一个模块：re，模块中有很多方法，其中有一个findall，格式：findall(pattern: AnyStr, string: AnyStr, flags: _FlagsType=...) -> List[Any] 示例如下： import re a = 'Thor|Hulk|Captain America|Wonder Woman|Iron Man' b = re.findall('Wonder Woman',a) if len(b) > 0: print('DC superhero in the team') print(b) 运行后输出结果如下，可以看到都返回了一个list： PS D:\\Python\\codefile\\expression> python module_1.py DC superhero in the team ['Wonder Woman'] 上面示例中只是查找了一串连续的字符，如果不是连续的，正则表达式也可以实现，例如找出a中所有的数字，示例如下： import re a = '1Thor2Hulk3Captain America4Wonder Woman5Iron Man' b = re.findall('\\d',a) print(b) 运行后输出结果如下： PS D:\\Python\\codefile\\expression> python module_1.py ['1', '2', '3', '4', '5'] 在正则表达式中，\\d表示数字0-9。在正则表达式中，‘Wonder Woman’是普通字符，\\d是元字符，可以混合在一起使用，根据匹配需求来选择。 学习正则表达式其实就是学习元字符的使用，从百度百科上截取了正则表达式元字符列表： 元字符 描述 \\ 将下一个字符标记符、或一个向后引用、或一个八进制转义符。例如，“\\n”匹配\\n。“\\n”匹配换行符。序列“\\\\”匹配“\\”而“(”则匹配“(”。即相当于多种编程语言中都有的“转义字符”的概念。 ^ 匹配输入字行首。如果设置了RegExp对象的Multiline属性，^也匹配“\\n”或“\\r”之后的位置。 $ 匹配输入行尾。如果设置了RegExp对象的Multiline属性，$也匹配“\\n”或“\\r”之前的位置。 * 匹配前面的子表达式任意次。例如，zo*能匹配“z”，也能匹配“zo”以及“zoo”。*等价于{0,}。 + 匹配前面的子表达式一次或多次(大于等于1次）。例如，“zo+”能匹配“zo”以及“zoo”，但不能匹配“z”。+等价于{1,}。 ? 匹配前面的子表达式零次或一次。例如，“do(es)?”可以匹配“do”或“does”。?等价于{0,1}。 {n} n是一个非负整数。匹配确定的n次。例如，“o{2}”不能匹配“Bob”中的“o”，但是能匹配“food”中的两个o。 {n,} n是一个非负整数。至少匹配n次。例如，“o{2,}”不能匹配“Bob”中的“o”，但能匹配“foooood”中的所有o。“o{1,}”等价于“o+”。“o{0,}”则等价于“o*”。 {n,m} m和n均为非负整数，其中n ? 当该字符紧跟在任何一个其他限制符（*,+,?，{n}，{n,}，{n,m}）后面时，匹配模式是非贪婪的。非贪婪模式尽可能少地匹配所搜索的字符串，而默认的贪婪模式则尽可能多地匹配所搜索的字符串。例如，对于字符串“oooo”，“o+”将尽可能多地匹配“o”，得到结果[“oooo”]，而“o+?”将尽可能少地匹配“o”，得到结果 ['o', 'o', 'o', 'o'] .点 匹配除“\\n”和\"\\r\"之外的任何单个字符。要匹配包括“\\n”和\"\\r\"在内的任何字符，请使用像“[\\s\\S]”的模式。 (pattern) 匹配pattern并获取这一匹配。所获取的匹配可以从产生的Matches集合得到，在VBScript中使用SubMatches集合，在JScript中则使用$0…$9属性。要匹配圆括号字符，请使用“\\(”或“\\)”。 (?:pattern) 非获取匹配，匹配pattern但不获取匹配结果，不进行存储供以后使用。这在使用或字符“(|)”来组合一个模式的各个部分时很有用。例如“industr(?:y|ies)”就是一个比“industry|industries”更简略的表达式。 (?=pattern) 非获取匹配，正向肯定预查，在任何匹配pattern的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如，“Windows(?=95|98|NT|2000)”能匹配“Windows2000”中的“Windows”，但不能匹配“Windows3.1”中的“Windows”。预查不消耗字符，也就是说，在一个匹配发生后，在最后一次匹配之后立即开始下一次匹配的搜索，而不是从包含预查的字符之后开始。 (?!pattern) 非获取匹配，正向否定预查，在任何不匹配pattern的字符串开始处匹配查找字符串，该匹配不需要获取供以后使用。例如“Windows(?!95|98|NT|2000)”能匹配“Windows3.1”中的“Windows”，但不能匹配“Windows2000”中的“Windows”。 (? 非获取匹配，反向肯定预查，与正向肯定预查类似，只是方向相反。例如，“(? (? 非获取匹配，反向否定预查，与正向否定预查类似，只是方向相反。例如“(? x|y 匹配x或y。例如，“z|food”能匹配“z”或“food”(此处请谨慎)。“[z|f]ood”则匹配“zood”或“food”。 [xyz] 字符集合。匹配所包含的任意一个字符。例如，“[abc]”可以匹配“plain”中的“a”。 [\\^xyz] 负值字符集合。匹配未包含的任意字符。例如，“[\\^abc]”可以匹配“plain”中的“plin”任一字符。 [a-z] 字符范围。匹配指定范围内的任意字符。例如，“[a-z]”可以匹配“a”到“z”范围内的任意小写字母字符。注意:只有连字符在字符组内部时,并且出现在两个字符之间时,才能表示字符的范围; 如果出字符组的开头,则只能表示连字符本身. [\\^a-z] 负值字符范围。匹配任何不在指定范围内的任意字符。例如，“[\\^a-z]”可以匹配任何不在“a”到“z”范围内的任意字符。 \\b 匹配一个单词的边界，也就是指单词和空格间的位置（即正则表达式的“匹配”有两种概念，一种是匹配字符，一种是匹配位置，这里的\\b就是匹配位置的）。例如，“er\\b”可以匹配“never”中的“er”，但不能匹配“verb”中的“er”；“\\b1”可以匹配“1_23”中的“1”，但不能匹配“213”中的“1”。 \\B 匹配非单词边界。“er\\B”能匹配“verb”中的“er”，但不能匹配“never”中的“er”。 \\cx 匹配由x指明的控制字符。例如，\\cM匹配一个Control-M或回车符。x的值必须为A-Z或a-z之一。否则，将c视为一个原义的“c”字符。 \\d 匹配一个数字字符。等价于[0-9]。grep 要加上-P，perl正则支持 \\D 匹配一个非数字字符。等价于[\\^0-9]。grep要加上-P，perl正则支持 \\f 匹配一个换页符。等价于\\x0c和\\cL。 \\n 匹配一个换行符。等价于\\x0a和\\cJ。 \\r 匹配一个回车符。等价于\\x0d和\\cM。 \\s 匹配任何不可见字符，包括空格、制表符、换页符等等。等价于[ \\f\\n\\r\\t\\v]。 \\S 匹配任何可见字符。等价于[\\^ \\f\\n\\r\\t\\v]。 \\t 匹配一个制表符。等价于\\x09和\\cI。 \\v 匹配一个垂直制表符。等价于\\x0b和\\cK。 \\w 匹配包括下划线的任何单词字符。类似但不等价于“[A-Za-z0-9_]”，这里的\"单词\"字符使用Unicode字符集。 \\W 匹配任何非单词字符。等价于“[\\^A-Za-z0-9_]”。 \\xn 匹配n，其中n为十六进制转义值。十六进制转义值必须为确定的两个数字长。例如，“\\x41”匹配“A”。“\\x041”则等价于“\\x04&1”。正则表达式中可以使用ASCII编码。 \\num 匹配num，其中num是一个正整数。对所获取的匹配的引用。例如，“(.)\\1”匹配两个连续的相同字符。 \\n 标识一个八进制转义值或一个向后引用。如果\\n之前至少n个获取的子表达式，则n为向后引用。否则，如果n为八进制数字（0-7），则n为一个八进制转义值。 \\nm 标识一个八进制转义值或一个向后引用。如果\\nm之前至少有nm个获得子表达式，则nm为向后引用。如果\\nm之前至少有n个获取，则n为一个后跟文字m的向后引用。如果前面的条件都不满足，若n和m均为八进制数字（0-7），则\\nm将匹配八进制转义值nm。 \\nml 如果n为八进制数字（0-7），且m和l均为八进制数字（0-7），则匹配八进制转义值nml。 \\un 匹配n，其中n是一个用四个十六进制数字表示的Unicode字符。例如，\\u00A9匹配版权符号（©）。 \\p{P} 小写 p 是 property 的意思，表示 Unicode 属性，用于 Unicode 正表达式的前缀。中括号内的“P”表示Unicode 字符集七个字符属性之一：标点字符。其他六个属性：L：字母；M：标记符号（一般不会单独出现）；Z：分隔符（比如空格、换行等）；S：符号（比如数学符号、货币符号等）；N：数字（比如阿拉伯数字、罗马数字等）；C：其他字符。*注：此语法部分语言不支持，例：javascript。 \\ 匹配词（word）的开始（\\）。例如正则表达式\\能够匹配字符串\"for the wise\"中的\"the\"，但是不能匹配字符串\"otherwise\"中的\"the\"。注意：这个元字符不是所有的软件都支持的。 ( ) 将( 和 ) 之间的表达式定义为“组”（group），并且将匹配这个表达式的字符保存到一个临时区域（一个正则表达式中最多可以保存9个），它们可以用 \\1 到\\9 的符号来引用。 | 将两个匹配条件进行逻辑“或”（or）运算。例如正则表达式(him|her) 匹配\"it belongs to him\"和\"it belongs to her\"，但是不能匹配\"it belongs to them.\"。注意：这个元字符不是所有的软件都支持的。 字符集 如果需要匹配字符串中的某一个字符，例如下面示例中需要匹配字符中单词第二个字母为c或者d的单词： import re a = 'abc,adc,aec,ajc,acc,aic,alc' b = re.findall('a[cd]c',a) c = re.findall('a[^cd]c',a) print(b) print(c) 运行后输出结果如下： PS D:\\Python\\codefile\\expression> python module_1.py ['adc', 'acc'] ['abc', 'aec', 'ajc', 'aic', 'alc'] 上面方法用到了普通字符和元字符的混合用法，在[cd]中c、d是或关系，加上^就是取反，[c-f]格式就是c到f字母都匹配。 概括字符集 在上面示例中，\\d可以用[0-9]实现，\\D可以用[\\^0-9]实现，像\\d这种可以叫概括字符集，就代表一类或者一串字符了， \\w可以代表所有单词字符，\\W代表非单词字符，制表符都属于非单词字符； 不敢是字符集，还是概括字符集，都只可以匹配单一的字符，例如下面示例，输出结果都是拆分后的字符： import re a = 'Thor1Hulk2Batman9' b = re.findall('\\w',a) print(b) 运行后输出结果如下： PS D:\\Python\\codefile\\expression> python module_1.py ['T', 'h', 'o', 'r', '1', 'H', 'u', 'l', 'k', '2', 'B', 'a', 't', 'm', 'a', 'n', '9'] \\s可以代表任何不可见字符，包括空格、制表符、换页符等等，或者叫空白字符。等价于[ \\f\\n\\r\\t\\v]： import re a = 'Thor &1Hulk2\\nBatman\\t9' b = re.findall('\\s',a) print(b) 运行后输出结果如下： PS D:\\Python\\codefile\\expression> python module_1.py [' ', '\\n', '\\t'] 数量词 之前的示例中，可以看到字符匹配都是单个字符，输出结果也是单个字符，如果需要是多个，则需要用到数量词，示例中的{4}就表示四个字符，{4，7}表示4到7个字符的匹配： import re a = 'thor342captain 342batman 2thanos 423hulk' b = re.findall('[a-z]{4}',a) c = re.findall('[a-z]{4,7}',a) print(b) print(c) 运行后输出结果如下： PS D:\\Python\\codefile\\expression> python module_1.py ['thor', 'capt', 'batm', 'than', 'hulk'] ['thor', 'captain', 'batman', 'thanos', 'hulk'] 贪婪和非贪婪 默认情况下Python倾向于贪婪匹配方式，例如{4,7}，Python匹配到第三个的时候，会继续匹配直到不满足条件。 在数量词后面加上问号，就可以改成非贪婪模式： import re a = 'thor342captain 342batman 2thanos 423hulk' b = re.findall('[a-z]{4}',a) c = re.findall('[a-z]{4,7}?',a) print(b) print(c) 运行后输出结果如下： PS D:\\Python\\codefile\\expression> python module_1.py ['thor', 'capt', 'batm', 'than', 'hulk'] ['thor', 'capt', 'batm', 'than', 'hulk'] 可以看到c和b的输出结果是一样的。 匹配次数 星号：*，匹配0次或无限多次； 加号：+，匹配1次或者无限次； 问好：？，匹配0次或者1次。一般用于去重，去除重复的字母。和非贪婪的用法和意义不一样； 点：. ，匹配除换行符\\n之外的其它所有字符。 示例如下： import re a = 'Thano0Thanos1Thanoss2' b = re.findall('Thanos*',a) c = re.findall('Thanos+',a) d = re.findall('Thanos?',a) print(b) print(c) print(d) 运行后输出结果如下： PS D:\\Python\\codefile\\expression> python module_1.py ['Thano', 'Thanos', 'Thanoss'] ['Thanos', 'Thanoss'] ['Thano', 'Thanos', 'Thanos'] 边界匹配 例如下面示例，需要密码是4到8位，用下面方法可以匹配下： import re password1 = '1234567' password2 = '123' password3 = '123456789' a = re.findall('\\d{4,8}',password1) b = re.findall('\\d{4,8}',password2) c = re.findall('\\d{4,8}',password3) print(a) print(b) print(c) 运行输出结果： PS D:\\Python\\codefile\\expression> python module_1.py ['1234567'] [] ['12345678'] 上面示例中只是个寻找匹配，不是完全匹配，这里就需要用到边界匹配； ^表示从字符串开头匹配，$表示从字符串末尾匹配，一前一后就可以匹配完整的字符串： import re password1 = '1234567' password2 = '123' password3 = '123456789' a = re.findall('^\\d{4,8}$',password1) b = re.findall('^\\d{4,8}&',password2) c = re.findall('^\\d{4,8}$',password3) print(a) print(b) print(c) 运行输出结果： PS D:\\Python\\codefile\\expression> python module_1.py ['1234567'] [] [] 组 下面字符串中包括多个Thanos，需要判断字符串中是否包含三个Thanos，把Thanos用括号括起来，括起来的字符就在正则表达式中称作组，在组的后面加上数量词，表示把组的字符重复多少次： import re a = 'ThanosThanosThanosThanos' b = re.findall('(Thanos){3}',a) print(b) 运行输出结果： PS D:\\Python\\codefile\\expression> python module_1.py ['Thanos'] 注意，之前用的[ ]，里面字符是或关系，这里的( )里面的字符是且关系。 匹配模式参数 之前提到过re.findall的格式：findall(pattern: AnyStr, string: AnyStr, flags: _FlagsType=...) -> List[Any]，还有一个参数flags就是匹配模式参数； 如何匹配忽略大小写，可以下模式参数下设置re.I，就可以了： import re hero = 'Thor,Hulk\\n,Iron Man,Batman' a = re.findall('hulk.{1}',hero,re.I | re.S) print(a) 运行输出结果： PS D:\\Python\\codefile\\expression> python module_1.py ['Hulk\\n'] 对于模式参数，可以接收好几种模式，多种模式通过 | 来隔开，参数间是且关系。re.I表示可以不区分大小写，re.S参数加入后就可以匹配到换行符了，不加的话，匹配字符里面的.{1}就会无效。 re.sub正则替换 re模块下有很多函数，sub用于字符串的替换，格式如下： def sub(pattern: AnyStr, repl: AnyStr, string: AnyStr, count: int=..., flags: _FlagsType=...) 例如下面示例尝试把Thanos换成Thor： import re hero = 'Iron Man,Captain America,Thanos,Hulk,Thanos' real_hero = re.sub('Thanos','Thor',hero,0) print(real_hero) 运行输出结果： PS D:\\Python\\codefile\\expression> python module_1.py Iron Man,Captain America,Thor,Hulk,Thor 可以看到成功替换了，count参数默认值是0，表示无限替换下去，就是有多少替换多少，如果设置1，那么就只替换一次了。 也可以使用下面方法去替换，调用replace函数，但是必须将值赋值给一个新的变量，因为字符串是不可变的，如果不赋值，打印出来的hero是不会改变的： import re hero = 'Iron Man,Captain America,Thanos,Hulk,Thanos' real_hero = hero.replace('Thanos','Thor') print(real_hero) 简单的建议用replace，复杂点的可以用re.sub。 sub还有个强大的功能，就是第二个参数可以是一个函数，例如定义一个函数superhero，先空着： import re hero = 'Iron Man,Captain America,Thanos,Hulk,Thanos' def superhero(value): print(value) real_hero = re.sub('Thanos',superhero,hero,0) print(real_hero) 运行输出结果： PS D:\\Python\\codefile\\expression> python module_1.py Iron Man,Captain America,,Hulk, 可以看到Thanos全没了。如果把一个函数作为sub第二个参数传到参数列表，运行流程是，当sub的一个参数Thanos匹配到一个结果后，会把匹配结果传到函数里面，函数返回结果会是一个新的结果，因为我们函数没有返回值，所以Thanos就会被空字符替换。 打印出来的value是个对象，可以调用value的group方法拿到匹配的字符： import re hero = 'Iron Man,Captain America,Thanos,Hulk,Thanos' def superhero(value): matched = value.group() return matched + ' is not a hero' real_hero = re.sub('Thanos',superhero,hero,0) print(real_hero) 运行输出结果： PS D:\\Python\\codefile\\expression> python module_1.py Iron Man,Captain America,Thanos is not a hero,Hulk,Thanos is not a hero 需要根据匹配结果，做不同的操作的时候，使用到函数就比较方便了， 下面的字符串中，我们要把字符中数字大于等于5的数值改成9，小于5的改成0： import re a = 'AF2582GELG834534' def convert(value): matched = value.group() if int(matched) >= 5: return '9' else: return '0' b = re.sub('\\d',convert,a) print(b) 运行输出结果： PS D:\\Python\\codefile\\expression> python module_1.py AF0990GELG900900 matched是个字符，所以要传换成一个整形，返回值也是一样，直接数字是不行的，要是一个字符串。 re.match和re.search re.match格式：def match(pattern: AnyStr, string: AnyStr, flags: _FlagsType=...) re.search格式：def match(pattern: AnyStr, string: AnyStr, flags: _FlagsType=...) 二者共同点就是只匹配一次，findall会匹配所有符合的元素。 下面示例中想匹配字符串a中的数字： import re a = 'tdfaf48tr48qhff4j' b = re.match('\\d',a) c = re.search('\\d',a) print(b) print(c) 运行后输出如下： PS D:\\Python\\codefile\\expression> python module_1.py None match输出结果是None，说明没有匹配到，serch有匹配到，但是返回的一个match对象。 match匹配特征是从字符串开始来匹配，a字符串开头是字母，所以直接返回了一个空值；如果把字符串第一个改成数字，返回和search一样都是一个对象了； search匹配是在字符串中搜索，找到第一个符合的条件后，就返回出结果。 上面示例中把第一个改成数字，并且用group来获取返回结果： import re a = '7dfaf48tr48qhff4j' b = re.match('\\d',a) c = re.search('\\d',a) print(b.group()) print(c.group()) 运行后输出如下： PS D:\\Python\\codefile\\expression> python module_1.py 7 7 group分组 下面示例中，需要匹配出am和！中间的字符，包括空格： import re a = 'I am Iron Man !' b = re.search('am.*!',a) print(b.group()) 运行后输出如下： PS D:\\Python\\codefile\\expression> python module_1.py am Iron Man ! 之前有学习过，点 . 就是匹配除换行符\\n之外的其它所有字符，*就是进行多次匹配，可以看到有匹配中间结果，但是根据需要，应该只是需要中间的名字，这样的匹配方式显然不满足需求， group可以传递参数，指定获取的组号，默认是0，之前的示例中只有一个组：am.*! ，加上括号也可以（am.*!），输出结果一样。 在上面的示例中改动下，把模糊匹配括起来作为一个组：（.*） import re a = 'I am Iron Man !' b = re.search('am(.*)!',a) print(b.group(1)) print(b) 运行后输出如下： PS D:\\Python\\codefile\\expression> python module_1.py Iron Man 可以看到是预期的结果，如果group参数不设置或者设置为0，输出都是完整的匹配结果，所有设置为1。 用findall也可以实现，更加简洁: import re a = 'I am Iron Man !' b = re.findall('am(.*)!',a) print(b) 运行后输出如下： PS D:\\Python\\codefile\\expression> python module_1.py [' Iron Man '] group也可以用group(0,1,2)这样用，可以用groups()这种就输出组里面的内容。 正则表达式学习总结 正则表达式可以完成一些字符串内置函数无法完成的功能。 常用正则表达式 下面内容截取自链接：https://www.cnblogs.com/zxin/archive/2013/01/26/2877765.html 校验数字的表达式 数字：\\^[0-9]*$ n位的数字：\\^\\d{n}$ 至少n位的数字：\\^\\d{n,}$ m-n位的数字：\\^\\d{m,n}$ 零和非零开头的数字：\\^(0|[1-9][0-9]*)$ 非零开头的最多带两位小数的数字：\\^([1-9][0-9]*)+(.[0-9]{1,2})?$ 带1-2位小数的正数或负数：\\^(\\-)?\\d+(\\.\\d{1,2})?$ 正数、负数、和小数：\\^(\\-|\\+)?\\d+(\\.\\d+)?$ 有两位小数的正实数：\\^[0-9]+(.[0-9]{2})?$ 有1~3位小数的正实数：\\^[0-9]+(.[0-9]{1,3})?$ 非零的正整数：\\^[1-9]\\d$ 或者 \\^([1-9][0-9]\\){1,3}$ 或 \\^\\+?[1-9][0-9]*$ 非零的负整数：\\^\\-[1-9][]0-9\"*$ 或 ^-[1-9]\\d*$ 非负整数：^\\d+$ 或 \\^[1-9]\\d*|0$ 非正整数：\\^-[1-9]\\d*|0$ 或 ^((-\\d+)|(0+))$ 非负浮点数：^\\d+(\\.\\d+)?$ 或 \\^[1-9]\\d\\.\\d|0\\.\\d[1-9]\\d|0?\\.0+|0$ 非正浮点数：^((-\\d+(\\.\\d+)?)|(0+(\\.0+)?))$ 或 ^(-([1-9]\\d\\.\\d|0\\.\\d[1-9]\\d))|0?\\.0+|0$ 正浮点数：\\^[1-9]\\d\\.\\d|0\\.\\d[1-9]\\d$ 或 ^(([0-9]+\\.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]*\\.[0-9]+)|([0-9]*[1-9][0-9]*))$ 负浮点数：^-([1-9]\\d\\.\\d|0\\.\\d[1-9]\\d)$ 或 ^(-(([0-9]+.[0-9]*[1-9][0-9]*)|([0-9]*[1-9][0-9]\\.[0-9]+)|([0-9]\\[1-9][0-9]*)))$ 浮点数：^(-?\\d+)(\\.\\d+)?$ 或 ^-?([1-9]\\d\\.\\d|0\\.\\d[1-9]\\d|0?\\.0+|0)$ 校验字符的表达式 汉字：\\^[\\u4e00-\\u9fa5]{0,}$ 英文和数字：\\^[A-Za-z0-9]+$ 或 \\^[A-Za-z0-9]{4,40}$ 长度为3-20的所有字符：^.{3,20}$ 由26个英文字母组成的字符串：\\^[A-Za-z]+$ 由26个大写英文字母组成的字符串：\\^[A-Z]+$ 由26个小写英文字母组成的字符串：\\^[a-z]+$ 由数字和26个英文字母组成的字符串：\\^[A-Za-z0-9]+$ 由数字、26个英文字母或者下划线组成的字符串：\\^\\w+$ 或 ^\\w{3,20}$ 中文、英文、数字包括下划线：\\^[\\u4E00-\\u9FA5A-Za-z0-9_]+$ 中文、英文、数字但不包括下划线等符号：\\^[\\u4E00-\\u9FA5A-Za-z0-9]+$ 或 \\^[\\u4E00-\\u9FA5A-Za-z0-9]{2,20}$ 可以输入含有^%&',;=?$\\\"等字符：[\\^\\%\\&'\\,\\;\\=\\?$\\x22]+ 禁止输入含有~的字符：[\\^~\\x22]+ 特殊需求表达式 Email地址：^\\w+([-+.]\\w+)*@\\w+([-.]\\w+)*\\.\\w+([-.]\\w+)*$ 域名：[a-zA-Z0-9][-a-zA-Z0-9]{0,62}(/.[a-zA-Z0-9][-a-zA-Z0-9]{0,62})+/.? InternetURL：[a-zA-z]+://[\\^\\s] 或 \\^http://([\\w-]+\\\\.)+[\\w-]+(/[\\w-./?%&=]\\)?$ 手机号码：^(13[0-9]|14[0-9]|15[0-9]|16[0-9]|17[0-9]|18[0-9]|19[0-9])\\d{8}$ (由于工信部放号段不定时，所以建议使用泛解析 ^([1][3,4,5,6,7,8,9])\\d{9}$) 电话号码(\"XXX-XXXXXXX\"、\"XXXX-XXXXXXXX\"、\"XXX-XXXXXXX\"、\"XXX-XXXXXXXX\"、\"XXXXXXX\"和\"XXXXXXXX)：^(\\(\\d{3,4}-)|\\d{3.4}-)?\\d{7,8}$ 6 国内电话号码(0511-4405222、021-87888822)：\\d{3}-\\d{8}|\\d{4}-\\d{7} 18位身份证号码(数字、字母x结尾)：^((\\d{18})|([0-9x]{18})|([0-9X]{18}))$ 帐号是否合法(字母开头，允许5-16字节，允许字母数字下划线)：\\^[a-zA-Z][a-zA-Z0-9_]{4,15}$ 密码(以字母开头，长度在6~18之间，只能包含字母、数字和下划线)：\\^[a-zA-Z]\\w{5,17}$ 强密码(必须包含大小写字母和数字的组合，不能使用特殊字符，长度在8-10之间)：^(?=.*\\d)(?=.*[a-z])(?=.*[A-Z]).{8,10}$ 日期格式：^\\d{4}-\\d{1,2}-\\d{1,2} 一年的12个月(01～09和1～12)：^(0?[1-9]|1[0-2])$ 一个月的31天(01～09和1～31)：^((0?[1-9])|((1|2)[0-9])|30|31)$ 钱的输入格式：有四种钱的表示形式我们可以接受:\"10000.00\" 和 \"10,000.00\", 和没有 \"分\" 的 \"10000\" 和 \"10,000\"：\\^[1-9][0-9]*$ 这表示任意一个不以0开头的数字,但是,这也意味着一个字符\"0\"不通过,所以我们采用下面的形式：^(0|[1-9][0-9]*)$ 一个0或者一个不以0开头的数字.我们还可以允许开头有一个负号：^(0|-?[1-9][0-9]*)$ 这表示一个0或者一个可能为负的开头不为0的数字.让用户以0开头好了.把负号的也去掉,因为钱总不能是负的吧.下面我们要加的是说明可能的小数部分：\\^[0-9]+(.[0-9]+)?$ 必须说明的是,小数点后面至少应该有1位数,所以\"10.\"是不通过的,但是 \"10\" 和 \"10.2\" 是通过的：\\^[0-9]+(.[0-9]{2})?$ 这样我们规定小数点后面必须有两位,如果你认为太苛刻了,可以这样：\\^[0-9]+(.[0-9]{1,2})?$ 这样就允许用户只写一位小数.下面我们该考虑数字中的逗号了,我们可以这样：\\^[0-9]{1,3}(,[0-9]{3})*(.[0-9]{1,2})?$ 1到3个数字,后面跟着任意个 逗号+3个数字,逗号成为可选,而不是必须：^([0-9]+|[0-9]{1,3}(,[0-9]{3})*)(.[0-9]{1,2})?$ 备注：这就是最终结果了,别忘了\"+\"可以用\"*\"替代如果你觉得空字符串也可以接受的话(奇怪,为什么?)最后,别忘了在用函数时去掉去掉那个反斜杠,一般的错误都在这里 xml文件：^([a-zA-Z]+-?)+[a-zA-Z0-9]+\\.[x|X][m|M][l|L]$ 中文字符的正则表达式：[\\u4e00-\\u9fa5] 双字节字符：[\\^\\x00-\\xff] (包括汉字在内，可以用来计算字符串的长度(一个双字节字符长度计2，ASCII字符计1)) 空白行的正则表达式：\\n\\s*\\r (可以用来删除空白行) HTML标记的正则表达式：?)\" id=\"reffn_>\">>\\>.*?| (网上流传的版本太糟糕，上面这个也仅仅能部分，对于复杂的嵌套标记依旧无能为力) 首尾空白字符的正则表达式：\\^\\s|\\s$或(^\\s)|(\\s$) (可以用来删除行首行尾的空白字符(包括空格、制表符、换页符等等)，非常有用的表达式) 腾讯QQ号：[1-9][0-9]{4,} (腾讯QQ号从10000开始) 中国邮政编码：[1-9]\\d{5}(?!\\d) (中国邮政编码为6位数字) IP地址：\\d+.\\d+.\\d+.\\d+ (提取IP地址时有用) "},"08-Python/01-Python基础学习笔记/08-Python学习笔记-JSON.html":{"url":"08-Python/01-Python基础学习笔记/08-Python学习笔记-JSON.html","title":"Python学习笔记-JSON","keywords":"","body":"Python学习笔记-JSON 全称：JavaScript Object Notation（JavaScript 对象标记） 是一种轻量级的数据交换格式； 字符串是JSON的表现形式； 符合JSON格式的字符串叫做JSON字符串； 相比XML，JSON优势： 易于阅读；易于解析；网络传输效率高； 共有特点：跨语言交换数据 反序列化 JSON的载体是字符串，在Python中就是个str； Python下有个模块叫json，模块下有很多方法去操作JSON数据，json.loads方法可以把JSON转换成Python对应的数据结构； 对于json_str数据，示例如下： import json json_str = \"{name:Thor,home:Asgard}\" superhero1 = json.loads(json_str) 运行后输出结果如下： PS D:\\Python\\codefile\\J_JSON> python module_1.py Traceback (most recent call last): File \"module_1.py\", line 3, in superhero1 = json.loads(json_str) File \"C:\\Users\\QianHuang\\AppData\\Local\\Programs\\Python\\Python38\\lib\\json\\__init__.py\", line 357, in loads return _default_decoder.decode(s) File \"C:\\Users\\QianHuang\\AppData\\Local\\Programs\\Python\\Python38\\lib\\json\\decoder.py\", line 337, in decode obj, end = self.scan_once(s, idx) json.decoder.JSONDecodeError: Expecting property name enclosed in double quotes: line 1 column 2 (char 1) 可以看到报错了，说明json_str格式不对，在JSON，字符需要用双引号表示，必须是双引号，用单引号也不行，因为JSON是跨语言的，方便其他语言去解析，所以规定了用双引号。里面用双引号后，外部用单引号，修改后如下： import json json_str = '{\"name\":\"Thor\",\"home\":\"Asgard\"}' superhero1 = json.loads(json_str) print(type(superhero1)) print(superhero1) print(superhero1['home']) 运行后输出结果如下，可以看到输出的是一个dict，并且格式也采用Python默认的单引号： PS D:\\Python\\codefile\\J_JSON> python module_1.py {'name': 'Thor', 'home': 'Asgard'} Asgard 对于同一个JSON字符串，不同的语言可能解析出来的数据类型是不一样的。 上面示例中提到的字符串对应到JSON里面来说表示是JSON的一个object，JSON还有array数组这种数据类型，示例如下： import json json_str = '[{\"name\":\"Thor\",\"home\":\"Asgard\"},{\"name\":\"Hulk\",\"home\":\"Earth\"}]' superhero = json.loads(json_str) print(type(superhero)) print(superhero) 运行后输出结果如下，可以看到输出是一个列表： PS D:\\Python\\codefile\\J_JSON> python module_1.py [{'name': 'Thor', 'home': 'Asgard'}, {'name': 'Hulk', 'home': 'Earth'}] 稍微修改下，加个元素，是个bool值，并且全小写： import json json_str = '[{\"name\":\"Thor\",\"home\":\"Asgard\",\"hero\":true},{\"name\":\"Hulk\",\"home\":\"Earth\"}]' superhero = json.loads(json_str) print(type(superhero)) print(superhero) 运行后输出结果如下，可以看到输出是一个列表，并且把bool值转换成Python中的格式： PS D:\\Python\\codefile\\J_JSON> python module_1.py [{'name': 'Thor', 'home': 'Asgard', 'hero': True}, {'name': 'Hulk', 'home': 'Earth'}] 在编程中，有一个术语来定义由字符串到某一种语言对象的解析过程，即反序列化。 下面做了一个表格来表示转换后的数据类型： 语言 字典 列表 字符 整型 浮点数 布尔值 JSON object array string number number true Python dict list str int float True 序列化 就是把Python的数据类型像JSON数据类型转换的过程。 定义一个字典superhero，但是使用了多行，现在转换成JSON数据类型，一样是引用json模块，使用模块下的json.dumps方法来实现： import json superhero = [ {'name': 'Thor', 'home': 'Asgard', 'hero': True}, {'name': 'Hulk', 'home': 'Earth'} ] json_str = json.dumps(superhero) print(type(json_str)) print(json_str) 运行后输出结果如下，可以看到bool值和字符类型转换成JSON的格式： PS D:\\Python\\codefile\\J_JSON> python module_1.py [{\"name\": \"Thor\", \"home\": \"Asgard\", \"hero\": true}, {\"name\": \"Hulk\", \"home\": \"Earth\"}] JSON总结 JSON数据类型是一种中间数据类型，用于多语言间的数据转换； JSON有自己的数据类型，虽然它和Javascript的数据类型有些类似。 豆瓣API:https://douban-api-docs.zce.me/ 用一个图形来概括JSON的用途： "},"08-Python/01-Python基础学习笔记/09-Python学习笔记-枚举.html":{"url":"08-Python/01-Python基础学习笔记/09-Python学习笔记-枚举.html","title":"Python学习笔记-枚举","keywords":"","body":"Python学习笔记-枚举 枚举基本概念 枚举其实是个类 有一类数据，经常用一些数字代表一些数据类型，例如，1代表Thor，2代表Hulk，3代表Thanos，4代表Batman，当我们读到数字的时候，无法指定其代表意义。 字典可能比较合适表示这类型数据，这里就需要枚举这个数据类型表示这种数据。 编写枚举需要导入一个枚举类，从enum模块导入类Enum； 枚举在Python本质是一个类，需要定义一个类，然后继承默认的Enum，所有枚举类都是Enum的子类； 示例如下： from enum import Enum class SuperHero(Enum): Thor = 1 Hulk = 2 Thanos = 3 Batman = 4 print(SuperHero.Thor) print(type(SuperHero.Thor)) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py SuperHero.Thor 枚举的标识名字，一般建议全部用大写，示例中首字母大写不推荐； 打印出来的结果就是SuperHero.Thor，类型可以看到是个枚举。这样才是枚举的意义所在，我们看代码时候，不在乎Thor具体数值是多少（可以为其它字符），对于写代码和读代码没多大意义，我们只需要知道代表的意义就行了。 枚举的特点和优势 上面的示例中，可以用字典表示下：{'Thor':1,'Hulk':2,'Thanos':3,'Batman':4},也可以用普通类表示，例如： class SuperHero(): Thor = 1 Hulk = 2 Thanos = 3 Batman = 4 上面两种表示方法都是可变的，就是可以在代码中轻易改变它们的值，并且没有防止相同标签的功能。 例如改变dict的值： a = {'Thor':1,'Hulk':2,'Thanos':3,'Batman':4} a['Thanos'] = 5 print(a) 可以看到被改变了。 不同的类型用不同的数字来代表，字典和普通的类可以拥有相同的数值。在枚举中，定义的是常量，不能轻易被更改， from enum import Enum class SuperHero(Enum): Thor = 1 Hulk = 2 Thanos = 3 Batman = 4 print(SuperHero.Thor) SuperHero.Thor = 5 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py SuperHero.Thor Traceback (most recent call last): File \"module_1.py\", line 27, in SuperHero.Thor = 5 raise AttributeError('Cannot reassign members.') AttributeError: Cannot reassign members. {'Thor': 1, 'Hulk': 2, 'Thanos': 5, 'Batman': 4} 可以看到执行后报错了，用Thor = 1 后，也不能用Thor = 2，同意执行后会报错。 枚举类型、枚举名称与枚举值 如何获取枚举类型某一个标签所对应的具体数值，获取的方式通过value这个值，格式如下：SuperHero.Thor.value,通过.name获取标签的名字，示例如下： from enum import Enum class SuperHero(Enum): Thor = 1 Hulk = 2 Thanos = 3 print(SuperHero.Thor.value) print(SuperHero.Thor.name) print(type(SuperHero.Thor.name)) print(SuperHero['Hulk']) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py 1 Thor SuperHero.Hulk 之前有打印SuperHero.Thor，可以看到是个枚举类型，现在我们打印的name是个字符串。SuperHero['Hulk']表示名称所对应的枚举类型。 SuperHero.Thor是枚举类型，Thor是枚举名称，1就是枚举值。 枚举的比较运算 两个枚举之间是可以进行等值比较的，示例如下： from enum import Enum class SuperHero(Enum): Thor = 1 Hulk = 2 result = SuperHero.Thor == SuperHero.Hulk print(result) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py False 如果将枚举和一个数值进行比较： from enum import Enum class SuperHero(Enum): Thor = 1 Hulk = 2 result = SuperHero.Thor == 1 print(result) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py False 可以看到不会报错，但是得不到预期的结果，判断的结果是False。 枚举类型之间是不支持进行大小比较的，示例如下： from enum import Enum class SuperHero(Enum): Thor = 1 Hulk = 2 result = SuperHero.Thor 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py Traceback (most recent call last): File \"module_1.py\", line 60, in result = SuperHero.Thor 可以看到报错了，说明不支持。 枚举类型直接支持身份比较，示例如下： from enum import Enum class SuperHero(Enum): Thor = 1 Hulk = 2 result = SuperHero.Thor is SuperHero.Thor print(result) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py Ture 不同的枚举之间的枚举类型数值是意义的，但是不同枚举之间不能做等值比较。 枚举注意事项 不能有两个相同的标签； 不同标签可以有两个相同的数值，示例如下： from enum import Enum class SuperHero(Enum): Thor = 1 Hulk = 1 print(SuperHero.Hulk) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py SuperHero.Thor 可是输出结果确实枚举类型却是Thor，而不是Hulk，在这种情况下，可以把Hulk看作成Thor的一个别名，本身不能代表一个枚举类型，改成Thor_ALIAS更适合。 枚举的遍历需要注意： from enum import Enum class SuperHero(Enum): Thor = 1 Hulk = 1 Thanos = 3 for a in SuperHero: print(a) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py SuperHero.Thor SuperHero.Thanos 可以看到只打印出了SuperHero.Thor，如果一定要打印出来： 可以采用下面方法，遍历SuperHero下面的members属性，使用模块members下的items方法： from enum import Enum class SuperHero(Enum): Thor = 1 Hulk = 1 Thanos = 3 for a in SuperHero.__members__.items(): print(a) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py ('Thor', ) ('Hulk', ) ('Thanos', ) 不调用items方法，直接调用members输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py Thor Hulk Thanos 枚举转换 将一个数值传换成枚举类型，使用类名，把a传递进来：SuperHero(a)，示例如下： from enum import Enum class SuperHero(Enum): Thor = 1 Hulk = 2 Batman = 3 a = 3 print(SuperHero(a)) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py SuperHero.Batman 枚举小结 除了Enum，还有IntEnum， 之前的示例中用的都是数字，也可以用字符串。如果不想用字符串，强制要求用数字，不允许用字符串，则可以用IntEnum； 如果不想用相同的枚举值，需要进行限制，则可以使用unique装饰器，使用示例如下： from enum import IntEnum,unique @unique class SuperHero(IntEnum): Thor = 1 Hulk = 1 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py Traceback (most recent call last): File \"module_1.py\", line 104, in class SuperHero(IntEnum): File \"C:\\Users\\AppData\\Local\\Programs\\Python\\Python38\\lib\\enum.py\", line 860, in unique raise ValueError('duplicate values found in %r: %s' % ValueError: duplicate values found in : Hulk -> Thor 可以看到报错提示说有重复的values。 "},"08-Python/01-Python基础学习笔记/10-Python学习笔记-高级语法与应用.html":{"url":"08-Python/01-Python基础学习笔记/10-Python学习笔记-高级语法与应用.html","title":"Python学习笔记-高级语法与应用","keywords":"","body":"Python学习笔记-高级语法与应用 闭包 在Python中函数是一个对象，在很多其它语言里面函数只是一段可执行的代码，不能进行实例化，Python中可以实例化。 Python中不仅可以把函数赋值给一个变量，还可以把另一个函数的参数，传递到另外的函数里，还可以把一个函数当作另外一个函数的返回结果。 例如下面顶一个函数，输出结果可以看到类型是个函数，并且是属于类： def x(): pass print(type(x)) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py 在函数的内部定义一个函数，在函数外是否可以调用： def super_hero(): def hero(): pass hero() 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py Traceback (most recent call last): File \"module_1.py\", line 4, in hero() NameError: name 'hero' is not defined 可以看到报错了，找不到hero，内部函数hero的作用域局限于super_hero函数的内部，在外部是不可调用的。 可以在super_hero的内部把hero函数返回回来，需要先调用super_hero，得到返回的hero，a就是hero函数： def super_hero(): def hero(): pass return hero a = super_hero() print(a) print(type(a)) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py .hero at 0x000001EB6062ACA0> 上面示例验证了可以把函数赋值给一个变量，还可以把一个函数当作另外一个函数的返回结果。 继续示例，传递参数进去： def super_hero(): t = 'Thor' def hero(x): return t*x return hero T = super_hero() print(T(2)) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py ThorThor 上面示例修改下，在函数外部对t重新赋值： def super_hero(): t = 'Thor' def hero(x): return t*x return hero t = 'Thaons' T = super_hero() print(T(2)) print(T.__closure__) print(T.__closure__[0].cell_contents) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py ThorThor (,) Thor 可以看到值并没有改变，这就涉及到闭包的概念，闭包就是由函数（hero）以及函数在定义时候的外部环境变量（t）构成的一个整体，一旦函数和他的环境变量形成了闭包，在任何地方调用都不会受其它的变量重新赋值影响，还是会引用环境变量。 t不能在hero的内部，也不能定义成全局变量，即superhero外部，这样都不能形成闭包； 示例中print(T.closure)打印出了闭包存放位置； print(T._closure[0].cell_contents) 取出了闭包的环境变量； 闭包 = 函数 + 环境变量（函数定义时候的变量） 闭包的意义 闭包的意义：保存的是一个环境，把一个函数调用时候的现场保存起来了。 def super_hero(): a = 'Thor' def hero(): a = 'Hulk' print(a) print(a) hero() print(a) super_hero() 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py Thor Hulk Thor super_hero()调用了函数super_hero，a 赋值后，定义了hero，没有调用或者执行hero，执行到print(a)，所以打印出来就是Thor，继续执行hero()，就调用了hero()，就执行hero()里面的内容，然后a就变成了 Hulk,hero()内部打印出来的a就是Hulk，继续执行super_hero()里的print(a)，可以看到打印出来是Thor，因为在hero的内部的a赋值 在Python中会被认为是一个局部变量，局部变量是不会影响到外部变量，所以打印出来是Thor。 a = 'Hulk'语句在的话，Python不会认为是个外部环境变量的改动，会被认为是一个局部变量，和外面的a就没有关系了，此时闭包就不存在了。 闭包示例 需要实现一个里程相加的功能，起始为0，如果走2米输出结果为2，如果继续走6米，里程相加，输出结果为8，先用非闭包的方式实现： origin = 0 def travel(x): global origin distance = origin + x origin = distance return distance print(travel(2)) print(travel(6)) print(travel(2)) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py 2 8 10 上面的示例中，注意要在函数内把origin全局化，即 global origin操作，如果不这样操作 ，在函数内部会认为origin是一个局部变量，当然也要去掉origin = distance （不去掉语法有问题），执行后输出结果就会一直是0。 下面用闭包的方法来实现： origin = 0 def travel(x): def distance(y): nonlocal x new_x = x + y x = new_x return new_x return distance traveler = travel(origin) print(traveler(2)) print(traveler(6)) print(traveler(2)) 运行后输出结果如下： PS D:\\Python\\codefile\\advanced> python module_1.py 2 8 10 可以看到成功实现了，但是我们在函数中加入了代码：nonlocal x，如果不加，执行会报错，Python会认为x是一个本地的局部变量，nonlocal x 就是强制声明x不是一个本地的局部变量。 闭包可以记忆住上一次调用的状态，所以闭包可以实现上面的功能。所以的操作都是在函数的内部，并没有改变全局变量origin的值。 闭包总结 闭包可以实现在函数外部间接调用函数内部的变量； 闭包中的环境变量是一直常驻在内存中的，容易造成内存泄漏。 "},"08-Python/01-Python基础学习笔记/11-Python学习笔记-函数式编程.html":{"url":"08-Python/01-Python基础学习笔记/11-Python学习笔记-函数式编程.html","title":"Python学习笔记-函数式编程","keywords":"","body":"Python学习笔记-函数式编程与装饰器 匿名函数 定义一个函数的时候，不需要去定义函数名 要定义一个匿名函数，需要借助lambda关键字，格式如下： lambda parameter_list: expression 例如，下面的普通函数： def add(x,y): return x + y print(add(2,3)) 利用匿名函数实现如下： z= lambda x,y:x+y print(z(2,3)) 调用匿名函数的话，可以将函数赋值给一个变量，然后再调用传递参数。 示例中还可以看到匿名函数的定义非常简洁。 但是在匿名函数中，后面expression是个表达式，不能是个代码块；在普通函数中，在函数里面可以写入条件语句或者定义函数，在匿名函数中，是不可以写入的，例如下面代码： z= lambda x,y:a = x+y print(z(2,3)) 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py File \"module_1.py\", line 5 z= lambda x,y:a = x+y ^ SyntaxError: cannot assign to lambda 可以看到报错了，赋值操作是一个完整的代码语句，不是一个表达式，所以认为语法错误。 三元表达式 判断两个数字大小，可以用if语句来实现： a = 2 b = 5 if a > b: print(a) else: print(b) 对于上面条件判断语句，可以用一个三元表达式来替代，格式如下： 条件为真是返回的结果 if 条件判断 else 条件为假时的返回结果 a = 2 b = 5 c = a if a > b else b print(c) a if a > b else b 是三元表达式，因为只是个表达式，所以用变量c来接收三元表达式的结果，运行输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py 5 三元表达式适合用在lambda表达式上。 map 格式如下： map(func: Callable[[_T1], _S], iter1: Iterable[_T1]) map(func, *iterables) --> map object 有一个列表，列表下面有多个数字，求列表下面每个数字的平方，并且把结果组成一个新的列表打印出来。 可以用for循环来实现： list_x = [1,2,3,4,5,6,7] def square(x): return x*x for x in list_x: y = square(x) print(y) 用map来实现： list_x = [1,2,3,4,5,6,7] def square(x): return x*x y = map(square,list_x) print(y) print(list(y)) 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py [1, 4, 9, 16, 25, 36, 49] y的值打印出来是个map的对象，转换成列表就达到了满足的需求了，转换成了平方的形式，并且输出还是个列表。 调用map后，map会对传入列表里面每一项元素都会传入到square函数里面去执行，并且接收函数的返回结果。 map与lambda lambda是一个函数，可以把square直接写在lambda里面，上面示例用lambda来实现： list_x = [1,2,3,4,5,6,7] y = map(lambda x: x*x,list_x) print(y) print(list(y)) 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py [1, 4, 9, 16, 25, 36, 49] 上面示例也是函数式编程的一个示例。 如果有多个参数需要传入，示例如下： list_x = [1,2,3,4,5,6,7] list_y = [7,6,5,4,3,2,1] z = map(lambda x,y: x*y,list_x,list_y) print(list(z)) 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py [7, 12, 15, 16, 15, 12, 7] 如果传入的参数列表中的元素数量不是相等的，输出结果元素个数取决于元素数量较小的参数列表，示例如下： list_x = [1,2,3,4,5,6,7] list_y = [7,6,5,4,3,2] z = map(lambda x,y: x*y,list_x,list_y) print(list(z)) 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py [7, 12, 15, 16, 15, 12] reduce 使用reduce需要先从functools模块下导入，格式如下： from functools import reduce def reduce(function, sequence, initial=None) reduce(function, sequence[, initial]) -> value reduce是一个函数，第一个参数是接受一个函数，reduce下的函数必须要有两个参数，示例如下： from functools import reduce list_x = [1,2,3,4,5,6,7] z = reduce(lambda x,y:x+y,list_x) print(z) 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py 28 在示例中，并没有传入参数y，但是可以正常输出没有报错； 可以看到输出结果是28，是将x元素全部相加了； reduce是做一个连续计算，连续调用lambda表达式，在第一次执行的适合，lambda会取前两个元素，也就是1 和2，然后进行表达式运算，结果为3，reduce函数特点，会把一次计算结果作为x传入到lambda表达式中，第二次调用lambda 函数y就是第三个参数3，计算结果就是6，依次类推，最后得到上面的结果，即计算流程是：(((((1+2)+3)+4)+5)+6)+7 就是每一次调用lambda的计算结果会作为下一次调用的参数，直到列表被遍历完成。 reduce 中还有一个参数，initial初始值，默认是None，把上面示例设置成20后： from functools import reduce list_x = [1,2,3,4,5,6,7] z = reduce(lambda x,y:x+y,list_x,20) print(z) 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py 48 可以看到结果加了20，并不是在之前运算完成后再加了20，而是把20作为一个初始值去进行计算，也就是从10+1开始。 filter 就是筛选，可以过滤掉一些不需要的元素或者不符合规则的元素，格式如下： def filter(function: None, iterable: Iterable[Optional[_T]]) filter(function or None, iterable) --> filter object 例如下面示例把list_a中的1筛选出来： list_a = [3,1,0,5,6,1,9,6,1,4,1] b = filter(lambda a:True if a == 1 else False,list_a ) print(b) print(list(b)) 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py [1, 1, 1, 1] 可以看到成功筛选出了，一样适合lambda函数和三元表达式一起使用。 上面示例中都是采用函数式编程的方式进行的，之前的学习章节中学习的是命令式编程方式进行的； 函数式编程常用的三个函数：map reduce filter ，以及算子：lambda 装饰器 如果想知道函数执行的时间，可以导入time模块下的time函数： import time def super_hero(): print(time.time()) print('Batman is a superhero') super_hero() 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py 1592315521.594548 Batman is a superhero 但是时间不是我们常见的时间格式，显示的是一个unix时间戳， 如果有很多个函数，所有的函数都需要添加打印时间的功能，每个函数一个个去加就很麻烦了。 编程的一个基本原则：对修改是封闭的，对扩展是开放的 一个个去修改函数不符合上面原则，可以专门定义一个函数去实现： import time def super_hero(): print('Batman is a superhero!') def hostile(): print('Thanos is hostile!') def print_time(func): print(time.time()) func() print_time(super_hero) print_time(hostile) 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py 1592316546.351815 Batman is a superhero! 1592316546.3528154 Thanos is hostile! 但是这种方式也比较复杂，可以用装饰器来实现，下面定义的嵌套函数就是装饰器： import time def decotator(func): def wrapper(): print(time.time()) func() return wrapper def super_hero(): print('Batman is a superhero!') a = decotator(super_hero) a() 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py 1592323161.3373797 Batman is a superhero! 当时上面的示例还是改变了调用规则，可以直接在super_hero前面@装饰器的名字，就不需要改变调用了： import time def decotator(func): def wrapper(): print(time.time()) func() return wrapper @decotator def super_hero(): print('Batman is a superhero!') super_hero() 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py 1592323524.7907574 Batman is a superhero! 如果给函数传递一个参数呢，如何修改装饰器，示例如下： import time def decotator(func): def wrapper(): print(time.time()) func() return wrapper @decotator def super_hero(hero): print(hero + 'is a superhero!') super_hero('Batman') 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py Traceback (most recent call last): File \"module_1.py\", line 113, in super_hero('Batman') TypeError: wrapper() takes 0 positional arguments but 1 was given 可以看到报错了，装饰器内部也需要修改： import time def decotator(func): def wrapper(hero): print(time.time()) func(hero) return wrapper @decotator def super_hero(hero): print(hero + 'is a superhero!') super_hero('Batman') 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py 1592401954.4871726 Batman is a superhero! 如果有多个函数呢，装饰器只有一个，可以在装饰器中用可变参数，例如下面示例中的*args，args是很多编程语言里面代表一组参数，是一个比较通用的用法，当然用其它也行，通用就建议采用这种命名： import time def decotator(func): def wrapper(*args): print(time.time()) func(*args) return wrapper @decotator def super_hero(hero): print(hero + ' is a superhero!') @decotator def hostile(scut): print(scut +' is hostile!') super_hero('Batman') hostile('Thanos') 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py 1592402396.377453 Batman is a superhero! 1592402396.3779383 Thanos is hostile! 如果函数中有关键字参数，例如下面示例函数中有关键字参数**kw。在装饰器中**kw是形参，名字可以随便命名： import time def decotator(func): def wrapper(*args,**kw): print(time.time()) func(*args,**kw) return wrapper @decotator def super_hero(hero): print(hero + ' is a superhero!') @decotator def hostile(scut,**kw): print(scut +' is hostile!') print(kw) super_hero('Batman') hostile('Thanos',a=1,b='59',c=1) 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py 1592406125.517447 Batman is a superhero! 1592406125.5184083 {'a': 1, 'b': '59', 'c': 1} 装饰器 如果想对一个函数增加一个功能，但是又不想取改变函数内部的实现，普通的函数是实现不了的，无论如何都会改变函数或者改变函数的调用，装饰器的优势就体现了。 "},"08-Python/01-Python基础学习笔记/12-Python学习笔记-爬虫学习.html":{"url":"08-Python/01-Python基础学习笔记/12-Python学习笔记-爬虫学习.html","title":"Python学习笔记-爬虫学习","keywords":"","body":"Python学习笔记-爬虫学习 爬虫思路要点 爬虫思路： 爬虫的前奏 明确目的 找到数据对应的网页 分析网页的结构并找到数据所在的标签位置 模拟HTTP请求，向服务器发送这个请求，获取到服务器返回的HTML； 用正则表达式提取需要的数据（电影名称，电影点播量） 模拟http请求抓取数据，Python有个内置的库：urllib ，里面有request，request下有个方法urlopen。 下面尝试抓取腾讯视频电影网中高分电影的人气并且进行排行。 爬虫分析要点 要寻找到一个标签，或者一个标识符，可以定位到抓取的信息，需要有一个标签定位抓取到的信息 一些常量的字符串可以起到定位的边界效果，在提炼htmls时候需要找到一个常量标签能够帮组从一大段htmls中把要提取的信息定位出来 选取标签原则： 尽量选取具有唯一标识性的标签作为定位标签，如果不唯一，很容易匹配到一些无用的信息 尽量寻找接近寻找的数据的标签 爬虫实战 抓取腾讯视频电影某一页中的电影名，播放量和评分 标签截取 寻找定位标签，电影名肖申克的救赎最近的标签可以选择\\，人气7808万比较近的可以选择div class=”figure_count\"，这两个标签是不是唯一的建议用代码去验证。 如果直接对找到的两个标签分别去做正则表达式分析，可以得到一组电影名和一组人气数值，但是两组数据如何对应起来就不方便了，所以建议把这个数据看作结合在一起的一组数据，在这组数据外面找一个标签，可以看到离这组数据最近标签可以选择\\，通过这个标签可以缩小匹配的范围，可拿到里面的内容，然后再用正则表达式去匹配里面的名字和人气值： ![标签截取](爬虫实战-1.png) \\([\\s\\S]\\*?)\\表达式中 ([\\s\\S]*?)用括号括起来是组的概念，表示只截取中间内容 尽量选取可以闭合的标签，例如上面示例中的\\，内部包含需要抓取的所有信息,闭合后是\\，\\是结束标记 代码调试 可以采用断点调试方式，代码行序号左边的红点就是标记的断点，运行后报错会指出，鼠标移动到对应的位置可以查看报错信息： 对于对象，也可以用鼠标光标指向进行查看，左边也有选项可以查看所有的对象，可以看到下面的是None，说明代码有问题： 下面就是查看获取的值，断点调试的时候可以验证是否是需要获取的数据，确认无误然后就可以继续下一步了： 完整代码 编写完整代码如下： # 导入正则表达式模块 import re # 从urllib中导入request from urllib import request # 定义一个类Reptile class Reptile(): # 定义一个类变量url保存抓取网页的地址 url = 'https://v.qq.com/channel/movie?channel=movie&itype=100062&listpage=1&sort=21' # 先把正则表达式字符串在类变量里面赋值给一个变量 root_pattern = '([\\s\\S]*?[\\s\\S]*?[\\s\\S]*?[\\s\\S]*?[\\s\\S]*?)' # 匹配名字的正则表达式 name_pattern = ' class=\"figure_title figure_title_two_row bold\">([\\s\\S]*?)' # 匹配评分的正则表达式 score_pattern = '([\\s\\S]*?)' # 匹配观看人数的正则表达式,$是从字符串尾开始匹配，刚好结尾字符就是需要的值，匹配到就结束 views_pattern = '([\\s\\S]*)$' # 定义一个私有方法获取网页内容 def __fetch_content(self): # 使用request下的方法urlopen，并且读取类变量，用一个变量保存返回结果 r = request.urlopen(Reptile.url) # read这个方法可以把结果读取出来 htmls = r.read() # htmls结果会是字节码，转换成字符串，并且指定编码方式 htmls = str(htmls,encoding='utf-8') # 返回htmls,后面entrance中的htmls就有值了 return htmls # 定义一个实例方法 def __analysis(self,htmls): # 调用正则表达式去匹配，并用root_html接收结果 root_html = re.findall(Reptile.root_pattern,htmls) # 定义一个list去接收最终结果 films = [] # 用循环遍历root_html去匹配 for html in root_html: # 匹配名字 name = re.findall(Reptile.name_pattern,html) # 匹配评分 score = re.findall(Reptile.score_pattern,html) # 匹配浏览量 views = re.findall(Reptile.views_pattern,html) # 用字典接收三个值 film = {'name':name,'score':score,'views':views} # 在列表中添加元素中append方法 films.append(film) # 调试时候可以打印root_html的0号元素进行查看内容 # print(root_html[0]) # 打印输出结果可以查看调试 # print(films) return(films) # 定义一个方法提炼优化输出结果 def __refine(self,films): # 使用lambda表达式来进行优化，用一个普通函数也可以 # strip()可以去掉前后的换行符和空格，此实例赘余的东西比较少，就score后面有个空格 refine = lambda film:{'name':film['name'][0], 'score':film['score'][0].strip(), 'views':film['views'][0]} # 返回结果，调用map会把films每个元素都传到refine里面去执行 return map(refine,films) # 定义一个方法指定排序规则 def __sort_rule(self,film): # 用正则表达式匹配出观看人数里面的数字（此时还是字符） num = re.findall('\\d*',film['views']) # 将字符转换成数字去排序 number = float(num[0]) # 可以看到数字里面有万这个单位，加入一个条件语句 if '万' in film['views']: # 将数字乘以万 number *= 10000 # 返回得到的的值 return number # 定义一个方法进行排序 def __sort(self,films): # Python内置了一个函数sorted可以进行排序,可以传入一个函数 # 必须加入key参数，作为排序的依据，可以传入一个函数指定排序规则ru # 默认是升序，reverse参数可以颠倒排序方式 films = sorted(films,key=self.__sort_rule,reverse=True) # 返回得到的结果 return films # 定义一个方法展示出结果 def __show(self,films): # 用for循环依次打印出来 for film in films: print('电影名：'+ '《' + film['name']+'》'+' 评分:'+film['score']+'分'+' 观看人数：'+film['views']) # 定义一个入口方法entrance def entrance(self): # 调用之前定义的__fetch_content,并且用htmls变量接收 htmls = self.__fetch_content() # 调用__analysis并且传入参数htmls,并用films接收结果 films = self.__analysis(htmls) # 调用__refine并且把films传入,重新赋值给films，结果是个对象，需要转换成list films = list(self.__refine(films)) # 调用__sort并把films传入 films = self.__sort(films) # 调用__show并把films传入 self.__show(films) # 调式时候可以打印films查看 # print(films) # 实例化Reptile reptile = Reptile() # 调用entrance reptile.entrance() 最终，输出结果得到理想的结果： PS D:\\Python\\codefile\\reptile> python module_1.py 电影名：《泰坦尼克号》 评分:9.5分 观看人数：9237万 电影名：《盗梦空间》 评分:9.5分 观看人数：9034万 电影名：《肖申克的救赎》 评分:9.7分 观看人数：7818万 电影名：《霸王别姬》 评分:9.6分 观看人数：6788万 电影名：《忠犬八公的故事》 评分:9.4分 观看人数：6276万 电影名：《阿甘正传》 评分:9.5分 观看人数：5605万 电影名：《机器人总动员》 评分:9.4分 观看人数：4428万 电影名：《海豚湾》 评分:9.3分 观看人数：3189万 电影名：《教父1》 评分:9.4分 观看人数：2650万 电影名：《辛德勒的名单》 评分:9.5分 观看人数：2166万 电影名：《灿烂人生》 评分:9.4分 观看人数：1977万 电影名：《大闹天宫》 评分:9.4分 观看人数：1970万 电影名：《放牛班的春天》 评分:9.4分 观看人数：1755万 电影名：《乱世佳人》 评分:9.3分 观看人数：1578万 电影名：《海上钢琴师》 评分:9.4分 观看人数：1454万 电影名：《七武士》 评分:9.2分 观看人数：1395万 电影名：《我们的父辈》 评分:9.6分 观看人数：1239万 电影名：《背靠背，脸对脸》 评分:9.4分 观看人数：882万 电影名：《摩登时代》 评分:9.3分 观看人数：872万 电影名：《永远的车神》 评分:9.2分 观看人数：781万 电影名：《茶馆》 评分:9.4分 观看人数：591万 电影名：《生活多美好》 评分:9.3分 观看人数：447万 电影名：《城市之光》 评分:9.3分 观看人数：379万 电影名：《切腹》 评分:9.2分 观看人数：245万 电影名：《贵妃醉酒》 评分:9.2分 观看人数：119万 电影名：《群英会京剧》 评分:9.1分 观看人数：107万 电影名：《丝路花雨》 评分:9.2分 观看人数：95万 电影名：《你逃我也逃》 评分:9.1分 观看人数：51万 电影名：《借东风》 评分:9.2分 观看人数：31万 电影名：《梅兰芳的舞台艺术 (下)》 评分:9.1分 观看人数：13万 总结 整体思路就是入口方法里面的步骤： 获取网页数据 用正则表达式分析数据，得到想要的数据 优化数据 对数据进行排序 展示数据 其它推荐 beautifulSoup这个库可以有更简单的方法提炼内容，不用太依赖正则表达式： https://www.crummy.com/software/BeautifulSoup/ Scrapy爬虫框架，做一些多线程的爬虫，可以考虑使用: https://scrapy.org/ 运行爬虫IP可能会被封，爬的频率最好不要太高. "},"08-Python/01-Python基础学习笔记/13-Python学习笔记-Pythonic.html":{"url":"08-Python/01-Python基础学习笔记/13-Python学习笔记-Pythonic.html","title":"Python学习笔记-Pythonic","keywords":"","body":"Python学习笔记-Pythonic 用字典映射代替switch case语句 在其它语言中，switch是一个条件分支语句，swithch后面可以接一个变量，当变量取某个值的时候，就执行什么代码； 例如C#里面的switch语句： switch (hero) { hero 0 : heroname = \"Thor\"; break; hero 1 : heroname = \"THanos\"; break; ... default : heroname = \"Batman\"; break } 在Python中可以用if else来代替，也可以用字典映射来代替： hero = 'A' superheros = { 'T':'Thor', 'A':'Captain America', 'H':'Hulk', 'I':'Iron Man', } superhero = superheros[hero] print(superhero) 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py Captain America 可以发现初步替代了，但是switch里面有default的选项，而字典里面如果传入的参数是不存在的，那么会报错，可以用Python内置get方法来实现，第一个参数仍然是需要传入的参数，第二个参数就是指定第一个参数对应的不存在的时候返回的结果： hero = 'C' superheros = { 'T':'Thor', 'A':'Captain America', 'H':'Hulk', 'I':'Iron Man', } superhero = superheros.get(hero,'Batman') print(superhero) 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py Batman 在字典中，value不仅可以是字符串，还可以是函数，如同把函数赋值给变量一个道理： hero = 'C' def get_ca(): return 'Captain America' def get_default(): return 'Batman' superheros = { 'T':'Thor', 'A':get_ca, 'H':'Hulk', 'I':'Iron Man', } superhero = superheros.get(hero,get_default)() print(superhero) 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py Batman 示例中调用了函数传入到字典中，在调用的时候返回也是函数，需要在后面加上()去调用函数的值，同样对于默认参数，如果有调入函数的，默认的返回结果也要传入一个函数，要不然会报错。 列表推导式 如果想根据一个已经存在的列表，创建一个新的列表，列表推导式很有用 例如一个列表，里面是数字，需要得到一个新的列表，值是原来列表数值的3次方，可以用之前学过的for循环来实现，也可以用map来实现； a = [2,4,6,8,10,12,14] b = [i**3 for i in a] print(b) 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py [8, 64, 216, 512, 1000, 1728, 2744] 也可以进行条件筛选： a = [2,4,6,8,10,12,14] b = [i**3 for i in a if i 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py [8, 64, 216, 512] 除了列表，用集合也行，列表推导式不一定是要中括号，改成啥就就输出什么类型的数据： a = [2,4,6,8,10,12,14] b = {i**3 for i in a if i 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py {8, 512, 64, 216} 字典符合编写列表推导式 例如下面示例提取key，需要调用items去遍历字典： superhero = { 'Thor':9, 'Captain America':8, 'Hulk':7 } hero = [key for key,value in superhero.items()] print(hero) 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py ['Thor', 'Captain America', 'Hulk'] 如果需要讲value和key颠倒输出，将列表推导式输出结果颠倒下就行了，并且表达式也用字典的格式： superhero = { 'Thor':9, 'Captain America':8, 'Hulk':7 } hero = {value:key for key,value in superhero.items()} print(hero) 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py {9: 'Thor', 8: 'Captain America', 7: 'Hulk'} 如果想输出元组类型： superhero = { 'Thor':9, 'Captain America':8, 'Hulk':7 } hero = (key for key,value in superhero.items()) print(hero) 但是这样会报错，如下所示： PS D:\\Python\\codefile\\Pythonic> python module_1.py at 0x00000205475B1200> 需要遍历下数据类型，因为元组是不可变的： superhero = { 'Thor':9, 'Captain America':8, 'Hulk':7 } hero = (key for key,value in superhero.items()) for i in hero: print(i) 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py Thor Captain America Hulk None 在Python表示空，从类型和值上来看，不等于空字符串，也不等于空的列表，也不是0，也不是Flase； a = [] b = False c ='' print(a==None) print(b==None) print(c==None) print(a is None) print(type(None)) 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py False False False False 继续进行示例： def function(): return None a = function() if not a: print('T') else: print('F') if a is None: print('T') else: print('F') 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py T T 可以看到两个输出都是T，但是这不能说明 not a和is None是一样的，修改下继续示例： a = [] if not a: print('T') else: print('F') if a is None: print('T') else: print('F') 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py T F 用列表后，not a 输出值是Ture，所以返回'T'，空列表不等同于None，所以a is None 结果是False，返回值就是'F'。 一般判空操作可以用 fi a: 或者用if not a来判断。 None 和Flase不是用一个数据类型，None是NoneType类型，Flase是bool类型； None表示不存在概念，Flase表示真假 有时候得到的结果相同，但是并不代表意义相同。 对象并不一定是True 当做if逻辑判断时候，Python每一个对象都和bool值有着对应关系，空字符串表示False，空列表表示False，非空字符串表示True； None永远对应这Flase， 里面不定义方法，实例化后进行判断： class Hero(): pass hero = Hero() if hero: print('T') else: print('F') 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py T 修改下，类中定义一个方法： class Hero(): def __len__(self): return 0 hero = Hero() if hero: print('T') else: print('F') 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py F 对类型进行bool判断： class Hero(): def __len__(self): return 0 hero = Hero() print(bool(hero)) print(bool(None)) print(bool([])) 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py False False False 对于自定义类，判断是否是True还是Flase和内置的两个方法有关。 len与bool内置方法 类下不存在任何方法，默认输出是True： class Hero(): pass print(bool(Hero())) 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py True 加上len方法： class Hero(): def __len__(self): return 0 print(bool(Hero())) 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py False 如果是其它数字（需要是整形），就是True。 加入bool方法后，不再受len影响： class Hero(): def __bool__(self): return False def __len__(self): return True print(bool(Hero())) 运行后输出结果如下： PS D:\\Python\\codefile\\Pythonic> python module_1.py False bool方法中不能用0替代False，执行会报错，等同于不代表类型是相同的； 有了bool方法后就不会去调用len方法，所以不受len影响； 在Python2中nonzero来确定对象最终bool值，在Python3中用bool方法替代了。 "},"08-Python/02-Python内置模块&方法/":{"url":"08-Python/02-Python内置模块&方法/","title":"Python内置模块&方法","keywords":"","body":"Python内置模块&方法 简介 Python初学者，本小节是一些Python内置模块和方法学习笔记。 内容 Python-操作系统接口 Python-time模块 Python-常见内置函数 Python-array&readline Python-常用字符串方法 "},"08-Python/02-Python内置模块&方法/01-Python-操作系统接口.html":{"url":"08-Python/02-Python内置模块&方法/01-Python-操作系统接口.html","title":"Python-操作系统接口","keywords":"","body":"Python-操作系统接口 os_多种操作系统接口 在 Python 中，使用字符串类型表示文件名、命令行参数和环境变量。 在某些系统上，在将这些字符串传递给操作系统之前，必须将这些字符串解码为字节。 os 模块提供了许多与操作系统交互的函数,收录一些常用的。 os.getcwd & os.chdir os.getcwd是获取当前工作目录，用法：os.getcwd() os.chdir是更改当前工作目录，用法：os.chdir(path) 示例如下： >>> import os >>> os.getcwd() '/tmp/rpm/python' >>> os.chdir('/tmp/rpm') >>> os.getcwd() '/tmp/rpm' os.system 在子shell中执行命令（字符串）。这是调用标准C函数system()来实现的，因此限制条件与该函数相同，用法：os.system(command) 执行命令后并返回一个结果，示例如下： >>> import os >>> os.system('mkdir test') 0 >>> os.system('pwd') /tmp/rpm 0 os.popen 格式如下： os.popen(cmd, mode='r', buffering=-1) 打开一个管道，它通往 / 接受自命令：cmd。返回值是连接到管道的文件对象；根据 mode 是 'r' （默认）还是 'w' 决定该对象可以读取还是写入。buffering 参数与内置函数 open() 相应的参数含义相同。返回的文件对象只能读写文本字符串，不能是字节类型。 示例如下： >>> import os >>> a = os.popen('pwd',mode='r',buffering=-1) >>> print(a) >>> print(a.read()) /tmp/rpm/python >>> 本方法是使用 subprocess.Popen 实现的，可以参阅该类的文档。 subprocess_子进程管理 subprocess 模块允许生成新的进程，连接它们的输入、输出、错误管道，并且获取它们的返回码。此模块打算代替一些老旧的模块与功能：os.system及os.spawn*等 替代os.system如下： sts = os.system(\"mycmd\" + \" myarg\") # becomes sts = subprocess.call(\"mycmd\" + \" myarg\", shell=True) run()函数 run() 函数是在 Python 3.5 中新增的。 格式如下： subprocess.run(args, *, stdin=None, input=None, stdout=None,stderr=None,capture_output=False, shell=False, cwd=None,timeout=None,check=False, encoding=None, errors=None,text=None,env=None, universal_newlines=None, **other_popen_kwargs) 功能：运行被 arg 描述的指令。等待指令完成, 然后返回一个 CompletedProcess 实例. 简单示例如下： >>> import subprocess >>> subprocess.run('ls -l',shell=True) >>> subprocess.run('ls -l',shell=True) total 100528 -rw-r----- 1 root system 1477 Jul 13 19:58 aix_reboot_check.py -rw-r----- 1 root system 243981 Jul 13 07:28 bzip2-1.0.8-2.aix6.1.ppc.rpm -rw-r----- 1 root system 284219 Jul 13 07:28 gdbm-1.18.1-1.aix6.1.ppc.rpm -rw-r----- 1 root system 40329593 Jul 13 07:14 python3-3.7.6-1.aix6.1.ppc.rpm -rw-r----- 1 root system 233022 Jul 13 11:17 python3-devel-3.7.6-1.aix6.1.ppc .rpm-rw-r----- 1 root system 13392 Jul 13 07:55 python3-tools-3.7.6-1.aix6.1.ppc .rpm-rw-r----- 1 root system 2525190 Jul 13 07:28 readline-8.0-2.aix6.1.ppc.rpm -rw-r----- 1 root system 7822627 Jul 13 07:28 sqlite-3.28.0-1.aix6.1.ppc.rpm CompletedProcess(args='ls -l', returncode=0) class subprocess.CompletedProcess是run()的返回值, 代表一个进程已经结束. Popen 构造函数 格式如下： class subprocess.Popen(args, bufsize=-1, executable=None, stdin=None, stdout=None, stderr=None,preexec_fn=None, close_fds=True, shell=False, cwd=None, env=None, universal_newlines=None,startupinfo=None, creationflags=0, restore_signals=True, start_new_session=False, pass_fds=(), *,encoding=None, errors=None, text=None) 在POSIX中，如果 args 是一个字符串，此字符串被作为将被执行的程序的命名或路径解释。但是，只有在不传递任何参数给程序的情况下才能这么做。 在POSIX中，当 shell=True，shell 默认为 /bin/sh。如果args是一个字符串，此字符串指定将通过shell执行的命令。这意味着字符串的格式必须和在命令提示符中所输入的完全相同。这包括，例如，引号和反斜杠转义包含空格的文件名。如果args是一个序列，第一项指定了命令，另外的项目将作为传递给 shell（而非命令）的参数对待。也就是说， Popen 等同于: Popen(['/bin/sh', '-c', args[0], args[1], ...]) 简单示例如下： >>> import subprocess >>> subprocess.Popen(['ls','-l']) total 0 -rw-r--r-- 1 root system 0 Jul 14 08:55 aix.py >>> subprocess.Popen('ls -l',shell=True) >>> total 0 -rw-r--r-- 1 root system 0 Jul 14 08:55 aix.py >>> subprocess.Popen(['/bin/sh','-c','ls -l']) >>> total 0 -rw-r--r-- 1 root system 0 Jul 14 08:55 aix.py >>> 有些命令可能比较复杂，可以用shlex.split()进行序列化 shlex类可以轻松地为类似于Unix shell的简单语法编写词法分析器。 这对于解析带引号的字符串通常很有用。 示例如下： >>> import shlex,subprocess >>> command = input() lslpp -h bos.rte >>> args = shlex.split(command) >>> print(args) ['lslpp', '-h', 'bos.rte'] >>> b = subprocess.Popen(args) >>> Fileset Level Action Status Date Time ---------------------------------------------------------------------------- Path: /usr/lib/objrepos bos.rte 7.1.4.30 COMMIT COMPLETE 01/22/19 20:20:24 Path: /etc/objrepos bos.rte 7.1.4.30 COMMIT COMPLETE 01/22/19 20:20:24 >>> command模块 Python 3.8中没有这个模块，以后估计也不会有了。 "},"08-Python/02-Python内置模块&方法/02-Python-time模块.html":{"url":"08-Python/02-Python内置模块&方法/02-Python-time模块.html","title":"Python-time模块","keywords":"","body":"Python-time模块 time_时间的访问和转换 该模块提供了各种时间相关的函数。可以使用以下函数在时间表示之间进行转换： 从 到 使用 自纪元以来的秒数 UTC 的 struct_time gmtime() 自纪元以来的秒数 本地时间的 struct_time localtime() UTC 的 struct_time 自纪元以来的秒数 calendar.timegm() 本地时间的 struct_time 自纪元以来的秒数 mktime() time.time() 返回以浮点数表示的从 epoch 开始的秒数的时间值。 示例如下： >>> time.time() 1391426626.4728231 time.asctime([t]) 转换由gmtime()或 localtime()所返回的表示时间的元组或struct_time为以下形式的字符串: 'Tue Jul 11 10:13:29 2000'。日期字段的长度为两个字符，如果日期只有一个数字则会以零填充，例如: 'Tue Jul 4 10:13:29 2000' 如果未提供 t，则会使用 localtime()所返回的当前时间。asctime()不会使用区域设置信息。 示例如下： >>> import time >>> time.asctime() 'Fri Jul 19 09:08:38 2019' time.gmtime([secs]) 将以自epoch开始的秒数表示的时间转换为UTC的 struct_time，其中 dst 标志始终为零。如果未提供 secs 或为None，则使用time()所返回的当前时间。 示例如下： >>> import time >>> time.gmtime(1592316546.3528154) time.struct_time(tm_year=2020, tm_mon=6, tm_mday=16, tm_hour=14, tm_min=9, tm_sec=6, tm_wd ay=1, tm_yday=168, tm_isdst=0) time.localtime([secs]) 与gmtime()相似但转换为当地时间。如果未提供secs或为None，则使用由time()返回的当前时间。当DST适用于给定时间时，dst标志设置为1。 示例如下： >>> import time >>> time.localtime(1592316546.3528154) time.struct_time(tm_year=2020, tm_mon=6, tm_mday=16, tm_hour=9, tm_min=9, tm_sec=6, tm_wda y=1, tm_yday=168, tm_isdst=1) time.mktime(t) 是localtime()的反函数。参数是struct_time或者完整的9元组（因为需要dst标志如果它是未知的则使用 -1 作为dst标志，它表示local的时间，而不是UTC。它返回一个浮点数，以便与time()兼容。 示例如下： >>> import time >>> a = time.localtime(1592316546.3528154) >>> time.mktime(a) 1592316546.0 时间戳转换时候一秒以内的小数将被忽略 time.sleep(secs) 暂停执行调用线程达到给定的秒数。参数可以是浮点数，以指示更精确的睡眠时间。实际的暂停时间可能小于请求的时间，因为任何捕获的信号将在执行该信号的捕获例程后终止 sleep() 。 示例如下： >>> import time >>> time.sleep(3) time.strftime(format,[t]) 转换一个元组或 struct_time 表示的由 gmtime() 或 localtime() 返回的时间到由 format 参数指定的字符串。如果未提供 t ，则使用由 localtime() 返回的当前时间。 format 必须是一个字符串。 以下指令可以嵌入 format 字符串中。它们显示时没有可选的字段宽度和精度规范，并被 strftime() 结果中的指示字符替换： 指令 含义 %a 本地化的缩写星期中每日的名称。 %A 本地化的星期中每日的完整名称。 %b 本地化的月缩写名称。 %B 本地化的月完整名称。 %c 本地化的适当日期和时间表示。 %d 十进制数 [01,31] 表示的月中日。 %H 十进制数 [00,23] 表示的小时（24小时制）。 %I 十进制数 [01,12] 表示的小时（12小时制）。 %j 十进制数 [001,366] 表示的年中日。 %m 十进制数 [01,12] 表示的月。 %M 十进制数 [00,59] 表示的分钟。 %p 本地化的 AM 或 PM 。 %S 十进制数 [00,61] 表示的秒。 %U 十进制数 [00,53] 表示的一年中的周数（星期日作为一周的第一天）作为。在第一个星期日之前的新年中的所有日子都被认为是在第0周。 %w 十进制数 [0(星期日),6] 表示的周中日。 %W 十进制数 [00,53] 表示的一年中的周数（星期一作为一周的第一天）作为。在第一个星期一之前的新年中的所有日子被认为是在第0周。 %x 本地化的适当日期表示。 %X 本地化的适当时间表示。 %y 十进制数 [00,99] 表示的没有世纪的年份。 %Y 十进制数表示的带世纪的年份。 %z 时区偏移以格式 +HHMM 或 -HHMM 形式的 UTC/GMT 的正或负时差指示，其中H表示十进制小时数字，M表示小数分钟数字 [-23:59, +23:59] 。 %Z 时区名称（如果不存在时区，则不包含字符）。 %% 字面的 '%' 字符。 注释: 当%p与 strptime() 函数一起使用时，如果使用 %I 指令来解析小时， %p 指令只影响输出小时字段。 %S范围真的是 0 到 61 ；值 60 在表示 leap seconds 的时间戳中有效，并且由于历史原因支持值 61 。 当%W与 strptime() 函数一起使用时， %U 和 %W 仅用于指定星期几和年份的计算。 示例如下： >>> import time >>> time.gmtime(1592316546.3528154) time.struct_time(tm_year=2020, tm_mon=6, tm_mday=16, tm_hour=14, tm_min=9, tm_sec=6, tm_wd ay=1, tm_yday=168, tm_isdst=0)>>> a = time.gmtime(1592316546.3528154) >>> time.strftime('%a %d %b %Y %H:%M:%S +0000',a) 'Tue 16 Jun 2020 14:09:06 +0000' time.strptime(string,[format]) 根据格式解析表示时间的字符串。 示例如下： >>> import time >>> time.strptime('12 Jul 15','%d %b %y') time.struct_time(tm_year=2015, tm_mon=7, tm_mday=12, tm_hour=0, tm_min=0, tm_sec=0, tm_wda y=6, tm_yday=193, tm_isdst=-1) class time.struct_time 返回的时间值序列的类型为 gmtime() 、 localtime() 和 strptime() 。它是一个带有 named tuple 接口的对象：可以通过索引和属性名访问值。 存在以下值： 索引 属性 值 0 tm_year （例如，1993） 1 tm_mon range [1, 12] 2 tm_mday range [1, 31] 3 tm_hour range [0, 23] 4 tm_min range [0, 59] 5 tm_sec range [0, 61]； 见 strftime() 介绍中的 (2) 6 tm_wday range [0, 6] ，周一为 0 7 tm_yday range [1, 366] 8 tm_isdst 0, 1 或 -1；如下所示 N/A tm_zone 时区名称的缩写 N/A tm_gmtoff 以秒为单位的UTC以东偏离 datetime_基本的日期和时间类型   datetime模块提供用于处理日期和时间的类。在支持日期时间数学运算的同时，实现的关注点更着重于如何能够更有效地解析其属性用于格式化输出和数据操作。 date对象 date对象代表一个理想化历法中的日期（年、月和日），格式如下： class datetime.date(year, month, day) 说明： 所有参数都是必要的。 参数必须是在下面范围内的整数： MINYEAR 1 1 如果参数不在这些范围内，则抛出ValueError异常 使用示例 获取当前日期： >>> import datetime >>> today = datetime.date.today() >>> print(today) 2020-12-28 >>> nowtime = datetime.datetime.now() >>> print(nowtime) 2020-12-28 16:28:37.426762 timedelta类对象 timedelta对象表示两个date或者time的时间间隔。标准格式如下： class datetime.timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0) 说明： 所有参数都是可选的并且默认为0 这些参数可以是整数或者浮点数，也可以是正数或者负数 使用示例 获取一天前和一个月前的时间： >>> import datetime >>> nowtime = datetime.datetime.now() >>> print(nowtime) 2020-12-28 16:28:37.426762 >>> yesterday = nowtime + datetime.timedelta(days=-1) >>> print(yesterday) 2020-12-27 16:28:37.426762 >>> lastmonth = nowtime + datetime.timedelta(days=-30) >>> print(lastmonth.strftime(\"%m%d%I%M%y\")) 1128042820 更多用法和示例参考官方文档：datetime---基本的日期和时间类型 "},"08-Python/02-Python内置模块&方法/03-Python-常用内置函数.html":{"url":"08-Python/02-Python内置模块&方法/03-Python-常用内置函数.html","title":"Python-常用内置函数","keywords":"","body":"Python-常见内置函数 Python中提供了一些内置函数可用直接调用，最常用的例如print()函数。官方文档:内置函数 基本数据处理 主要有三种： int()：返回一个基于数字或字符串 x 构造的整数对象，或者在未给出参数时返回 0 oct()：将一个整数转变为一个前缀为“0o”的八进制字符串 hex()：将整数转换为以“0x”为前缀的小写十六进制字符串 round() 标准格式： round(number,[ndigits])说明： 返回number舍入到小数点后ndigits位精度的值 如果ndigits被省略或为None，则返回最接近输入值的整数 使用示例： >>> sum([1.4,0.2]) 1.5999999999999999 >>> a = 1.4;b=0.2 >>> (a + b) == 1.6 False >>> c = round((a + b),2) >>> print(c) 1.6 注意：  对于浮点运算，另一个有用的工具是math.fsum()函数；round()有时候不是期望的结果，例如round(2.675, 2)将给出2.67而不是期望的2.68，可以参考官方说明： 浮点算术：争议和限制 还有tuple()、list()、str()、dict() 和set() 使用方法和示例在学习笔记中有:Python学习笔记-基本数据类型 常用内置函数 print() 标准格式：print(*objects, sep=' ', end='\\n', file=sys.stdout, flush=False) 目前用到的也是常用方法示例： for a in range(0,10,2): print(a,end='|') b = 'Iron Man!' print('I am '+b) 执行输出结果： PS D:\\Python\\codefile> python while_for.py 0|2|4|6|8| I am Iron Man! input() 标准格式：input([prompt])   如果存在prompt实参，则将其写入标准输出，末尾不带换行符。接下来，该函数从输入中读取一行，将其转换为字符串（除了末尾的换行符）并返回。当读取到 EOF 时，则触发 EOFError。示例如下： >>> input('Please input hdisk name:') Please input hdisk name:hdisk2 'hdisk2' 知识点： 可以直接将结果赋值给变量示例：hero = input('Please input hero name:') 返回结果是字符串，所有输入的数字也是字符串类型，如果需要转换注意转换成对应数据类型 quit() 在代码中输入quit()可以直接终止代码执行并退出到shell，就是后面的代码都不执行了。 range()   range 类型表示不可变的数字序列，通常用于在 for 循环中循环指定的次数:for i in range(0,10),基本示例如下： >>> list(range(0, 10, 3)) [0, 3, 6, 9] len()   返回对象的长度（元素个数）。实参可以是序列（如 string、bytes、tuple、list 或 range 等）或集合（如 dictionary、set 或 frozen set 等）。 在for循环中经常和range一起使用：for i in range(0,len(hex_ids))。 eval()   标准格式： eval(expression, [globals,[locals]]) 实参是一个字符串，以及可选的 globals 和 locals。globals 实参必须是一个字典。locals 可以是任何映射对象。 用到过的示例：oct_id = oct(eval('0x'+hex_ids[i]))，对eval里面表达式计算成16进制格式，然后再用oct()转换成8进制。 open() 标准格式：open(file, mode='r',buffering=-1,encoding=None,errors=None,newline=None,closefd=True,opener=None)说明： 打开file并返回对应的file object,如果该文件不能打开，则触发 OSError file是一个path-like object，表示将要打开的文件的路径（绝对路径或者当前工作目录的相对路径） mode是一个可选字符串，用于指定打开文件的模式。默认值是 'r' buffering是一个可选的整数，用于设置缓冲策略 encoding是用于解码或编码文件的编码的名称 errors是一个可选的字符串参数，用于指定如何处理编码和解码错误（不能在二进制模式下使用） newline控制universal newlines模式如何生效（它仅适用于文本模式） 如果closefd是False并且给出了文件描述符而不是文件名，那么当文件关闭时，底层文件描述符将保持打开状态。如果给出文件名则closefd必须为True（默认值），否则将引发错误 可以通过传递可调用的opener来使用自定义开启器 可用的模式有： 字符|意义 :---:|:--- 'r'|读取（默认） 'w'|写入，并先截断文件 'x'|排它性创建，如果文件已存在则失败 'a'|写入，如果文件存在则在末尾追加 'b'|二进制模式 't'|文本模式（默认） '+'|打开用于更新（读取与写入） 使用示例： >>> f = open('test2','w') >>> f.write('Miracles happen every day.') >>> f.close() bash-5.0# cat test2 Miracles happen every day. >>> with open('test2','w') as f: ... f.write('You can\\'t change the past\\n') ... f.close() ... 26 >>> bash-5.0# cat test2 You can't change the past   尝试使用上面方法写入变量，变量是多行的额，发现不行。如果写入的数据是多个或者多行，或者变量中有多行，可以使用readlines,示例如下： >>> import os >>> a = os.popen('ls -l') >>> with open('test2','w') as f: ... f.writelines(a) ... f.close() ... >>> bash-5.0# cat test2 total 4408 -rw-r----- 1 root system 1784 Dec 29 16:57 base.html drwxr-x--- 3 root system 256 Dec 29 13:14 script -rwxr-xr-x 1 root system 1587 Dec 29 13:12 setup.py format() 标准格式： format(value,[format_spec]) 目前还没使用过，看起来很有用，可以参考：格式规格迷你语言 max() & min() 标准格式：max(arg1, arg2, *args,[key]) 返回可迭代对象中最大的元素，或者返回两个及以上实参中最大的。 filter() 标准格式：filter(function, iterable)   用 iterable 中函数 function 返回真的那些元素，构建一个新的迭代器。经常和lambda表达式结合使用， 例如下面示例把list_a中的1筛选出来： list_a = [3,1,0,5,6,1,9,6,1,4,1] b = filter(lambda a:True if a == 1 else False,list_a ) print(b) print(list(b)) 运行后输出结果如下： PS D:\\Python\\codefile\\function_code> python module_1.py [1, 1, 1, 1] map()和reduce() 和filter()一样，结合使用的话实用性很大，使用方法在学习笔记函数式编程中有介绍，Python学习笔记-函数式编程 sort()   此方法会对列表进行原地排序，只使用 来进行各项间比较。异常不会被屏蔽:如果有任何比较操作失败，整个排序操作将失败（而列表可能会处于被部分修改的状态）,标准格式：sort(*, key=None, reverse=False),参数说明： key指定带有一个参数的函数，用于从每个列表元素中提取比较键 (例如 key=str.lower)。 对应于列表中每一项的键会被计算一次，然后在整个排序过程中使用。默认值None表示直接对列表项排序而不计算一个单独的键值 reverse为一个布尔值。如果设为True，则每个列表元素将按反向顺序比较进行排序 示例如下： list1 = [4,5,6,7,0,1,2,3] list1.sort() print(list1) list1.sort(key=None) print(list1) list1.sort(key=None,reverse=False) print(list1) list1.sort(reverse=True) print(list1) list1.sort(key=None,reverse=True) print(list1) 运行后输出结果如下： PS C:\\Users\\big1000\\vscode\\codefile\\Leetcode> python 1528.py [0, 1, 2, 3, 4, 5, 6, 7] [0, 1, 2, 3, 4, 5, 6, 7] [0, 1, 2, 3, 4, 5, 6, 7] [7, 6, 5, 4, 3, 2, 1, 0] [7, 6, 5, 4, 3, 2, 1, 0] sorted()   标准格式：sorted(iterable, *, key=None, reverse=False)根据iterable中的项返回一个新的已排序列表。具有两个可选参数，它们都必须指定为关键字参数： key指定带有单个参数的函数，用于从iterable的每个元素中提取用于比较的键(例如 key=str.lower)。默认值为 None(直接比较元素)。 reverse为一个布尔值。如果设为True，则每个列表元素将按反向顺序比较进行排序。 示例：在爬虫学习中有使用示例。 zip()   可以将两个有序数据一一对应进行聚合，标准格式：zip(*iterables),示例如下： a = 'codeleet' b = [4,5,6,7,0,2,1,3] zipped = zip(b,a) print(zipped) print(list(zipped)) x,y = zip(*zip(a,b)) print(x) print(y) 运行后输出结果如下： PS C:\\Users\\big1000\\vscode\\codefile\\Leetcode> python 1528.py [(4, 'c'), (5, 'o'), (6, 'd'), (7, 'e'), (0, 'l'), (2, 'e'), (1, 'e'), (3, 't')] ('c', 'o', 'd', 'e', 'l', 'e', 'e', 't') (4, 5, 6, 7, 0, 2, 1, 3) 应用实例：在解答leetcode题目1528. Shuffle String时候用到此方法。 sum()   标准格式：sum(iterable,/,start=0),从start开始从左向右对iterable的项求和并返回总计值。iterable项通常为数字，start值不允许为字符串。示例如下： a = [1,3,4,6,2,9,8] b = sum(a) print(b) 运行示例如下： PS C:\\Users\\big1000\\vscode\\codefile\\Leetcode> python 1672.py 33 应用实例：在解答leetcode题目1672.Richest Customer Wealth时候用到此方法。延申说明： 字符串拼接调用.join(sequence),在Python-常用字符串方法中有介绍。 要以扩展精度对浮点值求和，可以使用math.fsum() 要拼接一系列可迭代对象，可以使用itertools.chain() 其它常用内置函数待使用 "},"08-Python/02-Python内置模块&方法/04-Python-array&readline.html":{"url":"08-Python/02-Python内置模块&方法/04-Python-array&readline.html","title":"Python-array&readline","keywords":"","body":"Python-array&readline 学习记录一些阵列操作方法。 array高效的数值数组 此模块定义了一种对象类型，可以紧凑地表示基本类型值的数组：字符、整数、浮点数等。 array.append(x) 添加一个值为x的新项到数组末尾。注意不能添加多个项目。使用示例： class Solution: def shuffle(self, nums: List[int], n: int) -> List[int]: out_list = [] for i in range(0,n): j = i + n x = nums[i] out_list.append(x) y = nums[j] out_list.append(y) return out_list array.extend(iterable)   将来自iterable的项添加到数组末尾。如果iterable是另一个数组，它必须具有完全相同的类型码；否则将引发 TypeError 如果iterable不是一个数组，则它必须为可迭代对象并且其元素必须为可添加到数组的适当类型。 如果指定多个不是列表的元素，会报错,必须以列表的形式添加进去： extend() takes exactly one argument (2 given) 使用示例： item_list = [] mtype = {'title':'Machine Typy','value':self.get_type()} sn = {'title':'Serial Number','value':self.get_sn()} fw = {'title':'Platform Firmware Level','value':self.get_fw()} item_list.extend([mtype,sn,fw]) array.insert(i, x) 将值x作为新项插入数组的i位置之前。 负值将被视为相对于数组末尾的位置。 array常用操作 列表取第一列数据 示例如下： >>> array = [[1,3,5,7,9],[2,4,6,8,10],[31,23,45,67,2]] >>> newarray = [x[0] for x in array] >>> print(newarray) [1, 2, 31] 如果全是字符，第一列比较规则的话，可以采用切片方位方式: >>> import os >>> a = os.popen('errpt -dS -s 1120154520') >>> b = [x[0:8] for x in a] >>> b ['IDENTIFI', '1BA7DF4E', 'CB4A951F', 'CB4A951F', '1BA7DF4E', 'CB4A951F', 'CB4A951F', '1BA7 DF4E', 'CB4A951F', 'CB4A951F', '1BA7DF4E', 'CB4A951F', 'CB4A951F', '1BA7DF4E', 'CB4A951F', 'CB4A951F', '1BA7DF4E', 'CB4A951F', 'CB4A951F'] 根据第一列数据去重   有时候需要根据第一列数据去重，shell中sort和uniq都可以去重，排序后其它列的顺序也改变了，又不想改变其他列原有顺序，可以用python来实现。此示例不一定适用所有场合： import re a = [[1,3,5,],[2,4,5],[1,23,45],[3,13,5],[2,13,5]] list1 = [] for i in a: j = str(i[0]) k = [x[0] for x in list1] if not re.findall(j,str(k)): list1.append(i) print(list1) 运行示例： bash-5.0# python3 test.py [[1, 3, 5], [2, 4, 5], [3, 13, 5]] NumPY   Numeric Python扩展(NumPy)定义了另一种数组类型，是一个第三方库，需要安装，可以用于在数组提取某一列元素，或者矩阵按列进行重新组成新矩阵。官方网站：https://numpy.org/ 字典组合列表实例 例如有如下list： [{'id':1,'main':'IBM','sub':'power','name':'p720','url':'p720.com'}, {'id':2,'main':'IBM','sub':'power','name':'e980','url':'e980.com'}, {'id':3,'main':'IBM','sub':'storage','name':'v7000','url':'v7000.com'}, {'id':4,'main':'Python','sub':'flask','name':'huang','url':'big100.com'}, {'id':5,'main':'Python','sub':'flask','name':'flask','url':'flask.com'}, {'id':6,'main':'Python','sub':'jinja2','name':'jinja2','url':'jinja2.com'}, {'id':7,'main':'html','sub':'css','name':'css','url':'css.com'}] 根据字典中的key值进行排序，示例： >>> from operator import itemgetter >>> links = [{'id':1,'main':'IBM','sub':'power','name':'p720','url':'p720.com'},{'id':2,'m ain':'IBM','sub':'power','name':'e980','url':'e980.com'},{'id':3,'main':'IBM','sub':'storage','name':'v7000','url':'v7000.com'},{'id':4,'main':'Python','sub':'flask','name':'huang','url':'big100.com'},{'id':5,'main':'Python','sub':'flask','name':'flask','url':'flask.com'},{'id':6,'main':'Python','sub':'jinja2','name':'jinja2','url':'jinja2.com'},{'id':7,'main':'html','sub':'css','name':'css','url':'css.com'}] links.sort(key=itemgetter('sub')) 根据字典中key值进行筛选： >>> from itertools import groupby >>> for i in groupby(links,key=itemgetter('main')): ... print(i) ... ('IBM', ) ('Python', ) ('html', ) 可以看到返回的是一个对象，遍历查看内容： >>> for i,j in groupby(links,key=itemgetter('main')): ... print(i) ... for k in j: ... print(k) IBM {'id': 1, 'main': 'IBM', 'sub': 'power', 'name': 'p720', 'url': 'p720.com'} {'id': 2, 'main': 'IBM', 'sub': 'power', 'name': 'e980', 'url': 'e980.com'} {'id': 3, 'main': 'IBM', 'sub': 'storage', 'name': 'v7000', 'url': 'v7000.com'} Python {'id': 4, 'main': 'Python', 'sub': 'flask', 'name': 'huang', 'url': 'big100.com'} {'id': 5, 'main': 'Python', 'sub': 'flask', 'name': 'flask', 'url': 'flask.com'} {'id': 6, 'main': 'Python', 'sub': 'jinja2', 'name': 'jinja2', 'url': 'jinja2.com'} html {'id': 7, 'main': 'html', 'sub': 'css', 'name': 'css', 'url': 'css.com'} 可以看到进行了分类对应。进一步再通过key：sub进行分类： power [{'id': 1, 'main': 'IBM', 'sub': 'power', 'name': 'p720', 'url': 'p720.com'}, {'id': 2, 'main': 'IBM', 'sub': 'power', 'name': 'e980', 'url': 'e980.com'}] storage [{'id': 3, 'main': 'IBM', 'sub': 'storage', 'name': 'v7000', 'url': 'v7000.com'}] flask [{'id': 4, 'main': 'Python', 'sub': 'flask', 'name': 'huang', 'url': 'big100.com'}, {'id': 5, 'main': 'Python', 'sub': 'flask', 'name': 'flask', 'url': 'flask.com'}] jinja2 [{'id': 6, 'main': 'Python', 'sub': 'jinja2', 'name': 'jinja2', 'url': 'jinja2.com'}] css [{'id': 7, 'main': 'html', 'sub': 'css', 'name': 'css', 'url': 'css.com'}] 继续整理下，把弄到一个列表里面去： from operator import itemgetter from itertools import groupby links = [{'id':1,'main':'IBM','sub':'power','name':'p720','url':'p720.com'},{'id':2,'main':'IBM','sub':'power','name':'e980','url':'e980.com'},{'id':3,'main':'IBM','sub':'storage','name':'v7000','url':'v7000.com'},{'id':4,'main':'Python','sub':'flask','name':'huang','url':'big100.com'},{'id':5,'main':'Python','sub':'flask','name':'flask','url':'flask.com'},{'id':6,'main':'Python','sub':'jinja2','name':'jinja2','url':'jinja2.com'},{'id':7,'main':'html','sub':'css','name':'css','url':'css.com'}] links_list = [] for i,j in groupby(links,key=itemgetter('main')): j = list(j) sub_list = [] for x,y in groupby(j,key=itemgetter('sub')): y = list(y) subdict = {'subclass':x,'link':y} sub_list.append(subdict) maindict = {'mainclass':i,'subdict':sub_list} links_list.append(maindict) print(links_list) 输出如下： [{'mainclass': 'IBM', 'subdict': [{'subclass': 'power', 'link': [{'id': 1, 'main': 'IBM', 'sub': 'power', 'name': 'p720', 'url': 'p720.com'}, {'id': 2, 'main': 'IBM', 'sub': 'power', 'name': 'e980', 'url': 'e980.com'}]}, {'subclass': 'storage', 'link': [{'id': 3, 'main': 'IBM', 'sub': 'storage', 'name': 'v7000', 'url': 'v7000.com'}]}]}, {'mainclass': 'Python', 'subdict': [{'subclass': 'flask', 'link': [{'id': 4, 'main': 'Python', 'sub': 'flask', 'name': 'huang', 'url': 'big100.com'}, {'id': 5, 'main': 'Python', 'sub': 'flask', 'name': 'flask', 'url': 'flask.com'}]}, {'subclass': 'jinja2', 'link': [{'id': 6, 'main': 'Python', 'sub': 'jinja2', 'name': 'jinja2', 'url': 'jinja2.com'}]}]}, {'mainclass': 'html', 'subdict': [{'subclass': 'css', 'link': [{'id': 7, 'main': 'html', 'sub': 'css', 'name': 'css', 'url': 'css.com'}]}]}] 示例中使用了itemgetter和groupby，官方文档说明： operator-标准运算符替代函数 itertools-为高效循环而创建迭代器的函数 注意事项： 上面的示例中的数据想对比较整齐，如果在数据中添加如下数据： {'id':8,'main':'IBM','sub':'storage','name':'DS8000','url':'DS8000.com'} 输出效果： [{'mainclass': 'IBM', 'subdict': [{'subclass': 'power', 'link': [{'id': 1, 'main': 'IBM', 'sub': 'power', 'name': 'p720', 'url': 'p720.com'}, {'id': 2, 'main': 'IBM', 'sub': 'power', 'name': 'e980', 'url': 'e980.com'}]}, {'subclass': 'storage', 'link': [{'id': 3, 'main': 'IBM', 'sub': 'storage', 'name': 'v7000', 'url': 'v7000.com'}]}]}, {'mainclass': 'Python', 'subdict': [{'subclass': 'flask', 'link': [{'id': 4, 'main': 'Python', 'sub': 'flask', 'name': 'huang', 'url': 'big100.com'}, {'id': 5, 'main': 'Python', 'sub': 'flask', 'name': 'flask', 'url': 'flask.com'}]}, {'subclass': 'jinja2', 'link': [{'id': 6, 'main': 'Python', 'sub': 'jinja2', 'name': 'jinja2', 'url': 'jinja2.com'}]}]}, {'mainclass': 'html', 'subdict': [{'subclass': 'css', 'link': [{'id': 7, 'main': 'html', 'sub': 'css', 'name': 'css', 'url': 'css.com'}]}]}, {'mainclass': 'IBM', 'subdict': [{'subclass': 'storage', 'link': [{'id': 8, 'main': 'IBM', 'sub': 'storage', 'name': 'DS8000', 'url': 'DS8000.com'}]}]}]   新加的数据不会归纳到第一个IBM主类里面去，就不是想要达到的效果了，解决方法就是在做groupby之前，先进行排序，示例： links.sort(key=itemgetter('sub')) 示例代码： from operator import itemgetter from itertools import groupby links = [ {'id':1,'main':'IBM','sub':'power','name':'p720','url':'p720.com'}, {'id':2,'main':'IBM','sub':'power','name':'e980','url':'e980.com'}, {'id':3,'main':'IBM','sub':'storage','name':'v7000','url':'v7000.com'}, {'id':4,'main':'Python','sub':'flask','name':'flask','url':'flask.com'}, {'id':5,'main':'Python','sub':'jinja2','name':'jinja2','url':'jinja2.com'}, {'id':6,'main':'HTML','sub':'css','name':'css','url':'css.com'}, {'id':7,'main':'IBM','sub':'storage','name':'DS8000','url':'DS8000.com'}, {'id':8,'main':'HTML','sub':'bootstrap','name':'bootstrap','url':'bootstrap.com'}, {'id':9,'main':'Python','sub':'flask','name':'huang','url':'big100.com'}] links_list = [] links.sort(key=itemgetter('main')) for i,j in groupby(links,key=itemgetter('main')): j = list(j) j.sort(key=itemgetter('sub')) sub_list = [] for x,y in groupby(j,key=itemgetter('sub')): y = list(y) subdict = {'subclass':x,'link':y} sub_list.append(subdict) maindict = {'mainclass':i,'subdict':sub_list} links_list.append(maindict) print(links_list) 输出如下： [{'mainclass': 'HTML', 'subdict': [ {'subclass': 'bootstrap', 'link': [ {'id': 8, 'main': 'HTML', 'sub': 'bootstrap', 'name': 'bootstrap', 'url': 'bootstrap.com'}]}, {'subclass': 'css', 'link': [ {'id': 6, 'main': 'HTML', 'sub': 'css', 'name': 'css', 'url': 'css.com'}]}]}, {'mainclass': 'IBM', 'subdict': [ {'subclass': 'power', 'link': [ {'id': 1, 'main': 'IBM', 'sub': 'power', 'name': 'p720', 'url': 'p720.com'}, {'id': 2, 'main': 'IBM', 'sub': 'power', 'name': 'e980', 'url': 'e980.com'}]}, {'subclass': 'storage', 'link': [ {'id': 3, 'main': 'IBM', 'sub': 'storage', 'name': 'v7000', 'url': 'v7000.com'}, {'id': 7, 'main': 'IBM', 'sub': 'storage', 'name': 'DS8000', 'url': 'DS8000.com'}]}]}, {'mainclass': 'Python', 'subdict': [ {'subclass': 'flask', 'link': [ {'id': 4, 'main': 'Python', 'sub': 'flask', 'name': 'flask', 'url': 'flask.com'}, {'id': 9, 'main': 'Python', 'sub': 'flask', 'name': 'huang', 'url': 'big100.com'}]}, {'subclass': 'jinja2', 'link': [ {'id': 5, 'main': 'Python', 'sub': 'jinja2', 'name': 'jinja2', 'url': 'jinja2.com'}]}]}] 待补充 "},"08-Python/02-Python内置模块&方法/05-Python-常用字符串方法.html":{"url":"08-Python/02-Python内置模块&方法/05-Python-常用字符串方法.html","title":"Python-常用字符串方法","keywords":"","body":"Python-常用字符串方法   字符串实现了所有一般序列的操作，还额外提供了以下列出的一些附加方法。官方文档:内置类型 str.join()   返回一个由iterable中的字符串拼接而成的字符串。如果iterable中存在任何非字符串值包括bytes对象则会引发 TypeError。调用该方法的字符串将作为元素之间的分隔。标准格式：str.join(iterable),示例如下： x = ('l', 'e', 'e', 't', 'c', 'o', 'd', 'e') y = ','.join(x) print(y) y = ''.join(x) print(y) 运行后输出结果如下： PS C:\\Users\\vscode\\codefile\\Leetcode> python 1528.py l,e,e,t,c,o,d,e leetcode 应用实例：在解答leetcode题目1528. Shuffle String时候用到此方法。 str.strip()   标准格式：str.strip([chars])  返回原字符串的副本，移除其中的前导和末尾字符。chars参数为指定要移除字符的字符串,如果省略或为 None，则chars参数默认移除空格符。实际上chars参数并非指定单个前缀或后缀,而是会移除参数值的所有组合,示例如下： >>> import os >>> cmd_type = 'uname -M |awk -F, \\'{print $2}\\'' >>> mtype = os.popen(cmd_type) >>> mtype = mtype.read() >>> print(mtype) 9117-570 >>> print(mtype.strip()) 9117-570 >>> ' Captain America '.strip() 'Captain America' >>> 'www.google.com'.strip('cmowz.') 'google' str.split() 标准格式：str.split(sep=None, maxsplit=-1)说明： 返回一个由字符串内单词组成的列表，使用sep作为分隔字符串 如果给出了maxsplit，则最多进行maxsplit次拆分；如果maxsplit未指定或为-1，则不限制拆分次数 如果给出了sep，则连续的分隔符不会被组合在一起而是被视为分隔空字符串 示例如下： >>> import os >>> user_rate_cmd = 'iostat -t 1 5|awk \\'{print $3,$4,$5}\\'|sed -n \\'/^[0-9]/p\\'' >>> user_rate = os.popen(user_rate_cmd) >>> for i in user_rate: ... print(i) ... 1.0 2.9 96.1 0.5 2.2 97.3 0.7 2.5 96.8 0.2 1.8 98.0 0.2 1.3 98.5 >>> user_rate = os.popen(user_rate_cmd) >>> for i in user_rate: ... j = i.split(' ') ... print(j) ... ['2.9', '5.4', '91.8\\n'] ['0.3', '1.8', '98.0\\n'] ['0.2', '1.8', '98.0\\n'] ['0.2', '1.8', '97.9\\n'] ['0.4', '1.6', '98.0\\n'] 如果不进行分割，如果去遍历j，就会一个字符一个字符去遍历。 待补充 "},"08-Python/03-Python_LeetCode/":{"url":"08-Python/03-Python_LeetCode/","title":"Python_LeetCode","keywords":"","body":"leetcode 简介 LeetCode-全球极客挚爱的技术成长平台。 LeetCode官网:https://leetcode.com 内容 Python-简单题目 Python-简单题目_1 Python-中等难度 "},"08-Python/03-Python_LeetCode/01-Python-简单题目.html":{"url":"08-Python/03-Python_LeetCode/01-Python-简单题目.html","title":"Python-简单题目","keywords":"","body":"Python-简单题目 一些基础题目解答的过程。 1480. Running Sum of 1d Array 描述 Given an array nums. We define a running sum of an array as runningSum[i] = sum(nums[0]…nums[i]). Return the running sum of nums. 要求示例 Example 1:Input: nums = [1,2,3,4];Output: [1,3,6,10] Explanation: Running sum is obtained as follows: [1, 1+2, 1+2+3, 1+2+3+4]. Example 2:Input: nums = [1,1,1,1,1];Output: [1,2,3,4,5] Explanation: Running sum is obtained as follows: [1, 1+1, 1+1+1, 1+1+1+1, 1+1+1+1+1]. Example 3:Input: nums = [3,1,2,10,1];Output: [3,4,6,16,17] Constraints:1 解答 提交代码如下： class Solution: def runningSum(self, nums: List[int]) -> List[int]: x = 0 for i in range(0,len(nums)): x = x + nums[i] nums[i] = x return nums 刚开始做不熟悉LeetCode的模式，自己创建类和方法去解，可以实现功能，但是提交一直报错。刚开始没有用到切片方式，后来才想到，个人感觉还是上面切片方式简单，代码如下： class Solution: num = 0 list = [] def runningSum(self,nums): for i in nums: self.__class__.num += i self.__class__.list.append(self.__class__.num) print(self.__class__.list) def input_list(self): list_input = eval(input()) self.runningSum(list_input) solution = Solution() solution.input_list() 1512. Number of Good Pairs 描述 Given an array of integers nums. A pair (i,j) is called good if nums[i] == nums[j] and i 示例和要求 Example 1:Input: nums = [1,2,3,1,1,3];Output: 4;Explanation: There are 4 good pairs (0,3), (0,4), (3,4), (2,5) 0-indexed. Example 2:Input: nums = [1,1,1,1];Output: 6;Explanation: Each pair in the array are good. Example 3:Input: nums = [1,2,3];Output: 0 Constraints:1 解答 提交代码如下： class Solution: def numIdenticalPairs(self, nums: List[int]) -> int: count = 0 for i in range(0,len(nums)): for j in range(0,len(nums)): if nums[i] == nums[j] and i 1365.How Many Numbers Are Smaller Than the Current Number 描述 Given the array nums, for each nums[i] find out how many numbers in the array are smaller than it. That is, for each nums[i] you have to count the number of valid j's such that j != i and nums[j] 解答 class Solution: def smallerNumbersThanCurrent(self, nums: List[int]) -> List[int]: out_list = [] for i in range(0,len(nums)): count = 0 for j in nums: if j != nums[i] and j 1470.Shuffle the Array 描述 Given the array nums consisting of 2n elements in the form [x1,x2,...,xn,y1,y2,...,yn].Return the array in the form [x1,y1,x2,y2,...,xn,yn].Example 2:Input: nums = [1,2,3,4,4,3,2,1], n = 4Output: [1,4,2,3,3,2,4,1] 解答 提交代码如下： class Solution: def shuffle(self, nums: List[int], n: int) -> List[int]: out_list = [] for i in range(0,n): j = i + n x = nums[i] out_list.append(x) y = nums[j] out_list.append(y) return out_list 1431.Kids With the Greatest Number of Candies 描述 Given the array candies and the integer extraCandies, where candies[i] represents the number of candies that the ith kid has.For each kid check if there is a way to distribute extraCandies among the kids such that he or she can have the greatest number of candies among them. Notice that multiple kids can have the greatest number of candies. 解答 提交代码如下： class Solution: def kidsWithCandies(self, candies: List[int], extraCandies: int) -> List[bool]: out_list = [] for i in range(0,len(candies)): out_list.append((candies[i] + extraCandies >= max(candies))) return out_list 1672.Richest Customer Wealth 描述  You are given an m x n integer grid accounts where accounts[i][j] is the amount of money the i​​​​​​​​​​​th​​​​ customer has in the j​​​​​​​​​​​th​​​​ bank. Return the wealth that the richest customer has.  A customer's wealth is the amount of money they have in all their bank accounts. The richest customer is the customer that has the maximum wealth. 解答 提交代码如下： class Solution: def maximumWealth(self, accounts: List[List[int]]) -> int: wealth_list = [] for i in range(0,len(accounts)): wealth_sum = sum(accounts[i]) wealth_list.append(wealth_sum) return max(wealth_list) 1108.Defanging an IP Address 描述  Given a valid (IPv4) IP address, return a defanged version of that IP address.A defanged IP address replaces every period \".\" with \"[.]\". 解答 提交代码如下： class Solution: def defangIPaddr(self, address: str) -> str: import re new_add = re.sub('\\.','[.]',address,0) return new_add 771.Jewels and Stones 描述  You're given stringsJrepresenting the types of stones that are jewels,and Srepresenting the stones you have. Each character in S is a type of stone you have. You want to know how many of the stones you have are also jewels. The letters inJare guaranteed distinct,and all characters inJandSare letters. Letters are case sensitive, so\"a\"is considered a different type of stone from \"A\". 解答 提交代码如下： class Solution: def numJewelsInStones(self, J: str, S: str) -> int: count = 0 for i in J: for j in S: if i == j: count +=1 return count 1662.Check If Two String Arrays are Equivalent 描述  Given two string arraysword1and`word2,return true if the two arrays represent the same string,and false otherwise. A string is represented by an array if the array elements concatenated in order forms the string. 解答 提交代码如下： class Solution: def arrayStringsAreEqual(self, word1: List[str], word2: List[str]) -> bool: i = ''.join(word1) j = ''.join(word2) if i ==j: return True else: return False 1603.Design Parking System 描述  Design a parking system for a parking lot.The parking lot has three kinds of parking spaces:big,medium,andsmall,with a fixed number of slots for each size.Implement the ParkingSystem class: ParkingSystem(int big, int medium, int small) Initializes object of the ParkingSystem class. The number of slots for each parking space are given as part of the constructor. bool addCar(int carType) Checks whether there is a parking space of carType for the car that wants to get into the parking lot. carType can be of three kinds: big, medium, or small, which are represented by 1, 2, and 3 respectively. A car can only park in a parking space of its carType. If there is no space available, return false, else park the car in that size space and return true. 解答 提交代码如下： class ParkingSystem: def __init__(self, big: int, medium: int, small: int): self.big = big self.medium = medium self.small = small def addCar(self, carType: int) -> bool: if carType == 1: if self.big > 0: self.big -= 1 return True if carType == 2: if self.medium > 0: self.medium -= 1 return True if carType == 3: if self.small > 0: self.small -= 1 return True # Your ParkingSystem object will be instantiated and called as such: # obj = ParkingSystem(big, medium, small) # param_1 = obj.addCar(carType) 1313.Decompress Run-Length Encoded List 描述  We are given a listnumsof integers representing a list compressed with run-length encoding.Consider each adjacent pair of elements[freq, val] = [nums[2*i], nums[2*i+1]] (with i >= 0).For each such pair,there arefreqelements with valuevalconcatenated in a sublist.Concatenate all the sublists from left to right to generate the decompressed list.Return the decompressed list. 解答 提交代码如下： class Solution: def decompressRLElist(self, nums: List[int]) -> List[int]: result_list = [] for i in range(0,len(nums)//2): [freq, val] = [nums[2*i], nums[2*i+1]] array = freq * [val] result_list = result_list + array return result_list 下一题解答中 "},"08-Python/03-Python_LeetCode/02-Python-简单题目_1.html":{"url":"08-Python/03-Python_LeetCode/02-Python-简单题目_1.html","title":"Python-简单题目_1","keywords":"","body":"Python-简单题目 一些Leetcode简单题目解答的过程。题目的描述和示例有点多，占位置，详细可以在题目原链接上查看。 1486. XOR Operation in an Array 题目链接：https://leetcode.com/problems/xor-operation-in-an-array/ 说明 Given an integer n and an integer start.Define an array nums where nums[i] = start + 2*i (0-indexed) and n == nums.length.Return the bitwise XOR of all elements of nums. 解答 提交代码如下： class Solution: def xorOperation(self, n: int, start: int) -> int: from functools import reduce nums = [] for i in range(0,n): num = start + 2 * i nums.append(num) vaule = reduce(lambda x,y:x^y,nums) return vaule 1528. Shuffle String 题目链接：https://leetcode.com/problems/shuffle-string/ 说明 Given a string s and an integer array indices of the same length.The string s will be shuffled such that the character at the ith position moves to indices[i] in the shuffled string.Return the shuffled string. 解答 提交代码如下： class Solution: def restoreString(self, s: str, indices: List[int]) -> str: from functools import reduce zipped = zip(indices,s) sort_zip = sorted(zipped) a , b = zip(*sort_zip) result= reduce(lambda x,y:x+y,b) return result 之前一直用reduce，才了解到可以用join实现list中字符串相加： class Solution: def restoreString(self, s: str, indices: List[int]) -> str: zipped = zip(indices,s) sort_zip = sorted(zipped) a , b = zip(*sort_zip) result= ''.join(b) return result 下一题解答中 "},"08-Python/03-Python_LeetCode/11-Python-中等难度.html":{"url":"08-Python/03-Python_LeetCode/11-Python-中等难度.html","title":"Python-中等难度","keywords":"","body":"Python-中等难度 一些Leetcode中等难度题目解答的过程。题目的描述和示例有点多，占位置，详细可以在题目原链接上查看。 1476. Subrectangle Queries 题目链接：https://leetcode.com/problems/subrectangle-queries/ 说明 Implement the class SubrectangleQueries which receives a rows x cols rectangle as a matrix of integers in the constructor and supports two methods: updateSubrectangle(int row1, int col1, int row2, int col2, int newValue),Updates all values with newValue in the subrectangle whose upper left coordinate is (row1,col1) and bottom right coordinate is (row2,col2). getValue(int row, int col),Returns the current value of the coordinate (row,col) from the rectangle. 解答 第一次测试通过后提交代码如下： class SubrectangleQueries: def __init__(self, rectangle: List[List[int]]): self.rectangle = rectangle def updateSubrectangle(self, row1: int, col1: int, row2: int, col2: int, newValue: int) -> None: for i in range(row1,row2+1): if i == row1 and i == row2: for j in range(col1,col2+1): self.rectangle[i][j] = newValue elif i == row1 and i != row2: for k in range(col1,len(self.rectangle[0])): self.rectangle[row1][k] = newValue elif i != row1 and i == row2: for l in range(0,col2+1): self.rectangle[row2][l] = newValue else: for m in range(0,len(self.rectangle[0])): self.rectangle[i][m] = newValue return self.rectangle def getValue(self, row: int, col: int) -> int: value = self.rectangle[row][col] return value   测试运行通过，但是提交后报错，也就是不满足题目要求，把题目想复杂了，并且没有认真审题，错误理解是从(row1,col1)到(row2,col2)中间所有的值都要去修改，也没注意有下面要求： 0 修改后提交代码如下： class SubrectangleQueries: def __init__(self, rectangle: List[List[int]]): self.rectangle = rectangle def updateSubrectangle(self, row1: int, col1: int, row2: int, col2: int, newValue: int) -> None: for i in range(row1,row2+1): for j in range(col1,col2+1): self.rectangle[i][j] = newValue return self.rectangle def getValue(self, row: int, col: int) -> int: value = self.rectangle[row][col] return value 下一题解答中 "},"08-Python/04-Python_AIX脚本/":{"url":"08-Python/04-Python_AIX脚本/","title":"Python_AIX脚本","keywords":"","body":"Python_AIX脚本 简介 一些学习过程中写的简单脚本。 内容 Python-AIX环境部署 Python-检查系统 Python-AIX配置修改 Python-AIX日常巡检 "},"08-Python/04-Python_AIX脚本/01-Python-AIX环境部署.html":{"url":"08-Python/04-Python_AIX脚本/01-Python-AIX环境部署.html","title":"Python-AIX环境部署","keywords":"","body":"Python-AIX环境部署 AIX系统中安装Python不复杂，不过相对Windows和Linux步骤还是麻烦点，需要安装依赖包以及安装顺序也有要求。简单记录下免得忘记了。 AIX系统中安装Python AIX 系统版本：7100-04-03-1642；Python版本:Python 3.7。 安装包准备 Python安装包：python3-3.7.6-1.aix6.1.ppc.rpm 除了Python的安装包，还需要准备依赖包，也行版本不一样要求不一样，不知道需要什么依赖包的话，可以直接安装Python安装包，会有提示需要哪些包，如下所示： error: failed dependencies: bzip2 >= 1.0.8 is needed by python3-3.7.6-1 gdbm >= 1.18.1 is needed by python3-3.7.6-1 libgdbm.a(libgdbm.so.6) is needed by python3-3.7.6-1 libreadline.a(libreadline.so.8) is needed by python3-3.7.6-1 libsqlite3.so is needed by python3-3.7.6-1 readline >= 8.0-2 is needed by python3-3.7.6-1 sqlite >= 3.28.0 is needed by python3-3.7.6-1 所以还需要准备包： bzip2-1.0.8-2.aix6.1.ppc.rpm gdbm-1.18.1-1.aix6.1.ppc.rpm readline-8.0-2.aix6.1.ppc.rpm sqlite-3.28.0-1.aix6.1.ppc.rpm 开发工具包(根据需求装)： 附带开发工具：python3-tools-3.7.6-1.aix6.1.ppc.rpm 开发需要的libraries和header文件：python3-devel-3.7.6-1.aix6.1.ppc.rpm 这些rpm包下载地址：AIX Toolbox for Linux Applications 安装Python 安装顺序就是在直接安装Python时候提示的依赖包需求顺序，依次执行： rpm -ivh bzip2-1.0.8-2.aix6.1.ppc.rpm rpm -ivh gdbm-1.18.1-1.aix6.1.ppc.rpm rpm -ivh readline-8.0-2.aix6.1.ppc.rpm rpm -ivh sqlite-3.28.0-1.aix6.1.ppc.rpm rpm -ivh python3-3.7.6-1.aix6.1.ppc.rpm rpm -ivh python3-tools-3.7.6-1.aix6.1.ppc.rpm rpm -ivh python3-devel-3.7.6-1.aix6.1.ppc.rpm 查看是否安装,输入命令rpm -qa|grep python，输入Python3进入到IDLE： Python 3.7.6 (default, Feb 28 2020, 04:49:11) [GCC 8.3.0] on aix6 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> 安装pip 在使用Python中需要安装一些第三方库，用pip安装比较方便。需要安装包： python-setuptools-0.9.8-2.aix6.1.noarch.rpm python-pip-10.0.1-1.aix6.1.noarch.rpm 安装示例： # rpm -ivh python-setuptools-0.9.8-2.aix6.1.noarch.rpm Verifying... ################################# [100%] Preparing... ################################# [100%] Updating / installing... 1:python-setuptools-0.9.8-2 ################################# [100%] # rpm -ivh python-pip-10.0.1-1.aix6.1.noarch.rpm Verifying... ################################# [100%] Preparing... ################################# [100%] Updating / installing... 1:python-pip-10.0.1-1 ################################# [100%] 使用示例： # pip -V pip 10.0.1 from /opt/freeware/lib/python2.7/site-packages/pip (python 2.7)   对于PIP其它安装方法及常用命令，在本ebook的章节Python运维-基础知识中有详细的介绍和示例演示。 "},"08-Python/04-Python_AIX脚本/02-Python-检查系统.html":{"url":"08-Python/04-Python_AIX脚本/02-Python-检查系统.html","title":"Python-检查系统","keywords":"","body":"检查系统 一些检查系统状态的脚本，初学者，很多有待优化 检查AIX系统在升级后是否重启 说明 AIX系统在升级后需要重启，但是有些情况下耽搁或者忘记了，后期如果不知道，如果是PowerHA环境，会导致切换失败。 脚本中对于获取的系统升级时间是用户自定义的系统时间，可能是CST，也可能是CDT,脚本中默认是CST，可以根据不同系统时间修改脚本；获取的重启时间固定是UTC。 在Linux中用命令： date +%s -d \"Mon Jul 06 02:03:52 UTC 2019可以直接转换成UNIX时间戳，这样判断就很简单，但是AIX中date命令没有-d这个参数，需要自己写函数进行转换， 代码如下： #!/usr/bin/python3 #读取bos.rte安装时间和读取系统重启时间，判断在升级后系统是否重启过 import os import time class CheckReboot(): upgrade_time_cmd = 'lslpp -h bos.rte|awk \\'{print \\\"\\\"$4,$5\\\"\\\"}\\'|tail -1' reboot_time_cmd = 'alog -t boot -o|grep date|awk \\'{print \\\"\\\"$7,$8,$9,$10,$11,$12\\\"\\\"}\\'|tail -1' #命令输出时间格式为：03/21/19 11:32:57，定义方法转化时间 def __get_upgrade_time(self): upgrade_time = os.popen(CheckReboot.upgrade_time_cmd) upgrade_time = upgrade_time.read(17) upgrade_time = time.strptime(upgrade_time,'%m/%d/%y %H:%M:%S') upgrade_time = time.mktime(upgrade_time) print('The latest upgrade time is:'+ time.ctime(upgrade_time)) return upgrade_time #命令输出时间格式为：Fri Jul 19 09:08:38 UTC 2019，定义方法转化时间 def __get_reboot_time(self): reboot_time = os.popen(CheckReboot.reboot_time_cmd) reboot_time = reboot_time.read(28) reboot_time = reboot_time.strip() reboot_time = time.strptime(reboot_time,'%a %b %d %H:%M:%S %Z %Y') reboot_time = time.mktime(reboot_time) reboot_time = reboot_time + 28800 print('The latest reboot time is:' + time.ctime(reboot_time)) return reboot_time #定义方法进行判断 def __determine(self,upgrade_time,reboot_time): if upgrade_time 示例 在AIX7100-04-03-1642中运行示例如下： bash-5.0# python3 test1.py The latest upgrade time is:Tue Jan 22 20:20:24 2019 The latest reboot time is:Mon Jul 13 21:51:49 2020 The system has been restart after upgrade! 检查AIX系统 "},"08-Python/04-Python_AIX脚本/03-Python-AIX配置修改.html":{"url":"08-Python/04-Python_AIX脚本/03-Python-AIX配置修改.html","title":"Python-AIX配置修改","keywords":"","body":"Python-AIX配置修改 一些修改AIX系统的脚本，初学者，很多有待优化 自动修改hdisk的PVID 说明 AIX系统中有时候需要修改PVID，其实也不难，就是要算，十六进制转换成8进制写入即可，过程中容易出错，用脚本就比较方便了。 代码 #!/usr/bin/python3 #修改hdisk的PVID,只能修改未使用磁盘，脚本中加入了校验方法 #脚本中对输入的16进制的PVID也有校验，不符合条件不会被写入 import os import re import time class ChangePVID(): #校验输入的hdisk名称是否可以修改 def __input_disk(self): hdisk = input('Please input hdisk name:') getdsklst_cmd = 'lspv | awk \\'{if($3==\\\"None\\\"){print $1}}\\'' disk_list = os.popen(getdsklst_cmd) disk_list = disk_list.read() if hdisk in disk_list: print('The ' + hdisk +' can change!') return hdisk else: print('The '+ hdisk + ' cannot change PVID,please enter another!') quit() #校验输入的PVID是否可用，并且格式化输入的PVID def __input_pvid(self): new_PVID = input('Please enter new PVID:') if len(new_PVID) == 16 and re.findall('\\A[0-9a-fA-F]+\\Z',new_PVID): hex_ids = re.findall('[0-9a-fA-F]{2}',new_PVID) oct_ids = [];ids_list = [];new_id = '\\\\' for i in range(0,len(hex_ids)): oct_id = oct(eval('0x'+hex_ids[i])) oct_ids.append(oct_id) for j in range(0,len(oct_ids)): if re.findall('[0-9a-fA-F]{2,}',oct_ids[j]) == []: ids = ['00'] else: ids = re.findall('[0-9a-fA-F]{2,}',oct_ids[j]) id_str = str(ids[0]).zfill(4) ids_list.append(id_str) for k in range(0,len(ids_list)): new_id = new_id + ids_list[k] +'\\\\' new_id = new_id + 'c' return new_id else: print('The enter '+ new_PVID + ' format is incorrect,please try again!') quit() #修改PVID并且显示新的PVID def __change_pvid(self,hdisk,new_id): cmd1 = 'echo '+'\"'+new_id+'\"'+' > /tmp/myPVID' cmd2 = 'cat /tmp/myPVID | dd of=/dev/'+hdisk+' bs=1 seek=128' cmd3 = 'rmdev -dl '+hdisk cmd4 = 'lspv |grep '+hdisk os.popen(cmd1);os.popen(cmd2);os.popen(cmd3) os.popen('cfgmgr') print('Please wait 30 seconds!') time.sleep(30) print('Please check the pvid of '+hdisk+':') lspv = os.popen(cmd4) print(lspv.read()) def go_change_pvid(self): hdisk = self.__input_disk() new_id = self.__input_pvid() self.__change_pvid(hdisk,new_id) changepvid = ChangePVID() changepvid.go_change_pvid() 示例 在AIX7100-04-03-1642中运行示例如下： Please input hdisk name:hdisk1 The hdisk1 cannot change PVID,please enter another! bash-5.0# python3 test2.py Please input hdisk name:hdisk2 The hdisk2 can change! Please enter new PVID:00cb4d6e7649957x The enter 00cb4d6e7649957x format is incorrect,please try again! bash-5.0# python3 test2.py Please input hdisk name:hdisk2 The hdisk2 can change! Please enter new PVID:00cb4d6e7649957b 8+0 records in. 8+0 records out. Please wait 30 seconds! Please check the pvid of hdisk2: hdisk2 00cb4d6e7649957b None bash-5.0# "},"08-Python/04-Python_AIX脚本/04-Python-AIX日常巡检.html":{"url":"08-Python/04-Python_AIX脚本/04-Python-AIX日常巡检.html","title":"Python-AIX日常巡检","keywords":"","body":"Python-AIX日常巡检   学习过程中写的AIX自动巡检并生成HTML格式报告的脚本，初学者，还有很多有待优化。脚本存放位置：https://github.com/bond-huang/AIX-Check-Script 结构 整体结构如下： System Information System Error Check System Hardware Error Event System Software Error Event System Errlogger Event System Unknown Error Event System Performance Check CPU Performance Memory And PageSpace Check System Disk Performance Data System Adapter Performance Data System Rootvg Check File System Check Check the filesystem usage rate Check unmount filesystems of rootvg Check System Fix And Lpp Filesets Check the AIX system fix filesets Check the AIX system lpp filesets Check The System Device The system hdisk information The system adapter information Check The MPIO Device Path Check the disable path Check the defined path Check the missing path Check the failed path Check The System Process And Setting Check the system reboot and upgrade time Check the system process Check the system ulimit setting Check The PowerHA Check the HA cluster configuration status Get the cluster service status Get the cluster configuration information Get the cluster operating status Get the node operating status Archive system information 详细结构说明 System Information 获取的信息有： Machine Type Serial Number Platform Firmware Level Check Date Host Name AIX Level CPU Entitled Capacity Memory Size Page Space Size IP Address System Error Check   检查errpt命令输出的系统日志，分为四个类别分别检查和显示报错信息，有时候系统会持续报错，脚本根据报错ID进行了去重处理，避免大篇幅输出： System Hardware Error Event System Software Error Event System Errlogger Event System Unknown Error Event System Performance Check   分别检查了CPU,Memory&PageSpace,Disk及Adapter。 CPU Performance   示例中采样时间比较短，可以根据需求修改脚本，对CPU使用率进行了简单分析，对于CPU是Share类型的分区，对CPU性能项目entc也作了简单分析。 Memory And PageSpace Check   只是取出了系统相应的值，没有进行分析，只是简单说明下如何注意内存和换页空间的使用量。 System Disk Performance Data   对采样值进行了取最大和取平均，每个磁盘都进行了采样，采样频率可以根据需求修改脚本。 System Adapter Performance Data   对采样值进行了取最大和取平均，VSCSI和fcs适配器都进行了采样，采样频率可以根据需求修改脚本。 System Rootvg Check   获取了rootvg一些值和镜像同步状态，rootvg LV状态以及lg_dumplv配置，同时对一些项目进行简单说明，有如下项目： Rootvg State Rootvg Disk Member Total PPs Free PPs PP Size Rootvg disks all on bootlist? Rootvg have a mirror? All LVs are syncd? All LVs are open? Primary dump LV Forced copy flag Always allow dump Dump compression Rootvg last backup time File System Check Check the filesystem usage rate   对文件系统使用率进行了分析，大于80%的会列出来。 Check unmount filesystems of rootvg   有些情况下rootvg里面的文件系统不是全部挂载了，这里进行了检查，没挂载的会列出来。 Check System Fix And Lpp Filesets Check the AIX system fix filesets   检查了系统 fix filesets 安装情况，使用命令是instfix -i。 Check the AIX system lpp filesets   检查了系统 lpp filesets 安装情况，使用命令是lppchk -v。 Check The System Device   主要是列出硬盘和挂载硬盘的适配器的几个重要属性。 The system hdisk information   列出项目有：Status,VG,ALGO,HC_interval,HC_mode,Reserve及PCM。 The system adapter information 主要是两类适配器： 对于vscsi适配器列出项目有：Status和vscsi_err_recov 对于fscsi适配器列出项目有：Status,vscsi_err_recov,attach,dyntrk及fc_err_recov Check The MPIO Device Path   分四个类型检查path，正常的布列出，可能很多，如果检查出有问题的就会列出： Check the disable path Check the defined path Check the missing path Check the failed path Check The System Process And Setting   系统重要设置及进程检查。 Check the system reboot and upgrade time   一般AIX系统在升级后都建议重启，此处列出了重启时间和升级时间，并判断是否在升级后进行了重启。 Check the system process   只检查了两个进程：errdemon和srcmstr。 Check the system ulimit setting   列出了系统ulimit设置，并对各参数进行了简单说明。 Check The PowerHA   对于安装配置了PowerHA的系统进行检查。 Check the HA cluster configuration status   首先检查了系统是否配置了PowerHA集群，没有配置后面就不检查了。 Get the cluster service status   在配置了HA集群情况下，检查集群服务是否启动，启动了继续后面的检查 Get the cluster configuration information 获取集群配置信息，主要有： Cluster Name Cluster Tpye Heartbat Type Repository Disk Resource Group   网络配置信息整理在另外一个表里面包括服务IP和各节点的IP配置。 Get the cluster operating status 获取集群状态信息，包含一些进程，主要有： Cluster Name Cluster State Cluster Substate Cthags Subsystem Ctrmc Subsystem ClstrmgrES Subsystem ClevmgrdES Subsystem ClinfoES Subsystem Clconfd Subsystem Clcomd Subsystem Get the node operating status   获取各节点的状态信息，分为Local和Remote，分别有如下信息： Node name Group State Cluster services status Remote communications Cluster-Aware AIX status Network Name IP Label Get Resource Group information and status 获取的信息有： Resource Group name Startup Policy Fallover Policy Fallback Policy Site Policy Participating Nodes Resource Group state Archive system information   收集详细操作系统信息可以使用snap命令，但是解析需要专用工具，很多数据也很少用到。此节内容归档一些命令输出的信息并打包，可能会比较有用，例如df -g的输出。 目前收集的命令信息和对应文件命： prtconf : prtconf.log lscfg -vp : lscfg.log lparstat -i : lparstat.log lsdev : lsdev.log lspath :lspath.log lsfs : lsfs.log df -g : df.log errpt -a : errpt.log lspv : lspv.log lsvg -p rootvg : rootvg.log lsps -a : lsps.log alog -ot boot : alog.log cat /etc/hosts : hosts.log cat /etc/filesystems : filesystems.log cat /etc/inittab : inittab.log netstat -rn : netstat.log netstat -in : netstat.log netstat -a : netstat.log lsvg -o | lsvg -il : lsvg.log lsattr -El sys0 : sysattr.log lsdev -Cc disk |awk ' {print \"lsattr -El \"$1\"\"}' |sh : diskattr.log lspath |awk '{print $3}'|uniq|awk ' {print \"lsattr -El \"$1\"\"}' |sh : adapterattr.log   后续有补充再加。收集的数据放置在脚本当前文件夹下面，并用日期进行了命名。 使用说明 使用说明如下： 推荐使用Python3，测试使用Python版本3.7.6 脚本中尽量避免使用Python第三方库，但是jinja2是必须的 推荐AIX系统版本7.1或更高，测试使用AIX版本7100-04-03-1642 需要AIX系统root用户权限才能运行，有些命令必须要root权限 如果系统使用非IBM多路径软件，则路径检查脚本可能用处不大 如果使用了多个pagespace，可能获取信息不准确，脚本中暂时没考虑到此点，有空修改 脚本中PowerHA检查由于没有环境，没实测过 脚本中PowerHA检查只支持7.1及以上版本，并且对于多Site的可能不支持 其它说明   之前打算使用第三方库reportlab，可以画图、画表格、编辑文字,最后可以输出PDF格式，尝试了几次AIX系统安装不上。打算通过jinja2生成HTML报告，然后再使用wkhtmltopdf转成pdf，尝试了几次AIX系统安装不上。生成的HTML报告可以通过其它平台进行转换。对于报告更完善的界面和舒适阅读方式还在研究中。 "},"08-Python/05-Python_爬虫/":{"url":"08-Python/05-Python_爬虫/","title":"Python_爬虫","keywords":"","body":"Python_爬虫 简介 个人无聊写的一些爬虫，对于一些有知识产权的内容建议不要爬取。 内容 Python-视频信息爬取 Python-热点话题爬取 "},"08-Python/05-Python_爬虫/01-Python-视频信息爬取.html":{"url":"08-Python/05-Python_爬虫/01-Python-视频信息爬取.html","title":"Python-视频信息爬取","keywords":"","body":"Python-视频信息爬取 一些常用网站视频信息爬取，内容信息都是基本的，没什么实际意义，主要是学习。 鹅厂视频网站 说明 在学习笔记中根据教程写了一个基础爬虫，学习笔记中内容比较杂，去掉了一些多余注释以及稍微优化了一下，url内容更改成鹅厂视频网站任意一个相关链接应该都可以，我试过更换条目爬取。 代码 代码如下： import re from urllib import request # 定义一个类Reptile class Reptile(): # 定义一个类变量url保存抓取网页的地址 url = 'https://v.qq.com/channel/movie?listpage=1&channel=movie&itype=100012' root_pattern = '([\\s\\S]*?[\\s\\S]*?[\\s\\S]*?[\\s\\S]*?[\\s\\S]*?)' name_pattern = ' class=\"figure_title figure_title_two_row bold\">([\\s\\S]*?)' score_pattern = '([\\s\\S]*?)' views_pattern = '([\\s\\S]*)$' # 定义一个私有方法获取网页内容 def __fetch_content(self): r = request.urlopen(Reptile.url) htmls = r.read() htmls = str(htmls,encoding='utf-8') return htmls # 定义一个实例方法匹配内容 def __analysis(self,htmls): root_html = re.findall(Reptile.root_pattern,htmls) films = [] for html in root_html: name = re.findall(Reptile.name_pattern,html) score = re.findall(Reptile.score_pattern,html) views = re.findall(Reptile.views_pattern,html) film = {'name':name,'score':score,'views':views} films.append(film) return(films) # 定义一个方法提炼优化输出结果 def __refine(self,films): refine = lambda film:{'name':film['name'][0], 'score':film['score'][0].strip(), 'views':film['views'][0]} return map(refine,films) # 指定排序规则 def __sort_rule(self,film): num = re.findall('\\d*',film['views']) number = float(num[0]) if '万' in film['views']: number *= 10000 return number # 进行排序 def __sort(self,films): films = sorted(films,key=self.__sort_rule,reverse=True) return films # 展示出结果并加上序号 def __show(self,films): for rank in range(0,len(films)): print(str(rank + 1) +'. ' +'电影名：'+ '《' + films[rank]['name']+'》'+' 评分:'+films[rank]['score']+'分' +' 观看人数：'+films[rank]['views']) def entrance(self): htmls = self.__fetch_content() films = self.__analysis(htmls) films = list(self.__refine(films)) films = self.__sort(films) self.__show(films) reptile = Reptile() reptile.entrance() 结果 运行结果如下： 1. 电影名：《银河护卫队》 评分:8.9分 观看人数：8771万 2. 电影名：《钢铁飞龙之奥特曼崛起》 评分:6.6分 观看人数：8567万 3. 电影名：《黑猫警长之翡翠之星》 评分:7.4分 观看人数：8315万 4. 电影名：《末日之战》 评分:7.6分 观看人数：6830万 5. 电影名：《死亡飞车》 评分:8.6分 观看人数：5685万 6. 电影名：《星球大战8：最后的绝地武士》 评分:8.4分 观看人数：4990万 7. 电影名：《恐龙侵袭》 评分:6.5分 观看人数：3785万 8. 电影名：《星球大战9：天行者崛起》 评分:7.7分 观看人数：2452万 9. 电影名：《夺命五头鲨》 评分:6.3分 观看人数：1893万 10. 电影名：《惊涛迷局》 评分:7.8分 观看人数：400万 11. 电影名：《美人鱼》 评分:8.3分 观看人数：6亿 12. 电影名：《头号玩家》 评分:9.2分 观看人数：5亿 13. 电影名：《流浪地球》 评分:8.8分 观看人数：5亿 14. 电影名：《变形金刚5：最后的骑士》 评分:7.4分 观看人数：5亿 15. 电影名：《狂暴巨兽》 评分:8.1分 观看人数：4亿 16. 电影名：《复仇者联盟3：无限战争》 评分:8.9分 观看人数：4亿 17. 电影名：《复仇者联盟4：终局之战》 评分:9.2分 观看人数：3亿 18. 电影名：《环太平洋：雷霆再起》 评分:7.7分 观看人数：2亿 19. 电影名：《大黄蜂》 评分:8.4分 观看人数：2亿 20. 电影名：《复仇者联盟》 评分:9分 观看人数：2亿 21. 电影名：《变形金刚4：绝迹重生》 评分:8.2分 观看人数：2亿 22. 电影名：《哥斯拉2：怪兽之王》 评分:7.7分 观看人数：1亿 23. 电影名：《惊天魔盗团》 评分:8.7分 观看人数：1亿 24. 电影名：《钢铁飞龙之再见奥特曼》 评分:6.2分 观看人数：1亿 25. 电影名：《速度与激情：特别行动》 评分:8.1分 观看人数：1亿 26. 电影名：《星际穿越》 评分:9.4分 观看人数：1亿 27. 电影名：《超体》 评分:8.5分 观看人数：1亿 28. 电影名：《终结者：黑暗命运》 评分:8分 观看人数：1亿 29. 电影名：《蝙蝠侠：黑暗骑士》 评分:9.4分 观看人数：1亿 30. 电影名：《哥斯拉》 评分:8.1分 观看人数：1亿 "},"08-Python/05-Python_爬虫/02-Python-热点话题爬取.html":{"url":"08-Python/05-Python_爬虫/02-Python-热点话题爬取.html","title":"Python-热点话题爬取","keywords":"","body":"Python-热点话题爬取 某些网站热点信息爬取，没什么实际意义，直接去网站查看也很直观，主要是学习。 某度搜索风云榜 说明 爬取某度的搜索风云榜网站里面的实时热点,整体来说比较简单，主要问题说明： 关键字相对不好找，有的关键字还经常变，可能是网站反爬虫设计，例如搜索指数全面的关键字就发现了三种，并且很快进行变换，几分钟就变一次,写了几个if去判断，不知道会不会还会变，最后放弃了此关键字，三种如下： 有的内容进行了多次匹配，达到了预期效果，没有多余的字符需要去优化 本身就是排行榜，所以不需要进行排序 爬取的是实时热点页面，把链接换成同一页面的今日热点或者七日热点都行 不知道内容解码的时候用utf-8不行，改成了gbk 代码 完整代码如下： import re from urllib import request class PopularReptile(): url = 'http://top.baidu.com/buzz?b=1&c=513&fr=topbuzz_b42_c513' root_pattern = '([\\s\\S]*?)' top_pattern1 = '(\\d*)' top_pattern2 = '(\\d*)' name_pattern1 = '([\\s\\S]*?)' name_pattern2 = '>([\\s\\S]*?)$' icon_pattern1 = '([\\s\\S]*?)' icon_pattern2 = '>([\\s\\S]*?)$' def __fetch_content(self): web_content = request.urlopen(PopularReptile.url) web_content = web_content.read() web_content = str(web_content,encoding='gbk') return web_content def __analysis(self,web_content): root_popular = re.findall(PopularReptile.root_pattern,web_content) popular_list = [] for populars in root_popular: top = re.findall(PopularReptile.top_pattern1,populars) if len(top) == 0: top = re.findall(PopularReptile.top_pattern2,populars) name1 = re.findall(PopularReptile.name_pattern1,populars) name2 = re.findall(PopularReptile.name_pattern2,name1[0]) icon1 = re.findall(PopularReptile.icon_pattern1,populars) icon2 = re.findall(PopularReptile.icon_pattern2,icon1[0]) popular = {'top':top,'name':name2,'icon':icon2} popular_list.append(popular) return popular_list def __show(self,popular_list): for popular_item in popular_list: print('搜索排行'+ popular_item['top'][0]+'：'\\ + popular_item['name'][0]+';'\\ + '搜索指数:'+ popular_item['icon'][0]+'。') def entrance(self): web_content = self.__fetch_content() popular_list = self.__analysis(web_content) self.__show(popular_list) popular_reptile = PopularReptile() popular_reptile.entrance() 正则表达式写好爬取后，发现还比较整齐的，没有多余的字符，不需要进行优化，并且本身就是有排行，所以也不需要进行排序，示例如下： ['1'] ['官方通报西安明秦王府城墙坍塌'] ['4802320'] ['2'] ['河北女孩遭绑架杀害嫌疑人被抓'] ['4634239'] ['3'] ['黎巴嫩总统称3周前就知道有危险'] ['4472040'] 放到字典后： [{'top': ['1'], 'name': ['官方通报西安明秦王府城墙坍塌'], 'icon': ['4915359']}, {'top': ['2'], 'name': ['河北女孩遭绑架杀害嫌疑人被 抓'], 'icon': ['4743321']}, {'top': ['3'], 'name': ['黎巴嫩总统称3周前就知道有危险'], 'icon': ['4577305']}, {'top': ['4'], 'name': ['陈思诚为佟丽娅庆生'], 'icon': ['4417099']}, {'top': ['5'], 'name': ['宋小女称不会要张玉环一分赔偿金'], 'icon': ['4262501']}, {'top': ['6'], 'name': ['香港特区政府回应美国制裁'], 'icon': ['4113313']}, {'top': ['7'], 'name': ['王珞丹凌晨发文又秒删'], 'icon': ['3969347']}, {'top': ['8'], 'name': ['印度客机滑出跑道断成两截'], 'icon': ['3830420']}, {'top': ['9'], 'name': ['北京奥运12年'], 'icon': ['3696355']}, {'top': ['10'], 'name': ['广西女护士杀害男医生被提起公诉'], 'icon': ['3566983']}, {'top': ['11'], 'name': ['上海首例养 犬人遗弃犬只案'], 'icon': ['3442139']}, {'top': ['12'], 'name': ['蔡徐坤陈立农小船翻了'], 'icon': ['3321664']}, {'top': ['13'], 'name': ['骆惠宁回应美国财政部所谓制裁'], 'icon': ['3205405']}, {'top': ['14'], 'name': ['大妈闹市放羊啃食绿化带'], 'icon': ['3093216']}, {'top': ['15'], 'name': ['伊能静发小作文为张雨绮庆生'], 'icon': ['2984954']}, {'top': ['16'], 'name': ['比熊犬给黑豹幼崽当奶妈'], 'icon': ['2880480']}, {'top': ['17'], 'name': ['邓超送白玉兰花安慰孙俪'], 'icon': ['2779663']}, {'top': ['18'], 'name': ['郑恺发文回 忆跑男100期'], 'icon': ['2682375']}, {'top': ['19'], 'name': ['喻言成功追星明道'], 'icon': ['2497895']}, {'top': ['20'], 'name': [' 暴风集团冯鑫又被限制高消费'], 'icon': ['2410468']}, {'top': ['21'], 'name': ['腾讯回应特朗普禁令'], 'icon': ['2166124']}, {'top': ['22'], 'name': ['中国人均国民总收入首破1万美元'], 'icon': ['2090310']}, {'top': ['23'], 'name': ['山下智久与17岁高中生酒店约会'], 'icon': ['2017149']}, {'top': ['24'], 'name': ['英国外交部首席捕鼠官将退休'], 'icon': ['1946549']}, {'top': ['25'], 'name': ['加拿大将 对美国铝产品征收反关税'], 'icon': ['1878420']}, {'top': ['26'], 'name': ['美国新冠肺炎确诊超491万例'], 'icon': ['1812675']}, {'top': ['27'], 'name': ['新疆新增本土病例25例'], 'icon': ['1749231']}] 最后输出结果如下： 搜索排行1：官方通报西安明秦王府城墙坍塌;搜索指数:4799605。 搜索排行2：黎巴嫩总统称3周前就知道有危险;搜索指数:4631619。 搜索排行3：陈思诚为佟丽娅庆生;搜索指数:4313079。 搜索排行4：宋小女称不会要张玉环一分赔偿金;搜索指数:4162122。 搜索排行5：香港特区政府回应美国制裁;搜索指数:4016447。 搜索排行6：王珞丹凌晨发文又秒删;搜索指数:3875872。 搜索排行7：印度客机滑出跑道断成两截;搜索指数:3740216。 搜索排行8：北京奥运12年;搜索指数:3609309。 搜索排行9：广西女护士杀害男医生被提起公诉;搜索指数:3482983。 搜索排行10：上海首例养犬人遗弃犬只案;搜索指数:3361078。 搜索排行11：蔡徐坤陈立农小船翻了;搜索指数:3243441。 搜索排行12：骆惠宁回应美国财政部所谓制裁;搜索指数:3129920。 搜索排行13：大妈闹市放羊啃食绿化带;搜索指数:3020373。 搜索排行14：伊能静发小作文为张雨绮庆生;搜索指数:2914660。 搜索排行15：河北女孩遭绑架杀害嫌疑人被抓;搜索指数:2812647。 搜索排行16：邓超送白玉兰花安慰孙俪;搜索指数:2714204。 搜索排行17：郑恺发文回忆跑男100期;搜索指数:2619207。 搜索排行18：CBA选秀球员名单;搜索指数:2527535。 搜索排行19：喻言成功追星明道;搜索指数:2439071。 搜索排行20：暴风集团冯鑫又被限制高消费;搜索指数:2353703。 搜索排行21：中国人均国民总收入首破1万美元;搜索指数:2271324。 搜索排行22：北京12批次食品不合格;搜索指数:2191827。 搜索排行23：腾讯回应特朗普禁令;搜索指数:2041084。 搜索排行24：山下智久与17岁高中生酒店约会;搜索指数:1969647。 搜索排行25：英国外交部首席捕鼠官将退休;搜索指数:1900709。 搜索排行26：加拿大将对美国铝产品征收反关税;搜索指数:1834184。 搜索排行27：美国新冠肺炎确诊超491万例;搜索指数:1769988。 搜索排行28：新疆新增本土病例25例;搜索指数:1708038。 把链接换成同一页面的今日热点或者七日热点都行，七日热点输出示例如下： 搜索排行1：特朗普宣布45天后禁止与微信交易;搜索指数:718781。 搜索排行2：南京失联女生被其男友杀害埋尸;搜索指数:598367。 搜索排行3：影院老板砸花木兰宣传板;搜索指数:581728。 搜索排行4：张一山宋妍霏分手;搜索指数:552616。 搜索排行5：全球面临50年来最严重粮食危机;搜索指数:510307。 搜索排行6：杭州杀妻分尸案嫌犯被批捕;搜索指数:505780。 搜索排行7：黎巴嫩奶奶在破损房间中弹钢琴;搜索指数:479461。 搜索排行8：曾志伟妻子去世;搜索指数:478499。 搜索排行9：黎巴嫩首都爆炸已致70余人死亡;搜索指数:470845。 搜索排行10：美国取消全球旅行警告;搜索指数:445052。 搜索排行11：钟南山成为共和国勋章建议人选;搜索指数:441717。 搜索排行12：多地确定新学期开学日期;搜索指数:432286。 搜索排行13：白雪否认与张一山复合;搜索指数:429816。 搜索排行14：峨眉山警方通报林间发现两具尸体;搜索指数:421966。 搜索排行15：华为天才少年最高年薪201万元;搜索指数:385178。 搜索排行16：华为年薪201万天才少年回应;搜索指数:383934。 搜索排行17：张嘉译改名张嘉益;搜索指数:360950。 搜索排行18：南京遇害女生男友曾一起去报案;搜索指数:359921。 搜索排行19：张玉环称曾遭6天6夜刑讯逼供;搜索指数:348074。 搜索排行20：宋妍霏分手当日片场状态;搜索指数:341688。 搜索排行21：张天爱喊话跟拍者;搜索指数:338625。 搜索排行22：清华大学生起诉ofo反赔400元;搜索指数:315678。 搜索排行23：浙大犯强奸罪学生被开除学籍;搜索指数:311691。 搜索排行24：张玉环与前妻再见面紧握双手;搜索指数:310370。 搜索排行25：法国女婿回应吐槽中国丈母娘;搜索指数:306198。 搜索排行26：妈妈倒车时不慎撞死自己孩子;搜索指数:299914。 搜索排行27：云南吃野生菌中毒死亡人数超新冠;搜索指数:299442。 搜索排行28：张萌就吐槽林有有角色一事道歉;搜索指数:291734。 搜索排行29：酒吧打出优衣库女主角驻唱广告;搜索指数:287165。 搜索排行30：世卫警告新冠可能永远没有特效药;搜索指数:284278。 搜索排行31：襄阳失踪女童被翻墙逃走邻居杀害;搜索指数:279134。 搜索排行32：官方通报干部疑出轨在妻死后失联;搜索指数:277286。 搜索排行33：宋小女想把儿孙留在张玉环身边;搜索指数:276077。 搜索排行34：男子拒戴口罩捶公交司机16拳获刑;搜索指数:274010。 搜索排行35：四大行回应薪酬问题;搜索指数:273454。 搜索排行36：韩国25岁女运动员自杀;搜索指数:272617。 搜索排行37：外交部回应澳总理称欢迎中国崛起;搜索指数:265715。 搜索排行38：为救弟弟落水失踪微信余额被提现;搜索指数:259926。 搜索排行39：罗志祥 谢谢大家;搜索指数:257149。 搜索排行40：杭州新增1例无症状感染者;搜索指数:256641。 搜索排行41：妻子雨中吃面丈夫身旁打伞;搜索指数:256263。 搜索排行42：女生被杀案嫌犯父亲是司法局干部;搜索指数:252683。 搜索排行43：月嫂拍打抛扔出生6天婴儿;搜索指数:251161。 搜索排行44：美国驱逐中国记者 胡锡进评论;搜索指数:249031。 搜索排行45：北京新增1例本土确诊病例;搜索指数:248463。 搜索排行46：新手消防员分管供水车开心到飞起;搜索指数:247034。 搜索排行47：外交部回应美卫生部长拟率团访台;搜索指数:244320。 搜索排行48：黎巴嫩爆炸造成30万人无家可归;搜索指数:242211。 搜索排行49：三十而已样片泄露 出品方报警;搜索指数:240808。 搜索排行50：宋小女称再婚前曾提三个条件;搜索指数:238937。 "},"08-Python/06-Python_Excel数据分析/":{"url":"08-Python/06-Python_Excel数据分析/","title":"Python_Excel数据分析","keywords":"","body":"Python_Python_Excel数据分析 简介 初学者，学习过程中加以实践。 推荐学习网站：http://www.python-excel.org/ openpyxl学习网站：https://openpyxl.readthedocs.io/en/stable/ Pythonexcel网站：https://www.pythonexcel.com/ 内容 Openpyxl-各系统环境部署 Openpyxl-Excel基础操作 "},"08-Python/06-Python_Excel数据分析/01-Openpyxl-各系统环境部署.html":{"url":"08-Python/06-Python_Excel数据分析/01-Openpyxl-各系统环境部署.html","title":"Openpyxl-各系统环境部署","keywords":"","body":"Openpyxl-各系统环境部署 在不同的系统环境中安装Openpyxl过程。 Openpyxl相关包下载 老版本openpyxl下载地址：http://pypi.doubanio.com/simple/openpyxl最新版openpyxl下载地址：https://pypi.org/project/openpyxl/#filesjdcal下载地址：https://pypi.org/project/jdcal/#fileset_xmlfile下载地址：https://pypi.org/project/et_xmlfile/#files windows下安装 系统版本：Windows 10 企业版，Python版本：Python 3.8.3首先升级pip（直接安装提示pip版本低），示例如下： C:\\Users\\Bond>python -m pip install --upgrade pip Collecting pip Downloading https://files.pythonhosted.org/packages/4e/5f/528232275f6509b1fff703c9280e58951a81abe24640905de621c9f81839/pip-20.2.3-py2.py3-none-any.whl (1.5MB) |████████████████████████████████| 1.5MB 8.2kB/s Installing collected packages: pip Found existing installation: pip 19.2.3 Uninstalling pip-19.2.3: Successfully uninstalled pip-19.2.3 Successfully installed pip-20.2.3 然后安装openpyxl： C:\\Users\\Bond>pip install openpyxl Collecting openpyxl Using cached openpyxl-3.0.5-py2.py3-none-any.whl (242 kB) Collecting et-xmlfile Using cached et_xmlfile-1.0.1.tar.gz (8.4 kB) Collecting jdcal Downloading jdcal-1.4.1-py2.py3-none-any.whl (9.5 kB) Using legacy 'setup.py install' for et-xmlfile, since package 'wheel' is not installed. Installing collected packages: et-xmlfile, jdcal, openpyxl Running setup.py install for et-xmlfile ... done Successfully installed et-xmlfile-1.0.1 jdcal-1.4.1 openpyxl-3.0.5 成功后在IDLE中测试： Python 3.8.3 (tags/v3.8.3:6f8c832, May 13 2020, 22:37:02) [MSC v.1924 64 bit (AMD64)] on win32 Type \"help\", \"copyright\", \"credits\" or \"license()\" for more information. >>> from openpyxl import load_workbook >>> from openpyxl import workbook >>> AIX下安装 系统版本：7100-04-03-1642，Python版本：Python 3.7.6将下面三个安装包拷贝到系统中： jdcal-1.4.1.tar.gz et_xmlfile-1.0.1.tar.gz openpyxl-3.0.5.tar.gz 安装jdcal步骤： # gunzip jdcal-1.4.1.tar.gz # tar -xvf jdcal-1.4.1.tar # cd jdcal-1.4.1 # python3 setup.py install 安装et_xmlfile步骤： # gunzip et_xmlfile-1.0.1.tar.gz # tar -xvf et_xmlfile-1.0.1.tar # cd et_xmlfile-1.0.1 # python3 setup.py install 安装openpyxl步骤： # gunzip openpyxl-3.0.5.tar.gz # tar -xvf openpyxl-3.0.5.tar # cd openpyxl-3.0.5 # python3 setup.py install 安装成功后测试下： # python3 Python 3.7.6 (default, Feb 28 2020, 04:49:11) [GCC 8.3.0] on aix6 Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> from openpyxl import workbook >>> Linux下安装 安装步骤 操作系统版本：RHEL8.0，Python版本：Python 3.6.8安装步骤基本和AIX一致（解压简单点）： [root@redhat8 tmp]# tar -zxvf jdcal-1.4.1.tar.gz [root@redhat8 tmp]# cd jdcal-1.4.1 [root@redhat8 jdcal-1.4.1]# chmod 755 setup.py [root@redhat8 jdcal-1.4.1]# python3 setup.py install [root@redhat8 tmp]# tar -zxvf et_xmlfile-1.0.1.tar.gz [root@redhat8 tmp]# cd et_xmlfile-1.0.1 [root@redhat8 et_xmlfile-1.0.1]# python3 setup.py install [root@redhat8 tmp]# tar -zvxf openpyxl-3.0.5.tar.gz [root@redhat8 tmp]# cd openpyxl-3.0.5 [root@redhat8 openpyxl-3.0.5]# python3 setup.py install 安装成功后测试下： [root@redhat8 openpyxl-3.0.5]# python3 Python 3.6.8 (default, Jan 11 2019, 02:17:16) [GCC 8.2.1 20180905 (Red Hat 8.2.1-3)] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> from openpyxl import workbook >>> 安装报错示例 在刚开始安装过程中有报错,无法安装，示例如下： [root@redhat8 jdcal-1.4.1]# python3 setup.py install running install error: can't create or remove files in install directory The following error occurred while trying to add or remove files in the installation directory: [Errno 2] No such file or directory: '/usr/local/lib/python3.6/site-packages/test-easy-install-4302.write-test' The installation directory you specified (via --install-dir, --prefix, or the distutils default setting) was: /usr/local/lib/python3.6/site-packages/ This directory does not currently exist. Please create it and try again, or choose a different installation directory (using the -d or --install-dir option). 解决方法 首先在安装文件所在目录下运行如下命令： [root@redhat8 jdcal-1.4.1]# python3 -m site sys.path = [ '/tmp/jdcal-1.4.1', '/usr/lib64/python36.zip', '/usr/lib64/python3.6', '/usr/lib64/python3.6/lib-dynload', '/usr/lib64/python3.6/site-packages', '/usr/lib/python3.6/site-packages', ] USER_BASE: '/root/.local' (exists) USER_SITE: '/root/.local/lib/python3.6/site-packages' (doesn't exist) ENABLE_USER_SITE: True   看报错创建不了文件，可能是权限问题，但是我使用的是root用户，还是检查了/usr下lib和lib64目录的权限，没有写权限，还是修改了以下权限： [root@redhat8 usr]# chmod -R 755 lib [root@redhat8 usr]# chmod -R 755 lib64   尝试安装还是报错，参照如下文档将python3 -m site输出中USER_SITE提示的目录看来下确实not exist，然后创建了一个目录： [root@redhat8 site-packages]# pwd /root/.local/lib/python3.6/site-packages 参照文档:Error “can't create or remove files in install directory” when installing by source code in Python   报错中还或说目录不存在，并且提示用户可以用命令行参数去指定目录，看了下目录确实不存在，根据提示新建了一个目录： [root@redhat8 site-packages]# pwd /usr/local/lib/python3.6/site-packages 再次运行在安装文件所在目录下python3 -m site命令： [root@redhat8 python3.6]# python3 -m site sys.path = [ '/root/.local/lib/python3.6', '/usr/lib64/python36.zip', '/usr/lib64/python3.6', '/usr/lib64/python3.6/lib-dynload', '/root/.local/lib/python3.6/site-packages', '/usr/lib64/python3.6/site-packages', '/usr/lib/python3.6/site-packages', ] USER_BASE: '/root/.local' (exists) USER_SITE: '/root/.local/lib/python3.6/site-packages' (exists) ENABLE_USER_SITE: True 然后安装可以正常进行了。 "},"08-Python/06-Python_Excel数据分析/02-Openpyxl-Excel基础操作.html":{"url":"08-Python/06-Python_Excel数据分析/02-Openpyxl-Excel基础操作.html","title":"Openpyxl-Excel基础操作","keywords":"","body":"Openpyxl-Excel基础操作 使用Openpyxl对Excel进行基础操作的学习笔记。 创建工作表   不需要在文件系统中创建文件就可以使用openpyxl，导入Workbook类并且实例化，然后通过Workbook.active来创建worksheet，示例如下： from openpyxl import Workbook wb = Workbook() ws =wb.active 可以使用Workbook.create_sheet()方法创建新的worksheet: # 插入到末尾（默认） ws1 = wb.create_sheet(\"Mysheet\") # 在第一个位置插入 ws2 = wb.create_sheet(\"Mysheet\",0) # 在倒数第二个位置插入 ws3 = wb.create_sheet(\"Mysheet\",-1) 默认情况下Sheets会自动命名，按顺序编号（Sheet，Sheet1，Sheet2等），可以随时通过Worksheet.title属性更改名称,以及： ws.title = \"New Test\" 默认情况下包含该标题的选项卡的背景颜色为白色。可以更改此属性RRGGBB，通过Worksheet.sheet_properties.tabColor来更改： ws.sheet_properties.tabColor = \"1072BA\" 给worksheet命名后，就可以将其作为workbook的key： w3 = wb[\"New test\"] 使用Workbook.sheetname属性查看workbook中所有worksheet的名称,并且对worksheet进行遍历： print(wb.sheetnames) for sheet in wb: print(sheet.title) 可以使用Workbook.copy_worksheet()方法在单个workbook中创建worksheet的副本： source = wb.active target = wb.copy_worksheet(source) print(target) 以上所有代码整合到一起运行后结果示例如下： PS C:\\Users\\Desktop\\big1000\\vscode\\codefile\\openpyxl> python 1.py ['Mysheet1', 'New Test', 'Mysheet2', 'Mysheet'] Mysheet1 New Test Mysheet2 Mysheet 说明： 创建副本仅复制单元格（包括值，样式，超链接和注释）和某些工作表属性（包括尺寸，格式和属性），不复制所有其他工作簿/工作表属性，例如图像，图表等 也不能在工作簿之间复制工作表；如果工作簿是只读的或以只读模式打开的，则不能复制工作表 数据操作 访问一个cell 访问一个cell基本操作： # 单元格可以直接作为worksheet的key进行访问 a = ws['A4'] # 如果单元格不存在则创建一个单元格，可以直接分配值 ws['A4'] = 10 # 使用Worksheet.cell()方法指定行和列来访问单元格 b = ws.cell(row=4,clounm=2,value=100)   注意：在内存中创建工作表时，它不包含任何单元格，它们只是在首次访问时创建的。即使不为它们分配值，在内存中全部创建它们时候可以滚动浏览而不是直接访问它们，例如用一个for循环在内存中创建100x100的空单元格： for i in range(1,101): for j in range(1,101): ws.cell(row=i,column=j) 访问多个cell 使用切片及使用行和列范围访问单元格范围： cell_range = ws['B1':'D5'] colE = ws['E'] col_range = ws['A:E'] row9 = ws[9] row_range = ws[3:8] 也可以使用Worksheet.iter_rows()方法，示例： for row in ws.iter_rows(min_row=1,max_col=2,max_row=2): for cell in row: print(cell) 运行示例如下： PS C:\\Users\\Desktop\\big1000\\vscode\\codefile\\openpyxl> python 1.py 同样Worksheet.iter_cols()方法将返回列： for col in ws.iter_cols(min_row=1,max_col=3,max_row=2): for cell in col: print(cell) 运行示例如下： PS C:\\Users\\Desktop\\big1000\\vscode\\codefile\\openpyxl> python 1.py 注意：由于性能原因，方法Worksheet.iter_cols()在只读模式下不可用。 Worksheet.rows可以遍历文件的所有行或列： ws = wb.active ws['C7'] = 'Thanos' print(tuple(ws.rows)) 运行示例如下： ((, , ), (, , ), (, , ), (, , ), (, , ), (, , ), (, , )) 或Worksheet.columns属性： ws = wb.active ws['C4'] = 'Thanos' print(tuple(ws.columns)) 运行示例如下： ((, , , ), (, , , ), (, , , )) 注意：由于性能原因，方法Worksheet.columns在只读模式下不可用。 读取值   如果需要读取worksheet中的值，则可以使用Worksheet.values,会遍历worksheet中的所有行，但仅返回单元格值,示例如下： for row in ws.values: for values in row: print(value) 运行示例如下： None None None None None None None None None None None Thanos 可以在Worksheet.iter_rows()和Worksheet.iter_cols()中采用values_only参数，只返回单元格的值： for row in ws.iter_rows(min_row=1,max_col=3,max_row=4,values_only=True): print(row) 运行示例如下： (None, None, None) (None, None, None) (None, None, None) (None, None, 'Thanos') 存储数据 worksheet中有了cell，就可以给其分配值： a = ws['A4'] a.value = 'Miracles happen every day !' print(a.value) b = ws.cell(row=4,column=2) b.value = '3.1415926' print(b.value) 运行示例如下： PS C:\\Users\\Desktop\\big1000\\vscode\\codefile\\openpyxl> python 1.py Miracles happen every day ! 3.1415926 保存到文件 保存workbook的最简单，最安全的方法是使用对象Workbook中的 Workbook.save()方法： wb = Workbook() wb.save('test.xlsx') 说明： 此操作将覆盖现有文件，并且不会有提示 文件扩展名不是强制为xlsx或xlsm，不写也可以，但是使用过程中可能会比较麻烦 由于OOXML文件基本上是ZIP文件，因此可以使用相关ZIP玩家管理器将其打开使用 另存为流 如果要将文件保存到流中，例如在使用Web应用程序时，可以使用NamedTemporaryFile(),示例如下： from tempfile import NamedTemporaryFile from openpyxl import Workbook wb = Workbook() with NamedTemporaryFile() as tmp: wb.save(tmp.name) tmp.seek(0) stream = tmp.read() 可以指定属性template = True将workbook另存为模板： wb = load_workbook('document.xlsx') wb.template = True wb.save('document_template.xltx') 或将此属性设置为False（默认），以另存为文档： wb = load_workbook('document_template.xltx') wb.template = False wb.save('document.xlsx', as_template=False) 注意：注意数据属性和文档扩展名以将文档保存在文档模板中，否则表引擎可能无法打开文档。 从文件加载 可以使用openpyxl.load_workbook()打开现有的workbook： from openpyxl import load_workbook wb2 = load_workbook('test.xlsx') print wb2.sheetnames 运行示例如下： PS C:\\Users\\Desktop\\big1000\\vscode\\codefile\\openpyxl> python 2.py ['Sheet', 'test1', 'Newsheet'] "},"08-Python/07-Python_Flask/":{"url":"08-Python/07-Python_Flask/","title":"Python_Flask","keywords":"","body":"Python_Flask 简介   Flask是一个轻量级的可定制框架，使用Python语言编写，较其他同类型框架更为灵活、轻便、安全且容易上手。初学者，学习过程中加以实践。 Flask主页：https://palletsprojects.com/p/flask/ Flask文档：https://flask.palletsprojects.com/en/1.1.x/ Flask GitHub:https://github.com/pallets/flask Flask 中文文档：https://dormousehole.readthedocs.io/en/latest/ Python在线教程大全：https://docs.pythontab.com/ SQLite：https://sqlite.org/lang.html W3school：https://www.w3school.com.cn/index.html 十六进制颜色代码：https://www.color-hex.com/ html颜色代码：https://encycolorpedia.cn/html CSS文档：https://developer.mozilla.org/en-US/docs/Web/CSS jinjia2官方文档：https://jinja.palletsprojects.com/en/2.11.x/templates/ jinjia2中文手册：http://docs.jinkan.org/docs/jinja2/index.html jinjia2中文手册：http://www.ainoob.cn/docs/jinja2/intro.html 烧饼博客：https://sb.sb/blog/css-cdn/ js开源库：https://cdnjs.loli.net/ajax/libs/ vue.js教程：https://www.runoob.com/vue2/vue-tutorial.html vue后台教程：https://gitee.com/TZtudouni/vue-admin/blob/master/README.zh-CN.md vuejs官方教程：https://cn.vuejs.org/v2/guide/installation.html cdnjs主页：https://cdnjs.com/ cdnjs GitHub：https://github.com/cdnjs/cdnjs Bootstrap中文网：https://www.bootcss.com/ Bootstrap图标库：https://icons.bootcss.com/ 参考文档 文档1：https://blog.csdn.net/mist99/article/details/80771289 内容 Flask-基础环境搭建 Flask-布局及视图笔记 Flask-模板及网页布局笔记 Flask-操作请求数据 Flask-常见问题 HTML-基础学习笔记 SQLite-基础知识笔记 SQLite-常见问题 "},"08-Python/07-Python_Flask/01-Flask-基础环境搭建.html":{"url":"08-Python/07-Python_Flask/01-Flask-基础环境搭建.html","title":"Flask-基础环境搭建","keywords":"","body":"Flask-基础 学习Flask基础笔记，边学习边实践。 安装 当安装 Flask 时，以下配套软件会被自动安装。 Werkzeug:用于实现WSGI,应用和服务之间的标准 Python 接口 Jinja:用于渲染页面的模板语言 MarkupSafe与Jinja 共用，在渲染页面时用于避免不可信的输入，防止注入攻击 ItsDangerous:保证数据完整性的安全标志数据，用于保护Flask的session cookie Click:是一个命令行应用的框架。用于提供flask命令，并允许添加自定义管理命令 虚拟环境 本人采用Windows环境 Windows下安装 Python2需要首先安装virtualenv（Windows下需要先安装pip）： $ pip install virtualenv Collecting virtualenv Downloading virtualenv-20.0.31-py2.py3-none-any.whl (4.9 MB) |████████████████████████████████| 4.9 MB 29 kB/s Collecting six=1.9.0 Downloading six-1.15.0-py2.py3-none-any.whl (10 kB) Collecting appdirs=1.4.3 Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB) Collecting filelock=3.0.0 Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB) Collecting distlib=0.3.1 Downloading distlib-0.3.1-py2.py3-none-any.whl (335 kB) |████████████████████████████████| 335 kB 38 kB/s Installing collected packages: six, appdirs, filelock, distlib, virtualenv Successfully installed appdirs-1.4.4 distlib-0.3.1 filelock-3.0.12 six-1.15.0 virtualenv-20.0.31 Python3就从这里开始创建一个虚拟环境： $ mkdir osmproject $ cd osmproject $ pwd /d/osmproject $ python -m venv venv 打开CMD激活环境： D:\\osmproject>venv\\Scripts\\activate (venv) D:\\osmproject> 在git bash中： $ ls venv/ venvScriptsactivate 安装Flask: $ pip install Flask Collecting Flask Using cached Flask-1.1.2-py2.py3-none-any.whl (94 kB) Collecting Werkzeug>=0.15 Using cached Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB) Collecting itsdangerous>=0.24 Using cached itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB) Collecting click>=5.1 Using cached click-7.1.2-py2.py3-none-any.whl (82 kB) Collecting Jinja2>=2.10.1 Using cached Jinja2-2.11.2-py2.py3-none-any.whl (125 kB) Collecting MarkupSafe>=0.23 Using cached MarkupSafe-1.1.1-cp38-cp38-win_amd64.whl (16 kB) Installing collected packages: Werkzeug, itsdangerous, click, MarkupSafe, Jinja2, Flask Successfully installed Flask-1.1.2 Jinja2-2.11.2 MarkupSafe-1.1.1 Werkzeug-1.0.1 click-7.1.2 itsdangerous-1.1.0 克隆仓库到本地： $ git clone git@github.com:bond-huang/OS-Mangement.git Cloning into 'OS-Mangement'... Warning: Permanently added the RSA host key for IP address '52.74.223.119' to the list of known hosts. remote: Enumerating objects: 4, done. remote: Counting objects: 100% (4/4), done. remote: Compressing objects: 100% (3/3), done. remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0 Receiving objects: 100% (4/4), 4.52 KiB | 578.00 KiB/s, done. 创建test.py写入如下python代码： from flask import Flask app = Flask(__name__) @app.route('/') def Forrest_Gump(): return 'Life was like a box of chocolates, you never know what you\\'re gonna get.' 可以使用flask run命令或者python -m flask run运行这个应用。在运行应用之前，需要在终端里导出FLASK_APP环境变量: $ export FLASK_APP=test.py $ python -m flask run * Serving Flask app \"test.py\" * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) 说明： 打开浏览器输入地址即可看到相应的网页内容 运行时候最好在项目主目录运行，要不然会报错 github托管 clone仓库 可以根据之前学习的创建一个项目文件夹，我个人是克隆仓库（空的）到本地： $ git clone git@github.com:bond-huang/OS-Management.git Cloning into 'OS-Management'... Warning: Permanently added the RSA host key for IP address '52.74.223.119' to the list of known hosts. remote: Enumerating objects: 4, done. remote: Counting objects: 100% (4/4), done. remote: Compressing objects: 100% (3/3), done. remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 0 Receiving objects: 100% (4/4), 4.52 KiB | 578.00 KiB/s, done. 使用.gitignore来设置应当忽略的文件:GitBook识别有问题，用图片替代： 同步到github 首先查看状态(列出当前目录所有还未被git管理的文件或被git管理但修改后未提交的文件或目录)： $ git status On branch master Your branch is up to date with 'origin/master'. Untracked files: (use \"git add ...\" to include in what will be committed) .gitignore osmanagement/ venvScriptsactivate nothing added to commit but untracked files present (use \"git add\" to track) 添加一下即可，再次查看会提示有新文件： $ git add .gitignore warning: LF will be replaced by CRLF in .gitignore. The file will have its original line endings in your working directory $ git add osmanagement/ $ git status On branch master Your branch is up to date with 'origin/master'. Changes to be committed: (use \"git restore --staged ...\" to unstage) new file: .gitignore new file: osmanagement/__init__.py new file: osmanagement/auth.py new file: osmanagement/db.py new file: osmanagement/schema.sql Untracked files: (use \"git add ...\" to include in what will be committed) venvScriptsactivate 然后提交下,-m后面要加参数： $ git commit -m \"First commit\" [master 0f5fb28] First commit Committer: Your name and email address were configured automatically based on your username and hostname. Please check that they are accurate. You can suppress this message by setting them explicitly. Run the following command and follow the instructions in your editor to edit your configuration file: git config --global --edit After doing this, you may fix the identity used for this commit with: git commit --amend --reset-author 5 files changed, 172 insertions(+) create mode 100644 .gitignore create mode 100644 osmanagement/__init__.py create mode 100644 osmanagement/auth.py create mode 100644 osmanagement/db.py create mode 100644 osmanagement/schema.sql 再次查看状态： $ git status On branch master Your branch is ahead of 'origin/master' by 1 commit. (use \"git push\" to publish your local commits) Untracked files: (use \"git add ...\" to include in what will be committed) venvScriptsactivate nothing added to commit but untracked files present (use \"git add\" to track) 同步到GitHub： $ git remote add origin git@github.com:bond-huang/OS-Management.git fatal: remote origin already exists. $ git config --local --list core.repositoryformatversion=0 core.filemode=false core.bare=false core.logallrefupdates=true core.symlinks=false core.ignorecase=true remote.origin.url=git@github.com:bond-huang/OS-Management.git remote.origin.fetch=+refs/heads/*:refs/remotes/origin/* branch.master.remote=origin branch.master.merge=refs/heads/master $ git branch -M master $ git push -u origin master Enumerating objects: 9, done. Counting objects: 100% (9/9), done. Delta compression using up to 4 threads Compressing objects: 100% (8/8), done. Writing objects: 100% (8/8), 2.46 KiB | 838.00 KiB/s, done. Total 8 (delta 0), reused 0 (delta 0), pack-reused 0 To github.com:bond-huang/OS-Management.git f639045..98357c6 master -> master Branch 'master' set up to track remote branch 'master' from 'origin'. 说明： 后续提交命令不需要-u参数，即git push origin master 如果就一个master分支，输入git push命令即可 同步问题 后续在更新本地代码后，想同步到远程，发现如下报错： $ git push origin master To github.com:bond-huang/OS-Management.git ! [rejected] master -> master (fetch first) error: failed to push some refs to 'github.com:bond-huang/OS-Management.git' hint: Updates were rejected because the remote contains work that you do hint: not have locally. This is usually caused by another repository pushing hint: to the same ref. You may want to first integrate the remote changes hint: (e.g., 'git pull ...') before pushing again. hint: See the 'Note about fast-forwards' in 'git push --help' for details. 一般是由于本地和远程不一致造成的，这种不一致表示是远程有的代码本地没有，解决方法： 根据提示在使用push之前用git pull同步到本地，可能会丢失本地的更新 使用-f参数进行强制更新：git push -f origin master，使用要慎重，可能会丢失远程的更新 "},"08-Python/07-Python_Flask/02-Flask-布局及视图笔记.html":{"url":"08-Python/07-Python_Flask/02-Flask-布局及视图笔记.html","title":"Flask-布局及视图笔记","keywords":"","body":"Flask-布局及视图笔记 学习Flask项目搭建笔记，边学习边实践。 项目布局 项目包含如下内容（根据flask官方教程来的，内容基本一致）: osmanagement/：包含应用代码和文件的Python包 tests/ :包含测试模块的文件夹 venv/ :Python虚拟环境，用于安装Flask和其他依赖的包 告诉 Python 如何安装项目的安装文件 版本控制配置，如 git，不管项目大小，应当养成使用版本控制的习惯 项目需要的其他文件 项目计划布局如下： ├── osmanagement/ │ ├── __init__.py │ ├── db.py │ ├── schema.sql │ ├── auth.py │ ├── osm.py │ ├── templates/ │ │ ├── base.html │ │ ├── auth/ │ │ │ ├── login.html │ │ │ └── register.html │ │ └── osm/ │ │ ├── create.html │ │ ├── index.html │ │ └── update.html │ └── static/ │ └── style.css ├── tests/ │ ├── conftest.py │ ├── data.sql │ ├── test_factory.py │ ├── test_db.py │ ├── test_auth.py │ └── test_osm.py ├── venv/ ├── setup.py └── MANIFEST.in 应用设置   可以在一个函数内部创建Flask实例来代替创建全局实例。这个函数被称为应用工厂。所有应用相关的配置、注册和其他设置都会在函数内部完成，然后返回这个应用。 应用工厂 创建osmanagement文件夹并添加__init__.py文件： $ mkdir osmanagement $ cd osmanagement $ touch __init__.py $ ls __init__.py 在__init__.py文件写入内容如下： import os from flask import Flask def create_app(test_config=None): # create and configure the app app = Flask(__name__,instance_relative_config=True) app.config.from_mapping( SECRET_KEY='dev', DATABASE=os.path.join(app.instance_path,'osmanagment.sqlite'), ) if test_config is None: # load the instance config, if it exists, when not testing app.config.from_pyfile('config.py',silent=True) else: # load the test config if passed in app.config.from_mapping(test_config) # ensure the instance folder exists try: os.makedirs(app.instance_path) except OSError: pass # a simple page that says gump @app.route('/gump') def gump(): return 'Life was like a box of chocolates, \\ you never know what you\\'re gonna get.' return app 运行应用 运行应用，注意在项目目录下，不是在osmanagement包里面: $ export FLASK_APP=osmanagement $ export FLASK_ENV=development $ flask run * Serving Flask app \"osmanagement\" (lazy loading) * Environment: development * Debug mode: on * Restarting with stat * Debugger is active! * Debugger PIN: 142-805-651 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)   在开发模式下，当页面出错的时候会显示一个可以互动的调试器；当你修改代码保存的时候会重启服务器。此次运行我出现了调试器，说明代码有问题，根据提示我修改了，提示如下： File \"D:\\OS-Management\\osmanagement\\__init__.py\", line 5, in create_app app = Flask(__name__,instance_relative_config=Ture) NameError: name 'Ture' is not defined 修改后自动跳转恢复正常，注意页面地址是：http://127.0.0.1:5000/gump 定义操作和数据库   Python内置了SQLite数据库支持，相应的模块为sqlite3。使用SQLite的便利性在于不需要单独配置一个数据库服务器，并且Python 提供了内置支持,适合小应用。 连接数据库 创建文件db.py： $ pwd /d/OS-Management/osmanagement $ touch db.py 在db.py中写入如下内容： import sqlite3 import click from flask import current_app, g from flask.cli import with_appcontext def get_db(): if 'db' not in g: g.db = sqlite3.connect( current_app.config['DATABASE'], detect_types=sqlite3.PARSE_DECLTYPES ) g.db.row_factory = sqlite3.Row return g.db def close_db(e=None): db = g.pop('db',None) if db is not None: db.close() 说明： g是一个特殊对象，在处理请求过程中，它可以用于储存可能多个函数都会用到的数据。把连接储存于其中，可以多次使用，而不用在同一个请求中每次调用get_db时都创建一个新的连接 current_app 是另一个特殊对象，该对象指向处理请求的Flask应用。在处理一个请求时，get_db会被调用。这样就需要使用current_app sqlite3.connect() 建立一个数据库连接，该连接指向配置中的DATABASE指定的文件。这个文件目前还没有建立，后面会在初始化数据库的时候建立该文件 sqlite3.Row 告诉连接返回类似于字典的行，这样可以通过列名称来操作数据。 close_db 通过检查g.db来确定连接是否已经建立。如果连接已建立，那么就关闭连接。 创建表   在SQLite中，数据储存在表和列中。Flaskr会把用户数据储存在user表中，把内容储存在post表中。下面创建一个文件储存用于创建空表的SQL命令：创建文件schema.sql： $ pwd /d/OS-Management/osmanagement $ touch schema.sql 在schema.sql中写入如下内容： DROP TABLE IF EXISTS user; DROP TABLE IF EXISTS post; CREATE TABLE user ( id INTEGER PRIMARY KEY AUTOINCREMENT, username TEXT UNIQUE NOT NULL, password TEXT NOT NULL ); CREATE TABLE post ( id INTEGER PRIMARY KEY AUTOINCREMENT, author_id INTEGER NOT NULL, created TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP, title TEXT NOT NULL, body TEXT NOT NULL, FOREIGN KEY (author_id) REFERENCES user (id) ); 在db.py文件中添加运行这个SQL命令的函数： def init_db(): db = get_db() with current_app.open_instance_resource('schema.sql') as f: db.executescript(f.read().decode('utf8')) @click.command('init-db') @with_appcontext def init_db_command(): # Clear the existing data and create new tables. init_db() click.echo('Initialized the database') 说明： open_resource()打开一个文件，该文件名是相对于flaskr包的，这样就不需要考虑以后应用具体部署在哪个位置 get_db返回一个数据库连接，用于执行文件中的命令 click.command()定义一个名为init-db命令行，它调用init_db函数 在应用中注册   close_db和init_db_command函数需要在应用实例中注册，否则无法使用。我们使用了工厂函数，那么在写函数的时候应用实例还无法使用。可以写一个函数，把应用作为参数，在函数中进行注册（db.py文件中）： def init_app(app): app.teardown_appcontext(close_db) app.cli.add_command(init_db_command) 说明： app.teardown_appcontext()告诉Flask在返回响应后进行清理的时候调用此函数 app.cli.add_command()添加一个新的可以与flask一起工作的命令 在__init__.py中导入并调用这个函数: from . import db db.init_app(app) return app 初始化数据库文件 停止之前的虚拟环境，然后激活环境： (venv) D:\\OS-Management>venv\\Scripts\\deactivate D:\\OS-Management> D:\\OS-Management>venv\\Scripts\\activate (venv) D:\\OS-Management> 设置FLASK_APP和FLASK_ENV并运行init-db命令： $ export FLASK_APP=osmanagement $ export FLASK_ENV=development $ flask init-db Initialized the database   刚开始运行有些报错，有些是明显写错了，with current_app.open_instance_resource('schema.sql')这句应该是with current_app.open_resource('schema.sql')： with current_app.open_instance_resource('schema.sql') as f: File \"c:\\users\\qianhuang\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\flask\\app.py\", line 740, in open_instance_resource return open(os.path.join(self.instance_path, resource), mode) FileNotFoundError: [Errno 2] No such file or directory: 'D:\\\\OS-Management\\\\instance\\\\schema.sql' 运行成功后instance文件夹中会出现osmanagment.sqlite文件。 Blueprints和视图   视图是一个应用对请求进行响应的函数。Flask通过模型把进来的请求URL匹配到对应的处理视图。视图返回数据，Flask把数据变成出去的响应。Flask也可以反过来。 创建Blueprints   Blueprint是一种组织一组相关视图及其他代码的方式。Flaskr有两个蓝图，一个用于认证功能，另一个用于内容管理。每个蓝图的代码都在一个单独的模块中。创建auth.py文件 ： $ pwd /d/OS-Management/osmanagement $ touch auth.py 写入如下内容： import functools from flask import(Blueprint,flash,g,redirect,render_template,request,session,url_for) from werkzeug.security import check_password_hash,generate_password_hash from osmanagement.db import get_db bp = Blueprint('auth',__name__,url_prefix='/auth') 说明： 创建了一个名称为'auth'的Blueprint。和应用对象一样，Blueprint需要知道是在哪里定义的，因此把__name__作为函数的第二个参数 url_prefix会添加到所有与该Blueprint关联的URL前面 使用app.register_blueprint()导入并注册Blueprint。在__init__.py中加上如下内容： from . import auth app.register_blueprint(auth.bq) return app 注册视图   当用户访问/auth/registerURL时， register视图会返回用于填写注册内容的表单的HTML。当用户提交表单时会验证表单内容，验证失败会显示表单并显示一个出错信息，成功创建新用户并显示登录页面，在auth.py中继续写入如下内容: @bq.route('/register',methods=('GET','POST')) def register(): if request.method == 'POST': username = request.form['username'] passwork = request.form['password'] db = get_db() error = None if not username: error = 'Username is required!' elif not password: error = 'Password is required!' elif db.execute( 'SELECT id FROM user WHERE username = ?',(username,) ).fetchone()is not None: error = 'User {} is already registered,please enter another!'.format(username) if error is None: db.execute( 'INSERT INTO user (username,password) VALUES (?,?)', (username,generate_password_hash(password)) ) db.commit() return redirect(url_for('auth.login')) flash(error) return render_template('auth/register.html') 说明： @bp.route关联了URL:/register和register视图函数。当Flask收到一个指向/auth/register的请求时就会调用register视图并把其返回值作为响应 如果用户提交了表单，那么request.method将会是'POST'，然后会开始验证用户的输入内容。 request.form是一个特殊类型的dict，其映射了提交表单的key和vaule 代码中还验证了username和password是否为空 通过查询数据库，检查是否有查询结果返回来验证username是否已被注册。db.execute使用了带有?占位符的SQL查询语句 fetchone()根据查询返回一个记录行,如果查询没有结果，则返回 None。后面还用到fetchall()它返回包括所有结果的列表 如果验证成功，那么在数据库中插入新用户数据。使用generate_password_hash()生成安全的哈希值并储存到数据库中 然后调用db.commit()保存修改 用户数据保存后将转到登录页面。 url_for()根据登录视图的名称生成相应的URL 如果验证失败，那么会向用户显示一个出错信息。flash()用于储存在渲染模块时可以调用的信息 当用户最初访问auth/register或者注册出错时，应用会显示一个注册表单 render_template()会渲染一个包含HTML的模板 登录视图 和register视图差不多，在auth.py中继续写入如下内容： @bp.route('/login',methods=('GET','POST')) def login(): if request.method == 'POST': username = request.form['username'] password = request.form['password'] db = get_db() error = None user = db.execure( 'SELECT * FROM user WHERE username = ?',(username,) ).fetchone() if user is None: error = 'Incorrect username,please try again!' elif not check_password_hash(user['password'],password): errot = 'Incorrect password,please try again!' if error is None: session.clear() session['user_id'] = user['id'] return redirect(url_for('index')) flash(error) return render_template('auth/login.html') 说明： 首先需要查询用户并存放在变量中，以备后用 check_password_hash()以哈希值方法保存密码并比较哈希值 session是一个dict，用于储存横跨请求的值。当验证成功后，用户的id被储存于一个新的会话中，会话数据被储存到一个向浏览器发送的cookie中，在后继请求中浏览器会返回它。 Flask会安全对数据进行签名以防数据被篡改   用户的id已被储存在session中，可以被后续的请求使用。在个请求的开头，如果用户已登录，那么其用户信息应当被载入，以使其可用于其他视图，在auth.py中继续写入如下内容： @bp.before_app_request def load_logged_in_user(): user_id = session.get('user_id') if user_id is None: g.user = None else: g.user = get_db().execute( 'SELECT * FROM user WHERE id = ?',(user_id,) ).fetchone() 说明： bp.before_app_request()注册一个在视图函数之前运行的函数，不论其URL是什么 load_logged_in_user检查用户id是否已经储存在session中，并从数据库中获取用户数据，然后储存在g.user中 g.user的持续时间比请求要长 如果没有用户id ，或者id不存在，那么g.user将会是None 注销视图   注销的时候需要把用户id从session中移除。然后load_logged_in_user就不会在后继请求中载入用户了,在auth.py中继续写入如下内容： @bp.route('/logout') def logout(): session.clear() return redirect(url_for('index')) 其它视图中验证   只能用户登录后才能在其它网页中进行操作，在每个视图中可以用装饰器来完成这个工作，在auth.py中继续写入如下内容： def login_required(view): @functools.wraps(view) def wrapped_view(**kwargs): if g.user is None: return redirect(url_for('auth.login')) return view(**kwargs) return wrapped_view 说明： 装饰器返回一个新的视图，该视图包含了传递给装饰器的原视图 新的函数检查用户是否已载入，如果已载入，那么就继续正常执行原视图，否则就重定向到登录页面 在后续视图中会使用到这个装饰器 Endpoints和URLs 说明如下： url_for()函数根据视图名称和arguments生成URL,视图相关联的名称亦称为Endpoint，默认Endpoint名称与视图函数名称相同 例如，前文被加入应用工厂的 gump() 视图端点为'gump'，可以使用url_for('gump')来连接 当使用Blueprints的时候，Blueprints的名称会添加到函数名称的前面。上面的login函数的端点为 'auth.login'，因为它已被加入'auth' Blueprints中 "},"08-Python/07-Python_Flask/03-Flask-模板及网页布局笔记.html":{"url":"08-Python/07-Python_Flask/03-Flask-模板及网页布局笔记.html","title":"Flask-模板及网页布局笔记","keywords":"","body":"Flask-模板及网页布局笔记 学习Flask项目搭建笔记，边学习边实践。 模板   应用已经写好验证视图，但是如果现在运行服务器的话，访问任何URL都会看到一个TemplateNotFound错误。这是因为视图调用了render_template()，但是模板还没有写。模板简单说明： 模板文件会储存在osmanagement包内的templates文件夹内 模板是包含静态数据和动态数据占位符的文件 模板使用指定的数据生成最终的文档，Flask使用Jinja模板库来渲染模板 基础布局 应用中的每一个页面主体不同，但是基本布局是相同的。创建tmplates目录并创建base.html文件： $ mkdir templates $ cd templates $ touch base.html $ pwd /d/OS-Management/osmanagement/templates $ ls base.html 在base.html文件中写入： {%block title %}{$ endblock %} - Operating System Management Operating System Management {% if g.user %} {{ g.user['username'] }} Log Out {% else %} Register Log In {% endif %} {% block header %}{% endblock %} {% for message in get_flashed_messages() %} {{ message }} {% endfor %} {% block content %}{% endblock %} 说明： g在模板中自动可用。根据g.user是否被设置（在load_logged_in_user中进行），要么显示用户名和注销连接，要么显示注册和登录连接 url_for()也是自动可用的，可用于生成视图的URL，而不用手动来指定 在标题下面，正文内容前面，模板会循环显示get_flashed_messages()返回的每个消息 在视图中使用flash()来处理出错信息，在模板中就可以这样显示出出来 模板中定义三个块，这些块会被其他模板重载: {% block title %}会改变显示在浏览器标签和窗口中的标题 {% block header %}类似于title,但是会改变页面的标题 {% block content %}是每个页面的具体内容，如登录表单或文章等 其他模板直接放在templates文件夹内 属于某个Blueprints的模板会被放在与Blueprints同名的文件夹内 注册 在tmplates目录下创建auth目录，在其下面并创建register.html文件： $ mkdir auth $ cd auth $ touch register.html $ pwd /d/OS-Management/osmanagement/templates/auth 在register.html文件中写入： {% extends 'base.html' %} {% block header %} {% block title %}Register{% endblock %} {% endblock %} {% block content %} Username Password {% endblock %} 说明： {% extends 'base.html' %}告诉Jinja这个模板基于基础模板base.html，并需要替换相应的块,所有替换的内容必须位于{% block %}标签之内 代码中把{% block title %}放在{% block header %}内部，这里不但可以设置title块，还可以把其值作为header块的内容 input标记使用了required属性,告诉浏览器这些字段是必填的 登录 在auth目录下创建login.html文件，并写入如下内容： {% extends 'base.html' %} {% block header %} {% block title %}Log In{% endblock %} {% endblock %} {% block content %} Username Password {% endblock %} 注册用户 运行程序： $ export FLASK_APP=osmanagement $ export FLASK_ENV=development $ flask run * Serving Flask app \"osmanagement\" (lazy loading) * Environment: development * Debug mode: on * Restarting with stat * Debugger is active! * Debugger PIN: 142-805-651 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) 运行后有报错： File \"D:\\OS-Management\\osmanagement\\__init__.py\", line 31, in create_app app.register_blueprint(auth.bq) AttributeError: module 'osmanagement.auth' has no attribute 'bq' File \"D:\\OS-Management\\osmanagement\\auth.py\", line 67 return redirect(url_for('index')) ^ IndentationError: unexpected indent 缩进问题及字母写错了，修改后还是有报错： File \"D:\\OS-Management\\osmanagement\\templates\\base.html\", line 23, in template {% block content %}{% endblock %} jinja2.exceptions.TemplateSyntaxError: Unexpected end of template. Jinja was looking for the following tags: 'endblock'. The innermost block that needs to be closed is 'block'. 一般是{%的问题，中间有空格或者缺少空格或者写错了，找了半天找到下面语句中两处错误： {%block title %}{$ endblock %} - osmanagement 修改后进入http://127.0.0.1:5000/auth/register可以看到注册的页面,注册后报错了： File \"D:\\OS-Management\\osmanagement\\auth.py\", line 11, in register password = request.form['password'] werkzeug.exceptions.BadRequestKeyError: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand. KeyError: 'password'   应该是request.form['password']用法不支持还是错了，改成request.form.get('password')后不报错，但是提示Password is required!,也就是相当于没获取到密码,查了半天是前端register.html和login.html里面这句都写错了，name=\"username\"应该是name=\"password\"： 修改后运行报错变了： File \"D:\\OS-Management\\osmanagement\\auth.py\", line 23, in register db.execute( sqlite3.OperationalError: table user has no column named password 检查schema.sql文件发现下面内容手残打错了： passwork TEXT NOT NULL 修改后重新初始化一下数据库就可以了。 静态文件 在base.html模板中使用了： 说明： Flask自动添加一个static视图，视图使用相对于osmmanagerment/static的相对路径 除了CSS，还可以是JavaScript函数文件或者logo图片，都放置于flaskr/static文件夹中，并使用url_for('static', filename='...')来引用 改动静态文件后需要刷新页面，如果刷新无效，需要清除浏览器的缓存 在style.css文件中写入如下内容： html { font-family: sans-serif; background: #eee; padding: 1rem; } body { max-width: 960px; margin: 0 auto; background: white; } h1 { font-family: serif; color: #377ba8; margin: 1rem 0; } a { color: #377ba8; } hr { border: none; border-top: 1px solid lightgray; } nav { background: lightgray; display: flex; align-items: center; padding: 0 0.5rem; } nav h1 { flex: auto; margin: 0; } nav h1 a { text-decoration: none; padding: 0.25rem 0.5rem; } nav ul { display: flex; list-style: none; margin: 0; padding: 0; } nav ul li a, nav ul li span, header .action { display: block; padding: 0.5rem; } .content { padding: 0 1rem 1rem; } .content > header { border-bottom: 1px solid lightgray; display: flex; align-items: flex-end; } .content > header h1 { flex: auto; margin: 1rem 0 0.25rem 0; } .flash { margin: 1em 0; padding: 1em; background: #cae6f6; border: 1px solid #377ba8; } .post > header { display: flex; align-items: flex-end; font-size: 0.85em; } .post > header > div:first-of-type { flex: auto; } .post > header h1 { font-size: 1.5em; margin-bottom: 0; } .post .about { color: slategray; font-style: italic; } .post .body { white-space: pre-line; } .content:last-child { margin-bottom: 0; } .content form { margin: 1em 0; display: flex; flex-direction: column; } .content label { font-weight: bold; margin-bottom: 0.5em; } .content input, .content textarea { margin-bottom: 1em; } .content textarea { min-height: 12em; resize: vertical; } input.danger { color: #cc2f2e; } input[type=submit] { align-self: start; min-width: 10em; } 页面Blueprints 完成每个视图时，保持开发服务器运行。当保存修改后，请尝试在浏览器中访问URL，并进行测试。 Blueprints 定义blueprints并注册到应用工厂，在osmanagement目录下创建文件osm.py,并写入如下内容： from flask import( Blueprint,flash,g,redirect,render_templagte,request,url_for ) from werkzeug.exceptions import abort from osmanagement.auth import login_required from osmanagement.db import get_db bp = Blueprint('osm',__name__) 使用app.register_blueprint()在工厂中导入和注册蓝图,将新代码放在__init__.py的尾部，返回应用之前: from . improt osm app.register_blueprint(osm.bp) app.add_url_rule('/',endpoint='index') 说明： 与验证blueprints不同，内容管理blueprints没有url_prefix。因此index视图会用于/，create会用于/create，以此类推 但下面的index视图的端点会被定义为osm.index。一些验证视图会指定向普通的index端点。 我们使用 app.add_url_rule()关联端点名称'index'和/ URL，这样url_for('index')或url_for('osm.index')都会有效，会生成同样的/ URL 索引 索引会显示所有帖子，最新的会排在最前面。为了在结果中包含user表中的作者信息，使用了一个JOIN。在osm.py中继续写入一下内容： @bp.route('/') def index(): db = get_db() posts = db.execute( 'SELECT p.id, title, bode, created, author_id, username' 'FROM post p JOIN user u ON p.author_id = u.id' 'ORDER BY created DESC' ).fetchall() return render_template('osm/index.html',posts=posts) 创建index.html文件： $ pwd /d/OS-Management/osmanagement/templates/osm $ touch index.html 在index.html文件中写入如下内容： {% extends 'base.html' %} {% block header %} {% block title %}Posts{% endblock %} {% if g.user %} New {% endif %} {% endblock %} {% block content %} {% for post in posts %} {{ post['title'] }} by {{ post['username'] }} on {{ post['created'].strftime('%Y-%m-%d') }} {% if g.user['id'] == post['author_id'] %} Edit {% endif %} {{ post['body'] }} {% if not loop.last %} {% endif %} {% endfor %} {% endblock %} 说明： 当用户登录后，header块添加了一个指向create视图的连接 当用户是 博客作者时，可以看到一个“ Edit ”连接，指向 update 视图 loop.last 是一个 Jinja for 循环 内部可用的特殊变量，它用于在每个 博客帖子后面显示一条线来分隔帖子，最后一个帖子除外 创建视图   create视图与register视图原理相同。显示表单或发送内容，已通过验证且内容已加入数据库，或者显示一个出错信息。login_required装饰器用在了osm视图中，这样用户必须登录以后才能访问这些视图，否则会被重定向到登录页面。 osm.py中写入： @bp.route('/create', methods=('GET', 'POST')) @login_required def create(): if request.method == 'POST': title = request.form['title'] body = request.form['body'] error = None if not title: error = 'Title is required.' if error is not None: flash(error) else: db = get_db() db.execute( 'INSERT INTO post (title, body, author_id)' ' VALUES (?, ?, ?)', (title, body, g.user['id']) ) db.commit() return redirect(url_for('osm.index')) return render_template('osm/create.html') templates/osm/create.html内写入： {% extends 'base.html' %} {% block header %} {% block title %}New Post{% endblock %} {% endblock %} {% block content %} Title Body {{ request.form['body'] }} {% endblock %} 更新视图   update和delete视图都需要通过id来获取一个post ，并且检查作者与登录用户是否一致。为避免重复代码，可以写一个函数来获取post， 并在每个视图中调用它。 osm.py中写入： def get_post(id, check_author=True): post = get_db().execute( 'SELECT p.id, title, body, created, author_id, username' ' FROM post p JOIN user u ON p.author_id = u.id' ' WHERE p.id = ?', (id,) ).fetchone() if post is None: abort(404, \"Post id {0} doesn't exist.\".format(id)) if check_author and post['author_id'] != g.user['id']: abort(403) return post 说明： abort()会引发一个特殊的异常，返回一个HTTP状态码： 它有一个可选参数，用于显示出错信息，若不使用该参数则返回缺省出错信息 404表示“未找到”， 403代表“禁止访问” 401表示“未授权”，但是这里重定向到登录 页面来代替返回这个状态码 check_author参数的作用是函数可以用于在不检查作者的情况下获取一个post，这用于显示一个独立的帖子页面的情况，因为这时用户是谁没有关系， 用户不会修改帖子 在osm.py中写入： @bp.route('//update', methods=('GET', 'POST')) @login_required def update(id): post = get_post(id) if request.method == 'POST': title = request.form['title'] body = request.form['body'] error = None if not title: error = 'Title is required.' if error is not None: flash(error) else: db = get_db() db.execute( 'UPDATE post SET title = ?, body = ?' ' WHERE id = ?', (title, body, id) ) db.commit() return redirect(url_for('osm.index')) return render_template('osm/update.html', post=post) 说明： 和所有以前的视图不同， update函数有一个id参数。该参数对应路由中的 。一个真正的URL，类似 /1/update Flask会捕捉到URL中的 1 ，确保其为一个int，并将其作为id参数传递给视图 如果没有指定int: 而是仅仅写了 ，那么将会传递一个字符串。 要生成一个指向更新页面的URL，需要传递 id 参数给url_for()： url_for('blog.update', id=post['id']) 。 前文的index.html文件中同样如此 flaskr/templates/osm/update.html中写入： {% extends 'base.html' %} {% block header %} {% block title %}Edit \"{{ post['title'] }}\"{% endblock %} {% endblock %} {% block content %} Title Body {{ request.form['body'] or post['body'] }} {% endblock %} 说明： 这个模板有两个表单： 第一个提交已编辑过的数据给当前页面（ //update ） 另一个表单只包含一个按钮，它指定一个action属性，指向删除视图。这个按钮使用了一些JavaScript用以在提交前显示一个确认对话框。 参数request.form['title'] or post['title']用于选择在表单显示什么数据: 当表单还未提交时，显示原post数据 如果提交了非法数据，然后需要显示这些非法数据以便于用户修改时，就显示request.form中的数据 删除   删除视图没有自己的模板。删除按钮已包含于update.html之中，该按钮指向//delete URL 。既然没有模板，该视图只处理POST方法并重定向到index视图。 在osm.py中写入： @bp.route('//delete', methods=('POST',)) @login_required def delete(id): get_post(id) db = get_db() db.execute('DELETE FROM post WHERE id = ?', (id,)) db.commit() return redirect(url_for('osm.index')) "},"08-Python/07-Python_Flask/09-Flask-操作请求数据.html":{"url":"08-Python/07-Python_Flask/09-Flask-操作请求数据.html","title":"Flask-操作请求数据","keywords":"","body":"Flask-操作请求数据   对于web应用来说对客户端向服务器发送的数据作出响应很重要。在Flask中由全局对象request来提供请求信息。 请求对象 基础用法 必须从flask模块导入请求对象: from flask import request   通过使用method属性可以操作当前请求方法，通过使用form属性处理表单数据（在POST或者PUT请求中传输的数据）,示例如下： @app.route('/login', methods=['POST', 'GET']) def login(): error = None if request.method == 'POST': if valid_login(request.form['username'], request.form['password']): return log_the_user_in(request.form['username']) else: error = 'Invalid username/password' # 如果是POST请求方法执行以下代码 # 如果是GET或凭据无效则返回错误 return render_template('login.html', error=error) 说明： 当form属性中不存在这个键时会引发一个KeyError 如果你不像捕捉一个标准错误一样捕捉KeyError，那么会显示一个HTTP 400 Bad Request错误页面 要操作URL（如 ?key=value ）中提交的参数可以使用 args 属性: searchword = request.args.get('key', '')   用户可能会改变URL导致出现一个400请求出错页面，这样降低了用户友好度。推荐使用get或通过捕捉KeyError来访问URL参数。 请求对象方法和属性参见Request文档：Incoming Request Data "},"08-Python/07-Python_Flask/10-Flask-常见问题.html":{"url":"08-Python/07-Python_Flask/10-Flask-常见问题.html","title":"Flask-常见问题","keywords":"","body":"Flask-常见问题 学习和使用过程中遇到的问题处理记录。 运行报错 ValueError 报错示例如下： ValueError: urls must start with a leading slash 原因：蓝图中路由写错了，没加斜杠： @bp.route('', methods=('POST',)) 正确代码： @bp.route('/', methods=('POST',)) KeyError 错误示例： File \"D:\\navigator\\nav\\navigation.py\", line 36, in add maincategory = request.form['maincategory'] File \"C:\\Users\\AppData\\Local\\Programs\\Python\\Python38\\Lib\\site-packages\\werkzeug\\datastructures.py\", line 442, in __getitem__ raise exceptions.BadRequestKeyError(key) werkzeug.exceptions.BadRequestKeyError: 400 Bad Request: The browser (or proxy) sent a request that this server could not understand. KeyError: 'maincategory' 明显是获取不到数据： 可能是在对应的位置没有传递值 可能是指向了错误的路由，比如一个FORM删除的功能路由到添加里面去了 待补充 "},"08-Python/07-Python_Flask/11-HTML-基础学习笔记.html":{"url":"08-Python/07-Python_Flask/11-HTML-基础学习笔记.html","title":"HTML-基础学习笔记","keywords":"","body":"HTML-基础学习笔记 学习HTML记得基础笔记。 基础知识 标签和元素   元素里面有：属性、内容、嵌套标签和自封闭标签。有些标签不是成对出现，例如换行标签：。例如下面示例中就是标签，下面整个内容叫做元素： \"Interstellar\" 元素 分类： 块级元素 行内元素 基本框架 \"Interstellar\" 说明: ：文档声明标签，此为html5的 lang=\"en\":网页使用文字的语言，属性的值用双引号或者单引号 :不呈现在正文部分，是网页标题 :正文部分，就是网页页面呈现的内容 :声明网页编码模式 表格 表格样式 可以使用CSS控制网页样式和布局，代码不多可以直接写在html中： .infotable{ width:400px; height:100px; margin:0 auto } ... 也可以在创建表格时候直接添加属性： Item Value Remarks 常用标签 表格中常用标签： :标签定义HTML表格,链接：HTML table 标签 ：标签定义HTML表格中的行，链接：HTML tr 标签 :定义表格内的表头单元格,链接：HTML th 标签 :标签定义HTML表格中的标准单元格，链接：HTML td 标签 单元格的合并 通过HTML标签的colspan和rowspan属性实现: Disk kbps tps max avg max avg hdisk2 1.4 1.1 5 1.7 运行后样式如下图： colspan参考学习链接：https://www.w3school.com.cn/tags/att_td_colspan.asprowspan参考学习链接：https://www.w3school.com.cn/tags/att_td_rowspan.asp 说明   HTML5需要学习的比较多，后来买了一本书进行学习，笔记记录位置：HTML+CSS+JavaScript/HTML5，此处将只记录一些使用过程中的知识要点或注意事项 "},"08-Python/07-Python_Flask/15-SQLite-基础知识笔记.html":{"url":"08-Python/07-Python_Flask/15-SQLite-基础知识笔记.html","title":"SQLite-基础知识笔记","keywords":"","body":"SQLite-基础知识笔记   SQLite是一款轻型的数据库，是遵守ACID的关系型数据库管理系统，它包含在一个相对小的C库中。此处是学习SQLite记的基础笔记。 SQLite教程：https://www.runoob.com/sqlite/sqlite-tutorial.html W3school SQL 教程：https://www.w3school.com.cn/sql/index.asp vue5.com SQLite 教程：http://www.vue5.com/sqlite/sqlite_select_query.html 官方网站：https://www.sqlite.org/index.html SQLite数据库查看工具：https://sqlitebrowser.org/ 基础操作 创建数据库 SQLite的sqlite3命令用来创建新的SQLite数据库： $ sqlite3 test.db 或者使用.open来新建数据库文件： sqlite> .open test.db 打开数据库 命令同创建，如果数据库存在就会直接打开，示例如下： [root@VM-0-6-centos tmp]# sqlite3 nav.sqlite SQLite version 3.7.17 2013-05-20 00:56:22 Enter \".help\" for instructions Enter SQL statements terminated with a \";\" sqlite> .databases seq name file --- --------------- ---------------------------------------------------------- 0 main /tmp/nav.sqlite 退出 退出sqlite提示符示例： sqlite> .quit [root@VM-0-6-centos tmp]# CREATE创建表 语法 SQLite中CREATE TABLE语句用于在任何给定的数据库创建一个新表，语法如下： CREATE TABLE database_name.table_name( column1 datatype PRIMARY KEY(one or more columns), column2 datatype, ... columnN datatype, ); 实例 在之前学习Flask过程中使用到过，如下所示： DROP TABLE IF EXISTS user; DROP TABLE IF EXISTS post; CREATE TABLE user ( id INTEGER PRIMARY KEY AUTOINCREMENT, username TEXT UNIQUE NOT NULL, password TEXT NOT NULL ); CREATE TABLE post ( id INTEGER PRIMARY KEY AUTOINCREMENT, author_id INTEGER NOT NULL, created TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP, title TEXT NOT NULL, body TEXT NOT NULL, FOREIGN KEY (author_id) REFERENCES user (id) ); 上面示例中创建了两个表，说明如下： DROP TABLE IF EXISTS 表示如果表已经存在就DROP掉 首先创建了一个名为user表，ID作为主键 INTEGER 表示属性类型，后面的TEXT及TIMESTAMP都是类型之一 UNIQUE 表示此值是唯一的，不能重复 primary key 表示这个属性是主键 AUTOINCREMENT 表示这个值是自动增加的，默认的起始值是1 NOT NULL的约束表示在表中创建纪录时这些字段不能为NULL 在created列中，定义了默认值，DEFAULT CURRENT_TIMESTAMP表示获取当前时间戳 最后一句是设置外键，作用是保持数据一致性，完整性；控制存储在外键表中的数据，使两张表形成关联 参考链接 创建表参考教程： RUNOOB.COM SQLite创建表 W3school SQL CREATE TABLE 语句 Select语句 基本语法 基本语法： -- 获取指定的字段 SELECT column1, column2, columnN FROM table_name; -- 获取所有可用字段 SELECT * FROM table_name; 示例 获取所有可用字段： sqlite> SELECT * FROM links; 1|IBM|IBM Home Page|IBM官方中文网站|https://www.ibm.com/cn-zh 2|IBM|IBM Home Page|IBM Knowledge Center|https://www.ibm.com/support/knowledgecenter 3|IBM|IBM Home Page|IBM Fix Central|https://www-945.ibm.com/support/fixcentral/ ... 获取指定字段： sqlite> SELECT urlname FROM links; IBM官方中文网站 IBM Knowledge Center IBM Fix Central IBM Software Support ... 根据关键字获取数据： sqlite> SELECT * FROM links WHERE id = 1; 1|IBM|IBM Home Page|IBM官方中文网站|https://www.ibm.com/cn-zh sqlite> SELECT * FROM links WHERE subcategory = 'Docker'; 64|容器平台|Docker|Docker官方首页|https://www.docker.com/ 65|容器平台|Docker|Docker官方文档|https://docs.docker.com/ 66|容器平台|Docker|Docker中文社区|https://www.docker.org.cn/index.html 67|容器平台|Docker|Docker runoob教程|https://www.runoob.com/docker/docker-tutorial.html 76|容器平台|Docker|Docker官方博客|https://www.docker.com/blog/ 获取某一列数据并过滤去重： sqlite> SELECT distinct maincategory FROM links; IBM Linux_System Python WEB前端 虚拟化平台 容器平台 SAN_Switch 获取字段并根据某一列进行排序: sqlite> SELECT * FROM links order by maincategory; 1|IBM|IBM Home Page|IBM官方中文网站|https://www.ibm.com/cn-zh 2|IBM|IBM Home Page|IBM Knowledge Center|https://www.ibm.com/support/knowledgecenter 3|IBM|IBM Home Page|IBM Fix Central|https://www-945.ibm.com/support/fixcentral/ ... Insert语句 基本语法 INSERT INTO 语句有两种基本语法，如下所示： -- 向所有列添加值 INSERT INTO TABLE_NAME VALUES (value1,value2,value3,...valueN); -- 向指定的列添加值，确保值的顺序与列在表中的顺序一致 INSERT INTO TABLE_NAME (column1, column2, column3,...columnN) VALUES (value1, value2, value3,...valueN); 示例 insert一条数据示例： sqlite> INSERT INTO links (maincategory, subcategory, urlname, urllocation) \\ VALUES ('IBM','Power System','PowerE980','e980.com'); sqlite> SELECT * FROM links WHERE urlname = 'PowerE980'; 77|IBM|Power System|PowerE980|e980.com sqlite> INSERT INTO links VALUES ('78','IBM','Power System','PowerE880','e880.com'); sqlite> SELECT * FROM links WHERE id = 78; 78|IBM|Power System|PowerE880|e880.com Update语句 基本语法 基本语法如下 UPDATE table_name SET column1 = value1, column2 = value2...., columnN = valueN WHERE [condition]; 示例 示例如下： sqlite> UPDATE links SET maincategory = 'IBM', subcategory = 'Storage System', urlname = ' DS8888', urllocation = 'ds8888.com' WHERE id = 78; sqlite> SELECT * FROM links WHERE id = 78; 78|IBM|Storage System|DS8888|ds8888.com Delete语句 基本语法 带有WHERE子句的DELETE查询基本语法： DELETE FROM table_name WHERE [condition]; 示例 删除一条记录示例如下： sqlite> DELETE FROM links WHERE id = 78; sqlite> SELECT * FROM links WHERE id = 78; sqlite> insert or replace 基本语法 从table_2中取所有记录INSERT到table_1中： INSERT INTO table_1 SELECT * FROM table_2 如果两张表有重复的内容，主要是ID一样的： INSERT OR REPLACE INTO table_1 SELECT * FROM table_2 如果有重复的就REPLACE，合并两张表的方法，注意会覆盖数据，慎重操作。 待补充 "},"08-Python/07-Python_Flask/16-SQLite-常见问题.html":{"url":"08-Python/07-Python_Flask/16-SQLite-常见问题.html","title":"SQLite-常见问题","keywords":"","body":"SQLite-常见问题 记录一些使用过程中常见问题。 常见报错 创建表报错 创建时候发现报错： File \"D:\\navigator\\nav\\db.py\", line 20, in init_db db.executescript(f.read().decode('utf8')) sqlite3.OperationalError: near \")\": syntax error 以为Python代码写错了，后来发现是在创建表的SQL语句中，最后一项加了逗号，去掉即可。 UNIQUE问题 报错提示： sqlite3.IntegrityError: UNIQUE constraint failed: links.urlname 这个错误是因为在建表的时候设定了UNIQUE这个键，当出现重复的时候就报错。 locked锁表 示例一 报错如下： sqlite3.OperationalError: database is locked 因为sqlite只支持单线程操作，导致锁表操作不详，重启应用即可。 数据异常 数据丢失   最近发现SQLite丢数据了。我将项目文件包括数据库文件拷贝到TXY CentOS宿主系统上，然后拷贝到容器nav，没有用nginx，使用waitress运行成功后添加了不少数据，大概了七十多条。后来想使用nginx，做了个镜像到navigator，nav就没动过了，然后在navigator里面调试nginx和uwsgi，成功后发现数据少了十几条，然后回到nav，发现数据少了二十多条，少的内容不一样。 一开始怀疑是我频繁使用kill -9导致数据库损坏，参考网上链接进行处理： [root@cd414072bc2b instance]# sqlite3 nav.sqlite .dump > news.sqlite [root@cd414072bc2b instance]# ls nav.sqlite news.sqlite [root@cd414072bc2b instance]# cat news.sqlite 查看一下也没发现异常。参考链接：https://blog.csdn.net/m0_37168878/article/details/89430040   使用SQLite数据库查看软件也是少了数据，但是没发现什么异常，最后找到以前的数据表，和现有的合并一下。使用的DB Browser for SQLite软件，先把数据少的那个库里面表导出来，需要勾上“第一列列名”，导出后把表导入到数据多的那个库里面，执行语句： insert into links select * from temp Result: UNIQUE constraint failed: links.id At line 1: insert into links select * from temp 报错了，因为有重复的id的数据，使用下面方法： insert or replace into links select * from temp Result: 查询执行成功。耗时 0ms54 行数据受影响 At line 1: insert or replace into links select * from temp 删掉不需要的表保存即可。 数据丢失的原因还没找到，通过此方法恢复了数据，也算是学到一点，技术很重要，备份也很重要。 待补充 "},"08-Python/08-Python系统管理&自动化运维笔记/":{"url":"08-Python/08-Python系统管理&自动化运维笔记/","title":"Python系统管理&自动化运维笔记","keywords":"","body":"Python系统管理与自动化运维笔记 简介 记录学习过程中的笔记，方便查阅。 学习教材：《Python Linux系统管理与自动化运维》（赖明星著） 内容 Python运维-基础知识 Python运维-打造命令工具 Python运维-文本处理 Python运维-Linux系统管理 Python运维-Linux系统管理实例 "},"08-Python/08-Python系统管理&自动化运维笔记/01-Python运维-基础知识.html":{"url":"08-Python/08-Python系统管理&自动化运维笔记/01-Python运维-基础知识.html","title":"Python运维-基础知识","keywords":"","body":"Python运维笔记-基础知识 记录一些基础知识学习笔记。学习教材：《Python Linux系统管理与自动化运维》（赖明星著） Python内置小工具 下载服务器   Linux传输文件通常使用ftp等，用命令有时感觉不方便，Python有个内置web服务器，可以作为一个下载服务器，在Python3中，使用示例： [root@redhat8 shell]# ls basis for function gawk if-for input instance output regular sed sed_gawk test [root@redhat8 shell]# python3 -m http.server Serving HTTP on 0.0.0.0 port 8000 (http://0.0.0.0:8000/) ...   然后打开浏览器，输入地址http://192.168.18.131:8000/既可，可以看到类似FTP下载页面，使用笔记方便。如果目录下存在一个index.html的文件，默认显示该文件内容，如果没有，默认显示当前目录下的文件列表。 在Python2中的使用方法： python -m SimpleHTTPServer 字符串转换为JSON   JSON是一种轻量级的数据交换格式，网上可以搜索到在线JSON格式化工具，当然可以在命令行的Python解析器来解析JSOS串。使用示例： [root@redhat8 shell]# echo '{\"job\":\"devops\",\"name\":\"bond\",\"sex\":\"male\"}'|python3 -m json.t ool{ \"job\": \"devops\", \"name\": \"bond\", \"sex\": \"male\" } 还可以自动对齐和格式化，示例： [root@redhat8 shell]# echo '{\"address\":{\"province\":\"guangdong\",\"city\":\"shenzhen\"},\"name\":\" bond\",\"sex\":\"male\"}'|python3 -m json.tool { \"address\": { \"province\": \"guangdong\", \"city\": \"shenzhen\" }, \"name\": \"bond\", \"sex\": \"male\" } 检查第三方库 检查第三方库是否正确安装，只需要尝试import即可，不报错就没问题： [root@redhat8 shell]# python3 Python 3.6.8 (default, Jan 11 2019, 02:17:16) [GCC 8.2.1 20180905 (Red Hat 8.2.1-3)] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. >>> improt paramiko 或者使用-c参数快读执行import语句: [root@redhat8 python]# python3 -c \"import paramiko\" pip高级用法 Python生态主流的包管理工具是pip。 pip介绍 pip是用来安装和管理Python包的工具，手动安装： $sudo apt-get indstall python-pip 我系统中配置了软件仓库，安装时候提示已经安装了： [root@redhat8 python]# yum install python3-pip.noarch Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscription -manager to register.redhat8_app 0.0 B/s | 0 B 00:00 redhat8_os 0.0 B/s | 0 B 00:00 Failed to synchronize cache for repo 'redhat8_app', ignoring this repo. Failed to synchronize cache for repo 'redhat8_os', ignoring this repo. Package python3-pip-9.0.3-13.el8.noarch is already installed. Dependencies resolved. Nothing to do. Complete! 但是输入pip命令无效，查找以下即可： [root@redhat8 python]# whereis pip pip: /usr/bin/pip3.6 [root@redhat8 python]# pip3.6 install -U pip WARNING: Running pip install with root privileges is generally not a good idea. Try `pip3. 6 install --user` instead. 有些软件没有上传到pip网站，可以使用源码安装方式,示例： $ git clone https://github.bom/paramiko/paramiko.git $ cd paramiko $ python setup.py install pip常用命令 常用子命令如下： 命令 说明 install 安装软件包 download 下载软件包 uninstall 卸载安装包 freeze 按照requirements的格式输出按照包 list 列出当前系统中的安装包 show 查看安装包信息 check 检查安装包的依赖是否完整 search 查找安装包 wheel 打包软件到wheel格式 hash 计算按照包的hash值 completion 生成命令补全配置 help 获取pip和子命令的帮助信息 导出已安装的软件包列表到requirements文件，并从requirements文件按照示例： $ pip freeze > requirements.tex $ pip install -r requirements.tex pip加速安装技巧 使用豆瓣的pypi镜像源,示例安装flask： $ pip install -i https://pypi.douban.com/simple/ flask $ pip install -i https://mirrors.aliyun.com/pypi/simple/ flask 或者将镜像源写入到配置文件中： [root@redhat8 /]# cd ~ [root@redhat8 ~]# mkdir .pip [root@redhat8 ~]# cd .pip [root@redhat8 .pip]# touch pip.conf [root@redhat8 .pip]# vim pip.conf [root@redhat8 .pip]# pwd /root/.pip [root@redhat8 .pip]# cat pip.conf [global] timeout = 20 index-url=https://mirrors.aliyun.com/pypi/simple/ extra-index-url=https://pypi.douban.com/simple/ [install] trusted-host= mirrors.aliyun.com pypi.douban.con 也可以下载到本地，然后再安装： $ pip install --download=`pwd` -r requirements.txt $ pip install --no-index -f file://`pwd` -r requirements.txt pip能自动处理软件的依赖问题，里面下载flask时候，依赖包都会被下载到本地： $ pip install --download=`pwd` flask Python编辑器 vim插件 vim用的少，《Python Linux系统管理与自动化运维》书中介绍了三个，具体见书中： 一键执行插件:写完测试后不用退出vim，立即执行就能看到结果 代码补全插件snipmate：按tab键补全，方便快捷 语法检查插件Syntastic：提示哪些代码存在语法错误，哪些代码不符合编码规范，并给出具体提示信息 编程提示插件jedi-vim：基于jedi的自动补全插件 PyCharm 是目前最流行的Python IDE,目前没使用，具体介绍见《Python Linux系统管理与自动化运维》。 Python编程辅助工具 《Python Linux系统管理与自动化运维》书中介绍了不少，之前有朋友推荐过jupyter，虽然没用过，感觉很屌。 jupyter的使用 jupyter是一种新兴的交互式数据分析与记录工具。官方网站：https://jupyter.org/ 安装jupyter： [root@redhat8 python]# pip3.6 install jupyter [root@redhat8 python]# pip3.6 install -i https://pypi.douban.com/simple/ jupyter [root@redhat8 python]# pip3.6 install -i https://mirrors.aliyun.com/pypi/simple/ jupyter 虚拟机RedHat怎么也安装不成功，在windows下安装成功： C:\\Users\\QianHuang>pip install -i https://mirrors.aliyun.com/pypi/simple/ jupyter Looking in indexes: https://mirrors.aliyun.com/pypi/simple/ Collecting jupyter Downloading https://mirrors.aliyun.com/pypi/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB) Collecting jupyter-console ...... WARNING: You are using pip version 20.2.3; however, version 20.2.4 is available. You should consider upgrading via the 'c:\\users\\qianhuang\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command. 设置浏览器进行外部访问： C:\\Users\\QianHuang>jupyter notebook --no-browser [I 00:16:09.394 NotebookApp] Writing notebook server cookie secret to C:\\Users\\QianHuang\\AppData\\Roaming\\jupyter\\runtime\\notebook_cookie_secret [I 00:16:10.298 NotebookApp] Serving notebooks from local directory: C:\\Users\\QianHuang [I 00:16:10.298 NotebookApp] Jupyter Notebook 6.1.5 is running at: [I 00:16:10.300 NotebookApp] http://localhost:8888/?token=6ba5db71f72213c9941d66f981330bd7e21ad70ff73d395f [I 00:16:10.301 NotebookApp] or http://127.0.0.1:8888/?token=6ba5db71f72213c9941d66f981330bd7e21ad70ff73d395f [I 00:16:10.302 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation). [C 00:16:10.327 NotebookApp] To access the notebook, open this file in a browser: file:///C:/Users/QianHuang/AppData/Roaming/jupyter/runtime/nbserver-18428-open.html Or copy and paste one of these URLs: http://localhost:8888/?token=6ba5db71f72213c9941d66f981330bd7e21ad70ff73d395f or http://127.0.0.1:8888/?token=6ba5db71f72213c9941d66f981330bd7e21ad70ff73d395f 根据提示链接，打开浏览器即可访问，可以加上--ip来指定地址，默认是localhost： C:\\Users\\QianHuang>jupyter notebook --no-browser --ip=0.0.0.0 Python调试器   一些软件安装插件后有Python调试功能，例如VScode，还可以使用PyCharm的图形界面调试器，此处学习两个Python调试器，分别是Python标准库自带得pdb和开源的ipdb。 标准库的pdb   pdb是Python自带的一个库，提供了交互式的源代码调试功能，包含了现代调试器应有的功能，包括设置断点、单步调试、查看源码、查看程序堆栈等。部分pdb调试命令如下： 命令 缩写 说明 break b 设置断点 continue cont/c 继续执行下一个断点 next n 执行下一行，如果下一行是子程序，不会进入子程序 step s 执行下一行，如果下一行是子程序，会进入子程序 where bt/w 打印堆栈轨迹 enable - 启用禁用的断点 disable - 禁用启用的断点 pp/p - 打印变量或表达式 list l 根据参数值打印源码 up u 移动到上一层堆栈 down d 移动到下一层堆栈 restart run 重新开始调试 args a 打印函数参数 clear cl 清楚所有的断点 return r 执行到当前函数结束 直接在命令参数指定使用pdb模块,示例如下： [root@redhat8 python]# python3 -m pdb test_pdb.py > /python/test_pdb.py(1)() (Pdb)   另一种启用方法是在Python中调用pdb模块的set_trace方法设置一个断点，当程序运行至断点时，将会暂停执行斌打开pdb调试器，代码示例如下： #/usr/bin/python3 from __future__ import print_function import pdb def sum_nums(num): n = 0 for i in range(num): pdb.set_trace() n +=1 print(n) if __name__ == '__main__': sum_nums(10) 调试示例： [root@redhat8 python]# python3 test_pdb.py > /python/test_pdb.py(8)sum_nums() -> n +=1 (Pdb) bt /python/test_pdb.py(11)() -> sum_nums(10) > /python/test_pdb.py(8)sum_nums() -> n +=1 (Pdb) list 3 import pdb 4 def sum_nums(num): 5 n = 0 6 for i in range(num): 7 pdb.set_trace() 8 -> n +=1 9 print(n) 10 if __name__ == '__main__': 11 sum_nums(10) [EOF] (Pdb) p n 0 (Pdb) p i (Pdb) n > /python/test_pdb.py(9)sum_nums() -> print(n) 说明： 示例中先用bt命令查看当前函数的调用堆栈 然后使用list命令查看Python代码 再使用P命令打印n和i变量当前的取值 最后使用n执行下一行Python代码 开源的ipdb   ipdb是一个开源的Python调试器，和pdb有相同的接口，相对pdb它具有语法高亮、tab补全、更友好的堆栈信息等高级功能。ipdb是一个第三方库，使用前需要先安装： [root@redhat8 python]# pip install ipdb 使用方法和pdb类似。 Python代码检查规范 PEP 8编码规范介绍 Python官方编码风格指导手册：https://www.python.org/dev/peps/pep-0008/ PEP 8 编码规范简单介绍： 在Python中，import应该一次只导入一个模块，不同的模块应该独立一行 import语句应该处于源码文件的顶部，位于模块注释和文档字符串之后，全局变量和常量之前 导入不同的库时，应该按以下顺序分组，各个分组直接以空行分隔： 导入标准库模块 导入相关的第三方库模块 导入当前应用程序/库模块 Python中支持相对导入和绝对导入，推荐使用绝对导入 如果处理复杂的包结果，可以使用相对导入 使用pycodestyle检查代码规范   Python官方的代码规范成为PEP8，检查代码风格的命令工具也叫pep8，Python之父建议重命名为pycodestyle，通过pip安装即可： [root@redhat8 python]# pip install pycodestyle 对一个或多个文件运行pycodestyle，打印检查报告示例: [root@redhat8 python]# pycodestyle --first test.py 通过--show-source显示不符合规范的源码： [root@redhat8 python]# pycodestyle --show-source --show-pep8 test.py 使用autopep8将代码格式化   autopep8是一个开源的命令行工具，能够将Python代码自动格式化为PEP8风格，autopep8使用pycodestyle工具来决定代码中的哪些部分需要被可视化，安装方法： [root@redhat8 python]# pip install autopep8 使用方法（不指定--in-place选项，会将结果输出到命令行，使用--in-place选项后，将不会有任何输出）： [root@redhat8 python]# autopep8 --in-place test.py Python工具环境管理   在实际应用中，可能会同时用到Python2和Python3。学习两个工具：pyenv和virtualenv，前者用于管理不同的Python，后者用于管理不同的工作环境。 使用pyenv管理不同的Python版本 pyenv安装 直接从GitHub下载项目到本地，安装步骤如下： [root@redhat8 git-2.29.2]# git clone https://github.com/pyenv/pyenv.git ~/.pyenv Cloning into '/root/.pyenv'... git: 'remote-https' is not a git command. See 'git --help'. [huang@redhat8 ~]$ git clone git@github.com:pyenv/pyenv.git ~/.pyenv Cloning into '/root/.pyenv'... ssh: connect to host github.com port 22: Connection refused fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. 可能是虚拟机网络问题，使用windows系统clone下来: $ git clone git@github.com:pyenv/pyenv.git Cloning into 'pyenv'... Warning: Permanently added the RSA host key for IP address '192.30.255.112' to the list of known hosts. remote: Enumerating objects: 18376, done. remote: Total 18376 (delta 0), reused 0 (delta 0), pack-reused 18376 Receiving objects: 100% (18376/18376), 3.65 MiB | 1.26 MiB/s, done. Resolving deltas: 100% (12514/12514), done. 传到RHEL上，然后设置环境变量： [root@redhat8 pyenv]# cd /root/.pyenv [root@redhat8 .pyenv]# ls bin COMMANDS.md CONDUCT.md LICENSE plugins README.md terminal_output.png CHANGELOG.md completions libexec Makefile pyenv.d src test [root@redhat8 .pyenv]# echo 'export PYENV_ROOT=\"$HOME/.pyenv\"' >> ~/.bash_profile [root@redhat8 .pyenv]# echo 'export PATH=\"$PYENV_ROOT/bin:$PATH\"' >> ~/.bash_profile [root@redhat8 .pyenv]# echo 'eval \"$pyenv init -)\"' >> ~/.bash_profile 完成后需要重新载入配置文件，或者退出以后重新登录，也可以使用source命令重新载入配置文件，示例如下： [root@redhat8 .pyenv]# source ~/.bash_profile -bash: /root/.pyenv/bin/pyenv: Permission denied [root@redhat8 bin]# chmod 755 -R /root/.pyenv/bin [root@redhat8 bin]# source ~/.bash_profile /root/.pyenv/bin/pyenv: line 1: ../libexec/pyenv: Permission denied 各种尝试都是报错，权限问题或者跟我从windows传上来有关，等以后有空再研究。 使用vitualenv管理不同的项目   vitualenv本身是一个独立的项目，用以隔离不同项目的工作环境。上面的pyenv在RedHat上没安装成功，这个也等用到的时候再学。 "},"08-Python/08-Python系统管理&自动化运维笔记/02-Python运维-打造命令行工具.html":{"url":"08-Python/08-Python系统管理&自动化运维笔记/02-Python运维-打造命令行工具.html","title":"Python运维-打造命令行工具","keywords":"","body":"Python运维学习笔记-打造命令行工具 记录一些基础知识学习笔记。学习教材：《Python Linux系统管理与自动化运维》（赖明星著） 与命令行相关的Python语言特性 使用sys.argv获取命令行参数   在Python中，sys库下有一个名为argv的列表，保存了所有的命令行参数。例如下面的Python文件导入sys库，然后打印argv列表中的内容： from __future__ import print_function import sys print(sys.argv) 对上面文件进行运行测试： [root@redhat8 python]# python3 test_argv.py ['test_argv.py'] [root@redhat8 python]# python3 test_argv.py localhost 9527 ['test_argv.py', 'localhost', '9527'] 说明： 如果不传递任何参数，则sys.argv有且仅有一个元素，即Python程序名字 如果传递其它命令行参数时，所有的参数都以字符串的形式保存到sys.argv中 from __future__ import print_function在Python2的环境是使用Python3语句,我使用环境就是Python3，后续都不会加了，主要是print用法的区别   sys.argv是一个保存命令行参数的普通列表，可以直接修改sys.argv的内容，示例如下： import os import sys def main(): sys.argv.append(\"\") filename = sys.argv[1] if not os.path.isfile(filename): raise SystemExit(filename + ' does not exists') elif not os.access(filename, os.R_OK) raise SystemExit(filename + 'is not accessible') else: print(filename + ' is accessible') if __name__ == '__main__' main() 示例说明： 示例中，从命令行参数获取文件的名称，然后判断文件是否存在 如果文件不存在，则提示用户该文件不存在 如果文件存在，则使用os.access函数判断是否具有对文件的读权限 示例中通过sys.argv[1]获取文件的名称 如果用户直接运行程序不传递任何命令行参数，会出现索引越界的错误 避免此错误在访问sys.argv之前向其添加了一个空字符串sys.argv.append(\"\") 无论用户是否提供了命令行参数，在添加空字符串之后，访问sys.argv[1]都不会报错 如果用户传递了命令行参数，sys.argv[1]得到的是用户提供的命令行参数 使用sys.stdin和fileinput读取标准输入 使用sys.stdin   在Python标准库的sys库中，有stdin（标准输入）、stdout（标准输出）和stderr（错误输出）三个文件描述符。不需要调用open函数就可以直接使用，例如下面的read_stdin.py文件从标准输入中读取内容，然后打印到命令行终端： import sys for line in sys.stdin: print(line,end=\"\") 像shell脚本一样，通过标准输入给该程序输入内容： root@redhat8 python]# cat /etc/passwd |python3 read_stdin.py root:x:0:0:root:/root:/bin/bash ... [root@redhat8 python]# python3 read_stdin.py   可以使用sys.stdin调用文件对象的方法，如调用read函数读取标准输入中的所有内容，如下示例调用readlines函数将标准输入的内容读取到一个列表中： import sys def get_content(): return sys.stdin.readlines() print(get_content()) 使用fileinput   在Linux下，可以使用Python语言替代awk进行数据处理，awk对多文件处理提供了支持，在Python中可以使用fileinput进行多文件处理，可以依次读取命令行参数中给出的多个文件，fileinput会遍历sys.argv[1:]列表,如果列表为空，默认读取标准输入中的内容。例如文件read_from_fileinput.py： #!/usr/bin/python3 import fileinput for line in fileinput.input(): print(line,end=\"\") 示例说明： 示例中直接调用了fileinput模块的input方法按行读取内容 示例中先导入了fileinput模块，然后在for循环中遍历文件的内容 fileinput既可以从标准输入中读取数据，也可以从文件中读取数据，示例： [root@redhat8 python]# cat /etc/passwd |python3 read_from_fileinput.py root:x:0:0:root:/root:/bin/bash ... [root@redhat8 python]# python3 read_from_fileinput.py fileinput提供了一些方法告知当前所读取的内容属于哪一个文件： filename：当前正在读取的文件名 fileno：文件的描述符 fileineno：正在读取的行是当前文件的第几行 isfirstlin：正在读取的行是否当前文件的第一行 isstdin fileinput：正在读取文件还是直接从标准输入读取内容 这些方法的使用示例： #!/usr/bin/python3 import fileinput for line in fileinput.input(): mate = [fileinput.filename(),fileinput.fileno(),fileinput.filelineno(),fileinput.isfirstlin(),fileinput.isstdin()] print(*mate.end=\"\") print(*line.end=\"\") 使用SystemExit异常打印错误信息   sys.stdout与sys.stderr使用方法与sys.stdin类似，下面是示例分别使用sys.stdout与sys.stderr输出内容，文件名为test_stdout_stderr.py: import sys sys.stdout.write('Captain') sys.stderr.write('American')   通过重定向来验证'Captain'被输出到了标准输出，'American'被输出到了错误输出，示例如下： [root@redhat8 python]# python3 test_stdout_stderr.py > /dev/null American [root@redhat8 python]# python3 test_stdout_stderr.py 2> /dev/null Captain   一般情况下，不会直接用sys.stdout来输出内容，如果Python程序执行是被，需要在标准错误中输出错误信息，然后以非零的返回码退出程序，示例： import sys sys.stderr.write('error message') sys.exit(1) 也可以直接爆出一个SystemExit异常，示例如下： [root@redhat8 python]# cat test_system_exit.py raise SystemExit(\"Error Message\") [root@redhat8 python]# python3 test_system_exit.py Error Message [root@redhat8 python]# echo $? 1 使用getpass库读取密码   getpass主要包含getuser函数和getpass函数，前者用于从环境变量中获取用户名，后者用于等待用户输入密码，和input区别在于不会将输入显示在命令行中，使用示例： import getpass user = getpass.getuser('Please input your username: ') passwd = getpass.getpass('Please input your passwor: ') print(user,passwd) 使用ConfigParser解析配置文件   一个典型的配置文件包含一到多个（section），每个章节下面可以包含一个或多个选项（option），里面下面的MySQL配置文件： [client] port = 3306 user = mysql password = mysql host = 127.0.0.1 [mysqld] basedir = /usr datadir = /var/lib/mysql tmpdir = /tmp skip-external-locking   在Python3中，ConfigParse模块重命名为configparser，使用有细微差异。要解析一个配置文件，需先创建一个ConfigParse对象（名称自定义），然后用read方法读取配置文件，也可以使用readfp从一个已经打开的文件中读取配置： import configparser cf = configparser.ConfigParser(allow_no_value=True) cf.read('my.cnf')   参数allow_no_value默认取值是False，表示配置文件中是否允许选项没有值的情况，之前配置文件中skip-external-locking选项只有名称没有选区制，所有需指定allow_no_value值为True。ConfigParser中有很多方法，如下： sections：返回一个包含所有章节的列表 has_section：判断章节是否存在 items：以元组的形式返回所有选项 options：返回一个包含章节下所有选项的列表 get,getboolean,gitint,getfloat：获取选项的值 remove_section：删除一个章节 add_setcion：添加一个章节 remote_option：删除一个选项 set：添加一个选项 write将ConfigParser对象中的数据保存到文件中 以之前的MySQL配置文件为例，测试各种方法的使用： import configparser cf = configparser.ConfigParser(allow_no_value=True) cf.read('my.cnf') print(cf.get('client', 'host')) print(cf.sections()) print(cf.has_section('client')) cf.remove_option('mysqld','tmpdir') cf.remove_section('client') cf.add_section('mysql') cf.set('mysql','host','127.0.0.1') cf.write(open('new_my.cnf','w')) 运行示例如下： [root@redhat8 python]# python3 configparse_test.py 127.0.0.1 ['client', 'mysqld'] True [root@redhat8 python]# cat new_my.cnf [mysqld] basedir = /usr datadir = /var/lib/mysql skip-external-locking [mysql] host = 127.0.0.1 使用argparse解析命令行参数   在Python中，argparse是标准库中用来解析命令行参数的模块，能够根据程序中的定义从sys.argv中解析参数，并自动生成帮助和使用信息。 ArgumentParse解析器 创建解析器方式如下： import argparse parser = argparse.ArgumentParser()   ArgumentParser类的初始化函数有多个参数，比较常用的是description，是程序的描述信息，即帮助信息前的文字。为应用程序添加参数选项需要用ArgumentParser对象的add_argument方法，方法格式如下： add_argument(name or flags...[, action][, nargs][, const][, default][, type][, choices][, required][, help][, metavar][, dest]) 各参数含义： name/flags：参数的名字； action：遇到参数时的动作，默认值时store nargs：参数的个数，可以是具体的数组，或者“+”号（表示0或霍格参数）与“*”号（表示1或霍格参数） const action 和 nargs：需要的常量值 default：不指定参数时的默认值 type：参数的类型 choices：参数允许的值 required：可选参数是否可以省略 help：参数的帮助信息 metavar：在usage说明中的参数名称 dest：解析后的参数名称 示例以后用实例演示。 模仿MySQL客户端的命令行参数 MySQL几乎没接触，以后用到了再看。 使用logging记录日志 记录日志的两个目的： 诊断日志：记录与应用程序操作相关的日志 审计日志：为商业分析而记录的日志 Python的logging模块   直接导入logging模块，调用它的debug,info,warn,error和critical等函数记录日志。默认情况下打印WARRNING级别或更高级别日志到屏幕。示例如下： #!/usr/local/bin/python import logging logging.debug('debug message') logging.info('info meeeage') logging.warn('warn message') logging.error('error message') logging.critical('critical message') 执行后示例如下： [root@redhat8 python]# python3 logging_test.py WARNING:root:warn message ERROR:root:error message CRITICAL:root:critical message 各个日志级别的含义： 日志级别 权重 含义 CRITICAL 50 严重错误，表面软件已经不能继续运行了 ERROR 40 发生了严重的错误，必须马上处理 WARNING 30 应用程序可以容忍这些信息，软件还在正常工作，但是应该即使修复，避免后续发生问题 INFO 20 证明事情按预期工作，突出强调应用程序的运行过程 DEBUG 10 详细信息，只有开发人员调试程序时才需要关注的事情 配置日志格式   在使用logging记录日志之前，可以进行一些简单的配置，如下所示： #!/usr/local/bin/python # -*- coding:utf-8 -*- import logging logging.basicCconfig(filename='app.log',level=logging.INFO) logging.debug('debug message') logging.info('info meeeage') logging.warn('warn message') logging.error('error message') logging.critical('critical message')   执行程序，会在当前目录下产生一个app.log文件，文件中记录INFO及更高级别的日志信息。示例中使用basicCconfig进行了简单的配置，还可以进行更加复杂的日志配置： Logger：日志记录器，是应用程序中能直接使用的接口 Handler：日志处理器，用以表明将日志保存到什么地方以及保存多久 Formatter：格式化，用以配置日志的输出格式 下面是一个在Python源码中配置日志的示例： #!/usr/local/bin/python # -*- coding:utf-8 -*- import logging logging.basicCconfig( level=logging.DEBUG, format='%(asctime)s : %(levelname)s : %(message)s', filename=\"app.log\" ) logging.debug('debug message') logging.info('info meeeage') logging.warn('warn message') logging.error('error message') logging.critical('critical message') 对于复杂的项目，一般将日志配置保存到配置文件中，例如下面配置文件： [loggers] keys = root [handlers] keys = logfile [formatters] keys = generic [logger_root] handlers = logfile [handler_logfile] class = handlers.TimeRotatingFileHandler args = ('app.log','midnight',1,10) level = DEBUG fomatter = generic [fomatter_generic] format=%(asctime)s %(levelname)-5.5s [%(name)s:%(lineno)s] %(message)s 配置说明： 在[loggers]中声明一个名为root的logger 在[handlers]中声明一个名为logfile的handler 在[formatters]中声明一个名为generic的formatter 在[logger_root]中定义root这个logger所使用的handler 在[handler_logfile]中定义handler输出日志的方式、日志文件的切换时间等 最后在[fomatter_generic]定义了日志的格式，包括日志产生时间、日志级别、产生日志文件名和行号等信息   在Python中，使用logging.config模块的fileConfig函数加载日志配置，如下所示： #!/usr/local/bin/python # -*- coding:utf-8 -*- import logging import logging.config logging.config.fileConfig('logging.cnf') logging.debug('debug message') logging.info('info meeeage') logging.warn('warn message') logging.error('error message') logging.critical('critical message') 与命令行相关的开源项目 学习两个与命令行工具相关的开源项目。官方网站：https://click.palletsprojects.com/en/5.x/ 使用click解析命令行参数   Click是Flask的作者开发的一个第三方模块，用于快速创建命令行。作用与argparse相同，但使用更加简单。在使用前需要先安装： # pip install click 使用click步骤： 使用@click.command()装饰一个函数，使之成为命令行接口 使用@click.option()等装饰函数，为其添加命令行选项等 使用Click官方文档中的示例： import click @click.command() @click.option('--count',default=1,help='Number of greetings.') @click.option('--name',prompt='Your name',help='The person to gteet.') def hello(count,name): \"\"\"Simple prigram that greets NAME for a total of COUNT times.\"\"\" for x in range(count): click.echo('Hello %s!' % name) if __name__ == '__main__': hello() 示例说明： 示例中，函数hello接收两个参数，它们的取值从命令行中获取 示例中使用ckick模块中的command、option和echo： command：使函数hello成为命令行接口 option：增加命令行选项 echo：输出结果，使用echo是为了获取更好兼容性，在python2中print是一个语句，而python3中是一个函数 在option中使用了prompt函数，当没有直接指定name参数时，会提示在交互模式下输入 运行示例： [root@redhat8 python]# python3 test_click.py Your name: redhat Hello redhat! [root@redhat8 python]# python3 test_click.py --count 2 Your name: ROOT Hello ROOT! Hello ROOT! click和argparse一样，会自定产生帮助信息： [root@redhat8 python]# python3 test_click.py --help Usage: test_click.py [OPTIONS] Simple prigram that greets NAME for a total of COUNT times. Options: --count INTEGER Number of greetings. --name TEXT The person to gteet. --help Show this message and exit. option常用的设置参数如下： default：设置命令行参数的默认值 help：参数说明 type：参数类型，可以是string、int、float等 prompt：档名和中没有输入相应参数时，会根据prompt提示用户输入 nargs：指定命令行参数接受的值的个数   如果命令行参数只能取固定的几个值之一，可以使用Choice函数，Choice函数的参数是一个列表，列表中列出所有的可能值，示例如下： import click @click.command() @click.option('--hash_type',type=click.Chioce(['md5','shal'])) def digest(hash_type): click.echo(hash_type)   如果需要输入密码，设置prompt为True就能交互式输入密码，hide_input为True可以隐藏命令行输入，设置confirmation_prompt为True可以进行密码两次验证，示例如下： import click @click.command() @click.option('--password',prompt=True,hide_input=True,confirmation_prompt=True) def encrypt(password): click.echo('Encrypting password to %s' % password.encode('rot13')) if __name__ == '__main__': encrypt() 运行示例（会提示unknown encoding:rot13，应该是RHEL8中没有）： [root@redhat8 python]# python3 test_click_1.py Password: Repeat for confirmation:   在Bash中有fc命令编辑比较长的输入，比如输错了一个较长的命令，可以运行fc命令打开一个编辑器，编辑器保存了上一条命令内容，编辑修复错误的输入，退出后会自动运行编辑后的命令。使用Click也可以实现类似的功能，如下所示： import click message = click.edit() print(message,end=\"\") 使用prompt_toolkit打造交互式命令行工具   prompt_toolkit是一个处理交互式场景的开源库，用来取代开源的readline与curses，prompt_toolkit有很多高级功能，特性如下： 语法高亮 支持多行编辑 支持代码补全 支持自动提示 可以使用鼠标移动光标 支持Emacs与Vi风格的快捷键 支持查询历史 对Unicode支持友好 使用Python语言开发，跨平台 使用之前需要先安装： [root@redhat8 ~]# pip install prompt_toolkit   下面示例是Python开发的REPL（读取-求值-输出）应用,用户输入数据，Python程序打印用户的输入： while True: user_input = raw_input('>') print(user_input)   示例中，无法使用任何Linux下的快捷键，退格或删除都会出现问题，使用prompt_toolkit中的prompt函数来接受输入，就可以使用bash下的常用快捷键： from prompt_toolkit import prompt while True: user_input = prompt('>') print(user_input) 使用示例： [root@redhat8 python]# python3 test_prompt.py >Miracles happen every day. Miracles happen every day.   prompt_toolkit也可以实现查找历史的功能，使用prompt_toolkit.history模块下的FileHistory类，然后调用prompt时构造的FileHistory对象，并传递给history参数： from __future__ import unicode_literals from prompt_toolkit import prompt from prompt_toolkit.history import FileHistory while True: user_input = prompt('>', history=FileHistory('history.txt') ) print(user_input)   还可以利用历史输入的数据，在用户输入时进行自动提示，在调用prompt函数时指定auto_suggest参数即可： from __future__ import unicode_literals from prompt_toolkit import prompt from prompt_toolkit.history import FileHistory from prompt_toolkit.auto_suggest import AutoSuggestFromHistory while True: user_input = prompt('>', history=FileHistory('history.txt'), auto_suggest=AutoSuggestFromHistory() ) print(user_input)   输入两行字符串，随后输入匹配的历史输入时，就会以暗色字体显示匹配的历史输入，回车即可自动输入，运行示例如下图：   bash中tab键补全会选择提示的内容，使用prompt_toolkit中一个名为WordCompleter的函数即可实现，会将用户输入与可能建议的字典进行匹配，并提供一个列表，使用tab键从列表中进行选项，示例如下： from __future__ import unicode_literals from prompt_toolkit import prompt from prompt_toolkit.history import FileHistory from prompt_toolkit.auto_suggest import AutoSuggestFromHistory from prompt_toolkit.contrib.completers import WordCompleter SQLCompleter = WordCompleter(['select','from','insert','update','delete','drop'],ignore_case=True) while True: user_input = prompt('>', history=FileHistory('history.txt'), auto_suggest=AutoSuggestFromHistory(), completer=SQLCompleter ) print(user_input) 在python3中运行后提示无法import WordCompleter，查了下可能时兼容性问题。 "},"08-Python/08-Python系统管理&自动化运维笔记/03-Python运维-文本处理.html":{"url":"08-Python/08-Python系统管理&自动化运维笔记/03-Python运维-文本处理.html","title":"Python运维-文本处理","keywords":"","body":"Python运维学习笔记-文本处理   文本处理主要是一些基础字符串处理及正则表达式处理文本的知识，之前在Python基础学习中已经有所学习记录，此处记录一些编码及Jinja2模板学习笔记。学习教材：《Python Linux系统管理与自动化运维》（赖明星著） 字符集编码 学习字符集编码的历史，Unicode的概念及Python程序中如何处理字符集编码问题。 编码历史   ASCII编码将128个英文字符和符号映射到一个字节后的7bit，只有128个英文字符和符号，局限性很大。Unicode（万国码，国际码，统一码）时计算机科学领域李的一项业界标准，能够将实际上所有的符号都纳入其中。Unicode编码范围值0至0x10FFFF,通常记作U+xxxx，在Python中一般记作\\uxxxx，其中xxxx为十六进制的数字。 UTF-8编码   Unicode制定了各种存储编码的方式，称作UTF(Uniform Transformation Format)，流行的有UTF-8、UTF-16和UTF-32。实际工作中，大部分情况下使用UTF-8，主要因为： UTF-8采用字节为编码单元，不存在字节的大端和小端问题 UTF-8中每个ASCII字符只需一个字节去存储，向后兼容，也就是一个ASCII文本本身也是一个UTF-8的文本 UTF-8编码规则： 对于单字节的字符，字节的第一位设为0，后7位为这个符号的unicode码，对于英文字母，UTF-8编码和ASCII码时相同的 对于x字节的符号，第一个字节千x位都这位1，第x+1位设为0，后面的字节前两位一律设为10，其它二进制位为这个符号的unicode码 编码语法表如下： Unicode符号范围 UTF-8编码方式 0000 0000-0000 007F 0xxxxxxx 0000 0080-0000 07FF 110xxxxx 10xxxxxx 0000 0800-0000 FFFF 1110xxxx 10xxxxxx 10xxxxxx 0001 0000-0010 FFFF 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 示例如下： >>> name = '黄' >>> name '黄' >>> name.encode('utf-8') b'\\xe9\\xbb\\x84' 字符集问题   在Python3中默认使用Unicode，书中使用Python2示例，我使用Python3示例不了书中的问题，略过此节： >>> name = '刘德华' >>> name '刘德华' >>> print(name) 刘德华 >>> len(name) 3 >>> name[0:1] '刘' Python中的Unicode   在Python3中，字符串默认时Unicode，在Python2中使用Unicode需要在字符串签名加上一个“u”前缀，如果需要默认使用Unicode的字符串，可以使用下面方法导入： >>> name = u'刘德华' >>> from __future__ import unicode_literals Python3中，内置的open函数可以指定字符集编码： >>> name '刘德华' >>> with open('/tmp/data.txt','w',encoding='utf-8') as f: ... f.write(name)   在Python编程中，应该把编码和解码操作放在程序的最外围来处理，程序的核心部分都是用Unicode，可以在代码中使用下面的辅助函数，函数能够接受str或Unicode类型并返回需要的字符串类型，Python3的字符集处理辅助函数： def to_str(bytes_or_str): if isinstance(bytes_or_str,bytes): value = bytes_or_str.decode('utd-8') else: value = bytes_or_str return value def to_bytes(bytes_or_str): if isinstance(bytes_or_str,str): value = bytes_or_str.decode('utd-8') else: value = bytes_or_str return value Jinja2模板 学习在Python的web开发中广泛使用的模板语言Jinja2。 模板介绍   作为工程师，可以使用Jinja2管理工作中的配置文件，Ansible就是用Jinja2来管理配置文件。Python的标准库自带了一个简单的模板，但功能有限，无法在模板中使用控制语句和表达式，不支持继承和重用等操作。模板使用示例： >>> from string import Template >>> s = Template('$who is a $role') >>> s.substitute(who='Thor',role='God') 'Thor is a God' >>> s.substitute(who='Captain America',role='SuperHero') 'Captain America is a SuperHero' Jinja2语法入门   Jinja2是Flask作者开发的一个模板系统，其灵活、快速和安全等优点被广泛使用，主要具有以下优点： 相对于Template，Jinja2更加灵活，提供了控制结构、表达式和继承等 相对于Mako，Jinja2提供了仅有的控制结构，不允许在模板中编写太多的业务逻辑，避免乱用 相对于Django模板，Jinja2的性能更好 Jinja2模板的可读性很好 如果安装了Flask，Jinja2会随之安装，也可以进行单独安装： [root@redhat8 ~]# pip install jinja2 [root@redhat8 ~]# python3 -c \"import jinja2\" 语法块   Jinja2可以应用于任何基于文本的格式，如HTML和XML。Jinja2使用大括号的方式表示Jinja2的语法，主要有三种语法： 控制结构{% %} 变量取值{{ }} 注释{# #} 示例如下： {# note:disable template because we no longer user this {% for user in users %} ... {% endfor %} #}   在Jinja2中for循环使用与Python类似，但没了复合语句末尾的冒号，需要使用endfor作为结束标志，if语句也一样，需要使用endif作为结束标志，示例如下： {% if users %} {% for user in users %} {{ user.username }} {% endfor %} {% endif %} 变量   Jinja2模板中使用{{ }}语法表示一个变量。Jinja2识别所有的Python数据类型，包括复杂的数据类型，例如列表、字典和对象等，如下所示： A value from a dictionary: {{ mydict['key'] }}. A value from a list: {{ mylist[3] }}. A value from a list,with a variable index: {{ mylist[myintvar] }}. A value from an object's method: {{ myobj.somemethod() }}. Jinja2中的过滤器   变量可以通过“过滤器”进行修改，可以理解为Jinja2中的内置函数和字符串处理函数，常用的过滤器如下表所示： 过滤器名 说明 safe 渲染值时不转义 capitalize 把值的首字母转换成大写，其它字母转换成小写 lower 把值转换成小写形式 upper 把值转换成大写形式 title 把值中每个单词的首字母都转换成大写 trim 把值的首位空格去掉 striptags 渲染之前把值中所有的HTML标签都删掉 join 拼接多个值为字符串 replace 替换字符串的值 round 默认对数字进行四舍五入，也可以用参数进行控制 int 把值转换成整型 过滤器与变量通过管道（|）分割，多个过滤器可以链式调用，前一个过滤器的输出会作为后一个过滤器的输入，示例如下： {{ \"Hello World\" | replace(\"Hello\",\"Good\") }} ->Good World {{ \"Hello World\" | replace(\"Hello\",\"Good\") | upper }} ->GOOD WORLD {{ 58.59 | round }} ->59.0 {{ 58.59 | round | int }} ->59 更多过滤器可以参考官方文档： https://jinja.palletsprojects.com/en/2.11.x/templates/#builtin-filters Jinja2的控制结构   if语句类似Python中if语句，但需要使用endif作为结束标志，可以判断一个变量是否定义，是否为空，是否为真值，也可以使用elif和else构建多个分支，示例如下： {% if Thanos.sick %} Thanos is sick. {% elif Thanos.dead %} Thor kill Thanos!He is a superhero! {% else %} Thanos looks okay! {% endif %} Jinja2的for循环   Jinja2中的for循环用于迭代Python的数据类型，包括列表、元组和字典，在Jinja2中不存在while循环。在Jinja2中迭代列表示例如下： Members {% for user in users %} {{ user.username }} {% endfor %} 遍历字典示例： {% for key,value in d.iteritems() %} {{ key }} {{ value }} {% endfor %}   Jinja2还提供了一些特殊变量，不需要定义就可以直接使用，如下表所示： 变量 描述 loop.index 当前循环迭代的次数（从1开始） loop.index0 当前循环迭代的次数（从0开始） loop.revindex 到循环结束的次数（从1开始） loop.revindex0 到循环结束的次数（从0开始） loop.first 如果是第一次迭代，为True，否则为False loop.last 如果是最后一次迭代，为True，否则为False loop.length 序列中的项目数 loop.cycle 在一串序列间取值的辅助函数   有一个联系人信息的字典，key是名字，value是电话，想以表格的形式显示在HTML页面上，还希望第一列是序号，在Python代码中实现示例如下： data = dict(Thor=13856788888,Hulk=18675557777,Batman=18033339999) index = 0 for key,value in data.viewtiems(): index += 1 print(index,key,value,sep=\",\") 在Jinja2中示例如下： {% for key,value in data.iteritems() %} {{ loop.index }} {{ key }} {{ value }} {% endfor %} Jinja2的宏   宏类似于编程语言中的函数，用于将行为抽象成可重复调用的代码块，与函数一样，宏分为定义和嗲用，示例如下： {% macro input(name,type='text',value='') %} {% endmacro %} 宏说明： 在宏的定义中，使用macro关键字定义一个宏，input是宏的名称 input有三个参数，分别是name、type和value，其中type和value参数有默认值 与Jinja2中的for循环一样，不需要使用符合语句的冒号，用endmacro结束宏的定义 下面是宏的调用示例： {{ input('username',value='user') }} {{ input('password','password') }} {{ input('submit','submit','Submit') }} Jinja2的继承和Super函数   使用Jinja2进行文件管理，级别用不到继承功能，如果是进行web开发，Jinja2的继承功能使用广泛，最强大的部分就是模板继承。模板允许构建一个包含站点的共同元素的基本模板的“骨架”，并定义子模版可以覆盖的块。例如有个base.html的文档，内容如下： {% bolck head %} {% block title %}{% endblock %}-My Homepage {% endblock %} {% block content %}{% endblock %}   在base.html中，使用{% bolck name %}的方式定义了三个块，这些块可以在子模块中进行替换或调用。下面是名为index.html的文档，内容如下： {% extends \"base.html\" %} {% block title %}Index{% endblock %} {% block head %} {{ super() }} .important { color: #336699; } {% endblock %} {% block content %} Index Welcome on my homepage. {% endblock %}   在index.html中，使用{% extends \"base.html\" %}继承base.html后，其中的所有内容都会在index.html中展现，并在index.html中重新定义了title和contend这两个块的内容。 Jinja2的其它运算   Jinja2提供了算数操作、比较操作和逻辑操作，使用Jinja2模板时，尽量在Python代码中进行逻辑处理，在Jinja2中仅处理显示问题，所以一般很少使用Jinja2的变量和变量的运算操作，部分运算操作如下： 算数运算：+-*/ // % * ** 比较运算：== != > >= 逻辑运算：not and or Jinja2实战   在Flask中使用Jinja2，只需使用Flask包下的render_template函数访问模板即可。如果使用Jinja2管理配置文件，需要了解Jinja2提供的API。  Jinja2模板中有Environment类，用于存储配置和全局对象，然后从文件系统或其它位置加载模板。大多数应用会在初始化时创建一个Environment对象并用它加载模板，配置Jinja2为应用加载文档的最简单方式如下： from jinja2 import Environment, PackageLoader env = Environment(loader=PackageLoader('yourapplication','templates'))   上面代码创建了一个Environment对象和一个包加载器，该加载器会在yourapplication这个Python的templates目录下查找模板。然后以模板的名字作为参数调用Environment.get_template方法杰克，会返回一个模板，最后使用模板的render方法进行渲染，如下所示： template = env.get_template('mytemplate.html') print(template.render(the='variables',go='here'))   除使用包加载器外，还可以使用文件系统加载器，不需要模板位于一个Python包下，可以直接访问系统中的文件。便于功能演示，在接下来的例子中使用下面这个辅助函数： import os import jinja2 def render(tpl_path,**kwargs): path,falename = os.path.split(tpl_path) return jinja2.Environment( loader=jinja2.FileSystemLoader(path or './') ).get_template(filename).render(**kwargs) 基本功能演示 学习模板渲染示例，例如有一个名为simple.html的文件，内容如下： {{ title | trim }} {# This is a Comment #} {% for item in items %} {{ item['cation'] }} {% endfor %} {{ content }} 示例说明： 在示例HTML模板中，使用for循环遍历一个列表，列表中每一项是一个字典 字典中包含了文字和链接，将使用字典中的数据渲染成HTML的超链接 示例中还使用了Jinja2提供的过滤器trim删除title中的空格 执行下面Python代码： import os import jinja2 def render(tpl_path,**kwargs): path,falename = os.path.split(tpl_path) return jinja2.Environment( loader=jinja2.FileSystemLoader('./') ).get_template('simple.html').render(**kwargs) def test_simple(): title = \"Title H \" items = [{'herf':'big1000.com','caption':'big1000'},{'herf':'google.com','caption':'go ogle'}] content=\"This is content\" result = render('simple.html',**locals()) print(result) if __name__ == '__main__': test_simple() 执行后渲染模板结果如下： [root@redhat8 jinja2]# python3 simple.py Title H This is content   示例中，使用Jinja2渲染模板后title中的空格已经被删除，for循环也正确渲染了多个超链接标签。 继承功能演示 使用base.html和index.html演示继承功能。base.html内容如下： {% block head %} {% block title %}{% endblock %} - My HomePage {% endblock %} {% block content %} {% endblock %} {% block footer %} {% endblock %} index.html内容如下： {% extends \"base.html\" %} {% block title %}Index{% endblock %} {% block head %} {{ super() }} .important { color:#3333FF; } {% endblock %} {% block content %} This is h1 content Welcome on my homepage {% endblock %} 使用下面的Python代码渲染Jinja2模板： import os import jinja2 def render(tpl_path,**kwargs): path,falename = os.path.split(tpl_path) return jinja2.Environment( loader=jinja2.FileSystemLoader('./') ).get_template(index.html).render(**kwargs) def test_extend(): result = render('index.html') print(result) if __name__ == '__main__': test_extend() 渲染后生成的结果如下： [root@redhat8 jinja2]# python3 extend.py Index - My HomePage .important { color:#3333FF; } This is h1 content Welcome on my homepage 示例说明： 示例中渲染的是index.html，并没有直接渲染base.html，但最后生成的模板中保护玩的HTML框架 虽然在index.html中定义了title模块，但示例中使用{{ super() }}引用了base.html中的HEAD模块，所以最后渲染结果中有base.html中的head块和index.html中的head块，结果中的Index - My HomePage就是来自于此 示例在index.html中重新定义了content块的内容，所以最后生成的文档中正确位置显示了content块的内容 案例演示 使用Jinja2生成HTML表格和XML配置文件。 使用Jinja2生成HTML表格 "},"08-Python/08-Python系统管理&自动化运维笔记/04-Python运维-Linux系统管理.html":{"url":"08-Python/08-Python系统管理&自动化运维笔记/04-Python运维-Linux系统管理.html","title":"Python运维-Linux系统管理","keywords":"","body":"Python运维学习笔记-Linux系统管理 学习教材：《Python Linux系统管理与自动化运维》（赖明星著） 文件读写   文件可以进行多维度管理，例如重命名文件、获取文件属性、判断是否存在、备份文件及读写文件等。此小节主要学习文件的读写操作。 Python内置的open函数   Python内置的open函数可以打开文件，函授接受文件名和打开模式作为参数，返回一个文件对象，用户通过文件对象来操作文件，完成后使用close方法关闭即可。使用示例如下： >>> a = open('extend.py') >>> print(a.read()) import os import jinja2 def render(tpl_path,**kwargs): path,falename = os.path.split(tpl_path) return jinja2.Environment( loader=jinja2.FileSystemLoader('./') ).get_template('index.html').render(**kwargs) def test_extend(): result = render('index.html') print(result) if __name__ == '__main__': test_extend() >>> a.close() >>> open函数默认以'r'模式打开，也可以指定文件的打开模式，如下表所示： 模式 含义 'r' 默认以读模式打开文件，如果文件不存在，抛出FileNotFoundError异常 'w' 以写模式打开文件，如果文件非空，则文件已有的内容会被清空；如果文件不存在则创建文件 'x' 创建一个新的文件，如果文件已经存在，抛出FileExistsError异常 'a' 在文件末尾追加文件 演示示例如下： >>> a = open('test.txt','w') >>> [root@redhat8 jinja2]# ls base.html extend.py index.html simple.html simple.py test.txt >>> a = open('test.txt','w') >>> a.write('Miracles happen evary day!') 26 >>> a.close() >>> a = open('test.txt','x') Traceback (most recent call last): File \"\", line 1, in FileExistsError: [Errno 17] File exists: 'test.txt' >>> a = open('test1.txt','x') >>> a.write('Miracles happen evary day!') 26 >>> a.close() [root@redhat8 jinja2]# cat test1.txt Miracles happen evary day! 避免文件句柄泄露   计算机程序中，每打开一个文件就需要占用一个文件句柄，一个进程拥有的文件句柄数是有限的。Python中使用finally语句来关闭文件句柄，任何情况下都会被关闭，示例如下： try: f = open('test.txt') print(f.read()) finally: f.close()   Python中有更简洁优美的写法，即使用上下文管理器，使用上下文管理器处理文件打开、处理在再关闭的代码如下： with open('test.txt') as f: print(f(read)) 常见文件操作函数   Python的文件对象有多种类型的函数，刷新缓存的flush函数，获取文件位置的tell函数，改变文件读取偏移量的seek函数。使用比较多的是读写类函数： read：读取文件中的所有内容 readline：一次读取一行 readlines：将文件内容存到一个列表中，列表中的每一行对应于文件中的一行 write：写字符串到文件中，并返回写入的字符数 writelines：写一个字符串列表到文件中 读函数示例： >>> f = open('test.txt') >>> f.read() 'Miracles happen evary day!\\nI was messed up for a long time.\\n' >>> f.seek(0) 0 >>> f.readline() 'Miracles happen evary day!\\n' >>> f.seek(0) 0 >>> f.readlines() ['Miracles happen evary day!\\n', 'I was messed up for a long time.\\n'] 注意：read和readlines函数都是一次将所有内容读入到内存中，如果处理大文件，可能为出现Out Of Memory错误。写函数示例： >>> f = open('test2.txt','w') >>> f.write('Stupid is as stupid does.') 25 >>> f.writelines(['Miracles happen evary day!\\n', 'I was messed up for a long time.\\n']) [root@redhat8 jinja2]# cat test2.txt Stupid is as stupid does.Miracles happen evary day! I was messed up for a long time.   Python中还可以使用print函数将结果输出到文件中，比write和writelines函数更加灵活，示例如下： with open('test.txt','w') as f: print(1,2,'You cannot change the past',seq\",\",file=f) Python的文件是一个可迭代对象   在Python中，Python的文件对象实现了迭代器协议，for循环可以使用迭代器协议遍历可迭代对象，所以可以使用for循环遍历文件，用来依次处理文件的内容，for循环遍历文件内容的代码如下： with open('test.txt') as inf: for line in inf: print(line.upper()) 案例 将文件中所有的单词的首字母变成大写。为方便查阅，收录在Python运维-Linux系统管理实例 文件与文件路径管理   Python标准库的os模块对操作系统的API进行了封装，并使用统一的API访问不同的操作系统。os模块包含与操作系统的系统环境、文件系统、用户数据库以及权限进行交互的函数。 使用os.path进行路径和文件管理   os模块下getcwd函数和listdir函数，getcwd函数用来获取当前目录，listdir函数用来列出目录下的所有文件和文件夹，示例如下： >>> os.getcwd() '/python/jinja2' >>> os.listdir('.') ['simple.py', '.simple.html.swp', 'simple.html', 'index.html', 'extend.py', 'base.html', ' test1.txt', 'test.txt', 'test2.txt', 'test3.txt', 'captialize.py'] 拆分路径   os.path模块用来对文件和路径进行管理，它包含很多拆分路径的函数，相关函数有： split：返回一个二元组，包含文件的路径与文件名 dirname：返回文件的路径 basename：返回文件的文件名 splitext：返回一个除去文件扩展名的部分和扩展名的二元组 这几个函数功能示例如下： >>> import os >>> path = '/python/jinja2/test.txt' >>> os.path.dirname(path) '/python/jinja2' >>> os.path.split(path) ('/python/jinja2', 'test.txt') >>> os.path.basename(path) 'test.txt' >>> os.path.splitext(path) ('/python/jinja2/test', '.txt') 构建路径   os.path也包含了用以构建路径的函数，最常用的是expanduser、abspath和join函数： expanduser：展开用户的HOME目录，如~、~username abspath：得到文件或路径的绝对路径 join：根据不同的系统平台，使用不同的路径分隔符拼接路径 这几个函数功能示例如下： >>> import os >>> os.path.expanduser('~') '/root' >>> os.path.expanduser('~huang') '/home/huang' >>> os.path.abspath('.') '/python/jinja2' >>> os.path.abspath('./test.txt') '/python/jinja2/test.txt' >>> os.path.join('~','test','test.py') '~/test/test.py' >>> os.path.join(os.path.expanduser('~huang'),'test','test.py') '/home/huang/test/test.py' os.path模块中isabs函数用来检查一个路径是否为绝对路径： >>> os.path.isabs('/python/jinja2/test.txt') True >>> os.path.isabs('.') False   在Python中，可以使用__file__这个特殊的遍历表示当前代码所在的源文件。在编写代码时，有时需要导入当前源文件父目录下的软件包，代码如下： #!/usr/bin/python3 #_*_ coding: UTF-8 _*_ import os print('Current directory:',os.getcwd()) path = os.path.abspath(__file__) print('Full path of current file:',path) print('Parent directory of current file:', os.path.abspath(os.path.join(os.path.dirname(path),os.path.pardir))) 运行后示例： [root@redhat8 jinja2]# python3 test.py Current directory: /python/jinja2 Full path of current file: /python/jinja2/test.py Parent directory of current file: /python 获取文件属性   os.path模块也包含了若干函数用来获取文件的属性，包括文件的创建时间、修改时间、文件大小等： getatime：获取文件的访问时间 getmtime：获取文件的修改时间 getctime：获取文件的创建时间 getsize：获取文件的大小 判断文件类型   os.path模块中有若干函数来判断路径是否存在，以及路径所指文件的类型，这类函数一般以is开头，并返回一个Boolean型结果： exists：参数path所指向的路径是否存在 isfile：参数path所指向的路径存在，并且是一个文件 isdir：参数path所指向的路径存在，并且是一个文件夹 islink：参数path所指向的路径存在，并且是一个链接 ismount：参数path所指向的路径存在，并且是一个挂载点 获取当前用户home目录下的所有文件列表： [item for item in os.listdir(os.path.expanduser('~')) if os.path.isfile(item)] 获取当前用户home目录下的所有目录列表： [item for item in os.listdir(os.path.expanduser('~')) if os.path.isdir(item)] 获取当前用户home目录下的所有目录的目录名到绝对路径之间的字典： {item: os.path.realpath(item) for item in os.listdir(os.path.expanduser('~')) if os.path.isdir(item)} 获取当前用户home目录下的所有文件到文件大小之间的字典： {item: os.path.getsize(item) for item in os.listdir(os.path.expanduser('~')) if os.path.isfile(item)} 使用os模块管理文件和目录 os模块的文件和目录的操作函数： chdir：修改当前目录 unlink/remome：删除path路径所指向的文件 rmdir：删除path路径所指向的文件夹，该文件夹必须为空，否则报错 mkdir：创建一个文件夹 rename：重命名文件或文件夹 使用示例： >>> import os >>> os.getcwd() '/python/jinja2' >>> os.chdir(os.path.expanduser('~')) >>> os.getcwd() '/root' [root@redhat8 test]# ls 11.png 12.png test1 test1.py test2 test2.py test.py >>> os.remove('11.png') >>> os.unlink('12.png') >>> os.rmdir('test1') >>> os.removedirs('test2') [root@redhat8 test]# ls test1.py test2.py test.py >>> os.mkdir('test3') >>> os.rename('test2.py','test3.py') [root@redhat8 test]# ls test1.py test3 test3.py test.py   os模块也包含了文件权限、判断文件权限的函数，即chmod和access，用三个常量来表示读、写、可执行权限，即R_OK、W_OK、X_OK，示例如下： #!/usr/bin/python #_*_ coding: UTF-8 _*_ import os import sys def main(): sys.argv.append('') filename = sys.argv[1] if not os.path.isfile(filename): raise SystemExit(filename + ' does not exists!') elif not os.path.access(filename,os.R_OK): os.chmod(filename,0777) else: with open(filename) as f: print(f.read()) if __name__ == '__main__': main() 示例说明： 示例中首先通过命令行读取文件的名称，先判断文件是否存在，如果不存在就直接退出 然后判断文件是否具有读权限，如果没有，则将文件赋予777权限 如果文件存在并且具有读权限，则读取文件内容 案例：打印最常用的10条Linux命令 为方便查阅，收录在Python运维-Linux系统管理实例 查找文件 使用fnmatch找到特定的文件 下面示例使用字符串匹查找可以找到当前目录下所有的文本文件： >>> [item for item in os.listdir('.') if item.endswith('.txt')] ['test1.txt', 'test.txt', 'test2.txt', 'test3.txt']   需要更加灵活的字符串匹配，可以使用标准库的fnmatch库，此库专门用来进行文件名匹配，支持通配符进行字符串匹配，支持通配符： 通配符 含义 * 匹配任何数量的字符 ? 匹配单个字符 [seq] 匹配seq中的字符 [!seq] 匹配除了seq以外的任何字符 fnmatch库有四个函数： fnmatch：判断文件名是否符合特定的模式 fnmatchcase：判断文件名是否符合特定的模式，不区分大小写 filter：返回输入列表中，符合特定模式的文件名列表 translate：将通配符模式转换成正则表达式 使用fnmatch函数示例如下： [root@redhat8 fnmatch]# touch {a..b}1.txt {c..d}2.png >>> import os >>> import fnmatch >>> os.listdir('.') ['a1.txt', 'b1.txt', 'c2.png', 'd2.png'] >>> [name for name in os.listdir('.') if fnmatch.fnmatch(name,'*.png')] ['c2.png', 'd2.png'] >>> [name for name in os.listdir('.') if fnmatch.fnmatch(name,'[a-c]*')] ['a1.txt', 'b1.txt', 'c2.png'] >>> [name for name in os.listdir('.') if fnmatch.fnmatch(name,'[a-c]?.txt')] ['a1.txt', 'b1.txt'] >>> [name for name in os.listdir('.') if fnmatch.fnmatch(name,'[!a-c]*')] ['d2.png']   filter与fnmatch函数类似，区别在于fnmatch每次对一个文件名进行匹配判断，filter函数每次对一组文件名进行匹配判断。filter接受文件名列表位第一个参数，文件名模式位第二参数，示例如下： >>> names = os.listdir('.') >>> names ['a1.txt', 'b1.txt', 'c2.png', 'd2.png'] >>> fnmatch.filter(names,\"[a-c]?.txt\") ['a1.txt', 'b1.txt'] >>> fnmatch.filter(names,\"[!a-c]*\") ['d2.png'] 使用glob找到特定的文件   glob相当于os.lsitdir加上fnmatch，使用glob后不需要调用os.lsitdir获取文件列表，直接通过模式匹配即可，示例如下： >>> import glob >>> glob.glob('*.txt') ['a1.txt', 'b1.txt'] >>> glob.glob('[a-c]?.png') ['c2.png'] >>> glob.glob('[!a-c]?.png') ['d2.png'] 使用os.walk遍历目录树   walk函数遍历某个目录及其子目录，对于每一个目录，返回一个三元组(dirpath,dirnames,filenames),dirpath保存当前目录，dirnames是当前目录下的子目录列表，filenames是当前目录下的文件列表，使用示例如下： #!/usr/bin/python #_*_ coding: UTF-8 _*_ import os import fnmatch files = ['*.py','*.html'] matches = [] for root,dirnames,filenames in os.walk(os.path.expanduser(\"/python\")): for extensions in files: for filename in fnmatch.filter(filenames,extensions): matches.append(os.path.join(root,filename)) print(matches) 运行后示例如下： [root@redhat8 python]# python3 walk.py ['/python/test_pdb.py', '/python/test_argv.py', '/python/read_stdin.py', '/python/read_fro m_fileinput.py', '/python/test_stdout_stderr.py', '/python/test_system_exit.py', '/python/test_click.py', '/python/test_click_1.py', '/python/test_prompt.py', '/python/test_prompt1.py', '/python/walk.py', '/python/configparse_test.py', '/python/logging_test.py', '/python/test_prompt2.py', '/python/git-2.29.2/git-p4.py', '/python/git-2.29.2/contrib/fast-import/import-zips.py', '/python/git-2.29.2/contrib/hg-to-git/hg-to-git.py', '/python/git-2.29.2/contrib/hooks/multimail/git_multimail.py', '/python/pyenv/plugins/python-build/scripts/add_miniconda.py', '/python/jinja2/simple.py', '/python/jinja2/extend.py', '/python/jinja2/captialize.py', '/python/jinja2/test.py', '/python/jinja2/simple.html', '/python/jinja2/index.html', '/python/jinja2/base.html', '/python/jinja2/test/test1.py', '/python/jinja2/test/test3.py', '/python/jinja2/test/test.py'] 如果想要忽略某一个子目录，可以直接修改三元组中的dirnames，即从dirnames列表中移除需要忽略掉的目录，如下所示： for root,dirnames,filenames in os.walk(os.path.expanduser(\"/python\")): ... if 'exclude_dir' in dirnames: dirnames.remove('exclude_dir') 案例：找到目录下最大（或最老）的十个文件 为方便查阅，收录在Python运维-Linux系统管理实例 高级文件处理接口shutil   os模块的函数和shutil模块包中的函数有一些重叠。os模块是对操作系统的接口的封装，主要左右是跨平台，shutil模块包含复制、移动、重命名和删除文件及目录的函数，主要作用是管理文件和目录，二者是互补关系。 复制文件和文件夹 copy:拷贝一个文件，copytree：拷贝一个目录，示例如下： [root@redhat8 shutil]# ls a.py dir1 [root@redhat8 shutil]# python3 >>> import shutil >>> shutil.copy('a.py','b.py') 'b.py' >>> shutil.copytree('dir1','dir2') 'dir2' [root@redhat8 shutil]# ls a.py b.py dir1 dir2 文件和文件夹的移动与改名   shutil模块中move(src,dst)用来将路径src处的文件移动到dst处，并返回新的位置的绝对路径。如果dst是一个目录，则将文件一定到目录下，如果dst是一个文件名称，则将文件一定到目标目录下，并重命名为dst。示例如下： [root@redhat8 shutil]# ls a.py dir1 [root@redhat8 shutil]# python3 >>> import shutil >>> shutil.move('a.py','b.py') 'b.py' >>> shutil.move('b.py','dir1') 'dir1/b.py' [root@redhat8 shutil]# ls dir1 b.py [root@redhat8 shutil]# ls dir1 删除目录 os模块的remove和unlink函数可以删除文件，os模块的rmdir和removedirs函数可以删除目录，但是此两个函数都要求被删除的目录非空，不能强制删除。而shutil.rmtree不管目录是否为空，都直接删除整个目录。示例如下： [root@redhat8 shutil]# ls dir1 [root@redhat8 shutil]# python3 >>> import os >>> import shutil >>> os.rmdir('dir1') Traceback (most recent call last): File \"\", line 1, in OSError: [Errno 39] Directory not empty: 'dir1' >>> shutil.rmtree('dir1') [root@redhat8 shutil]# ls [root@redhat8 shutil]# 文件内容管理 目录和文件比较 创建如下文件和目录： [root@redhat8 filecmp]# tree . ├── dir1 │ ├── a_copy.txt │ ├── a.txt │ ├── b.txt │ ├── c.txt │ └── sdir1 │ └── sa.txt └── dir2 ├── a.txt ├── b.txt ├── c.txt ├── sdir1 │ └── sb.txt └── sdir2 5 directories, 9 files   两个目录中a.txt和c.txt内容一样，不过是分别创建的两个文件，a_copy.txt是从a.txt文件cp生成的，两个目录中b.txt的内容不一样，详细内容如下所示： [root@redhat8 filecmp]# cd dir1 [root@redhat8 dir1]# cat a.txt Life was like a box of chocolates [root@redhat8 dir1]# cat b.txt Stupid is as stupid does [root@redhat8 dir1]# cat c.txt Life was like a box of chocolates [root@redhat8 dir1]# cd sdir1 [root@redhat8 sdir1]# cat sa.txt Life was like a box of chocolates [root@redhat8 sdir1]# cd .. [root@redhat8 dir1]# cd .. [root@redhat8 filecmp]# cd dir2 [root@redhat8 dir2]# cat b.txt Miracles happen every day [root@redhat8 dir2]# cd sdir1 [root@redhat8 sdir1]# cat sb.txt Stupid is as stupid does filecmp模块中cmp函数用来比较两个文件是否相同，在dir1示例如下： >>> import filecmp >>> filecmp.cmp('a.txt','b.txt') False >>> filecmp.cmp('a.txt','a_copy.txt') True >>> filecmp.cmp('a.txt','c.txt') True filecmp模块中copyfiles函数用来比较两个不同目录下多个文件： >>> import filecmp >>> filecmp.cmpfiles('dir1','dir2',['a.txt','b.txt','c.txt','a_copy.txt']) (['a.txt', 'c.txt'], ['b.txt'], ['a_copy.txt']) 可以使用dircmp函数比较两个目录： >>> result = filecmp.dircmp('dir1','dir2') >>> result.report() diff dir1 dir2 Only in dir1 : ['a_copy.txt'] Only in dir2 : ['sdir2'] Identical files : ['a.txt', 'c.txt'] Differing files : ['b.txt'] Common subdirectories : ['sdir1'] >>> result.left_list ['a.txt', 'a_copy.txt', 'b.txt', 'c.txt', 'sdir1'] >>> result.right_list ['a.txt', 'b.txt', 'c.txt', 'sdir1', 'sdir2'] >>> result.left_only ['a_copy.txt'] "},"08-Python/08-Python系统管理&自动化运维笔记/05-Python运维-Linux系统管理实例.html":{"url":"08-Python/08-Python系统管理&自动化运维笔记/05-Python运维-Linux系统管理实例.html","title":"Python运维-Linux系统管理实例","keywords":"","body":"Python运维学习笔记-Linux系统管理实例 学习过程中摘自教材：《Python Linux系统管理与自动化运维》（赖明星著）中的实例。 文件读写实例 案例：将文件中所有的单词的首字母变成大写 代码如下： with open('test.txt') as inf,open('test3.txt','w') as outf: for line in inf: outf.write(' '.join([word.capitalize() for word in line.split()])) outf.write(\"\\n\") 运行后示例如下： [root@redhat8 jinja2]# python3 captialize.py [root@redhat8 jinja2]# cat test3.txt Miracles Happen Evary Day! I Was Messed Up For A Long Time. 示例说明： 示例中，使用上下文管理器同时管理了两个文件，以读模式打开文件，然后以写模式打开输出文件 对于输入文件，使用for循环依次遍历文件的每一行，然后使用字符串处理函数split来拆分这一行中的单词 然后使用capitalize函数将单词的首字母转换为大写 最后使用''.join()（注意示例中的空格）将各个单词链接起来，并写入到输出文件中 上面示例也可以使用print函数来简化输出语句，如下所示： with open('test.txt') as inf,open('test3.txt','w') as outf: for line in inf: print(*[word.capitalize() for word in line.split()],file=outf) 文件与文件路径管理 案例：打印最常用的Linux命令   在Linux系统中，~/.bash_history文件保存了命令的历史，可以读取此文件进行统计，统计时只统计命令的名称，同一个命令不同参数的也算同一个命令，下面是找出出现次数最多的五条命令： import os from collections import Counter c = Counter() with open(os.path.expanduser('~/.bash_history')) as f: for line in f: cmd = line.strip().split() if cmd: c[cmd[0]] += 1 print(c.most_common(5)) 运行后示例如下： [root@redhat8 test]# python3 test.py [('ls', 171), ('vi', 95), ('cd', 87), ('python3', 71), ('cat', 67)] 查找文件 案例：找到目录下最大（或最老）的十个文件   查找某个目录及子目录下最大的十个文件，或者最老，或者包含某个名字的文件，这些需求有一个共同需求，即找到某个目录及其子目录下的某种文件，更加通用需求是，找到某个目录树中，除部分特殊目录外，其它目录中的某一些文件。可以用函数先实现这个通用需求，然后调用这个函数实现其它需求，函数代码如下： #!/usr/bin/python #_*_ coding: UTF-8 _*_ import os import fnmatch def is_file_match(filename,patterns): for pattern in patterns: if fnmatch.fnmatch(filename,pattern): return True return False def find_specific_files(root,patterns=['*'],exclude_dirs=[]): for root,dirnames,filenames in os.walk(root): for filename in filenames: if is_file_match(filename,patterns): yield os.path.join(root,filename) for d in exclude_dirs: if d in dirnames: dirnames.remove(d)   上面代码中定义了find_specific_files函数，接受三个参数，分别是查找根路径，匹配的文件模式列表和需要排除的目录列表，匹配模式列表和排除的目录列表都有默认值（默认 情况下找到根路径下的所有文件）。查找目录下的所有文件： for item in find_specific_files(\".\"): print(item) 查找目录下所有图片： patterns=['*.jpg','*.png','*.jpeg','*.tif','*.tiff','*.gif'] for item in find_specific_files(\".\",patterns): print(item) 查找目录树下，除test目录宜为其它目录下所有图片： patterns=['*.jpg','*.png','*.jpeg','*.tif','*.tiff','*.gif'] exclude_dirs=['test'] for item in find_specific_files(\".\",patterns,exclude_dirs): print(item) 找到某个目录极其子目录下最大的十个文件： files = {name: os.path.getsize(name) for name in find_specific_files('.')} result = sorted(files.items(),key=lambda d: d[1],reverse=True)[:10] for i , t in enumerate(result,1): print(i,t[0],t[1]) 示例说明： 示例中首先通过字典推导创建了一个字典，字典的key是找到的文件，字典的value是文件的大小 构建出字典后，使用Python内置的sorted函数对字典进行逆序排序，排序完成后即可获得最大的十个文件 也可以指定参数排除.git目录： files = {name: os.path.getsize(name) for name in find_specific_files('.'),exclude_dirs=['.git']} result = sorted(files.items(),key=lambda d: d[1],reverse=True)[:10] for i , t in enumerate(result,1): print(i,t[0],t[1]) 找到某个目录及其子目录下最老的十个文件： files = {name: os.path.gettime(name) for name in find_specific_files('.')} result = sorted(files.items(),key=lambda d: d[1])[:10] for i , t in enumerate(result,1): print(i,t[0],time.ctime(t[1])) 找到某个目录及其子目录下，所有文件名中包含“test”的文件： files = [name for name in find_specific_files('.',patternas=['*test*'])] for i , name in enumerate(files,1): print(i,name) 示例说明： 示例中，除了传递目录外，还传递了相应的匹配模式 为了支持多种匹配模式，模式匹配这个参数以列表的形式表示 找到某个目录及子目录下，排除.git子目录以后所有Python源文件： files = [name for name in find_specific_files('.',patternas=['*.py'],exclude_dirs=['.git'])] for i , name in enumerate(files,1): print(i,name) 删除某个目录及其子目录下的所有pyc文件： files = [name for name in find_specific_files('.',patternas=['*.pyc'])] for name in files: os.remove(name) 文件内容管理 "},"08-Python/08-Python系统管理&自动化运维笔记/06-Python运维-监控Linux系统.html":{"url":"08-Python/08-Python系统管理&自动化运维笔记/06-Python运维-监控Linux系统.html","title":"Python运维-监控Linux系统","keywords":"","body":""},"08-Python/08-Python系统管理&自动化运维笔记/07-Python运维-文档与报告.html":{"url":"08-Python/08-Python系统管理&自动化运维笔记/07-Python运维-文档与报告.html","title":"Python运维-文档与报告","keywords":"","body":"Python运维学习笔记-文档与报告 学习教材：《Python Linux系统管理与自动化运维》（赖明星著） 使用Python处理Excel文档 教程中使用的是openpyxl，之前有专门学习过，回头继续学习。 使用Python操作PDF文档 之前打算学习reportlab，但是发现AIX中安装不了，学习下课本中的PyPDF2。官方文档：https://pythonhosted.org/PyPDF2/index.html PyPDF2安装与介绍 PyPDF2是一个开源的库，需要先安装： [root@redhat8 pdf]# pip install PyPDF2 使用PdfFileReader读取PDF文件 随便找个PDF文件：IBM i Basic printing.pdf，示例如下： >>> import PyPDF2 f.py:1736]>>> reader = PyPDF2.PdfFileReader(open('IBM i Basic printing.pdf','rb')) >>> reader.getNumPages() 424 >>> reader.getIsEncrypted() False >>> page = reader.getPage(10) >>> page.extractText() '2.If print spooling is selected, the output data is placed in a spooled file and the spoo led file is placed\\nin an output queue. If dir\\nect printing is selected, the output data is sent dir\\nectly to the printer\\n. ... >>> reader.getDocumentInfo() {'/Creator': 'XPP', '/Keywords': '', '/Subject': '', '/Author': 'IBM', '/Title': 'IBM i: B asic printing', '/CreationDate': \"D:20180804081225-05'00'\", '/ModDate': \"D:20180804081225-05'00'\", '/Producer': 'PDFlib+PDI 9.0.5 (AIX)'} 示例说明： 示例中首先使用二进制读模式打开PDF文件，并传递给PdfFileReader类的初始化函数 PdfFileReader类的初始化函数会返回一个PdfFileReader类的对象，可以通过此对象来获取PDF文件内容 使用getNumPages函数获取了文件页数，使用getIsEncrypted查看是否加密 通过传递下标给getPage的方式获取PDF的页面，在PyPDF2中下标从0开始，所以getPage(10)是第十一页内容 PdfFileReader类的getPage函数会返一个PageObject对象，对象中有旋转页面的rotateClockwise方法，合并页面的mergePage方法，示例中使用extractText方法提取页面中的文本 最后通过PdfFileReader的getDocumentInfo方法获取PDF文件的元信息 "},"08-Python/09-Python_常见问题及注意事项/":{"url":"08-Python/09-Python_常见问题及注意事项/","title":"Python_常见问题及注意事项","keywords":"","body":"Python_常见问题及注意事项 简介 记录一些Python学习和实践过程中遇到的问题和注意事项。 内容 Python-常见问题 Python-注意事项 Python-编写脚本注意事项 "},"08-Python/09-Python_常见问题及注意事项/01-Python-常见问题.html":{"url":"08-Python/09-Python_常见问题及注意事项/01-Python-常见问题.html","title":"Python-常见问题","keywords":"","body":"Python-常见问题 记录一些学习和实践过程中遇到的问题。 运行常见报错 缩进问题 预期缩进的块： expected an indented block unindent与任何外部缩进级别都不匹配 unindent does not match any outer indentation level 以上两个检查缩进。 数据类型问题 示例一： TypeError expected string or bytes-like object 在取字典里面的值进行字符串相加时候报错，把格式转换成字符串即可，例如：dict['name'][0] 编码报错 报错示例一 报错：'utf-8' codec can't decode byte 0xc8 in position 334: invalid continuation byte原因：编码模式不对str(web_content,encoding='utf-8') gb18030,或者使用GBK 修改后发现正则表达式匹配不到数据，单独做测试发现如下报错： SyntaxError: Non-UTF-8 code starting with '\\xe9' in file test.py on line 15 需要在脚本开头加上：# -*- coding:gb18030 -*-或者#coding:utf-8 报错示例二 报错示例： bash-5.0# python3 setup.py System check in progress! Get system information,please waiting...... Traceback (most recent call last): File \"setup.py\", line 16, in print(content) UnicodeEncodeError: 'latin-1' codec can't encode character '\\uff1a' in position 443: ordin al not in range(256) 在写html中，一个冒号使用了中文的字符，因为没有指定UTF-8，但是我使用的全是英文，所以改过来即可。 正则表达式注意 示例一 正则表达式中使用变量作为参数： import re a = [[1,3,5,],[2,4,5],[1,23,45],[3,13,5],[2,13,5]] list1 = [] for i in a: j = i[0] if not re.findall(j,list1): list1.append(i) print(list1) 会报错 TypeError: first argument must be string or compiled pattern 查看正则表达式findall格式： re.findall(pattern, string, flags=0) 应该有两个问题： pattern在示例中是整型，改成字符串 string在示例中是列表，同样改成字符串 修改后代码如下： import re a = [[1,3,5,],[2,4,5],[1,23,45],[3,13,5],[2,13,5]] list1 = [] for i in a: j = str(i[0]) if not re.findall(j,str(list1)): list1.append(i) print(list1) 运行示例： [[1, 3, 5], [2, 4, 5]] 示例二 跟示例一问题类似，出现问题是因为是对象，示例代码： vg_disk_cmd = 'lsvg -p rootvg |awk \\'NR>2{print $1}\\'' vg_disk = os.popen(vg_disk_cmd) bootlist_cmd = 'bootlist -m normal -o' bootlist = os.popen(bootlist_cmd) for i in vg_disk: if re.findall(i,bootlist): print('x') 报错如下： Traceback (most recent call last): File \"test7.py\", line 9, in if re.findall(i,bootlist): File \"/opt/freeware/lib64/python3.7/re.py\", line 223, in findall return _compile(pattern, flags).findall(string) TypeError: expected string or bytes-like object 两个问题： 变量i在从对象中遍历后可能会有换行符，去掉换行符即可 变量bootlist是个对象，在正则表达式中使用会有上面报错，改成字符串即可 改后代码如下所示： vg_disk_cmd = 'lsvg -p rootvg |awk \\'NR>2{print $1}\\'' vg_disk = os.popen(vg_disk_cmd) bootlist_cmd = 'bootlist -m normal -o' bootlist = os.popen(bootlist_cmd) bootlist = bootlist.read().strip() for i in vg_disk: i = i.strip() if re.findall(i,bootlist): print('x') 内置函数使用问题 len()使用报错 报错内容： TypeError: object of type '_wrap_close' has no len() 原因是我在使用os.popen()运行系统命令赋值给变量后得到的是一个对象： cpu_type = os.popen(type_cmd) if len(cpu_type) == 0: 使用read函数读取对象内容即可： cpu_type = os.popen(type_cmd) cpu_type = cpu_type.read() if len(cpu_type) == 0: 待补充 "},"08-Python/09-Python_常见问题及注意事项/02-Python-注意事项.html":{"url":"08-Python/09-Python_常见问题及注意事项/02-Python-注意事项.html","title":"Python-注意事项","keywords":"","body":"Python-其它注意事项 记录一些学习和实践过程中遇到的一些注意事项。 jinja2 模板使用问题   Python中使用jinja2模板处理文本时候，例如下面代码,本来获取到的是一个list，我转化成字符串，在Python中打印最后结果也是换行显示，但是将变量传入jinja2模板渲染后，结果html打开后显示是一行文本： sw_err = os.popen(sw_ckcmd) swerr_list = [] for i in sw_err: j = i[0:10] k = [x[0:10] for x in swerr_list] if not re.findall(j,str(k)): swerr_list.append(i) sw_err = ''.join(swerr_list) sw_err = sw_err.strip() swerr_result = 'Found some software event,please check:\\n'+ sw_err   如果直接在jinja2中遍历上面变量，会一个字母一个字母遍历，达不到预期效果，可以传入list，然后在jinja2模板中遍历即可，Python代码修改如下： sw_err = os.popen(sw_ckcmd) swerr_list = [] for i in sw_err: j = i[0:10] k = [x[0:10] for x in swerr_list] if not re.findall(j,str(k)): swerr_list.append(i) swerr_result = ['Found some software event,please check:\\n']+ swerr_list jinja2模板中代码如下： System Software Error Event {% for swerr in swerr_result %} {{ swerr }} {% endfor %} 变量使用问题   在jinja2中，变量是一个字典，调用变量可以使用{{ }}语法表示一个变量， 获取字典变量中值可以类似使用切片方法，但是下面代码使用不行： {% for abnormal in abnormal_path_result %} Check the {{ abnormal['name'] }} path {% if {{ abnormal['result'] }} is string %} {{ abnormal['result'] }} abnormal_path_result是一个Python字典变量，使用会报错： File \"./base.html\", line 265, in template {% if {{ abnormal['result'] }} is string %} jinja2.exceptions.TemplateSyntaxError: expected token ':', got '}'   原因在控制结构{% %}中间，不需要使用{{ }}再去表示一个变量，就好比第一行代码那样，所以代码修改如下即可： {% for abnormal in abnormal_path_result %} Check the {{ abnormal['name'] }} path {% if abnormal['result'] is string %} {{ abnormal['result'] }} 浮点运算   在浮点运算中，用sum()内置函数进行运算的时候，会出现小数点位特别多的情况，而实际上原来相加的小数点是有限的，示例如下： >>> sum([0.1,0.1]) 0.2 >>> sum([0.1,0.2]) 0.30000000000000004 >>> sum([1.4,0.2]) 1.5999999999999999 >>> a = 1.4;b = 0.2 >>> (a + b) == 1.6 False 可以使用round()内置函数来进行四舍五入取浮点数位数： >>> c = round((a + b),2) >>> print(c) 1.6 另一个方法是使用math.fsum()函数： >>> import math >>> sum([0.1] * 10) == 1.0 False >>> math.fsum([0.1] * 10) == 1.0 True math.fsum()官方介绍：math—数学函数 待补充 "},"08-Python/09-Python_常见问题及注意事项/03-Python-编写脚本注意事项.html":{"url":"08-Python/09-Python_常见问题及注意事项/03-Python-编写脚本注意事项.html","title":"Python-编写脚本注意事项","keywords":"","body":"Python-其它注意事项 记录一些学习和编写脚本过程中遇到的一些注意事项。 AIX脚本编写注意 命令执行问题   例如sw_err是python变量，一串字符，想使用awk去处理sw_err中的内容，会将shell命令结果进行执行，而达不到预期结果： identifier = os.popen('awk \\'{print $1}\\' ' + sw_err) 下面写法一样,得到的不是命令执行结果，而是再去执行命令的结果： ident_cmd = 'awk \\'{print $1}\\' ' + sw_err identifier = os.popen(ident_cmd) 上面的方法使用是一厢情愿，行不通。下面的方法是可以： cmd1 = 'rmdev -dl '+hdisk cmd1 = 'lspv |grep '+hdisk os.popen(cmd1);os.popen(cmd2) 上面示例中hdisk变量只代表“hdisk1”，此方式可以。 脚本中运行命令问题 示例代码如下： >>> disk_list_cmd = 'lspv |awk \\'{print $1}\\'' >>> disk_list = os.popen(disk_list_cmd) >>> for disk in disk_list: ... disk_iostat_cmd = 'iostat -d '+disk+' 1 5 |grep '+disk+'| awk \\'{print $2,$3,$4,$5,$6}\\'' ... disk_iostat = os.popen(disk_iostat_cmd) ... for i in disk_iostat: ... print(i) 执行后会报错，只执行到'iostat -d '+disk+： /bin/sh[2]: 1: not found. /bin/sh[3]: 0403-057 Syntax error at line 3 : `|' is not expected. 但是同样的赋值语句代码，下面这种就没问题： >>> import os >>> disk = 'hdisk3' >>> disk_iostat_cmd = 'iostat -d '+disk+' 1 5 |grep '+disk+'| awk \\'{print $2,$3,$4,$5,$6}\\'' >>> disk_iostat = os.popen(disk_iostat_cmd) >>> for i in disk_iostat: ... print(i)   两个示例代码中，不同的是变量disk，第一个示例代码变量disk是从对象中遍历出来的，估计是有换行符，shell就从1开始执行了，所以报错，进行了如下测试： >>> disk_list = os.popen(disk_list_cmd) >>> for disk in disk_list: ... print(disk) ... hdisk3 hdisk4 hdisk5 >>> disk_list = os.popen(disk_list_cmd) >>> for disk in disk_list: ... disk = disk.strip() ... print(disk) ... hdisk3 hdisk4 hdisk5 所以在最开始报错代码中修改下代码使用strip()将变量disk的换行符去掉即可。 获取命令使用read()问题   例如通过os.popen()运行命令后获取了一个对象，在一个if语句中调用read()去读取，在else中继续使用变量，就会发现是read()后的结果，而不是运行os.popen()获取的对象： def missing_check(self): missing_cmd= 'lspath -F \"name status path_id parent connection\"\\ |grep -i missing' missing_path = os.popen(missing_cmd) missing_path_list = [] if len(missing_path.read()) == 0: missing_result = 'No missing path was found.' else: for path in missing_path: print(path) path = path.strip() path = path.split(' ') print(path)   示例中应该运行else，但是发现else后面可以运行，但是for循环后面的都没有结果，包括print(path)都不会输出。问题应该是在if语句中使用read()读取了missing_path，修改后代码如下： def missing_check(self): missing_cmd= 'lspath -F \"name status path_id parent connection\"\\ |grep -i missing' missing_path = os.popen(missing_cmd) missing_path = missing_path.read() missing_path_list = [] if len(missing_path) == 0: missing_result = 'No missing path was found.' else: missing_path = os.popen(missing_cmd) for path in missing_path: path = path.strip() 待补充 "},"09-Shell脚本/":{"url":"09-Shell脚本/","title":"Shell脚本","keywords":"","body":"Shell脚本 简介   Shell类型有多种，主流Linux系统一般是Bourne Again Shell (简称bash)，AIX系统中是Korn Shell（简称ksh）。不同Shell类型中Shell脚本有所差别，不过AIX安装个bash就可以切换到bash。 内容 Shell脚本学习笔记 Shell脚本快速指南 Shell_AIX脚本 Shell编写脚本注意 "},"09-Shell脚本/01-Shell学习笔记/":{"url":"09-Shell脚本/01-Shell学习笔记/","title":"Shell学习笔记","keywords":"","body":"Shell学习笔记 简介 使用RedHat系统作为学习平台，学习教程：《Linux命令行与shell脚本编程大全》（第3版） 内容 Shell笔记-基础脚本 Shell笔记-条件语句 Shell笔记-循环语句 Shell笔记-处理用户输入 Shell笔记-呈现数据 Shell笔记-函数 Shell笔记-sed和gawk基础 Shell笔记-正则表达式 Shell笔记-sed编辑器 Shell笔记-gawk程序 Shell笔记-脚本控制 "},"09-Shell脚本/01-Shell学习笔记/01-Shell笔记-基础脚本.html":{"url":"09-Shell脚本/01-Shell学习笔记/01-Shell笔记-基础脚本.html","title":"Shell笔记-基础脚本","keywords":"","body":"Shell笔记-基础脚本 shell脚本基础只是学习笔记 输入和显示 直接上脚本进行示例： #!/bin/bash #This script it a test script! echo \"who's logged into the system:\" who am i echo -n \"The date is:\" date echo This is a test script! 脚本中知识点： 第一行指定使用的shell类型 第二行是注释，一般用\"#\"号(第一行例外) 直接写入命令就可以，执行脚本时候会输出命令输出结果 两个命令可用分号\";\"隔开写在同一行 echo输出用户自定义内容，不需要引号，如果定义内容里有引号，需要加入引号 如果想让echo输出内容和后面命令输出内容显示在同一行，用-n参数 执行后输出结果如下： [root@redhat8 basis]# ./basis_1.sh who's logged into the system: huang pts/1 2014-02-21 07:55 (192.168.18.1) The date is:Sat Feb 21 08:26:27 EDT 2014 This is a test script! 使用变量 脚本示例如下： #!/bin/bash #Environment variable usage echo The user home directory is $HMOE echo \"The system hostname is $HOSTNAME\" echo \"The cost of the phone is \\$199\" time1=20 time2=$time1 name1=\"Bond\" echo \"$name1 will get off work in $time2 minutes.\" 脚本中知识点： 调用系统环境变量可用直接调用，放在有双引号字符串中也可以 调用变量使用符合\"$\",当作为它本身时候需要加上转义字符反斜杠\"\\\" 可以自定义变量，shell脚本自动决定变量类型，在脚本结束时候定义的变量被删除 可以将变量赋值给变量，一定要用\"$\" 执行后输出结果如下： [root@redhat8 basis]# ./basis_2.sh The user home directory is The system hostname is redhat8 The cost of the phone is $199 Bond will get off work in 20 minutes. 命令替换 shell脚本可以从命令输出中提取信息，有两种方法： 反引号字符：` $()格式 示例如下： #!/bin/bash #Get the command output syst1=`date` syst2=$(date) echo \"The system date is：\"$syst1 echo The system date is：$syst2 today=$(date +%y%m%d) cat /etc/filesystems > filesystems.bak.$today ls -l 脚本中知识点： 示例了两种获取系统命令输出的方法，并且回顾了之前echo的用法 后面示例了实际中常用的调用方法，备份文件时候在输出文件名中加入自定义时间格式 命令替换会创建一个子shell运行命令，子shell是不会使用脚本中创建的命令 执行后输出结果如下： [root@redhat8 basis]# sh basis_3.sh The system date is：Sat Feb 21 08:26:27 EDT 2014 The system date is：Sat Feb 21 08:26:27 EDT 2014 total 8 -rw-r--r--. 1 root root 206 Feb 21 02:12 basis_3.sh -rw-r--r--. 1 root root 66 Feb 21 02:12 filesystems.bak.140221 重定向输入和输出 在刚才的示例中已经用到了重定向输出的用法，继续详细学习。 重定向输出 示例如下： ls -l > test1 cat test1 date >> test1 cat test1 示例中知识点： 使用符合\">\"将输出重定向到指定文件中，系统没有此文件会自动创建一个 如果不想覆盖原文件内容，可以使用符号\">>\"来追加数据 执行后输出结果如下： [root@redhat8 basis]# ls -l > test1 [root@redhat8 basis]# cat test1 total 8 -rw-r--r--. 1 root root 0 Feb 21 02:26 test1 [root@redhat8 basis]# date >> test1 [root@redhat8 basis]# cat test1 total 9 -rw-r--r--. 1 root root 0 Feb 21 02:26 test1 Sat Feb 21 08:26:27 EDT 2014 重定向输入 输入重定向采用符号\" wc 执行后输出结果如下： [root@redhat8 basis]# wc wc命令会对数据中的文本进行计数，默认情况下输出3个值：文件的行数、词数和字节数。 还有一种输入重定向方法，叫内联输入重定向（inline input redirection，采用符号\"command 。示例如下： [root@redhat8 basis]# wc This is a test string > also is a test string > END 2 10 44 输入命令后显示次提示符\"wc命令会对输入的数据进行处理。 管道 经常需要将一个命令的输出作为另一个命令的输入，可以通过重定向来实现，但是相对比较麻烦。使用管道方法就很方便，日常中经常用到，直接示例： [root@redhat8 basis]# rpm -qa | sort | grep python3 | more > python3.rpmlist libpeas-loader-python3-1.22.0-6.el8.x86_64 python36-3.6.8-1.module+el8+2710+846623d6.x86_64 python3-asn1crypto-0.24.0-3.el8.noarch 输出命令rpm -qa结果，用sort排序，然后用grep查找python3，然后用文本分页命令more将输出按屏显示,最后将结果重定向到文件\"python3.rpmlist\"中。 数学运算 shell脚本中有两种途径来进行数学相关运算。 expr命令 关于expr命令操作符，后面章节采用专业页面收录，方便查阅。 直接在shell命令行中操作： [root@redhat8 basis]# expr 10+10 10+10 [root@redhat8 basis]# expr 10 \\* 10 100 注意，对于一些字符在shell有特殊含义的，需要使用转移字符\"\\\"来让符号表示原有的含义。 脚本中示例如下: #!/bin/bash #use the expr conmmand num1=100;num2=10 num3=$(expr $num1 / $num2) echo The number is $num3 执行后输出结果如下： [root@redhat8 basis]# sh basis_4.sh The number is 10 使用方括号 使用方括号比expr命令方便多了，命令行中示例如下： [root@redhat8 basis]# nums=$[10+10];echo $nums 20 脚本中示例如下： #!/bin/bash num1=100;num2=10;num3=20 num4=$[$num2 * ($num1-$num3)] echo The number is $num4 执行后输出结果如下： [root@redhat8 basis]# sh basis_4.sh The number is 800 注意事项： 在使用方括号的时候，不用担心乘号或其它符号代表非运算符的情况，所以不需要转义字符； 支支持整数运算，若要进行任意实际数字的计算，需要采用其它方法。 浮点解决方案 有几种方法可以在bash中客服整数运算的限制，常见的方法就是内建的bash计算机，简称\"bc\"。bash计算机能够识别的内容： 数字（整数和浮点数） 变量（简单变量和数组） 表达式和函数 注释（以#或C语言中/ /开始的行） 编程语句（例如if-then） 直接运行命令bc就可以访问bash计算器，示例如下： [root@redhat8 basis]# bc bc 1.07.1 Copyright 1991-1994, 1997, 1998, 2000, 2004, 2006, 2008, 2012-2017 Free Software Foundatio n, Inc.This is free software with ABSOLUTELY NO WARRANTY. For details type `warranty'. scale=4 100*10+100/20-66.66/37 1003.1984 num1=10 num2=20 num3=num2 / num1 print num3 2.0000 示例中知识点： 使用scale指定输出的小数位数，scale变量默认值是0 bash计算机还支持变量，引用就直接引用，用print去打印出来 脚本中使用示例如下： #!/bin/bash num1=10 num2=3.1415926 num3=$(echo \"scale=3; 20 * 10 / 5 - $num2\" | bc) num4=$(echo \"scale=2; $num3 * $num2\" | bc) echo The number is $num4 num5=$(bc 执行后输出结果如下： [root@redhat8 basis]# sh basis_4.sh The number is 115.7940999 The answer fot this mess is 252.6525073 脚本中的知识点： scale指定浮点运算小数位，应该是乘除不尽时候保留小数位 使用管道来调用bash计算器进行运算 可以使用内联输入重定向来可以针对较复杂的运算表达式，逐行显示，清晰明了 退出脚本 在shell中，每个命令都是以退出码状态（exit status）反馈给shell它已经运行完毕。退出状态码是一个0~255的整数，在命令结束时候由命令转给shell。有时候需要捕捉这个状态值在脚本中使用。 查看状态退出码 在Linux中，可以使用变量\"$?\"来保存上个已执行命令的退出码状态，示例如下： [root@redhat8 basis]# ls basis_1.sh basis_2.sh basis_3.sh basis_4.sh filesystems.bak.140221 test1 [root@redhat8 basis]# echo $? 0 [root@redhat8 basis]# lsfeage bash: lsfeage: command not found... [root@redhat8 basis]# echo $? 127 Linux中退出状态码： 状态码 描述 0 命令成功结束 1 一般性未知错误 2 不适合的shell命令 126 命令不可执行 127 没找到命令 128 无效的退出参数 128+x 与Linux信号x相关的严重作为 130 通过Ctrl+C终止的命令 255 正常范围之外的退出状态码 exit命令 命令exit运行用户在脚本结束时指定一个自定义的退出码状态，同样最大值是255 例如在刚才basis_4.sh脚本中加入exit 168，示例： [root@redhat8 basis]# sh basis_4.sh The number is 115.7940999 The answer fot this mess is 252.6525073 [root@redhat8 basis]# echo $? 168 也可以调用变量的值进行返回，如果返回数值大于255，shell会通过模运算，最终结果是指定的值减去256得到的余数。 "},"09-Shell脚本/01-Shell学习笔记/02-Shell笔记-条件语句.html":{"url":"09-Shell脚本/01-Shell学习笔记/02-Shell笔记-条件语句.html","title":"Shell笔记-条件语句","keywords":"","body":"Shell笔记-条件语句 主要内容是if条件判断语句和test命令的用法。 if-then-else语句 格式如下： if command then command else command fi 当if语句中命令返回退出码状态为0时，then部分中的命令会被执行，当返回非零退出状态码时候，shell会执行else部分中的命令。else部分可以根据需求是否添加。脚本示例如下： #!/bin/bash testuser=NoneUser if grep $testuser /etc/passwd then echo \"Tha bash files for user $testuser are:\" ls -al /home/$testuser/.b* else echo \"The user $testuser does not exist on the system!\" fi 执行后输出结果如下： [root@redhat8 if-for]# ./test1.sh The user NoneUser does not exist on the system! 嵌套if 有时候需要多种判断条件，可以使用嵌套的if-then语句。同样检查用户是否存在脚本示例，在Home目录下建立一个用户文件夹，但是不创建用户：mkdir /home/NoneUser。脚本示例如下: #!/bin/bash testuser=NoneUser if grep $testuser /etc/passwd then echo \"Tha user $testuser exsits on the system!\" else echo \"The user $testuser does not exist on the system!\" if ls -d /home/$testuser/ then echo \"The user $testuer has a directory!\" fi fi 执行后结果如下： [root@redhat8 if-for]# ./test2.sh The user NoneUser does not exist on the system! /home/NoneUser/ The user has a directory! 如同条件更多呢，可以使用else部分另外一种性质elif，上面示例修改如下： #!/bin/bash testuser=NoneUser if grep $testuser /etc/passwd then echo \"Tha user $testuser exsits on the system!\" elif ls -d /home/$testuser/ then echo \"The user $testuser does not exist on the system!\" echo \"The user $testuer has a directory!\" fi 执行后结果如下： [root@redhat8 if-for]# ./test2.sh /home/NoneUser/ The user NoneUser does not exist on the system! The user has a directory! 再更近一步，在检查一项，elif后面加上else，示例代码如下： #!/bin/bash testuser=noneuser if grep $testuser /etc/passwd then echo \"Tha user $testuser exsits on the system!\" elif ls -d /home/$testuser/ then echo \"The user $testuser does not exist on the system,but has a directory!\" else echo \"The user $testuser does not exist on the system,and does not have a directory!\" fi 执行后结果如下： [root@redhat8 if-for]# ./test2.sh ls: cannot access '/home/noneuser/': No such file or directory The user noneuser does not exist on the system,and does not have w directory! 可以继续将多个elif语句串起来，格式如下： if command1 then command set 1 elif command2 then command set2 elif command3 then command set3 fi test命令 在if-then语句中，不能测试命令退出状态码之外的条件。命令test提供了在if-then语句中不同条件的途径，如果命令test中条件成立，命令test就会退出并返回退出状态码0，如果不成立，返回非0的退出状态码，if-then语句就不会继续执行了。 test命令格式比较简单：test condition，condition是test命令要测试的一系列参数和值,可以判断的条件有三种：数值比较、字符串比较和文件比较，格式如下： if test condition then commands fi 也可以用方括号替代： if [ condition ] then commands fi 数值比较 示例如下： #!/bin/bash num1=10;num2=99 if [ $num1 -gt 9 ] then echo \"The number $num1 is greater then 9!\" fi if [ $num2 -eq $num1 ] then echo \"The numbers are equal!\" else echo \"The numbers are different!\" fi 执行后结果如下： [root@redhat8 if-for]# ./test3.sh The number 10 is greater then 9! The numbers are different! 注意事项： 方括号前后都要有空格，在RHEL8中会报错，上面示例中不加空格会提示：[10: command not found；或者：./test3.sh: line 3: [: missing `]' 对于浮点值的比较，bash shell是不能处理的 命令test的数值比较功能对照表： 比较方式 描述 n1 -eq n2 检查n1是否与n2相等 n1 -ge n2 检查n1是否大于或等于n2 n1 -gt n2 检查n1是否大于n2 n1 -le n2 检查n1是否小于或等于n2 n1 -lt n2 检查n1是否小于n2 n1 -ne n2 检查n1是否不能于n2 字符串比较 示例如下： #!/bin/bash testuser=tmpusr;string=\"\" hero1=Thor;hero2=Hulk if [ $USER != $testuser ] then echo \"This is not $testuser! \" else echo \"Welcome $testuser! \" fi #大小比较 if [ $hero1 \\> $hero2 ] then echo \"$hero1 is stronger than $hero2!\" else echo \"$hero2 is weaker than $hero2!\" fi #字符串大小 if [ -n $string ] then echo \"The string '$string' is empty!\" else echo \"The string '$string' is not empty!\" fi 执行后结果如下： [root@redhat8 if-for]# ./test4.sh This is not tmpusr! Thor is stronger than Hulk! The string '' is empty! 示例中的知识点： 比较字符串相等性时候，会将所有的大小写以及标点都考虑在内 大于号和小于号必须要用转义字符转义，不然会认为是重定向符号 大小写的顺序和sort命令锁采用的不同，比较测试中，大写字母是小于小写字母，采用的标准的ASCII顺序，而sort命令恰好相反 字符串比较测试表： 比较方式 描述 str1 = str2 检查str1是否和str2相同 str1 != str2 检查str1是否和str2不同 str1 检查str1是否比str2小 str1 > str2 检查str1是否比str2大 -n str1 检查str1长度是否非0 -z str1 检查str1长度是否为0 文件比较 文件比较在shell编程中使用的比较多，允许测试Linux文件系统上文件和目录的状态，先直接上表： 比较方式 描述 -d file 检查file是否存在并是一个目录 -e file 检查file是否存在 -f file 检查file是否存在并是一个文件 -r file 检查file是否存在并可读 -s file 检查file是否存在并非空 -w file 检查file是否存在并可写 -x file 检查file是否存在并可执行 -O file 检查file是否存在并属当前用户所有 -G file 检查file是否存在并且默认组于当前用户相同 file1 -nt file2 检查file1是否比file2新 file1 -ot file2 检查file1是否比file2旧 代码示例如下： #!/bin/bash homedir=$HOME;file1=\"testfile\" if [ -e $homedir ] then echo \"The $homedir directory exists and now checking the $file1!\" if [ -f $homedir/$file1 ] then echo \"The $file is a file and exist!\" ls -l > $homedir/$file1 if [ $homedir/$file1 -nt $homedir/test ] then echo \"The $homedir/$file1 newer then $homedir/test\" else echo \"The $homedir/$file1 older then $homedir/test\" fi else echo \"The $file1 does not exist!\" fi else echo \"The $homedir directory is not exist!\" fi 执行后结果如下： [huang@redhat8 if-for]$ ./test5.sh The /home/huang directory exists and now checking the testfile! The is a file and exist! The /home/huang/testfile newer then /home/huang/test 一般检查思路就是：检查所在的目录是否存在，然后检查是否是一个文件，然后再检查次文件是否空文件或者是否可读或者可写可执行等。 复合条件测试 if-then语句允许用户使用布尔逻辑来组合测试： [ condition1 ] && [ condition2 ] [ condition1 ] || [ condition2 ] 第一种是and布尔运算组合条件，要让then部分执行，两个条件必须同时满足，第二种满足其中一个，then部分就会执行。示例如下: #!/bin/bash if [ -d $HOME ] && [ -w $HOME/testfile ] then echo \"The file exists and you can write!\" else echo \"You cannot write the file!\" fi 执行后结果如下： [huang@redhat8 if-for]$ ./test6.sh The file exists and you can write! if-then的高级特性 bash 提供了良心可在if-then语句中使用的高级特性： 用于数学表达式的双括号 用于高级字符串处理功能的双方括号 使用双括号 双括号允许用户再比较过程中使用高级数学表达式，常用命令符号如下 符号 描述 val++ 后增 val-- 后减 ++val 先增 --val 先减 ! 逻辑求反 ~ 位求反 ** 幂运算 左位移 >> 右位移 & 位布尔和 | 位布尔或 && 逻辑和 || 逻辑或 示例如下： #!/bin/bash num1=10 if (( $num1 ** 3 > 90 )) then (( num2 = $num1 ** 2 )) echo \"The square of the $num1 is $num2!\" fi 执行后结果如下： [root@redhat8 if-for]# sh test7.sh The square of the 10 is 100! 使用双方括号 双方括号里面的expression使用了test命令中采用的标准字符串比较，也提供了一个test命令没有的特征：匹配模式（pattern maching）。示例如下： #!/bin/bash if [[ $HOSTNAME == r* ]] then echo \"The hostname is $HOSTNAME!\" else echo \"Unkonw hostname!\" fi 执行后结果如下： [root@redhat8 if-for]# sh test7.sh The hostname is redhat8! 注意：不是所有的shell都指定双方括号，RedHat8是支持的。 case命令 当在一组值中寻找特定的值的时候，可能会写出很长的if-then-else语句，有了case命令就很简单了，语法如下： case varibale in pattern1 | prttern2) commands1;; pattern3) commands2;; *) default commands3;; easc 示例如下： #!/bin/bash case $USER in huang | root) echo \"Welcome,$USER,please enjoy your visit!\";; testuser) echo \"Special testuser account\";; tmpusr) echo \"Do not forget to log off when you donot operating the system!\";; *) echo \"Sorry,you are not allowed here\";; esac 执行后结果如下： [root@redhat8 if-for]# sh test8.sh Welcome,root,please enjoy your visit! 我是root用户，将root从条件中改成其它用户选项，输出结果如下： [root@redhat8 if-for]# sh test8.sh Sorry,you are not allowed here 其实就是依次判断条件是否满足，满足就执行对于的命令。 "},"09-Shell脚本/01-Shell学习笔记/03-Shell笔记-循环语句.html":{"url":"09-Shell脚本/01-Shell学习笔记/03-Shell笔记-循环语句.html","title":"Shell笔记-循环语句","keywords":"","body":"Shell笔记-循环语句 for循环 简单的一般直接在shell中写入，格式：for var in list;do,shell会提示输入命令，然后输入done就开始执行。例如我现在就在shell下创建几个测试脚本文件： [root@redhat8 for]# for i in 1 2 3 4 5 > do > touch test$i.sh > done 标准格式如下： for var in list do commands done 读取列表中的值 直接代码示例： #!/bin/bash for hero in \"Captain America\" Thor \"Iron Man\" do echo \"$hero is a SuerpHero!\" done list=\"Batman WonderWoman\" list=$list\" SuperMan\" for hero in $list do echo \"$hero is a SuerpHero!\" done 说明： 列表中的内容用空格来划分，如果一个值本身有空格，用双引号括起来，并且shell不会把双引号当成内容的一部分 列表中的内容本身有引号，例如：I'am Iron man,同样可以用双引号括起来，也可以用转义字符(反斜杠)来转义 从变量中读取列表也可以，示例中也演示了向列表中添加元素的方法 运行后输出结果如下： [root@redhat8 for]# sh test1.sh Captain America is a SuerpHero! Thor is a SuerpHero! Iron Man is a SuerpHero! Batman is a SuerpHero! WonderWoman is a SuerpHero! SuperMan is a SuerpHero! 读取命令中的值 shell中可以用命令替换来执行任何能产生输出的命令，然后可以在for循环中使用命令的输出。新建一个文件SuperHero，查看内容： [root@redhat8 for]# cat SuperHero Thor Captain America Hulk Iron Man 然后用代码来遍历： #!/bin/bash file=\"SuperHero\" IFS=$'\\n' for hero in $(cat $file) do echo \"The superhero is $hero!\" done 执行后输出如下： [root@redhat8 for]# sh test2.sh The superhero is Thor! The superhero is Captain America! The superhero is Hulk! The superhero is Iron Man! 可以看到for将文本中的换行符作为字段分隔符，并不是之前列表示例中的空格，也没额外加上引号。这跟IFS=$'\\n'这条命令有关。 这里我们用到了特殊环境变量IFS(Iinternal Field Separator),IFS定义了一系列bash shell中用作字段分隔符，默认情况下，bash shell 的字段分隔符有：空格、制表符和换行符可以在脚本中临时改变一下IFS的值，例如只识别换行符，忽略空格和制表符：IFS=$'\\n'。其它用法示例： 如果代码中多次用到IFS，后面的想用默认的，方法： IFS.OLD=$IFS IFS=$'\\n' :代码中使用新的IFS IFS=$IFS.OLD:后续的操作就使用默认的IFS 遍历冒号分隔的值（/etc/passwd），可以将IFS设置成冒号：IFS=: 需要指定多个字符的情况，串起来即可,例如换行符、冒号、分号和双引号一起：IFS=$'\\n':;\" 用通配符读取目录 代码示例如下： #!/bin/bash for file in /shell/for/hero/* /shell/for/hero/test do if [ -f \"$file\" ] then echo \"The $file is a file!\" elif [ -d \"$file\" ] then echo \"The $file is a directory!\" else echo \"The $file is not exist!\" fi done 运行后输出如下： [root@redhat8 for]# sh test3.sh The /shell/for/hero/herodir is a directory! The /shell/for/hero/SuperHero is a file! The /shell/for/hero/test is not exist! 注意事项： 目录和文件名中有空格也是合法的，所以用分号将变量括起来：\"$file\" 用到了之前的test命令中方括号方法，注意方括号前后要加空格，不然会报错 C语言风格的for 我试了下AIX中ksh不支持此用法，安装个bash就支持了。bash shell中示例如下： #!/bin/bash for ((i=1; i 使用多个变量时候循环会单独处理每个变量，但是只能定义一个条件，示例： #!/bin/bash for ((i=1,j=3;i 执行后结果如下： bash-5.0# ./test1.sh 1 + 3 2 + 2 3 + 1 while循环 while某种意义上是if-then和for循环的混合。定义一个要测试的命令，然后循环执行一组命令，只要定义的测试命令返回的退出码状态是0，返回非0时候，while会终止执行那组命令。基本格式如下： while test command do other command done 多个测试命令的示例如下： #!/bin/bash num1=3 while echo $num1 [ $num1 -ge 0 ] do echo \"This is a test loop!\" num1=$[ $num1 - 1 ] done 运行后输出如下： [root@redhat8 for]# sh test4.sh 3 This is a test loop! 2 This is a test loop! 1 This is a test loop! 0 This is a test loop! -1 注意： 示例中定义了两个测试命令，两个都要满足才会继续， 每次迭代中所有的测试命令都会执行，例如最后值是-1了，执行了echo $num1,第二个也执行了，只是返回为非零，条件不满足，while循环就终止了，这种用法要注意。 until命令 until命令和while的工作方式完全相反。until要求指定一个通常返回非零退出码的测试命令，只有测试命令退出码不为零时，才会继续执行循环中列出的命令，直到测试命令返回的退出状态码为0，循环终止。 嵌套循环 被嵌套循环也称为内部循环(inner loop),被嵌套的循环会在外部循环的每次迭代中遍历一次它所有的值。 while和for混用 示例代码： #!/bin/bash num1=3 while [ $num1 -ge 0 ] do echo \"Outer loop:$num1\" for ((num2=1;num2 echo命令中首行空两格可以在输出结果中缩进，运行后输出如下: [root@redhat8 for]# sh test5.sh Outer loop:3 Inner loop:3+1 = 4 Inner loop:3+2 = 5 Outer loop:2 Inner loop:2+1 = 3 Inner loop:2+2 = 4 Outer loop:1 Inner loop:1+1 = 2 Inner loop:1+2 = 3 Outer loop:0 Inner loop:0+1 = 1 Inner loop:0+2 = 2 while和until混用 示例代码： #!/bin/bash num1=2 until [ $num1 -eq 0 ] do echo \"Outer loop:$num1\" num2=1 while [ $num2 -lt 3 ] do num3=$(echo \"scale=4; $num1 / $num2\" | bc) echo \" Inner loop: $num1 / $num2 = $num3\" num2=$[ $num2 + 1 ] done num1=$[ $num1 - 1 ] done 运行后输出结果如下： [root@redhat8 for]# sh test6.sh Outer loop:2 Inner loop: 2 / 1 = 2.0000 Inner loop: 2 / 2 = 1.0000 Outer loop:1 Inner loop: 1 / 1 = 1.0000 Inner loop: 1 / 2 = .5000 循环处理文件数据 通常遍历文件中的数据，通常需要用到嵌套循环和IFS环境变量。比较典型的例子就是处理/etc/passwd里面的数据，示例代码如下： #!/bin/bash IFS=$'\\n' for user in $(cat /etc/passwd) do echo \"User information:$user -\" IFS=: for value in $user do echo \" $value\" done done 执行后输入如下（太多了，只显示其中一个用户的）： User information:huang:x:1000:1000:huang:/home/huang:/bin/bash - huang x 1000 1000 huang /home/huang /bin/bash 循环控制 控制循环命令：break命令和continue命令 break命令 当shell执行break命令时，会尝试跳出当前正在执行的循环，代码示例如下： #!/bin/bash for i in {1..5} do if [ $i -eq 3 ] then break fi echo \"Iteration number:$i\" done echo \"The loop is end!\" 运行后输出结果如下： [root@redhat8 for]# sh test8.sh Iteration number:1 Iteration number:2 The loop is end! 知识点： 这种方法同样适用于while和until循环。 跳出内部循环的时候，把break写在内部循环的if语句中即可； 如果在内部循环中要停止外部循环，break命令接受单个命令行参数值：break n。n指定了跳出循环的层次，默认情况下，n的值为1，表示跳出的是当前的循环，值为2的时候，break命令就会停止下一级的外部循环。 continue命令 continue命令可以提前中止某次循环中的命令，但是不会终止整个循环，示例如下： #!/bin/bash for ((i = 1; i 运行后输出结果如下： [root@redhat8 for]# sh test9.sh The number is 1 ! The number is 2 ! The number is 3 ! The number is 6 ! The number is 7 ! The number is 8 ! 可以看到大于3和小于6的项目被跳过了，if-then里面的条件满足，会跳过循环中剩余的命令，不满足时候，循环继续。同样适用于while和until循环，使用要小心，但是如果在某个条件里面对测试的条件变量进行增值，就会出现问题，会变成死循环，不停执行，示例代码如下： #!/bin/bash i=0 while echo \"while interation:$i\" [ $i -lt 10 ] do if [ $i -gt 3 ] && [ $i -lt 6 ] then continue fi echo \" The number is $i !\" i=$[ $i + 1 ] done 运行后最后会一直不停输出，无穷无尽：while interation:4 同样continue命令接受单个命令行参数值：continue n，n定义了要继续的循环的层级。 处理循环输出 代码示例如下： #!/bin/bash for file in /shell/for/* do if [ -d \"$file\" ] then echo \"$file is a directory!\" else echo \"$file is a file!\" fi done > output.txt 执行脚本后，不会显示在屏幕上，会将输出写过重定向到output.txt文件中，查看文件内容如下： [root@redhat8 for]# cat output.txt /shell/for/hero is a directory! /shell/for/output.txt is a file! /shell/for/SuperHero is a file! /shell/for/test10.sh is a file! /shell/for/test11.sh is a file! /shell/for/test1.sh is a file! 如果在done后面加入echo的语句，shell会在for完成后在屏幕显示echo的内容。也可以使用管道符，例如在done后面加上| sort，就会对for循环的输出进行排序。 "},"09-Shell脚本/01-Shell学习笔记/04-Shell笔记-处理用户输入.html":{"url":"09-Shell脚本/01-Shell学习笔记/04-Shell笔记-处理用户输入.html","title":"Shell笔记-处理用户输入","keywords":"","body":"Shell笔记-处理用户输入 命令行参数 bash shell会将一些称为位置参数(positional parameter)的特殊变量分配给输入到命令中的所有参数。位置参数变量是标准的数字：$0是程序名，$1是第一个参数，$2是第二个参数，依次类推，直到第九个参数$9，如果有更多的，需要加上大括号，例如：${10}、${11}。 读取参数 示例脚本如下： #!/bin/bash total=$[ $1 * $2 ] echo $1 \\* $2 = $total echo The name of $3 is $4! echo \"I am ${10}!\" 将参数写入命令行中，并执行脚本： [root@redhat8 input]# ./test1.sh 3 6 \"Captain America\" Steve 1 3 4 5 6 \"Iron Man\" 3 * 6 = 18 The name of Captain America is Steve! I am Iron Man! 知识点： shell会自动将命令行参数的值分配给变量，每个参数间必须用空格隔开 文本和字符串都可以作为命令行参数 当一个参数中有空格时候，必须用引号（单引号或双引号均可） 当参数超过九个的时候，需要加上花括号，例如：${10} 示例中用到了星号，原本只是想输出乘号，但是输出的不是，说明冲突了，需要加上转义字符 读取脚本名 可以用$0参数获取shell在命令行启动的脚本名，脚本示例如下： #!/bin/bash echo \"The running script is:$0\" 三种方式运行示例： [root@redhat8 input]# bash test2.sh The running script is:test2.sh [root@redhat8 input]# ./test2.sh The running script is:./test2.sh [root@redhat8 input]# bash /shell/input/test2.sh The running script is:/shell/input/test2.sh 可以看到把路径也加进去了，要剥离掉路径，可以采用basename命令，示例如下： #!/bin/bash echo \"The running script is:$(basename $0)\" 完整路径执行后如下所示： [root@redhat8 input]# bash /shell/input/test2.sh The running script is:test2.sh 测试参数 脚本中使用了命令行参数，而脚本不加参数运行，脚本运行就会报错。可以使用-n来检查命令行参数$1中是否有数据，示例如下： #!/bin/bash if [ -n \"$1\" ] then echo \"Hello $1,glad to meet you!\" else echo \"Sorry,you did not indentify yourself!\" fi 注意变量要加上引号：\"$1\"，运行示例如下： [root@redhat8 input]# sh test3.sh Sorry,you did not indentify yourself! [root@redhat8 input]# sh test3.sh Bond Hello Bond,glad to meet you! 特殊参数变量 在bash shell中有些特殊变量，它们会记录命令行参数。 参数统计 特殊变量$#含有脚本运行时携带的命令行参数的个数，示例如下： #!/bin/bash if [ $# -lt 2 ] then echo \"Please usage this format:test4.sh a b\" else echo $1 \\* $2 = $(( $1 * $2 )) fi params=$# echo The numbers of parameters are $params! echo The last parameter is ${!#} 加参数运行后结果： [root@redhat8 input]# sh test4.sh 3 4 5 2 4 3 * 4 = 12 The numbers of parameters are 5! The last parameter is 注意事项： 可以对参数数量进行测试，如果参数数量不对，会显示错误消息提醒格式 书中用${!#}可以获取到最后一个参数，但是我跑脚本不行，不知道是不是RHEL原因 抓取所有数据 有时候需要抓取命令行上提供的所有参数。变量$*和变量$@可以用来访问所有参数： 变量$*会将命令行上提供的所有参数当作一个元素保存，并将这些参数视为一个整体 变量$@会将命令行上提供的所有参数当作同意字符串的多个独立的元素；可以通过for来遍历所有的参数值去得到每个参数 代码示例如下： #!/bin/bash count=1 for param in \"$*\" do echo Parameter $count = $param count=$[ $count + 1 ] done # count=1 for param in \"$@\" do echo \" Parameter $count = $param\" count=$[ $count + 1 ] done 加参数执行后如下所示： [root@redhat8 input]# sh tst5.sh Hulk Thor \"Captain America\" Parameter 1 = Hulk Thor Captain America Parameter 1 = Hulk Parameter 2 = Thor Parameter 3 = Captain America 移动变量 bash shell中shift命令可以用来操作命令参数，根据它们的相对位置来移动命令行参数。在使用shift命令时候，默认会将每个参数移动到前一个位置，$3的值会移动到$2中，到最后$1的值会被删除，$0不会改变。所以可以用来遍历命令行参数，在不知道参数多少时候，可以操作$1，然后移动参数，继续操作$1。脚本示例： #!/bin/bash shift 2 echo \"The new first parameter is $1\" count=1 while [ -n \"$1\" ] do echo Parameter $count = $1 count=$[ $count + 1 ] shift done 加参数运行脚本后示例： [root@redhat8 input]# sh test6.sh 3 2 Thor Hulk Batman The new first parameter is Thor Parameter 1 = Thor Parameter 2 = Hulk Parameter 3 = Batman 处理选项 选项是跟在单破折线后的单个字母，它能改变命令的行为。 查找选项 脚本示例： #!/bin/bash while [ -n \"$1\" ] do case \"$1\" in -a) echo \"Found the -a option\";; -b) echo \"Found the -b option\";; *) echo \"$1 is not an option\";; esac shift done 运行脚本示例如下： [root@redhat8 input]# sh test7.sh -a -b -c -d Found the -a option Found the -b option -c is not an option -d is not an option 分离参数和选项 在Linux中用双破折号--来将命令行上的选项和参数划分开来。脚本示例： #!/bin/bash while [ -n \"$1\" ] do case \"$1\" in -a) echo \"Found the -a option\" ;; -b) echo \"Found the -b option\" ;; --) shift break ;; *) echo \"$1 is not an option\";; esac shift done count=1 for param in \"$@\" do echo Parameter $count = $param count=$[ $count + 1 ] done 加入参数和选项运行脚本示例如下： [root@redhat8 input]# sh test8.sh -a -b -c -- Thor Hulk Found the -a option Found the -b option -c is not an option Parameter 1 = Thor Parameter 2 = Hulk 处理带值得选项 有些选项会带一个额外得参数值，脚本示例如下： #!/bin/bash while [ -n \"$1\" ] do case \"$1\" in -a) echo \"Found the -a option\" ;; -b) param=\"$2\" echo \"Found the -b option with parameter value $param\" shift ;; --) shift break ;; *) echo \"$1 is not an option\";; esac shift done count=1 for param in \"$@\" do echo Parameter $count = $param count=$[ $count + 1 ] done 加入参数和选项运行脚本示例如下： [root@redhat8 input]# sh test9.sh -a -b Hulk -c Found the -a option Found the -b option with parameter value Hulk -c is not an option [root@redhat8 input]# sh test9.sh -c -b Hulk -a -c is not an option Found the -b option with parameter value Hulk Found the -a option 使用getopt命令（AIX中适用） getopt命令是在处理命令行选项和参数时非常方便的工具,格式：getopt optstring parameters,举例如下： [root@redhat8 input]# getopt ab:cd -a -b Thor -cd Hulk Batman -a -b Thor -c -d -- Hulk Batman [root@redhat8 input]# getopt -q ab:cd -a -b Thor -cd Hulk Batman -e -a -b 'Thor' -c -d -- 'Hulk' 'Batman' 解释如下： optstring定义了四个有效字母，a,b,c和d，在b后面又冒号，因为b选项需要一个参数 当getopt运行时候会检查提供的参数列表(-a -b Thor -cd Hulk Batman),基于提供的optstring进行解析 注意，会自动将-cd选项分成两个单独的选项，并插入--来分割行中的额外参数 如果有不在optstring中的选项就会报错，在命令后面加入-q选项即可（AIX中不会报错加-q也没用） 脚本示例： #!/bin/bash set -- $(getopt -q ab:cd \"$@\") while [ -n \"$1\" ] do case \"$1\" in -a) echo \"Found the -a option\" ;; -b) param=\"$2\" echo \"Found the -b option with parameter value $param\" shift ;; --) shift break ;; *) echo \"$1 is not an option\";; esac shift done count=1 for param in \"$@\" do echo Parameter $count = $param count=$[ $count + 1 ] done 加入参数和选项运行脚本示例如下： [root@redhat8 input]# sh test10.sh -a -b Thor -cd Hulk Batman Found the -a option Found the -b option with parameter value 'Thor' -c is not an option -d is not an option Parameter 1 = 'Hulk' Parameter 2 = 'Batman' 说明： set命令的选项--会将命令行参数替换成set命令的命令行值 第一行代码set行方式是将原始脚本的命令行参数传递给getopt，只后再将getopt命令的输出传给set命令，用格式化后的命令行参数来替换环视的命令行参数 getopt命令不能处理带空格和引号的参数值，它会将空格单子参数分隔符 使用getopts命令（AIX中适用） getopts命令与getopt不通，getopts调用的时候只处理命令行上检测到的一个参数，处理完所有参数偶，它会退出并返回一个大于0的退出状态码,格式：getopts optstring variable,举例如下： #!/bin/bash while getopts c opt do case \"$opt\" in a) echo \"Found the -a option\" ;; b) echo \"Found the -b option with parameter value $OPTARG\" ;; c) echo \"Found the -c option\" ;; *) echo \"Unknown option: $opt\" ;; esac done 加入参数和选项运行脚本示例如下： [root@redhat8 input]# sh test11.sh -ab \"Captain America\" -c -e Found the -a option Found the -b option with parameter value Captain America Found the -c option Unknown option: ? 说明： while语句定义了getopts命令，指明需要查找的命令行选项，以及每次迭代中存储它们的变量名“opt\" getopts解析命令选项是会移开-，所有在case定义在不需要- getopts可以在参数值中包含空格和引号 getopts能将命令行上找到的所有未定义的选项统一输出成问号 能在所有shell脚本中使用的全功能命令行选项和参数的处理工具： #!/bin/bash while getopts cd opt do case \"$opt\" in a) echo \"Found the -a option\" ;; b) echo \"Found the -b option with parameter value $OPTARG\" ;; c) echo \"Found the -c option\" ;; d) echo \"Found the -c option\" ;; *) echo \"Unknown option: $opt\" ;; esac done shift $[ $OPTIND - 1 ] count=1 for param in \"$@\" do echo Parameter $count = $param count=$[ $count + 1 ] done 加入参数和选项运行脚本示例如下： [root@redhat8 input]# sh test12.sh -ab \"Iron Man\" -c Thor Hukl Found the -a option Found the -b option with parameter value Iron Man Found the -c option Parameter 1 = Thor Parameter 2 = Hukl 说明： 在getopts处理每个选项时，会将OPTIND环境变量值增一 在getopts处理完成时，可以使用shift命令和OPTIND值来移动参数 选项标准化 选项可以自定义，但是有些字母选项在Linux中已经拥有了某种程度的标准含义，推荐使用统一标准的含义，方便他人阅读。常用Linxu命令选项： 选项 描述 -a 显示所有对象 -c 生成一个计数 -d 指定一个目录 -e 扩展一个对象 -f 指定读入数据的文件 -h 显示命令的帮助信息 -i 忽略文本大小 -l 产生输出的长格式版本 -n 使用非交互模式（批处理） -o 将所有输出重定向到指定的输出文件 -q 以安静模式运行 -r 递归地处理目录和玩家 -s 以安静模式运行 -v 生成详细输出 -x 排除某个对象 -y 对所有问题回答yes 获得用户输入 bash shell中提供了read命令，增强交互性。 基本的读取 read命令从标准输入（键盘）或另一个文件描述符中接受输入。在接收到输入后，read命令会将数据放进一个变量。脚本示例： #!/bin/bash echo -n \"Please enter the hero's name: \" read hero echo \"YES,$hero is a superhero!\" # read -p \"Please enter the hero's home and ideal: \" home ideal echo \"The superhero come from $home,and will $ideal!\" 运行后示例如下： [root@redhat8 input]# sh test13.sh Please enter the hero's name: Batman YES,Batman is a superhero! Please enter the hero's home and ideal: earth save the world The superhero come from earth,and will save the world! 知识点： echo命令使用了-n选项，该选项不会再字符串末尾输出换行符，用户可以在后面输入数据，然后用read接受了输入的数据，并且赋值给指定变量 可以在read中定义多个变量去接受输入数据，输入中以空格作为分隔符，如果变量不够，剩下的数据就会全部分配给最后一个变量，试过用冒号不行 如果在read中不定义变量，read会将接收到的所有数据放进特殊环境变量REPLY中，用$REPLY调用即可 有时候不想在屏幕上显示输入信息，比如密码，可以在read命令中使用-s选项 超时 脚本可能一直等待用户输入，可以设定一个计时器，用-t选项，该选项指定了read命令等待输入的秒数，当设定时间到了后，read命令会返回一个非零退出状态码。脚本示例如下： #!/bin/bash if read -t 5 -p \"Please enter the hero's name: \" name then echo \" The superhero name is $name!\" else echo echo \"Sorry,your enter is too slow!\" fi 运行后一直不输入情况下示例结果： [root@redhat8 input]# sh test14.sh Please enter the hero's name: Sorry,your enter is too slow! 也可以不设置时间，当用户输入达到一定的字符后，就自动突出并将输入的数据赋值给变量，示例： #!/bin/bash read -n1 -p \"Will you marry me?[Y/N] \" answer case $answer in Y | y) echo echo \"Yes,I do!\" ;; N | n) echo echo \"Sorry,you are a good man,goodbye!\" exit ;; esac echo \"Let's paddle together!\" 运行示例如下： [root@redhat8 input]# sh test15.sh Will you marry me?[Y/N] Y Yes,I do! Let's paddle together! [root@redhat8 input]# sh test15.sh Will you marry me?[Y/N] n Sorry,you are a good man,goodbye! 从文件中读取 read可以从文件中读取内容，每次调用read命令，它都会从文件中读取一行文本，文本中没有内容时候就返回非零退出状态码。代码示例如下： #!/bin/bash count=1 cat test | while read line do echo \"Line $count:$line\" count=$[ $count + 1 ] done 运行后示例： [root@redhat8 input]# sh test16.sh Line 1:Yes,I do! Line 2:Let's paddle together! "},"09-Shell脚本/01-Shell学习笔记/05-Shell笔记-数据呈现.html":{"url":"09-Shell脚本/01-Shell学习笔记/05-Shell笔记-数据呈现.html","title":"Shell笔记-数据呈现","keywords":"","body":"Shell笔记-数据呈现 标准文件描述符   Linux系统将每个对象当作文件处理，这包括输入和输出进程。Linux用文件描述符（file descriptor）来标识每个文件对象，文件描述符是一个非负整数，每个进程一次最多有九个文件描述符，出于特殊目的，bash shell保留了前三个文件描述符，详细见下表： 文件描述符 缩写 描述 0 STDIN 标准输入 1 STDOUT 标准输出 2 STDERR 标准错误 STDIN SIDIN文件描述符代表shell的标准输入。对终端界面来说，标准输入是键盘。cat命令处理SIDIN示例： [root@redhat8 ~]# cat I am Iron Man! I am Iron Man! [root@redhat8 input]# cat 说明：由键盘输入，也可以用重定向符号强制cat命令接收来自非SIDIN文件的输入。 STDOUT SIDIN文件描述符代表shell的标准输出。对终端界面来说，标准输入就是终端显示器。输出导向STDOUT文件描述符示例： [root@redhat8 output]# ls -l > tes [root@redhat8 output]# pwd >> test [root@redhat8 output]# cat test total 0 -rw-r--r--. 1 root root 0 Aug 3 09:16 test -rw-r--r--. 1 root root 0 Aug 3 09:16 test1.sh /shell/output STDERR Shell通过特殊的STDERR文件描述符来处理错误消息。 只重定向错误消息（用2>，注意是紧贴着）示例如下： [root@redhat8 output]# ls -l test3 > test4 ls: cannot access 'test3': No such file or directory [root@redhat8 output]# ls -l test3 2> test4 [root@redhat8 output]# cat test4 ls: cannot access 'test3': No such file or directory 重定向错误和数据示例如下： [root@redhat8 output]# ls -l test2 test3 2> test5 1> test6 [root@redhat8 output]# cat test5 ls: cannot access 'test3': No such file or directory [root@redhat8 output]# cat test6 -rw-r--r--. 1 root root 0 Aug 3 09:29 test2 [root@redhat8 output]# ls -l test2 test3 &>test7 [root@redhat8 output]# cat test7 ls: cannot access 'test3': No such file or directory -rw-r--r--. 1 root root 0 Aug 3 09:29 test2 在脚本种重定向输出 临时重定向 如果有意在脚本种生成错误消息，可以将单独得一行输出重定向到STDERR。示例如下： #!/bin/bash echo \"This is a error message!\" >&2 echo \"This is a normal output!\" 运行后示例如下： [root@redhat8 output]# sh test1.sh This is a error message! This is a normal output! [root@redhat8 output]# sh test1.sh 2> test8 This is a normal output! [root@redhat8 output]# cat test8 This is a error message! 永久重定向 如果脚本种有大量数据需要重定向，可以使用exec命令告诉shell在脚本执行期间重定向某个特定文件描述符。脚本示例： #!/bin/bash exec 2>testerror echo \"This is the start of hte script!\" echo \"Redirecting all output to another location\" exec 1>testout echo \"This output should go to the testout file\" echo \"But this should go to the testerror file\" >&2 运行后示例如下： [root@redhat8 output]# sh test2.sh This is the start of hte script! Redirecting all output to another location [root@redhat8 output]# cat testerror But this should go to the testerror file [root@redhat8 output]# cat testout This output should go to the testout file 说明如下： 脚本用exec命令来讲发给STDERR的输出重定向到testerror 然后用echo想STDOUT显示了几行文本 随后再次使用exec命令在讲STDOUT重定向到testout文件 虽然STDOUT被重定向了，仍然可以讲echo的语句输出发给STDERR 在脚本种重定向输入 exec命令允将STDIN重定向到Linux系统上的文件种：exex 0,示例如下： #!/bin/bash exec 0 运行后输出如下： [root@redhat8 output]# sh test3.sh Line 1 : Yes,I do! Line 2 : Let's paddle together! Line 3 : 创建自定义的重定向   在shell中，最对个可以有9个打开的文件描述符，其它3-8的文件描述符均可作为输入或输出重定向。可以将这些文件描述符中的人一个分配给文件，然后再脚本中使用。 创建输出文件描述符 脚本示例如下： #!/bin/bash exec 3>test9 echo \"This should display on the monitor!\" echo \"And this should be stored in the file\" >&3 echo \"Then this should be back on the monitor!\" 运行后示例如下： [root@redhat8 output]# sh test4.sh This should display on the monitor! Then this should be back on the monitor! [root@redhat8 output]# cat test9 And this should be stored in the file 说明：如果想输入到现有的文件中，可以使用：exec 3>>test9。 重定向文件描述符 可以将STDOUT的原来位置重定向到另一个文件描述符，然后再利用该文件描述符的重定向回STDOUT，示例如下： #!/bin/bash exec 3>&1 exec 1>test10 echo \"This should store in the output file!\" echo \"Along with this line!\" exec 1>&3 echo \"Now things should be back to normal!\" 运行后示例如下： [root@redhat8 output]# sh test5.sh Now things should be back to normal! [root@redhat8 output]# cat test10 This should store in the output file! Along with this line! 说明： 脚本将文件描述符3重定向刀文件描述符1的当前位置，也就是STDOUT 第二个exec命令将STDOUT重定向到文件，shell会将发送给STDOUT的输出直接重定向到输出文件中 但是文件描述符3仍然指向STDOUT原来的位置，也就是显示器，此时将输出数据发送给文件描述符3，它仍然回出现在显示器上，尽管STDOUT已经被重定向了 在向STDOUT（现在指向一个文件）发送一些输出后，脚本将STDOUT重定向到文件描述符3当前的位置（现在仍然事显示器），这意味着STDOUT又指向了它原来的位置：显示器 创建输入文件描述符 可以用和重定向输出文件描述符同样的方法重定向输入文件描述符。示例如下： #!/bin/bash exec 6 运行后示例如下： [root@redhat8 output]# sh test6.sh Line #1 : Yes,I do! Line #2 : Let's paddle together! Line #3 : Will you marry me?[Y/N] y Yes,I do! 说明： 文件描述符6用来保存STDIN的位置，然后脚本将STDIN重定向到一个文件 read命令的所有输入都来自重定向后的STDIN（也就是输入文件） 在读取所有行文件后，脚本会将STDIN重定向到文件描述符6，从而将STDIN的位置回复到源线的位置 改脚本用了另外一个read命令来测试STDIN是否恢复正常了，并且等待键盘的输入 创建读写文件描述符 使用需要注意，会覆盖原有的数据示例如下： #!/bin/bash exec 3<> testfile read line &3 运行示例如下： [root@redhat8 output]# cat testfile Yes,I do! Let's paddle together! This is the third line! [root@redhat8 output]# sh test7.sh Read:Yes,I do! [root@redhat8 output]# cat testfile Yes,I do! This is a test line ! This is the third line! 说明： 用exec将文件描述符3分配给文件testfile以进行文件读写，然后通过分配好的文件描述符，使用read命令读取文件中的第一行，然后将这一行显示在STDOUT上，最后用echo语句将一行数据写入由同一个文件描述符打开的文件中 脚本开始时候运行正常，输出内容表面脚本读取了testfile文件中的第一行，脚本运行完毕后，查看testfile文件内容的话，会发现写入文件中的数据覆盖了已有的数据 当脚本向文件中写入数据时，他会从文件指针所处的位置开始。read命令读取了第一行数据，所以它使得文件指针指向了第二行数据的第一个字符，在echo语句将数据输出到文件时，他会将数据放在文件指针的当前位置，覆盖了该位置已有的数据 关闭文件描述符   shell会在脚本退出时自动关闭创建的文件描述符，有些情况下，需要在脚本结束前手动关闭。关闭文件描述符，将它重定向到特殊符号&-,例如：exec 3>&-,脚本示例如下： #!/bin/bash exec 3> test11 echo \"This is a test line of data\" >&3 exec 3>&- cat test11 exec 3> test11 echo \"This will be bad\" >&3 脚本运行后示例： [root@redhat8 output]# sh test8.sh This is a test line of data [root@redhat8 output]# cat test11 This will be bad 说明： 一旦关闭了文件描述符，就能在脚本中向它写入任何数据，否则会报错 但是，随意在脚本中打开了同一个文件输出，shell会用一个新的文件来替换已有文件，也就是输出的新数据会覆盖已有文件 列出打开的文件描述符   lsof命令会列出整个Linux系统打开的所有文件描述符（普通用户运行可能要全路径：/user/sbin/lsof），输出会比较多，可以使用命令行选项和参数过滤输出，例如-p:指定进程ID（PID），-d：允许指定要显示的文件描述符编号。示例如下： [root@redhat8 output]# lsof -a -p $$ -d 0,1,2 COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME bash 2546 root 0u CHR 136,0 0t0 3 /dev/pts/0 bash 2546 root 1u CHR 136,0 0t0 3 /dev/pts/0 bash 2546 root 2u CHR 136,0 0t0 3 /dev/pts/0 说明： 想知道进程的当前PID，可以用特殊环境变量$$(shell会将他设为当前PID) 选项-a用来对其它两个选择的结果执行布尔and运算 上面示例显示了当前进程（bash shell）的默认文件描述符（0、1和2） lsof的默认输出有7列信息，描述如下： 列 描述 COMMAND 正在运行的命令的前9个字符 PID 进程的PID USER 进程属主的登录名 FD 文件描述符号以及访问类型（r代表读，w代表写，u代表读写） TYPE 文件类型（CHR字符型，BLK块型，DIR目录，REG常规文件） DEVICE 设备的设备号（主设备号和从设备号） SIZE 如果有的话，表示文件的大小 NODE 本地文件的节点号 NAME 文件名称   与STDIN、STDOUT和STDERR关联的文件类型是字符型，三种文件描述符都指向终端，所有输出的文件名称就是终端的设备名，三种都支持读和写，脚本示例如下： #!/bin/bash exec 3> test12 exec 6> test13 exec 7 脚本运行后示例： [root@redhat8 output]# sh test9.sh COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME sh 2935 root 0u CHR 136,0 0t0 3 /dev/pts/0 sh 2935 root 1u CHR 136,0 0t0 3 /dev/pts/0 sh 2935 root 2u CHR 136,0 0t0 3 /dev/pts/0 sh 2935 root 3w REG 253,0 0 782380 /shell/output/test12 sh 2935 root 6w REG 253,0 0 789185 /shell/output/test13 sh 2935 root 7r REG 253,0 57 782397 /shell/output/testfile 阻止命令输出   有时候不想显示脚本的输出，如果允许在后台的脚本出现错误消息，可以发送邮件给属主，但是有时候会很麻烦，可以将STDERR重定向到一个叫做null文件的特殊文件，shell输出到null文件的任何数据都补i保持，全部都被丢掉了，在Linux中标准位置是/dev/null，重定向到此的任何数据都会被丢掉。示例如下： [root@redhat8 output]# cat test8 This is a error message! [root@redhat8 output]# cat /dev/null > test8 [root@redhat8 output]# cat test8 [root@redhat8 output]# date > /dev/null [root@redhat8 output]# cat /dev/null [root@redhat8 output]# ls -al badfile test9 2> /dev/null -rw-r--r--. 1 root root 38 Aug 3 11:00 test9 说明： 可用于快速清除文件，例如示例中的test8，也是日常中清除日志文件的常用方法 这是避免出现错误消息，也无需保存他们的一个常用方法，示例中最后一个示例 创建临时文件   在Linux中，可以使用mktemp命令在/tmp目录中创建一个唯一的临时文件，但不会使用默认的umask值，它会将文件的读和写权限分配给文件的数字，并将你设置长文件的属主，一旦创建了，在脚本中就有完整的读写权限，其它非root用户无法访问。 创建本地临时文件   默认情况下，mktemp会在本地目录中创建一个文件，用mktemp命令时候，指定一个文件名模板就行了，模板可以包含任意文本文件名，在文件名末尾加上6个X就可以，mktemp会用6个字符替代6个X，确保文件名的唯一性，示例如下： [root@redhat8 output]# mktemp test.XXXXXX test.O7Y4vI 在脚本中示例如下： #!/bin/bash tmpfile=$(mktemp test.XXXXXX) exec 3>$tmpfile echo \"This script writes to temp file $tmpfile\" echo \"This is the first line!\" >&3 echo \"This is the second line!\" >&3 echo \"This is the last line!\" >&3 exec 3>&- echo \"Done creating temp file.The contents are: \" cat $tmpfile rm -f $tmpfile 2> /dev/null 运行后示例如下： [root@redhat8 output]# sh test10.sh This script writes to temp file test.hBLWII Done creating temp file.The contents are: This is the first line! This is the second line! This is the last line! [root@redhat8 output]# ls -al test.hBLWII ls: cannot access 'test.hBLWII': No such file or directory 说明： 示例脚本用mktemp命令来创建临时文件并将文件名赋给$tmpfile变量 接着将这个临时文件作为文件描述符3的输出重定向文件 在将临时文件名显示在STDOUT之后，向零食文件中写入了几行文本，然后关闭了该文件描述符 最后，显示出临时文件的内容，并用rm命令将其删除 在/tmp目录篡改就临时文件   mktemp命令的-t选项会在系统的临时目录来创建该文件，在用这个特性时，会返回用来创建临时文件的全路径，而不是只有文件名，示例如下： [root@redhat8 output]# mktemp -t test.XXXXXX /tmp/test.pbRqLV 说明：由于返回的是全路径名，可以在系统上任何目录中银行用该临时文件，不管临时文件在哪里。 创建临时目录   mktemp命令的-d选项可以创建一个临时目录而不是临时文件，这样就能够用该目录进行任何需要的操作，比如创建其它临时文件，示例如下： [root@redhat8 output]# mktemp -d dir.XXXXXX dir.EMEN9F [root@redhat8 output]# ls -l total 84 drwx------. 2 root root 6 Aug 10 11:55 dir.EMEN9F 记录消息   将输出同时发送到显示器和日志文件，不需要输出重定向两次，用tee命令就行。tee命令相当于一个管道的T型接头，它将STDIN过来的数据同时发往两处，一处是STDOUT,另一处是tee命行所指定的文件名：tee filename。示例如下： [root@redhat8 output]# date | tee test14 Mon Aug 10 12:01:42 EDT 2010 [root@redhat8 output]# cat test14 Mon Aug 10 12:01:42 EDT 2010 huang pts/0 2010-08-10 09:39 (192.168.18.1) [root@redhat8 output]# cat test14 huang pts/0 2010-08-10 09:39 (192.168.18.1) [root@redhat8 output]# date | tee -a test14 Mon Aug 10 12:05:07 EDT 2010 [root@redhat8 output]# cat test14 huang pts/0 2010-08-10 09:39 (192.168.18.1) Mon Aug 10 12:05:07 EDT 2010 说明： 由于tes会重定向来自STDIN的数据，可以配合管道命令来重定向命令输出 tee命令会在每次使用时覆盖文件内容 使用-a选项可以将数据追加到文件中 利用此方法，可以将数据保存在文件中，同时也能将数据显示在屏幕上，示例： #!/bin/bash tmpfile=test15 echo \"This is the first line!\" | tee $tmpfile echo \"This is the second line!\" | tee -a $tmpfile echo \"This is the last line!\" | tee -a $tmpfile 运行后示例如下： [root@redhat8 output]# sh test11.sh This is the first line! This is the second line! This is the last line! [root@redhat8 output]# cat test15 This is the first line! This is the second line! This is the last line! 实例 实例收录在以下章节，方便查阅：Shell-bash脚本实例 "},"09-Shell脚本/01-Shell学习笔记/06-Shell笔记-函数.html":{"url":"09-Shell脚本/01-Shell学习笔记/06-Shell笔记-函数.html","title":"Shell笔记-函数","keywords":"","body":"Shell笔记-函数 格式 函数是一个脚本代码块，可以为其命名并在代码中任何位置重用。在bash shell中函数有两种格式，如下所示： function name { commands } 以及： name (){ commands } 函数使用 函数示例如下： #!/bin/bash function heros { echo \"Thor,Hulk,Wonder Woman,Batman,Captain America\" } count=1 while [ $count -le 2 ] do heros count=$[ $count +1 ] done echo \"Super Hero:heros\" 运行后示例如下： [root@redhat8 function]# sh test1.sh Thor,Hulk,Wonder Woman,Batman,Captain America Thor,Hulk,Wonder Woman,Batman,Captain America Thor,Hulk,Wonder Woman,Batman,Captain America 注意事项： 在函数定义之后才能使用该函数，定义之前调用会报错 函数名必须是唯一的，如果重复了，新定义函数会覆盖原来的函数 返回值 运行结束时会返回一个退出状态码，有三种不同方式来为函数生成退出状态码。 默认退出状态码   默认情况下，函数的退出状态码是函数中最后一条命令返回的退出状态码，在函数执行结束后可以用标准变量$?来确定函数的退出状态码。使用默认退出状态码值是通过最后一条命令判断，但是无法知道函数中其它命令是否运行成功，示例如下： #!/bin/bash function1 () { ls -l badfile echo \"Test bad command\" } echo \"Test the function:\" function1 echo \"The exit status is $?\" 运行后示例如下： [root@redhat8 function]# sh test2.sh Test the function: ls: cannot access 'badfile': No such file or directory Test bad command The exit status is 0 使用return命令   bash shell使用return命令来退出函数并返回特定的退出状态码。return命令允许指定一个数值来定义函数的退出状态码，脚本示例如下： #!/bin/bash function db1 { read -p \"Enter a value: \" value echo \"Doubling the value\" return $[ $value * 2 ] } db1 echo \"The new value is $?\" 运行后示例如下： [root@redhat8 function]# sh test3.sh Enter a value: 100 Doubling the value The new value is 200 注意事项： 函数一结束就取返回值，如果中途运行了其它命令，函数的返回值就会丢失 退出状态码必须是0-255，任何大于256的值都会产生一个错误值 使用函数输出 可以将函数的输出保存到变量中,例如将db1函数的输出赋值给result变量：result=`db1`,示例如下： #!/bin/bash db1 () { read -p \"Enter a number: \" value echo $[ $value * 2 ] } result=$(db1) echo \"The new number is $result!\" 运行后示例如下： [root@redhat8 function]# sh test4.sh Enter a number: 1118 The new number is 2236! 说明:  示例中使用了read取获取输入，read命令的输出bash shell并没将其作为STDOUT的一部分，如果使用echo语句生成这样的消息向用户查询，那么会与输出值一起被读进shell变量中。 在函数中使用变量 向函数传递参数   函数可以使用标准的参数环境变量来表示命令行上传给函数的参数。例如，$0是函数名，函数命令行上的任何参数都会通过$1、$2等定义，特殊环境变量$#来判断传递给函数的参数数目。在脚本中指定函数时，必须将参数和函数放在同一行，示例：function $value 1118。示例如下： #!/bin/bash addnum () { if [ $# -eq 0 ] || [ $# -gt 2 ] then echo -1 elif [ $# -eq 1 ] then echo $[ $1 + $1 ] else echo $[ $1 + $2 ] fi } echo -n \"Adding 18 and 19: \" value=$(addnum 18 19);echo $value echo -n \"Try adding just one number: \" value=$(addnum 18);echo $value echo -n \"Try adding no number: \" value=$(addnum);echo $value echo -n \"Try adding three numbers: \" value=$(addnum 18 19 20);echo $value 运行后示例如下： [root@redhat8 function]# sh test5.sh Adding 18 and 19: 37 Try adding just one number: 36 Try adding no number: -1 Try adding three numbers: -1 注意：  由于函数使用的特殊参数环境变量作为字节的参数值，因此他无法直接获取脚本在命令行中的参数值，所以不能再脚本后面加参数去传入到函数中。如果需要用到脚本的参数，可以在调用函数的时候手动传入，例如：value=$(addnum $1 $2)。 在函数中处理变量 函数使用的两种类型的变量： 全局变量：在shell脚本中任何地方都有效的变量；默认情况下脚本中定义的任何变量都是全局变量 局部变量：不需要在函数中使用全局变量时，函数内部的任何变量都可以被声明为局部变量，在变量声明前加上local关键字即可，也可以在变量赋值语句前面使用关键字：local tmp=$[ $value + 1 ]。 全局变量 示例： #!/bin/bash function test1 { value=$[ $value * 3 ] } read -p \"Please Enter a value: \" value test1 echo \"The new value is: $value\" 运行后示例如下： [root@redhat8 function]# sh test6.sh Please Enter a value: 168 The new value is: 504 说明： 变量$value在函数外定义并被赋值，当test1被调用时，该变量及其值在函数中都依然有效 如果变量在函数内被赋予了新值，那么在脚本中引用该变量时，新值也依然有效 局部变量   如果一个函数调用了一个变量，并赋予了新值，接下来另外一个函数需要调用变量，并且是需要原来的值，此时调用却会是新的值，采用局部变量可以解决此问题。脚本示例如下： #!/bin/bash test1 () { local tmp=$[ $value +2] result=$[ $tmp * 2 ] } tmp=3;value=5;test1 echo \"The result is $result\" if [ $tmp -gt $value ] then echo \"Tmp is larger!\" else echo \"Tmp is smaller!\" fi 运行后示例如下： [root@redhat8 function]# sh test7.sh The result is 14 Tmp is smaller! 数组变量和函数 向函数传递数组参数   如果直接将数组作为函数参数进行传递，那么函数只会读取数组变量的第一个值。必须将数组变量的值分解成单个的值，然后将这些值作为函数的参数使用，在函数内部，可以将所有的参数重新组合成一个新的变量。示例如下： #!/bin/bash function test2 { local newarray1 newarray1=($(echo \"$@\")) echo \"The new array value is: ${newarray1[*]}\" } array1=(1 2 3 4) echo \"The original array is ${array1[*]}\" test2 ${array1[*]} addarray () { local sum=0 local newarray2 newarray2=($(echo \"$@\")) for value in ${newarray2[*]} do sum=$[ $sum + $value ] done echo $sum } myarray=(4 3 2 1) echo \"The array is : ${myarray[*]}\" arg1=$( echo ${myarray[*]}) result=$(addarray $arg1) echo \"The result is $result\" 运行后示例如下： [root@redhat8 function]# sh test8.sh The original array is 1 2 3 4 The new array value is: 1 2 3 4 The array is : 4 3 2 1 The result is 10 说明：在函数内部，数组仍然可以像其它数组一样使用，上面示例中就使用for循环遍历了数组。 从函数返回数组   函数使用echo语句来按正确顺序输出单个数组值，然后脚本再将它们重新放进一个新的数组变量中，示例如下： #!/bin/bash arraydblr () { local origarray local newarray local elements local i origarray=($(echo \"$@\")) newarray=($(echo \"$@\")) elements=$[ $# - 1 ] for (( i =0; i 运行后输出示例如下： [root@redhat8 function]# sh test9.sh The original array is :2 7 4 9 1 The new array is 4 14 8 18 2 函数递归   局部函数变量的一个特性是自成体系，除了从脚本命令行获得的变量，自成体系的函数不需要使用任何外部资源。这个特性使得函数可以递归的调用，也就是函数可以调用自己来得到结果。  通常递归函数都一个最终可迭代到的基准值。最经典例子就是计算阶乘，例如阶乘：3！=1*2*3,用递归方程可以写成：x!=x * (x-1)!,脚本示例如下： #!/bin/bash factorial () { if [ $1 -eq 1 ] then echo 1 else local tmp=$[ $1 - 1 ] local result=$(factorial $tmp) echo $[ $result * $1 ] fi } read -p \"Please enter number: \" num result=$(factorial $num) echo \"The factorial of enter number is $result\" 运行后输出示例如下： Please enter number: 9 The factorial of enter number is 362880 创建库   当需要在多个脚本中使用同一段代码时候，可以创建一个函数库文件，在多个脚本中引用该库文件。首先是创建一个包含所需函数的公用库文件，例如testfuncs库文件，定义了几个简单的函数： function addem { echo $[ $1 + $2 ] } multem () { echo $[ $1 * $2 ] } divem () { fi [ $2 -ne 0 ] then echo $[ $1 / $2 ] else echo -1 fi }   shell函数同样有作用域问题，和环境变量一样，运行testfuncs shell脚本，会创建一个新的shell并在其中运行这个脚本。当像普通脚本那样运行库文件，函数并不会出现在脚本中。使用函数库的关键在于source命令，source命令会在当前shell上下文中执行命令，而不是创建一个新的shell。source命令有个快捷的别名，称作点操作符（dot operator），调用刚才库文件的脚本示例如下： #!/bin/bash . ./testfuncs num1=10 num2=5 result1=$(addem $num1 $num2) result2=$(multem $num1 $num2) result3=$(divem $num1 $num2) echo \"The result of adding them is:$result1\" echo \"The result of adding them is:$result2\" echo \"The result of adding them is:$result3\" 运行后输出示例如下： [root@redhat8 function]# sh test11.sh The result of adding them is:90 The result of adding them is:176 The result of adding them is:44 命令行上使用函数 采用单号方式进行函数定义，示例如下： [root@redhat8 function]# function multem { echo $[ $1 * $2 ];} [root@redhat8 function]# multem 9 9 81 [root@redhat8 function]# doubleit () { read -p \"Enter number: \" num;echo $[ $num * 2 ];} [root@redhat8 function]# doubleit Enter number: 9 18 注意事项：如果给函数起了一个内建命令或与另一命令相同的名字，函数会覆盖原来的命令。 在.bashrc文件中定义函数   命令行上定义的函数在退出shell时函数就消失了，可以将函数定义在一个特定的位置，每次启动一个新的shell时候，都会有shell重新载入，这个最佳位置就是.bashrc文件，不管是交互式shell还是从现有的shell中启动新的shell，都会在主目录下查找这个文件。  在RHEL中，文件.bash在用户的home目录下，里面有预定义一些东西，不要删除，把个人写的函数放在文件末尾就行了，文件.bashrc的示例如下： [huang@redhat8 ~]$ pwd /home/huang [huang@redhat8 ~]$ cat .bashrc # .bashrc # Source global definitions if [ -f /etc/bashrc ]; then . /etc/bashrc fi # User specific environment PATH=\"$HOME/.local/bin:$HOME/bin:$PATH\" export PATH # Uncomment the following line if you don't like systemctl's auto-paging feature: # export SYSTEMD_PAGER= # User specific aliases and functions   在.bashrc文件中加入如下函数或者库文件，并且用source（点操作符）调用（注意会在下次重新启动bash shell时候生效）： addtest () { echo $[ $1 + $2 ] } . /shell/function/testfuncs 在命令行调用示例如下： [huang@redhat8 function]$ addtest 2 4 6 [huang@redhat8 function]$ addem 3 13 16 [huang@redhat8 function]$ divem 81 9 9 "},"09-Shell脚本/01-Shell学习笔记/07-Shell笔记-sed和gawk基础.html":{"url":"09-Shell脚本/01-Shell学习笔记/07-Shell笔记-sed和gawk基础.html","title":"Shell笔记-sed和gawk基础","keywords":"","body":"Shell笔记-sed和gawk基础 这两个工具能够极大简化需要进行的数据处理任务。 sed编辑器   sed编辑器被称作流编辑器（stream editor），和普通的交互式文本编辑器恰号相反。流编辑器会在编辑器处理数据之前基于预先提供的一组规则来编辑数据流。  sed编辑器会根据命令来处理数据流中的数据，这些命令要么从命令行中输入，要么存储在一个命令文本文件中，sed编辑器会执行下列操作： 一次从输入中读取一行数据 根据所提供的编辑器命令匹配数据 按照命令修改流中的数据 将新的数据输出到STDOUT 说明： 在流编辑器将所有命令与一行数据匹配完毕后，它会读取下一行数据并重复这个过程，直到处理完所有数据行 命令是按顺序逐行给出，sed编辑器只需对数据流进行一遍处理就可以完成编辑操作 sed命令格式如下： sed options script file sed命令选项： 选项 描述 -e script 处理输入时，将script重指定的命令添加到已有得命令中 -f file 处理输入时，将file重指定的命令添加到已有的命令中 -n 不产生命令输出，使用print命令来完成输出   script参数指定了应用于流数据上的单个命令，如果需要使用多个命令，要么使用-e选项在命令行中指定，要么使用-f选项在单独的文件中指定。 在命令行定义编辑器命令 默认情况下，sed编辑器会将指定的命令应用到STDIN输入流上，示例如下： [root@redhat8 sed_gawk]# echo \"I am Thor!\" | sed 's/Thor/Iron Man/' I am Iron Man! [root@redhat8 sed_gawk]# cat test1 I am Captain America! I am Captain America! [root@redhat8 sed_gawk]# sed 's/Captain America/Iron Man/' test1 I am Iron Man! I am Iron Man! [root@redhat8 sed_gawk]# cat test1 I am Captain America! I am Captain America! [root@redhat8 sed_gawk]# sed -e 's/am/am not/; s/Captain America/Thanos/' test1 I am not Thanos! I am not Thanos! [root@redhat8 sed_gawk]# sed -e ' > s/am/am not/ > s/Captain America/Thanos/ > ' test1 I am not Thanos! I am not Thanos! [root@redhat8 sed_gawk]# cat test2.sed s/am/am not/ s/Captain America/Thanos/ [root@redhat8 sed_gawk]# sed -f test2.sed test1 I am not Thanos! I am not Thanos! 说明和注意： 在第一个示例中使用了s命令（substitute），s命令会使用斜线间指定第二个文本字符串来替换第一个文本字符串 第二个示例中示例修改整个文件，注意sed编辑器并不会修改文本文件的数据 第三个示例使用了多个编辑器命令，可以写在一行上，注意命令直接必须用分号隔开，并且在命令末尾和分号之间不能有空格 第四个示例采用多个编辑器命令，并且分行写入，注意要在封尾单引号所在行结束命令 第五个示例是从文件中读取编辑器命令，不用在每条命令后放一个分号 一遍建议将sed编辑器脚本文件以.sed作为文件的扩展名 gawk程序 gawk程序是Unix中的原始awk程序的GNU版本，它提供了一种编辑语言而不只是编辑器命令，可以做的事情如下： 定义变量来保存数据 使用算数和字符串操作符来处理数据 使用结构化编程概念（if语句和循环）来为数据处理增加处理逻辑 通过提取数据文件的数据元素，将其重新排列或格式化，生成格式化报告   gawk最完美的例子是格式化日志文件，可以从日志文件中过滤出需要的数据元素，然后可以将其格式化，使得重要的数据更易于阅读。标准格式如下： gawk options program file gawk程序的可用选项： 选项 描述 -F fs 指定行中划分数据字段的字段分隔符 -f file 指定的文件中读取程序 -v var=value 定义gawk程序中的一个变量及其默认自 -mf N 指定要处理的数据文件中的最大字段数 -mr N 指定数据文件中的最大数据行数 -W keyword 是定gawk的兼容模式或警告等级 从命令行读取程序脚本 示例如下： [root@redhat8 sed_gawk]# gawk '{print \"I am Iron Man!\"}' Who are you? I am Iron Man! Nice! I am Iron Man! 说明： gawk程序脚本用一对花括号来定义，必须将脚本命令放到两个花括号（{}）中 由于gawk命令假定脚本是单个文本字符串，所有还必须将脚本放到单引号中 示例程序定义了一个命令：print，它会将文本打印到STDOUT，但是执行后说明也没输出，原因在于没有在命令行上指定文件名，所有gawk会从STDIN接收数据，所以输入了两组数据后，输出了结果 终止gawk程序，可以使用组合键Ctrl+D来生成EOF（End-of-File）, 使用数据字段变量   gawk的主要特性之一是其处理文本文件中数据的能力，它会自动给一行中的每个数据元素分配一个变量，默认情况下分配变量： $0代表整个文本行 $1代表文本行中的第1个数据字段 $2代表文本行中的第2个数据字段 $n代表文本行中的第n个数据字段   在文本中，每个数据字段都是通过字段分隔符划分的，gawk中默认的字段分隔符是任意的空白字符（例如空格或制表符），示例如下： [root@redhat8 sed_gawk]# gawk '{print $3 $4}' test1 CaptainAmerica! CaptainAmerica! [root@redhat8 sed_gawk]# gawk -F : '{print $1}' /etc/passwd root bin ... [root@redhat8 sed_gawk]# echo \"I am Thanos !\"|gawk '{$3=\"Iron Man\";print $0}' I am Iron Man ! [root@redhat8 sed_gawk]# gawk '{ > $3=\"Iron Man\" > print $0}' I am Thanos ! I am Iron Man ! 说明： 示例1中gawk读取了文件，并根据需求打印出了$3和$4的值 示例2用-F指定了将冒号作为字符按分隔符 示例3示例了文本替换和使用多条命令，在命令之间加上分号即可 示例4中使用了多行输入，当使用了起始单引号，shell会使用次提示符来提示输入数据，直到输入了结尾的单引号 示例4中没有在命令行指定文件名，gawk会从SIDIN中获取数据 要退出程序，同样使用Ctrl+D组合键 从文件中读取程序 示例如下： [root@redhat8 sed_gawk]# cat test.gawk {print $1 \"'s home directory is \" $6} [root@redhat8 sed_gawk]# gawk -F : -f test.gawk /etc/passwd root's home directory is /root bin's home directory is /bin daemon's home directory is /sbin ... [root@redhat8 sed_gawk]# cat test1.gawk { text=\"'s home directory is \" print $1 text $6 } 说明： 示例中指定了用-F指定了将冒号作为字符按分隔符，并且用-f指定了文件 可以在程序文件中指定多条命令，一条命令放一行即可，不需要用分号 注意，gawk程序在引用变量时并未像shell脚本一样使用美元符号 在处理数据前运行脚本   gawk允许指定程序脚本何时运行，默认情况下会从输入中读取一行文本，然后针对该文本进行数据的执行程序脚本，有时候需要在处理数据前提前运行脚本，比如为报告创建标题。BEGIN关键字就是用来实现创建标题，示例如下： [root@redhat8 sed_gawk]# gawk 'BEGIN {print \"I am Iron Man!\"}' I am Iron Man! [root@redhat8 sed_gawk]# gawk 'BEGIN {print \"The test fiie contents:\"} > {print $0}' test1 The test fiie contents: I am Captain America! I am Captain America! 在处理数据后运行脚本 与BEGIN关键字类似，END关键字允许你指定一个程序脚本,在gawk读完数据后执行它，示例如下： [root@redhat8 sed_gawk]# gawk 'BEGIN {print \"The test fiie contents:\"} > {print $0} > END {print \"End of file\"}' test1 The test fiie contents: I am Captain America! I am Captain America! End of file 小程序脚本示例： [root@redhat8 sed_gawk]# cat test2.gawk BEGIN { print \"The latest list of uers and shells\" print \" UserID \\t Shell\" print \"------- \\t -------\" FS=\":\" } { print $1 \" \\t \" $7 } END{ print \"This concludes the listing\" } [root@redhat8 sed_gawk]# gawk -f test2.gawk /etc/passwd The latest list of uers and shells UserID Shell ------- ------- root /bin/bash bin /sbin/nologin daemon /sbin/nologin adm /sbin/nologin lp /sbin/nologin [...] apache /sbin/nologin This concludes the listing sed编辑器基础 更多的替换选项 替换标记示例如下： [root@redhat8 sed_gawk]# cat test2 I am Captain America! I am Captain America! I am Captain America! I am Captain America! [root@redhat8 sed_gawk]# sed 's/Captain America/Iron Man/' test2 I am Iron Man! I am Captain America! I am Iron Man! I am Captain America! [root@redhat8 sed_gawk]# sed 's/Captain America/Iron Man/2' test2 I am Captain America! I am Iron Man! I am Captain America! I am Iron Man! [root@redhat8 sed_gawk]# sed 's/Captain America/Iron Man/g' test2 I am Iron Man! I am Iron Man! I am Iron Man! I am Iron Man! [root@redhat8 sed_gawk]# vi test3 [root@redhat8 sed_gawk]# sed 's/Captain America/Iron Man/gw test3' test2 I am Iron Man! I am Iron Man! I am Iron Man! I am Iron Man! [root@redhat8 sed_gawk]# cat test3 I am Iron Man! I am Iron Man! I am Iron Man! I am Iron Man! [root@redhat8 sed_gawk]# cat test4 This is a test line. This is a different line. [root@redhat8 sed_gawk]# sed -n 's/test/trial/p' test4 This is a trial line. 上面示例中使用了替换标记（substitution flag）格式：s/pattern/relpaceement/flags,有四种可用的替换标记： 数字，表明新文本将替换第几处模式匹配的地方 g，表明新文本将会替换所有匹配的文本 p，表明替换行的内容打印出来，通常和send的-n（禁止send编辑器输出）选项一起使用 w file,将替换的结果写到文件中 字符替换示例： [root@redhat8 sed_gawk]# sed 's/\\/bin\\/bash/\\/bin\\/csh/' /etc/passwd root:x:0:0:root:/root:/bin/csh [root@redhat8 sed_gawk]# sed 's!/bin/bash!/bin/csh!' /etc/passwd root:x:0:0:root:/root:/bin/csh   上面的示例中，路径用的/和sed里面/冲突了，需要用反斜杠来转义，但是看起来似乎不方便，可用使用感叹号作为字符串分隔符，这样路径名就容易理解和阅读了。 使用地址   默认情况下，sed编辑器中使用的命令会作用于文本数据的所有行，如果执行将命令作用于特定的行或某些行，必须使用寻址（line addressing），sed编辑器中有两种形式的行寻址： 以数字形式表示的行区间 用文本模式来过滤出行 标准格式：[address]command,或者将特定地址的多个命令分组： address { command1 command2 } 数字方式的行寻址示例如下： [root@redhat8 sed_gawk]# sed '1s/Captain America/Batman/' test5 I am Batman! I am Captain America! I am Captain America! [root@redhat8 sed_gawk]# sed '1,3s/Captain America/Batman/' test5 I am Batman! I am Batman! I am Batman! [root@redhat8 sed_gawk]# sed '1,$s/Captain America/Batman/' test5 I am Batman! I am Batman! I am Batman! 说明： sed编辑器会将文本流中的第一行编号为1，按顺序进行编号 在命令中指定的地址可以是单个行号，或者1,3这种指定的一定区间范围内的行 可以使用美元符号，例如1,$表示从第一行开始的所有行 使用文本模式过滤器示例如下： [root@redhat8 sed_gawk]# grep huang /etc/passwd huang:x:1000:1000:huang:/home/huang:/bin/bash [root@redhat8 sed_gawk]# sed '/huang/s/bash/ksh/' /etc/passwd root:x:0:0:root:/root:/bin/bash [...] huang:x:1000:1000:huang:/home/huang:/bin/ksh 说明： 指定文本模式来过滤出要作用的行格式：/pattren/command 示例中演示了只修改huang的默认shell 命令组合示例（使用地址区间一样）： [root@redhat8 sed_gawk]# sed '2{ > s/am/am not/ > s/Captain America/Thanos/ > }' test5 I am Captain America! I am not Thanos! I am Captain America! 删除行 示例如下: [root@redhat8 sed_gawk]# cat test6 1. I am Captain America! 2. I am Captain America! 3. I am Captain America! [root@redhat8 sed_gawk]# sed '2d' test6 1. I am Captain America! 3. I am Captain America! [root@redhat8 sed_gawk]# sed '1,$d' test6 [root@redhat8 sed_gawk]# sed '/1. am/d' test6 2. I am Captain America! 3. I am Captain America! [root@redhat8 sed_gawk]# sed 'd' test6 [root@redhat8 sed_gawk]# cat test6 1. I am Captain America! 2. I am Captain America! 3. I am Captain America! 说明： 删除命令d会删除匹配指定寻址模式的所有行 可以指定地址和d一起使用，可以指定特定区间，或者模式匹配特性也适用于删除命令 sed编辑器不会修改原始文件，删除的行只是从sed编辑器的输出中删除 更多示例： [root@redhat8 sed_gawk]# sed '/1/,/2/d' test6 3. I am Captain America! [root@redhat8 sed_gawk]# cat test7 1. I am Captain America! 2. I am Captain America! 3. I am Captain America! 1. I am Iron man ! 2. I am Thanos 3. I am Captain America! test line [root@redhat8 sed_gawk]# sed '/1/,/2/d' test7 3. I am Captain America! 3. I am Captain America! test line [root@redhat8 sed_gawk]# sed '/1/,/4/d' test7 [root@redhat8 sed_gawk]# 说明： 上面第一个示例中指定第一个模式会打开行删除功能，第二个模式会关闭行删除功能，编辑器会删除两个行之间的所有行，包括指定的行 第二个示例中，发现了第二个数字\"1\"，然后再次触发了删除命令 第三个示例中，没有匹配到结束模式，所有整个数据流都被删掉了 插入和附加文本 sed编辑器允许向数据流插入和附加文本行： 插入（insert）命令（i）会在指定行前增加一个新行 附加（append）命令（a）会在指定行后增加一个新行 必须指定是要将行插入还是附加到另一行，标准格式如下： sed '[address]command\\ new line' 示例如下： [root@redhat8 sed_gawk]# echo \"I am Iron Man\" |sed 'i\\I am Thanos' I am Thanos I am Iron Man [root@redhat8 sed_gawk]# echo \"I am Iron Man\" |sed 'a\\I am Thanos' I am Iron Man I am Thanos [root@redhat8 sed_gawk]# cat test1 I am Captain America! I am Captain America! [root@redhat8 sed_gawk]# sed '2i\\ > I am Iron Man!' test1 I am Captain America! I am Iron Man! I am Captain America! [root@redhat8 sed_gawk]# sed '2a\\ > I am Iron Man!' test1 I am Captain America! I am Captain America! I am Iron Man! [root@redhat8 sed_gawk]# sed '$a\\ > I am Iron Man!\\ > I am Batman!' test1 I am Captain America! I am Captain America! I am Iron Man! I am Batman! 说明： 想要将新行附加到数据流的末尾，只要用代表数据最后一行的美元符号就可以了 要插入或附加多行文本，必须对要插入或附加的新文本中的每一行使用反斜线，直到最后一行 修改行 修改（change）命令允许修改数据流中整行文本的内容，示例如下： [root@redhat8 sed_gawk]# sed '2c\\ > I will save the world!' test6 1. I am Captain America! I will save the world! 3. I am Captain America! [root@redhat8 sed_gawk]# cat test7 1. I am Captain America! 2. I am Captain America! 3. I am Captain America! 1. I am Iron man ! 2. I am Thanos 3. I am Captain America! [root@redhat8 sed_gawk]# sed '/2. I am/c\\ > I will save the world!' test7 1. I am Captain America! I will save the world! 3. I am Captain America! 1. I am Iron man ! I will save the world! 3. I am Captain America! [root@redhat8 sed_gawk]# sed '2,5c\\ > I will save the world!' test7 1. I am Captain America! I will save the world! 3. I am Captain America! test line 说明： 可以使用数字或文本进行寻址，文本模式修改命令会修改它匹配的数据流中的任意文本 当使用地址区间时，会用这一行文本替换数据流中的两行文本，而不是逐一修改这两行文本 转换命令 转换（transform）命令（y）是唯一可以处理单个字符的sed编辑器命令。格式如下 [address]y/inchars/outchars/ 示例如下： [root@redhat8 sed_gawk]# sed 'y/123/789/' test7 7. I am Captain America! 8. I am Captain America! 9. I am Captain America! 7. I am Iron man ! 8. I am Thanos 9. I am Captain America! test line [root@redhat8 sed_gawk]# echo \"This 1 is a test of 1 try.\" |sed 'y/123/456/' This 4 is a test of 4 try. 说明： 转换会对inchars和outchars值进行一对一的映射 inchars中的第一个字符会被转换为outchars中的第一个字符，第二个字符会被转换成outchars中的第二个字符 映射过程会一直持续到处理完指定字符 如果inchars和outchars的长度不同，则sed编辑器会产生一条错误消息 转换命令是一个全局命令，会对文本中找到的所有指定字符自动进行转换 回顾打印 之前介绍过使用p标记和替换命令显示sed编辑器修改过的行，另外还有三个命令也能用来打印数据流中的信息： p命令用来打印文本行 等号（=）命令用来打印行号 小写字母l（小写L）命令用来列出行 打印行示例： [root@redhat8 sed_gawk]# echo \"I am Iron Man!\"|sed 'p' I am Iron Man! I am Iron Man! [root@redhat8 sed_gawk]# echo \"I am Iron Man!\"|sed -n 'p' I am Iron Man! [root@redhat8 sed_gawk]# sed -n '/Iron man/p' test7 1. I am Iron man ! [root@redhat8 sed_gawk]# sed -n '2,4p' test7 2. I am Captain America! 3. I am Captain America! 1. I am Iron man ! [root@redhat8 sed_gawk]# sed -n '/Thanos/{ > p > s/Thanos/Batman/p > }' test7 2. I am Thanos 2. I am Batman 说明： 在命令行上用-n选项可以禁止输出其他行，只打印包含匹配文本模式的行 最后一个示例中首先找到包含Thanos的行，并且打印出来了，然后用s命令替换文本，并用p标记打印出替换结果，同时显示了原来的文本和新文本 打印行号示例： [root@redhat8 sed_gawk]# sed '=' test1 1 I am Captain America! 2 I am Captain America! [root@redhat8 sed_gawk]# sed -n '/Iron man/{ > = > p > }' test7 4 1. I am Iron man ! 说明： 等号命令回去打印行在数据流中的当前行号，行号有数据流中的换行符决定 第二个示例是数据流中查找特定文本，并标记行号，利用-n选项让sed编辑器只显示了包含匹配文本模式的行的行号和文本   列出（list）命令（l）可以打印数据流中的文本和不可打印的ASCII字符。任何不可打印的字符要么在其八进制前加一个反斜杠，要么使用标准C风格的命名法，比如\\t来代表制表符。列出行示例： [root@redhat8 sed_gawk]# cat test8 I am Iron Man ! [root@redhat8 sed_gawk]# sed -n 'l' test8 I\\tam\\tIron\\tMan !$ $ 说明： 制表符位置使用\\t来显示，行尾的灭怨妇表示换行符 如果数据流包含了转义字符，列出命令会在毕业时候用八进制来显示 使用sed处理文件 写入文件 命令w来向文件写入行，格式：[address]w filename。说明如下： filename可以使用相对路径或绝对路径，运行sed编辑器的用户必须有文件的写权限 地址可以是sed中支持的任意类型的寻址方式，例如单个行号、文本模式、行区间或文本模式 示例如下: [root@redhat8 sed_gawk]# sed '1,2w test9' test7 1. I am Captain America! 2. I am Captain America! 3. I am Captain America! 1. I am Iron man ! 2. I am Thanos 3. I am Captain America! test line [root@redhat8 sed_gawk]# cat test9 1. I am Captain America! 2. I am Captain America! [root@redhat8 sed_gawk]# sed -n '/Captain America/w test10' test7 [root@redhat8 sed_gawk]# cat test10 1. I am Captain America! 2. I am Captain America! 3. I am Captain America! 3. I am Captain America! 说明： 第一个示例中将数据流中的前两行打印到文本文件test9中 可以使用-n选项让行选项不显示到STDOUT上 第二个示例只将包含文本模式的数据行写入到目标文件，次方法非常有用 从文件读取数据   读取（read）命令（r）允许将一个独立的文件中的数据插入到数据流中，格式：[address]r filsname。在读取命令中使用地址区间，只能指定单独的一个行号或文本模式地址，sed编辑器会将文件中的文本插入到指定的地址后。示例如下： [root@redhat8 sed_gawk]# cat test11 I am Iron Man! I will save the world ! [root@redhat8 sed_gawk]# cat test1 I am Captain America! I am Captain America! [root@redhat8 sed_gawk]# sed '1r test11' test1 I am Captain America! I am Iron Man! I will save the world ! I am Captain America! [root@redhat8 sed_gawk]# sed '/Iron Man/r test1' test11 I am Iron Man! I am Captain America! I am Captain America! I will save the world ! [root@redhat8 sed_gawk]# sed '$r test11' test1 I am Captain America! I am Captain America! I am Iron Man! I will save the world ! 可以和删除命令一起使用：利用一个文件中的数据来替换文件中的占位文本，例如有一份保持hero的文本文件,： [root@redhat8 sed_gawk]# cat hero.std Would the following hero: LIST They will save the world! [root@redhat8 sed_gawk]# cat test12 Thor,T Asgard Hulk,H Earth 现在就将hero.std中的LIST替换成hero清单，示例如下： [root@redhat8 sed_gawk]# sed '/LIST/{ > r test12 > d > }' hero.std Would the following hero: Thor,T Asgard Hulk,H Earth They will save the world! "},"09-Shell脚本/01-Shell学习笔记/08-Shell笔记-正则表达式.html":{"url":"09-Shell脚本/01-Shell学习笔记/08-Shell笔记-正则表达式.html","title":"Shell笔记-正则表达式","keywords":"","body":"Shell笔记-正则表达式 正则表达式是用户定义的模式模板（pattren template），Linux工具可以用它来过滤文本。 在Linux中，有两种流行的正则表达式引擎： POSIX基础正则表达式（basic regular expression，BRE)引擎 POSIX扩展正则表达式（extended regular expression，ERE）引擎 BRE模式   大多数Linux工具都至少符合POSIX BRE引擎规范，有些工具（sed编辑器）只符合了BRE引擎规范的子集。最基本的BRE模式是匹配数据流中的文本字符，本节内容也主要是学习BRE模式。 纯文本 回顾下之前学习的sed编辑器和gawk程序中用标准文本字符串来过滤数据： [root@redhat8 regular]# echo \"I am Iron Man !\" |sed -n '/Iron/p' I am Iron Man ! [root@redhat8 regular]# echo \"I am Iron Man !\" |sed -n '/iron/p' [root@redhat8 regular]# echo \"I am Iron Man !\" |sed -n '/Captain/p' [root@redhat8 regular]# echo \"I am Iron Man !\" |gawk '/Iron/{print $0}' I am Iron Man ! [root@redhat8 regular]# echo \"I am Iron Man !\" |gawk '/iron/{print $0}' [root@redhat8 regular]# echo \"I am Iron Man !\" |gawk '/Captain/{print $0}' [root@redhat8 regular]# echo \"I am Iron Man !\" |sed -n '/Ir/p' I am Iron Man ! [root@redhat8 regular]# echo \"I am Iron Man !\" |gawk '/Ir/{print $0}' I am Iron Man ! [root@redhat8 regular]# echo \"I am Iron Man !\" |sed -n '/I am/p' I am Iron Man ! [root@redhat8 regular]# echo \"I am Iron Man !\" |sed -n '/Ir n/p' [root@redhat8 regular]# cat test1 I am Iron Man! I am Iron Man! [root@redhat8 regular]# sed -n '/ /p' test1 I am Iron Man! 说明： 正则表达式不关心模式在数据流中的位置，也不关心模式出现了多少次 正则表达式模式都区分大小写，只会匹配大小写相符的模式 正则表达式中，不用写出整个单词，只要定义的文本出现在数据流中就能匹配 可以在正则表达式中使用空格和数字，空格和其它字符并没有什么区别 如果在正则表达式中定义了空格，那么它必须出现在数据流中，才能匹配到数据 最后示例单词间有两个空格的行匹配正则表达式模式是用来查看文本中空格问题的好办法 特殊字符 有些字符在正则表达式中有特别的含义，正则表达式识别的特殊字符包括：.*[]^${}\\+?|()。示例如下： [root@redhat8 regular]# cat test2 My current profit is $3,042! [root@redhat8 regular]# sed -n '/\\$/p' test2 My current profit is $3,042! [root@redhat8 regular]# echo \"\\ is a special character\"|sed -n '/\\\\/p' \\ is a special character [root@redhat8 regular]# echo \"99 / 9\" |sed -n '/\\//p' 99 / 9 说明： 如果要是有某个特殊字符作为文本字符，就必须转义，使用反斜线（\\） 反斜线（\\）也是特殊字符，在正则表达式中使用时候，也必须转义 尽管正斜线（/）不是正则表达式的特殊字符，但是使用时候也必须转义 锚字符 有两个特殊字符可以用来将模式锁定在数据流中的行首或行尾。 锁定在首行   脱字符（^）定义从数据流中文本行的行首开始的模式，如果模式出现在行首之外的位置，正则表达式模式则无法匹配，示例如下： [root@redhat8 regular]# echo \"Miracles happen every day\"|sed -n '/^Miracles/p' Miracles happen every day [root@redhat8 regular]# cat test3 Miracles happen every day! To make each day count. Stupid is as stupid does. [root@redhat8 regular]# sed -n '/^To/p' test3 To make each day count. 说明： 要是有脱字符，必须将它放在正则表达式中指定的模式前面 脱字符会在每个有换行符决定的新数据行的首行检查模式 如果将脱字符放到模式开头之外的其它位置，那么它就和普通字符一样 如果指定正则表达式模式时只用了脱字符，就不需要用反斜线来转义 锁定在行尾 特殊字符美元符（$）定义了行尾锚点，要想匹配，文本模式必须是行的最后一部分，示例如下： [root@redhat8 regular]# echo \"Life was like a box of chocolates\"|sed -n '/chocolate$/p [root@redhat8 regular]# echo \"Life was like a box of chocolates\"|sed -n '/chocolates$/p' Life was like a box of chocolates 组合锚点 示例如下： [root@redhat8 regular]# cat test3 Miracles happen every day! To make each day count. Stupid is as stupid does. [root@redhat8 regular]# sed -n '/^To make each day count.$/p' test3 To make each day count. [root@redhat8 regular]# cat test4 Miracles happen every day! Stupid is as stupid does. [root@redhat8 regular]# sed '/^$/d' test4 Miracles happen every day! Stupid is as stupid does. 说明： 第一个示例中sed编辑器过滤了那次不单单包含指定的文本的行 第二个示例将两个锚点组合在一起，直接没有任何文本，这样过滤了数据流中的空白行，这是删除文档中空白行的有效方法 点号字符 特殊字符点号用来匹配除换行符之外的任意单个字符，示例如下： [root@redhat8 regular]# cat test5 This is a test of a line. The cat is sleeping. That is a very nice hat. This test is at line four. at ten o'clock we'll go home. [root@redhat8 regular]# sed -n '/.at/p' test5 The cat is sleeping. That is a very nice hat. This test is at line four. 说明： 如果在点号的位置没用字符，那么模式就不成立，示例中第五行就是，点号放在行首就不会匹配该模式了 第四行匹配到了，虽然at前面看起来没有任何字符，实际上有空格，在正则表达式中，空格也是字符 字符组   如果想限定待匹配的具体字符，在正则表达式中，可以使用字符组（character class），可以定义用来匹配文本模式中的某个位置的一组字符，如果字符组中的某个字符出现来了数据流中，那它就匹配了该模式。使用方括号来定义一个字符组，示例如下： [root@redhat8 regular]# sed -n '/[ch]at/p' test5 The cat is sleeping. That is a very nice hat. [root@redhat8 regular]# echo \"Yes\" |sed -n '/[Yy]es/p' Yes [root@redhat8 regular]# echo \"yes\" |sed -n '/[Yy]es/p' yes [root@redhat8 regular]# echo \"YeS\" |sed -n '/[Yy][Ee][Ss]/p' YeS [root@redhat8 regular]# sed -n '/[0123]/p' test6 This line has 2 number on it This line number is 3 说明： 方括号中包含所有希望出现在该字符组中的字符，并且字符组中必须有个字符来匹配相应的位置 不太确定某个字符的大小写时，字符组会非常有用 可以在单个表达式中使用多个字符组 字符组中还可以使用数字，也可以组合在一起使用   字符和数字组合在一起使用进行匹配，比如电话号码和邮编，当尝试匹配某种特定的格式时，需要注意，下面示例第一次虽然匹配处理邮政编码，但是也通过了六位数的数字，可以指定行首和行尾进行匹配，示例如下： [root@redhat8 regular]# cat test7 518031 5180 5180555 518 51866 [root@redhat8 regular]# sed -n ' > /[0123456789][0123456789][0123456789][0123456789][0123456789][0123456789]/p > ' test7 518031 5180555 [root@redhat8 regular]# sed -n ' > /^[0123456789][0123456789][0123456789][0123456789][0123456789][0123456789]$/p > ' test7 518031 字符组一个常见的用法是解析拼错的单词，当然正确拼写的也能匹配出来，示例如下： [root@redhat8 regular]# cat test8 Miracles happen every dey! To make each day count. Stupid is as stopid does. [root@redhat8 regular]# sed -n ' > /d[ea]y/p > /st[ou]pid/p > ' test8 Miracles happen every dey! To make each day count. Stupid is as stopid does. 排除型字符组   可以寻找组总没有的字符，而不是去匹配组总含有的字符，在字符组的开头加一个脱字符即可，示例如下： [root@redhat8 regular]# sed -n '/[^ch]at/p' test5 This test is at line four. 说明： 示例中匹配除c或h之外的所有字符，包括空格，所以匹配出来了 即使是排除，字符组也必须匹配一个字符，示例中匹配的是空格，所以在test5中第五行依旧没有匹配出来 区间 之前邮编匹配例子中每个数字都输入了，比较麻烦，可以使用区间来简化，示例如下： [root@redhat8 regular]# sed -n ' > /^[0-9][0-9][0-9][0-9][0-9][0-9]$/p > ' test7 518031 [root@redhat8 regular]# echo \"x86\"|sed -n '/^[0-9][0-9]$/p' [root@redhat8 regular]# echo \"x86\"|sed -n '/[0-9][0-9]/p' x86 [root@redhat8 regular]# echo \"x86\"|sed -n '/[0-9][0-9]$/p' x86 [root@redhat8 regular]# sed -n '/[a-i]at/p' test5 The cat is sleeping. That is a very nice hat. [root@redhat8 regular]# sed -n '/[a-dg-i]at/p' test5 The cat is sleeping. That is a very nice hat. 说明： 使用区间可以减少很多键盘的输入 同样方法也适用于字母，也可以都在单个字符组指定多个不连续的字母区间 特殊字符组 BRE特殊字符组： 组 描述 [[:alpha:]] 匹配任意字母字符，不管是大写还是小写 [[:alnum:]] 匹配任意字母数字字符0~9、a~z或A~Z [[:blank:]] 匹配空格或制表符 [[:digit:]] 匹配0~9之间的数字 [[:lower:]] 匹配小写字母字符a~z [[:print:]] 匹配任意可打印的字符 [[:punct:]] 匹配标点符号 [[:space:]] 匹配任意空白字符：空格、制表符、NL、FF、VT和CR [[:upper:]] 匹配任意大写字母字符A~Z 可以在正则表达式模式中将特殊字符组像普通字符组一样使用： [root@redhat8 regular]# echo \"Hope can set you free\"|sed -n '/[[:digit:]]/p' [root@redhat8 regular]# echo \"Hope can set you free\"|sed -n '/[[:alpha:]]/p' Hope can set you free [root@redhat8 regular]# echo \"x86\"|sed -n '/[[:digit:]]/p' x86 [root@redhat8 regular]# echo \"Hope can set you free\"|sed -n '/[[:punct:]]/p' [root@redhat8 regular]# echo \"Hope can set you free !\"|sed -n '/[[:punct:]]/p' Hope can set you free ! 星号 在字符后面放置星号表明该字符必须在匹配模式的文本中出现0次或多次： [root@redhat8 regular]# echo \"lt\" | sed -n '/le*t/p' lt [root@redhat8 regular]# echo \"let\" | sed -n '/le*t/p' let [root@redhat8 regular]# echo \"leet\" | sed -n '/le*t/p' leet 经常用于处理常见拼写错误或不同语言中拼写不同的情况，例如color和colour： [root@redhat8 regular]# echo \"IBM color is bule!\"|sed -n '/colou*r/p' IBM color is bule! [root@redhat8 regular]# echo \"IBM colour is bule!\"|sed -n '/colou*r/p' IBM colour is bule!   可以将点号特殊字符和星号特殊字符组合使用，这个组合能够匹配任意数量的任意字符，通常用在数据流中两个可能相邻或不相邻的文本字符串之间： [root@redhat8 regular]# echo \"All life is a game of luck.\" | sed -n ' > /of.*luck/p' All life is a game of luck. 星号还能用在字符组上，它允许指定可能在文本中出现多次的字符组或字符区间。 [root@redhat8 regular]# echo \"lt\" | sed -n '/l[ea]*t/p' lt [root@redhat8 regular]# echo \"lat\" | sed -n '/l[ea]*t/p' lat [root@redhat8 regular]# echo \"let\" | sed -n '/l[ea]*t/p' let [root@redhat8 regular]# echo \"leet\" | sed -n '/l[ea]*t/p' leet [root@redhat8 regular]# echo \"laaeet\" | sed -n '/l[ea]*t/p' laaeet 扩展正则表达式   POSIX ERE模式包括了一些可供Linux应用和工具使用的额外符号，gawk程序能够识别ERE模式，但sed编辑器不能。本节内容主要是学习gawk程序中的较常见的ERE模式符号。 问号   问号类似星号，问号表明前面的字符可以出现0次或1次，但是仅限于此，它不会匹配多次出现的字符。示例如下： [root@redhat8 regular]# echo \"lt\" |gawk '/le?t/{print $0}' lt [root@redhat8 regular]# echo \"let\" |gawk '/le?t/{print $0}' let [root@redhat8 regular]# echo \"leet\" |gawk '/le?t/{print $0}' leet [root@redhat8 regular]# echo \"lt\" |gawk '/l[ae]?t/{print $0}' lt [root@redhat8 regular]# echo \"let\" |gawk '/l[ae]?t/{print $0}' let [root@redhat8 regular]# echo \"laet\" |gawk '/l[ae]?t/{print $0}' [root@redhat8 regular]# echo \"leet\" |gawk '/l[ae]?t/{print $0}' 加号   加号类似星号的另一个模式符号，加号表明前面的字符可以出现1次或多次，必须至少出现一次。示例如下： [root@redhat8 regular]# echo \"lt\" |gawk '/le+t/{print $0}' [root@redhat8 regular]# echo \"let\" |gawk '/le+t/{print $0}' let [root@redhat8 regular]# echo \"leet\" |gawk '/le+t/{print $0}' leet [root@redhat8 regular]# echo \"lt\" |gawk '/l[ae]+t/{print $0}' [root@redhat8 regular]# echo \"let\" |gawk '/l[ae]+t/{print $0}' let [root@redhat8 regular]# echo \"lat\" |gawk '/l[ae]+t/{print $0}' lat [root@redhat8 regular]# echo \"leat\" |gawk '/l[ae]+t/{print $0}' leat [root@redhat8 regular]# echo \"leet\" |gawk '/l[ae]+t/{print $0}' leet [root@redhat8 regular]# echo \"laaeet\" |gawk '/l[ae]+t/{print $0}' laaeet 使用花括号   ERE中的花括号允许为可重复的正则表达式指定一个上限，通常称为间隔（interval），这个特性可以精确调整字符或字符集在模式中具体出现的次数，可以有两种格式来指定区间： m：正则表达式准确出现m次 m,n：正则表达式至少出现m次，至多n次 示例如下： [root@redhat8 regular]# echo \"lt\"|gawk --re-interval '/le{1}t/{print $0}' [root@redhat8 regular]# echo \"let\"|gawk --re-interval '/le{1}t/{print $0}' let [root@redhat8 regular]# echo \"leet\"|gawk --re-interval '/le{1}t/{print $0}' [root@redhat8 regular]# echo \"leet\"|gawk --re-interval '/le{2}t/{print $0}' leet [root@redhat8 regular]# echo \"lt\"|gawk --re-interval '/le{1,2}t/{print $0}' [root@redhat8 regular]# echo \"let\"|gawk --re-interval '/le{1,2}t/{print $0}' let [root@redhat8 regular]# echo \"leet\"|gawk --re-interval '/le{1,2}t/{print $0}' leet [root@redhat8 regular]# echo \"leeet\"|gawk --re-interval '/le{1,2}t/{print $0}' [root@redhat8 regular]# echo \"lt\"|gawk --re-interval '/l[ae]{1,2}t/{print $0}' [root@redhat8 regular]# echo \"let\"|gawk --re-interval '/l[ae]{1,2}t/{print $0}' let [root@redhat8 regular]# echo \"leet\"|gawk --re-interval '/l[ae]{1,2}t/{print $0}' leet [root@redhat8 regular]# echo \"laet\"|gawk --re-interval '/l[ae]{1,2}t/{print $0}' laet [root@redhat8 regular]# echo \"laaeet\"|gawk --re-interval '/l[ae]{1,2}t/{print $0}' 管道符号   管道符号允许在检查数据流时，用逻辑OR方式指定正则表达式引擎要用的两个或多个模式，如果任何一个模式匹配了数据流文本，文本就通过测试，格式：expr1|expr2,示例如下： [root@redhat8 regular]# echo \"Hope can set you free\" |gawk '/can|yes/{print $0}' Hope can set you free [root@redhat8 regular]# echo \"Hope can set you free\" |gawk '/[ch]an|yes/{print $0}' Hope can set you free 注意：正则表达式和管道符号之间不能有空格，否则会当作正则表达式的一部分。 表达式分组   正则表达式模式也可以用圆括号进行分组，当使用正则表达式模式分组时，改组会被视为一个标准字符，示例如下： [root@redhat8 regular]# echo \"Sat\"|gawk '/Sat(urday)?/{print $0}' Sat [root@redhat8 regular]# echo \"Satutday\"|gawk '/Sat(urday)?/{print $0}' Satutday [root@redhat8 regular]# echo \"cat\"|gawk '/(c|b)a(b|t)/{print $0}' cat [root@redhat8 regular]# echo \"cab\"|gawk '/(c|b)a(b|t)/{print $0}' cab [root@redhat8 regular]# echo \"bat\"|gawk '/(c|b)a(b|t)/{print $0}' bat [root@redhat8 regular]# echo \"bab\"|gawk '/(c|b)a(b|t)/{print $0}' bab [root@redhat8 regular]# echo \"tab\"|gawk '/(c|b)a(b|t)/{print $0}' 说明： 可以像普通字符一样给该组使用特殊字符 示例中urday分组以及问号，使模式可以匹配完整的Saturday或缩写Sat 模式(c|b)a(b|t)会匹配第一组中字母的任意组合以及第二组中字母的任意组合 正则表达式实战 为方便查阅，收录在以下章节，：Shell-正则表达式实例 "},"09-Shell脚本/01-Shell学习笔记/09-Shell笔记-sed编辑器.html":{"url":"09-Shell脚本/01-Shell学习笔记/09-Shell笔记-sed编辑器.html","title":"Shell笔记-sed编辑器","keywords":"","body":"Shell笔记-sed编辑器   之前学习过一些sed编辑器的基础命令，能够满足大多数日常文本编辑的需求，本节学习sed编辑器提供的一些高级特性。 多行命令   之前学习的sed编辑器是定义好的脚本命令一次处理一行数据，处理完成后再到下一行重复这个过程。有时候需要跨多行的数据执行操作，sed编辑器包含了三个可用来处理多行文本的特殊命令： N:将数据流中的下一行加进来创建一个多行组（multiline group）来处理 D:删除多行组中的一行 P:打印多行组中的一行 next命令 单行next命令   小写的n命令会告诉sed编辑器移动到数据流中的下一行文本，而不用重新回到命令的最开始再执行一遍。示例如下： [root@redhat8 sed]# cat test1 Miracles happen every day ! To make each day count ! Stupid is as stupid does ! [root@redhat8 sed]# sed '/^$/d' test1 Miracles happen every day ! To make each day count ! Stupid is as stupid does ! [root@redhat8 sed]# sed '/happen/{n;d}' test1 Miracles happen every day ! To make each day count ! Stupid is as stupid does ! 说明： 示例中一共五行，两行是空的，目标是删除首行之后的空白行，而留下另一个空白行，使用删除空白行的sed脚本会删除两个空白行 可以使用n命令解决，示例中，脚本会查找含有单词happen的行，找到后n命令会让sed编辑器移动到文本的下一行，也就是空白行，然后继续执行命令列表，下一个就是d命令，也就是删除 sed编辑器执行完脚本后，会从数据流中读取下一行文本，并从头开始执行脚本，但是找不到含有单词happen的行了 合并文本行   单行next命令ui将数据流中的下一个文本行移动到sed编辑器的工作空间（称为模式空间）；多行版的next命令（用大写N）会将下一个文本添加到模式空间中已有的文本后，示例如下： [root@redhat8 sed]# cat test2 Miracles happen every day ! To make each day count ! Stupid is as stupid does ! [root@redhat8 sed]# sed '/count/{N;s/\\n/ /}' test2 Miracles happen every day ! To make each day count ! Stupid is as stupid does ! 说明： 示例中将数据流中的两个文本行合并到同一个模式空间中，虽然又换行符，但是sed编辑器会当作一行来处理 sed编辑器找到含有count的那行文本，然后用N命令将下一行合并到此行，然后用替换命令s将换行符替换成空格 在数据文件中查找一个可能分散在两行中的文本短语示例： [root@redhat8 sed]# cat test4 Today,the RHEL System Administrator's group meeting will be held. All System Administrators should attend. Thank you for your attenddance. [root@redhat8 sed]# sed 'N;s/System Administrator/Desktop User/' test4 Today,the RHEL System Administrator's group meeting will be held. All Desktop Users should attend. Thank you for your attenddance. [root@redhat8 sed]# sed 'N;s/System.Administrator/Desktop User/' test4 Today,the RHEL Desktop User's group meeting will be held. All System Administrators should attend. Thank you for your attenddance. 说明： 示例中用N命令将发现的第一个单词的那行和下一行进行合并处理，即使出现了换行符，同样可以找到 替换命令在两个单词之间使用了通配符模式（.）来匹配空格和换行符   上面示例中将两行合并成一行，有时候也行并不需要，可以使用两个替换命令，一个用来匹配出现在多行的情况，一个用来匹配出现在单行情况，示例如下： [root@redhat8 sed]# sed 'N > s/System\\nAdministrator/Desktop\\nUser/ > s/System Administrator/Desktop User/ > ' test4 Today,the RHEL Desktop User's group meeting will be held. All Desktop Users should attend. Thank you for your attenddance.   脚本也有问题，当到最后一行时候，没有下一行了，N命令会让sed编辑器停止，如果要匹配的文本正好在最后一行，就不会匹配到数据了，解决方法就是将单行命令放到N命令前面，并将多行命令放到N命令后面，示例如下： [root@redhat8 sed]# cat test4 Today,the RHEL System Administrator's group meeting will be held. All System Administrators should attend. [root@redhat8 sed]# sed 'N;s/System Administrator/Desktop User/' test4 Today,the RHEL System Administrator's group meeting will be held. All System Administrators should attend. [root@redhat8 sed]# sed 'N > s/System\\nAdministrator/Desktop\\nUser/ > s/System Administrator/Desktop User/ > ' test4 Today,the RHEL Desktop User's group meeting will be held. All System Administrators should attend [root@redhat8 sed]# sed ' > s/System Administrator/Desktop User/ > N > s/System\\nAdministrator/Desktop\\nUser/ > ' test4 Today,the RHEL Desktop User's group meeting will be held. All Desktop Users should attend. 多行删除命令   sed编辑器提供了多行删除命令D，它只删除模式空间中的第一行，会删除到换行符（含换行符）为止的所有字符，示例如下： [root@redhat8 sed]# sed 'N;/System\\nAdministrator/D' test4 Administrator's group meeting will be held. All System Administrators should attend. Thank you for your attenddance. [root@redhat8 sed]# cat test3 All life is a game of luck! Everything you see exists together in a delicate balance ! [root@redhat8 sed]# sed '/^$/{N;/luck/D}' test3 All life is a game of luck! Everything you see exists together in a delicate balance ! 说明： 第一个示例中，文本的第二行被N命令加到了模式空间，但仍然完好，此方法可以用来删除目标数据字符串所在行的前一行文本 第二个示例中，删除了数据流中出现的第一行前的空白行；先查找空白行，然后N命令将下一个文本行添加到模式空间，新的模式空间中含有luck单词，D命令会删除模式空间中的第一行 如果不结合使用N命令和D命令，就不可能在不删除其它空白行的情况下只删除一个空白行 多行打印命令   多行打印命令（P）沿用了和之前同样的方法，它只打印多行模式空间中的第一行，直到换行符为止的所有字符。当用-n选项来阻止脚本输出时，和单行p命令用法大同小异，示例如下： [root@redhat8 sed]# sed -n 'N;/System\\nAdministrator/P' test4 Today,the RHEL System 保持空间   模式空间（pattern space）是一块活跃的缓冲区，在sed编辑器执行命令时它会保存待检查的文本。但它并不是sed编辑器保存文本的唯一空间。   sed编辑器又另一块称作保持空间（hold space）的缓冲区域，可以用来临时保存一些行，有5条命令可用来操作保持空间，如下表所示： 命令 描述 h 将模式空间复制到保持空间 H 将模式空间附加到保持空间 g 将保持空间复制到模式空间 G 将保持空间附加到模式空间 x 交换模式空间和保持空间的内容 示例如下： [root@redhat8 sed]# sed -n '/1./{h;p;n;p;g;p}' test5 1.Miracles happen every day ! 2.To make each day count ! 1.Miracles happen every day ! 说明： sed编辑器在地址中用正则表达式来过滤出含有1.的行 当含有1.的行出现时，h命令将改行放到保持空间 p命令打印模式空间也就是第一个数据行的内容 n命令提取数据流中的下一行（2.开头那行），并将它放到模式空间 p命令打印模式空间的内容，也就是第二个数据行 g命令将保持空间的内容（1.开头那行）放回到模式空间，替换当前文本 p命令打印模式空间的内容，也就是第一个数据行 少一个p就会改变输出，此方法可以用来将整个文件的文本进行反转，示例如下： [root@redhat8 sed]# sed -n '/1./{h;n;p;g;p}' test5 2.To make each day count ! 1.Miracles happen every day ! 排除命令   感叹号命令（!）用来排除（negate）命令，也就是让原本会起作用的命令不起作用，示例如下： [root@redhat8 sed]# sed -n '/happen/!p' test5 2.To make each day count ! 3.Stupid is as stupid does ! 4.All life is a game of luck!   正常p会答应匹配的的那一行，示例中恰号相反，其它的行都打印了。在之前有一种情况是sed编辑器无法处理数据流中的最后一行文本，因为只会再也没有其他行了，可以用感叹号来解决这个问题。 [root@redhat8 sed]# sed 'N > s/System\\nAdministrator/Desktop\\nUser/ > s/System Administrator/Desktop User/ > ' test4 Today,the RHEL Desktop User's group meeting will be held. All System Administrators should attend [root@redhat8 sed]# sed '$!N; > s/System\\nAdministrator/Desktop\\nUser/ > s/System Administrator/Desktop User/ > ' test4 Today,the RHEL Desktop User's group meeting will be held. All Desktop Users should attend. 说明：   美元符号表示数据流中的最后一行文本，当sed编辑器到了最后一行时，它没有执行N命令，但它对所有其他行都执行了这个命令。 可以用来反转数据流中文本行的顺序，可以参照如下方法使用模式空间： 在模式空间中放置一行 将模式空间中的行放到保持空间中 在模式空间中放入下一行 将保持空间附加到模式空间后 将模式空间中的所有内容都放到保持空间中 重复执行第3-5步，直到所有行都反序放到了保持空间中 提取并打印行 方法说明： 不想在处理过程中打印行，要使用sed的-n命令行选项 下一步决定如何将保持空间文本附加到模式空间文本后面，可以使用G命令完成 不想将保持空间附加到要处理的第一行文本后面，可以使用感叹号解决：1!G 下一步是将新的模式空间（含已反转的行）放到保持空间，用h命令就行 将模式空间中的整个数据流都反转后，就是打印结果，打印需要用$p 示例如下： [root@redhat8 sed]# cat test2 Miracles happen every day ! To make each day count ! Stupid is as stupid does ! [root@redhat8 sed]# sed -n '{1!G ; h ; $p }' test2 Stupid is as stupid does ! To make each day count ! Miracles happen every day ! 在Linux中，tac命令会倒序显示一个文本文件，cat命令拼写相反，示例如下： [root@redhat8 sed]# tac test2 Stupid is as stupid does ! To make each day count ! Miracles happen every day ! 改变流   一般sed编辑器会从脚本的顶部开始，一直执行号脚本的结尾（D命令除外，它会强制sed返回到脚本的顶部）。sed编辑器提供了一个方法来改变命令脚本的执行流程，其结果与结构化编程类型。 分支   sed编辑器可以基于地址、地址模式或地址区间排除一整块命令，允许只对数据流中的特定行执行一组命令，分支（branch）命令b的格式：[address]b [label]。说明： address参数决定了哪些行的数据会触发分支命令 label参数定义了要跳转到的位置 如果没有label参数，跳转命令会跳转到脚本的结尾 示例如下： [root@redhat8 sed]# cat test6 This is the header line! This is the first data line! This is the second data line! This is the last line! [root@redhat8 sed]# sed '{2,3b;s/This is/Is this/;s/line!/test?/}' test6 Is this the header test? This is the first data line! This is the second data line! Is this the last test? 说明： 分支命令在数据流中的第2行和第3行处跳过了两个替换命令 不希望跳到脚本的几位，可以为分支命令定义一个标签，最多七个字符长度，格式：:label12 需要指定标签时候将其加到b命令后即可 使用标签允许跳过地址匹配出的命令，但仍然会执行脚本中的其它命令 示例如下： [root@redhat8 sed]# sed '{/first/b jump1;s/This is the/No jump on/ > :jump1 > s/This is the/Jump here on/}' test6 No jump on header line! Jump here on first data line! No jump on second data line! No jump on last line! 说明： 跳转命令指定如果文本中出现了first，程序应该跳到标签为jump1的脚本行 如果分支命令的模式没有匹配，sed会继续执行脚本中的命令，包括分支标签后的命令 所有替换命令都会在不匹配分支模式的行上执行 如果某行匹配了分支模式，sed会跳转到带有分支标签的那行，所有只有最后一个替换命令会执行   上面示例中是跳转到sed脚本后面的标签上，可以跳转到脚本中靠前的标签上，这样可以达到循环效果，示例如下： [root@redhat8 sed]# echo \"A, test, to, remove, commas.\"|sed -n '{ > :start > s/,//1p > b start > }' A test, to, remove, commas. A test to, remove, commas. A test to remove, commas. A test to remove commas. ^C [root@redhat8 sed]# echo \"A, test, to, remove, commas.\"|sed -n '{ > :start > s/,//1p > /,/b start > }' A test, to, remove, commas. A test to, remove, commas. A test to remove, commas. A test to remove commas. 说明： 脚本每次迭代都会删除文本中的第一个逗号，并打印字符串 第一次示例中有问题，脚本陷入了死循环，不停查找逗号，需要用ctrl+c终止脚本 防止进入死循环，可以为分支命令指定一个地址模式来查找，第二次示例中使用了逗号，当脚本中最后一个逗号被删除后，分支命令就不会再执行了 测试   测试（test）命令（t）也可以用来改变sed编辑器脚本的执行流程，测试命令会根据替换命令的结果跳转到某个标签，而不是根据地址跳转。格式：[address]t [label]，说明： 如果替换命令成功匹配并替换了一个模式，测试命令就会跳转到指定的标签 如果替换命令未能匹配指定的模式，测试命令就不会跳转 在没有指定标签的情况下，如果测试成功，sed会跳转到脚本的结尾 测试命令提供了对数据流中的文本执行基本的if-then语句的一个低成本的方法 例如已经做了一个替换，不需要再做另一个替换，可以使用测试命令： [root@redhat8 sed]# sed '{ > s/first/matched/ > t > s/This is the/No match on/ > }' test6 No match on header line! This is the matched data line! No match on second data line! No match on last line! [root@redhat8 sed]# echo \"A, test, to, remove, commas.\"|sed -n '{ > :start > s/,//1p > t start > }' A test, to, remove, commas. A test to, remove, commas. A test to remove, commas. A test to remove commas. 说明： 第一个替换命令会查找模式文本first，匹配了行中的模式，就会替换文本，而且测试命令会跳过后面的替换命令 如果第一个替换命令未能匹配到模式，第二个替换命令就会被执行 第二个示例演示了用测试命令结束之前用分支命令形成的无限循环 当无需替换时，测试命令不会跳转而是继续实行剩下的脚本 模式替代   在使用通配符时，很难知道到底哪些文本会匹配模式。例如想在行中匹配的单词边上放上引号，如果只是要匹配模式中的一个单词，就比较简单,如果模式中使用通配符（.）来匹配多个单词，就满足不了需求： [root@redhat8 sed]# echo \"The cat sleeps in his hat.\"|sed 's/cat/\"cat\"/' The \"cat\" sleeps in his hat. [root@redhat8 sed]# echo \"The cat sleeps in his hat .\"|sed 's/.at/\".at\"/g' The \".at\" sleeps in his \".at\" . &符号   &符号可以用来代表替换命令中的匹配的模式，不管模式匹配的是什么文本，都可以在替换模式中使用&符号来使用这段文本，这样就可以操作模式所匹配到的任何单词了，示例如下： [root@redhat8 sed]# echo \"The cat sleeps in his hat .\"|sed 's/.at/\"&\"/g' The \"cat\" sleeps in his \"hat\" . 说明： 当模式匹配到了单词cat，\"cat\"就会出现在了替换后的单词里面 当匹配到了单词hat，\"cat\"就会出现在了替换后的单词里面 替换单独的单词   &符号提取匹配替换命令中的指定模式的整个字符串，有时候只想提取字符串的一部分。在sed编辑器中用圆括号来定义替换模式的子模式，子模式说明： 可以在替换模式中使用特殊字符来引用每个子模式，替代字符用反斜线和数字组成，数字表示子模式的位置 sed编辑器会给第一个子模式分配字符\\1,给第二个分配字符\\2，依此类推 示例如下： [root@redhat8 sed]# echo \"The System Administrator manual\" | sed ' > s/\\(System\\) Administrator/\\1 User/' The System User manual 说明： 在替换命令中使用圆括号时必须用转义字符将他们标为分组而不是普通圆括号 示例中替换命令用一对圆括号将单词System括起来，表示其为一个子模式 然后在替换模式中使用\\1来提起第一个匹配的子模式   如果需要用一个单词来替换一个短语，而这个单词刚好是该短语的子字符串，但是那个子字符串恰巧使用了通配符，这时候使用子模式会很方便： [root@redhat8 sed]# echo \"The furry cat is pretty\"|sed 's/furry \\(.at\\)/\\1/' The cat is pretty [root@redhat8 sed]# echo \"The furry hat is pretty\"|sed 's/furry \\(.at\\)/\\1/' The hat is pretty 说明： 这种情况下，不能用&符号，因为他会替换整个匹配的模式 子模式允许选择将模式中的某部分作为替代模式 当需要在两个或多个子模式间插入文本时，尤为有用。下面示例中使用子模式在大数字中插入逗号： [root@redhat8 sed]# echo \"1234567\"|sed '{ > :start > s/\\(.*[0-9]\\)\\([0-9]\\{3\\}\\)/\\1,\\2/ > t start > }' 1,234,567 说明： 示例脚本将匹配模式分成了两部分：.*[0-9]和[0-9]{3} 这个模式会查找两个子模式，第一个子模式是以数字结尾的任意长度的字符，第二个是若干组三位数字，注意正则表达式中使用花括号时候用了转义字符 如果这个模式在文本中找到阿里，替代文本会在两个子模式之间加一个逗号，每个子模式都会通过其位置来标示 示例脚本使用测试命令来遍历这个数字，知道放置好所有的逗号 在脚本中使用sed 实用包装脚本   sed编辑器有时候写的脚本会比较长，可以讲sed编辑器命令放到shell包装脚本（wrapper）中，不需要每次使用都重新键入整个脚本。包装脚本充当sed编辑器脚本和命令行之间的中间人角色。在shell脚本中，可以讲普通的shell变量及参数和sed编辑器脚本一起使用，示例脚本如下： #!/bin/bash # Shell wrapper for sed editor script. # Shell wrapper to reverse text file lines. sed -n '{ 1!G ; h ; $p }' $1 # 运行脚本示例如下： [root@redhat8 sed]# sh reverse.sh test6 This is the last line! This is the second data line! This is the first data line! This is the header line! 重定向sed的输出   默认情况下sed编辑器会将脚本输出到STDOUT上，也可以使用$()将输出重定向到一个变量中，示例脚本如下： #!/bin/bash # Add commas ro number in factorial answer factorial=1 counter=1 number=$1 # while [ $counter -le $number ] do factorial=$[ $factorial * $counter ] counter=$[ $counter + 1 ] done # result=$(echo $factorial | sed '{ :start s/\\(.*[0-9]\\)\\([0-9]\\{3\\}\\)/\\1,\\2/ t start }') echo \"The restult is $result\" 脚本运行示例如下： [root@redhat8 sed]# sh fact.sh 20 The restult is 2,432,902,008,176,640,000 sed实用工具 为方便查阅，收录在以下位置：Shell-sed&gawk实例 "},"09-Shell脚本/01-Shell学习笔记/10-Shell笔记-gawk程序.html":{"url":"09-Shell脚本/01-Shell学习笔记/10-Shell笔记-gawk程序.html","title":"Shell笔记-gawk程序","keywords":"","body":"Shell笔记-gawk程序 使用变量 gawk编程语言支持两种不同类型的变量：内建变量和自定义变量。 内建变量 gawk程序使用内建变量来引用程序数据的一些特殊功能。 字段和记录分隔符变量   之前学习了内建变量中的数据字段变量，可以使用美元符号（$）和字段在该记录中的位置值来引用记录对应的字段。默认情况下，字段分隔符是一个空白字符，空格或者制表符，可以使用命令行参数-F或者在gawk程序中使用特殊内建变量FS来更改字段分隔符。gawk数字字段和记录变量： 变量 描述 FIELDWIDTHS 由空格分隔的一列数字，定义了每个数据字段确切宽度 FS 输入字段分隔符 RS 输入记录分隔符 OFS 输出字段分隔符 ORS 输出记录分隔符   变量FS和OFS定义了gawk如何处理数据流中的数据字段，FS来定义记录中的字段分隔符，OFS功能一致只是用在print输出上，示例如下： [root@redhat8 gawk]# cat test1 Thor,Hulk,Captain America,Iron man Batman,Wonder Woman,Super Man [root@redhat8 gawk]# gawk 'BEGIN{FS=\",\"} {print $1,$2,$3}' test1 Thor Hulk Captain America Batman Wonder Woman Super Man [root@redhat8 gawk]# gawk 'BEGIN{FS=\",\";OFS=\"\"}{print $1,$2,$3}' test1 ThorHulkCaptain America BatmanWonder WomanSuper Man 说明： 默认情况下，gawk会将OFS设置成一个空格 通过OFS变量，可以在输出中使用任意字符串来分隔字段   FIELDWIDTHS变量允许不依靠字段分隔符来读取记录，一些应用程序中，数据没有使用字段分隔符，而是放置在记录中的特定列，需要设定FIELDWIDTHS变量来匹配数据在记录中的位置，示例如下： [root@redhat8 gawk]# cat test2 1103.1418866.66 911-5.328499.00 02711.1133100.9 [root@redhat8 gawk]# gawk 'BEGIN{FIELDWIDTHS=\"3 5 2 5\"} > {print $1,$2,$3,$4}' test2 110 3.141 88 66.66 911 -5.32 84 99.00 027 11.11 33 100.9 说明： 一旦设置了FIELDWIDTHS变量，gawk就会忽略FS变量，并根据提供的字段宽度来计算字段 示例中FIELDWIDTHS变量定义了四个字段，gawk依此来解析数据记录 一旦设置了FIELDWIDTHS变量的值，就不能再改变了，这种方法不适用于边长的字段   变量RS和ORS定义了gawk程序如何处理数据流中的记录，默认情况下都是换行符，RS的默认值表明输入数据流中的每行新文本就是一条新记录，示例如下： [root@redhat8 gawk]# cat test3 Bond Huang 123 ZhongXin street ShenZhen,518000 0755-12345678 Bond Huang 321 HongFu street DongGuan,523000 0769-87654321 [root@redhat8 gawk]# gawk 'BEGIN{FS=\"\\n\";RS=\"\"}{print $1,$4}' test3 Bond Huang 0755-12345678 Bond Huang 0769-87654321 说明： 示例中一个字段占据多行，使用默认的FS和RS时候gawk会把每行作为一个单独的记录，并将记录中的空格当作字段分隔符 示例中将FS设置成换行符，表示数据流中每行都是一个单独的字段，每行所有数据都是同一个字段 把RS设置成空字符串，然后在记录间保留一个空白行，gawk就会把每个空白行当作一个记录分隔符 数据变量 下表列出gawk中的其它内建变量： 变量 描述 ARGC 当前命令行参数个数 ARGIND 当前文件在ARGV中的位置 ARGV 包含命令行参数的数组 CONVFMT 数字的转换个数(参见printf语句)默认值为%.6 g ENVIRON 当前shell环境变量及其值组成的关联数组 ERRNO 当读取或关闭输入文件发生错误时的系统错误号 FILENAME 用作gawk输入数据的数据文件的文件名 FNR 当前数据文件中的数据行数 IGNORECASE 设成非零值时，忽略gawk命令中出现的字符串的字符大小写 NF 数据文件中的字段总数 NR 已处理的输入记录数 OFMT 数字的输出格式，默认值为%.6 g RLENGTH 由match函数所匹配的子字符串的长度 RSTART 由match函数所匹配的子字符串的起始位置 ARGC和ARGV变量允许从shell中获得命令行参数总数以及大妈的值： [root@redhat8 gawk]# gawk 'BEGIN{print ARGC,ARGV[1]}' test1 2 test1 说明： gawk并不会将程序脚本当成命令行参数的一部分，所以示例中两个参数是gawk命令和test1参数 ARGV数组从索引0开始，代表的是命令，第一个数组值是gawk命令后的第一个命令行参数 在脚本中引用gawk变量时候，变量名前面不用加美元符，跟shell变量不一样 ENVIRON变量关联数组来提取shell环境变量： [root@redhat8 gawk]# gawk 'BEGIN{print ENVIRON[\"HOME\"] > print ENVIRON[\"PATH\"]}' /root /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin 说明： 关联数组用文本作为数组的索引值，而不是数值；数组索引中的文本是shell的环境变量名，而数组的值则是shell环境变量的值 变量ENVIRON[\"HOME\"]从shell中提取了HOME环境变量的值，这种方法可以从shell中提取任何环境变量的值 当在gawk程序中跟踪数据字段和记录时，变量FNR、NR和NF用起来非常方便： [root@redhat8 gawk]# gawk 'BEGIN{FS=\":\";OFS=\":\"} > {print $1,$NF}' /etc/passwd root:/bin/bash bin:/sbin/nologin daemon:/sbin/nologin adm:/sbin/nologin lp:/sbin/nologin 说明： 变量NF可以在当不知道具体位置情况下可以指定最后一个字段数据，不管数据到底有多少个数据字段 变量NF含有数据文件最后一个数据段的数据，可以加美元符号作为字段变量   变量FNR和NR变量类似，也有所区别，FNR变量含有当前数据文件中已处理过的记录数，NR变量则含有已处理过的记录总数，示例如下： [root@redhat8 gawk]# gawk 'BEGIN{FS=\",\"} > {print $1,\"FNR=\"FNR}' test1 test1 Thor FNR=1 Batman FNR=2 Thor FNR=1 Batman FNR=2 [root@redhat8 gawk]# gawk 'BEGIN{FS=\",\"} > {print $1,\"FNR=\"FNR,\"NR=\"NR} > END{print \"There ware\",NR,\"records processed\"}' test1 test1 Thor FNR=1 NR=1 Batman FNR=2 NR=2 Thor FNR=1 NR=3 Batman FNR=2 NR=4 There ware 4 records processed 说明： 第一个示例中gawk程序的命令行定义了两个同样的输入文件，脚本会打印第一个数据字段的值和FNR变量的当前值 第一个示例中当gawk程序处理第二个数据文件时，FNR值被设回了1 第二个示例中，FNR值在处理第二个数据文件时候被重置了，但是NR变量值在处理第二个数据文件时候继续计数 如果只使用一个数据文件作为输入，FNR和NR的值是相同的，如果处理多个，FNR值处理每个数据文件时候会被重置，NR的值回继续计数知道处理完所有数据文件 自定义变量   gawk自定义变量可以是任意数目的字母、数字和下划线，但是不能以数字开头，并且区分大小写。 在脚本中给变量赋值 在gawk中给变量赋值一样用赋值语句： [root@redhat8 gawk]# gawk 'BEGIN{test=\"Miracles happen every day\" > print test;test=189;print test}' Miracles happen every day 189 [root@redhat8 gawk]# gawk 'BEGIN{x=5;x=x*3+1;print x}' 16 说明： 一般建议不同的gawk命令放到不同的行，示例中写在一行实际中不推荐 第一个示例中print语句输出的是test变量的当前值，gawk变量可以保存数值或文本值，可以重新进行赋值 第二个示例中赋值语句包含了数学算式来处理数字值 在命令行上给变量赋值   可以用gawk命令行来给程序中的变量赋值，允许在正常的代码之外赋值，即使改变变量的值，示例如下： [root@redhat8 gawk]# cat script1 BEGIN{FS=\",\"} {print $n} [root@redhat8 gawk]# gawk -f script1 n=1 test1 Thor Batman [root@redhat8 gawk]# gawk -f script1 n=3 test1 Captain America Super Man 说明：这个特性可以在不改变脚本代码的情况下就可以改变脚本的行为。 但有一个问题，示例如下： [root@redhat8 gawk]# cat script2 BEGIN{print \"The starting value is\",n; FS=\",\"} {print $n} [root@redhat8 gawk]# gawk -f script2 n=3 test1 The starting value is Captain America Super Man [root@redhat8 gawk]# gawk -v n=3 -f script2 test1 The starting value is 3 Captain America Super Man 说明： 第一个示例中，设置了变量后，这个值在代码的BEGIN部分不可用 第二个示例中用-v命令行参数解决了此问题，允许在BEGIN代码之前设定变量，-v必须放在脚本代码之前 处理数组 gawk编程语言使用关联数组提供数组功能，特点： 关联数组跟数字数组不同之处在于它的索引值可以是任意的文本字符串 不需要用连续的数字来标识数组中的数据原始，相反，关联数组用各种字符串来引用值 每个索引字符都必须能够唯一的标识出赋给它的数据元素（跟散列列表和字典概念相同） 定义数组变量   使用标准复制语句来定义数组变量：var[index] = element,其中var是变量名，index是关联数组的索引值，element是数据元素值。示例如下： [root@redhat8 gawk]# gawk 'BEGIN{ > superhero[\"Asgard\"] = \"Thor\" > print superhero[\"Asgard\"] > }' Thor [root@redhat8 gawk]# gawk 'BEGIN{num[1] = 10;num[2] = 5 > total = num[1] + num[2] > print total }' 15 遍历数组变量 在gawk中遍历一个关联数组，可以用for语句的一种特殊形式： for (var in array) { statements }   此for语句会在每次循环时将关联数组array的下一个索引值赋给遍历var，然后执行一遍statements，变量中存储的是索引值而不是数组元素值，可以将这个变量用作数组的所有，提取出数据元素值，示例如下： [root@redhat8 gawk]# gawk 'BEGIN{ > var[\"a\"] = 1 > var[\"b\"] = 2 > var[\"c\"] = 3 > for (test in var) > { > print \"Index:\",test,\" - value :\",var[test] > } > }' Index: a - value : 1 Index: b - value : 2 Index: c - value : 3 说明： 索引值不会按任何特定的顺序返回，但它们都能够指向对应的数据元素值 删除数组变量 格式：delete array[index],示例如下： [root@redhat8 gawk]# gawk 'BEGIN{ > var[\"a\"] = 1;var[\"g\"] = 2 > delete var[\"g\"] > for (test in var) > print \"Index:\",test,\" -Value:\",var[test] > }' Index: a -Value: 1 注意：一旦从关联数组中删除了索引值，就没法再用它来提取元素。 使用模式 gawk程序支持多种类型的匹配模式来过滤数据记录，和sed编辑器类似。 正则表达式 在使用正在表达式时，正则表达式必须出现在它要控制的程序脚本的左花括号前： [root@redhat8 gawk]# cat test1 Thor,Hulk,Captain America,Iron man Batman,Wonder Woman,Super Man [root@redhat8 gawk]# gawk 'BEGIN{FS=\",\"} /Th/{print $1}' test1 Thor 说明： gawk程序会用正则表达式对记录中的所有数据字段进行匹配，包括字段分隔符 如果需要用正则表达式匹配某个特定的数据示例，应该使用匹配操作符 匹配操作符   匹配操作符（matching operator）允许将正则表达式限定在记录中的特定数据字段，匹配操作符是波浪线（~）。可以指定匹配操作符、数据字段变量以及要匹配的正则表达式：$1 ~ /^data/。 $1变量代表记录中的第一个数据段 这个表达式会过滤出第一个字段以文本data开头的所有记录 示例如下： [root@redhat8 gawk]# cat test4 data11,data12,data13,data14,data15 data21,data22,data23,data24,data25 data31,data32,data33,data34,data35 [root@redhat8 gawk]# gawk 'BEGIN{FS=\",\"} $2 ~ /^data2/{print $0}' test4 data21,data22,data23,data24,data25 [root@redhat8 gawk]# gawk -F: '$1 ~ /huang/{print $1,$NF}' /etc/passwd huang /bin/bash 说明： 匹配操作符会用正则表达式/^data2来比较第二个数据段，正则表达式指明字符串要以文本data2开头 第二个示例中会在第一个数据字段中查找文本huang，如果在记录中找打了，会打印该记录的第一个和最后袷数据字段值 可以使用!符号来排除正则表达式的匹配：$1 !~ /expression/，示例如下： [root@redhat8 gawk]# gawk -F: '$1 !~ /huang/{print $1,$NF}' /etc/passwd root /bin/bash bin /sbin/nologin daemon /sbin/nologin adm /sbin/nologin ... 数学表达式 例如想显示所有属于root用户组（组ID为0）的用户，脚本示例： [root@redhat8 gawk]# gawk -F: '$4 == 0{print $1}' /etc/passwd root sync shutdown halt operator 常见数学比较表达式： x == y:值x等于y x x x >= y:值x大于等于y x > y:值x大于y 对文本数据使用表达式示例： [root@redhat8 gawk]# gawk -F, '$1 == \"data\"{print $1}' test4 [root@redhat8 gawk]# gawk -F, '$1 == \"data21\"{print $1}' test4 data21 说明： 对用文本数据使用表达式时，表达式必须完全匹配，数据必须跟模式严格匹配 示例中第一个匹配没用记录，说明没有匹配到，第二个精准匹配到了一条记录 结构化命令 if语句 gawk编程语言支持标准的if-then-else格式的if语句： 必须为if语句定义一个求职的条件，并将其用圆括号括起来 如果条件求值为TURE，紧跟在if语句后面的语句会执行 如果条件求值为FALSE，这条语句就会被跳过 格式： if (condition) statement1 或者： if (condition) statement1 可以在单行上使用esle自居，但必须在if语句部分之后使用分号： if (condition) statement1; else statement2 示例如下： [root@redhat8 gawk]# cat test5 1 8 4 [root@redhat8 gawk]# gawk '{if ($1 > 5) print $1}' test5 8 [root@redhat8 gawk]# gawk '{ > if ($1 > 5) > { > a = $1 * 5 > print a > } > }' test5 40 [root@redhat8 gawk]# gawk '{ > if ($1 > 5) > { > a = $1 * 5 > print a > } else > {a = $1 + 100 > print a > }}' test5 101 40 104 [root@redhat8 gawk]# gawk '{if($1>5) print $1 * 5;else print $1 + 100}' test5 101 40 104 while语句 while语句格式： while (condition) { statements }   while循环允许遍历一组数据，并检查迭代的结束条件，例如在计算中必须使用每条记录中的多个数据值，示例如下： [root@redhat8 gawk]# cat test6 150 120 135 160 113 140 145 180 216 [root@redhat8 gawk]# gawk '{total = 0;i = 1 > while(i {total += $i;i++} > avg = total / 3 > print \"Average:\",avg > }' test6 Average: 135 Average: 137.667 Average: 180.333 示例说明： while语句会遍历记录中的数据字段，将每个值都加到total变量上，并将计数器变量i增值 当计数器值等于4时，while的条件变成了FALSE，循环结束，然后执行脚本中下一条语句，及计算并打印平均值 以上过程会在数据文件中的每条记录上不断重复 gawk支持在while循环中使用break语句和continue语句： [root@redhat8 gawk]# gawk '{total = 0;i = 1 > while(i {total += $i > if (i == 2) > break > i++} > avg = total / 2 > print \"The average of the first two data is:\",avg > }' test6 The average of the first two data is: 135 The average of the first two data is: 136.5 The average of the first two data is: 162.5 do-while语句   do-while语句类似于while语句，但会在检查条件语句之前执行命令,格式如下： do { statements }while (condition)   这种格式保证了语句在条件被求值之前至少执行一次，当需要在求值条件前执行语句是非常方便： [root@redhat8 gawk]# gawk '{total = 0;i = 1 > do > {total += $i;i++ > }while (total print total }' test6 150 160 325 示例说明： 示例脚本会读取每条记录的数据字段并将它们加在一起，直到累加结果达到150 如果第一个数据字段大于等于150，例如第一条和第二条记录中的一个数据字段，脚本会保证在条件被求值前至少读取第一个数据字段的内容 for语句 gawk支持C语言风格的for循环： for ( variable assignment; condition; iteration process) 将多个功能合并到一个语句有助于简化循环： [root@redhat8 gawk]# gawk '{total = 0 > for (i = 1;i { > total += $i > } > avg = total / 3 > print \"Average:\",avg > }' test6 Average: 135 Average: 137.667 Average: 180.333 格式化打印 格式化打印命令printf格式： printf \"format string\",var1,var2 ... 说明： format string是格式化输出的关键，会用文本元素和格式化指定符来具体指定如何呈现格式化输出 格式化指定符是一种特殊的代码，会指明显示什么类型的的变量以及如何显示 gawk程序会将每个格式化指定符作为占位符，供命令中的变量使用 第一个格式化指定符对应列出的第一个变量，第二个对应第二个变量 格式化指定符格式如下： %[modifier]control-letter 说明： control-letter是一个单字符代码，用于指明显示说明类型的数据 modifier定义了可选的格式化特性 下表是可用在格式化指定符中的控制字母： 控制字母 描述 c 将一个数作为ASCII字符显示 d 显示一个整数值 i 显示一个整数值（跟d一样） e 用科学计数法显示一个数 f 显示一个浮点值 g 用科学计数法或浮点数显示（选择较短的格式） o 显示一个八进制值 s 显示一个文本字符串 x 显示一个十六进制值 X 显示一个十六进制值，但用大写字母 示例如下： [root@redhat8 gawk]# gawk 'BEGIN{ > x = 100 * 1000 > printf \"The answer is: %e\\n\",x > }' The answer is: 1.000000e+05 除了控制字母外，还有3种修饰符可以用来进一步控制输出： width：指定了输出字段最小宽度的数字值，如果输出短于这个值，printf会将文本右对齐，并用空格填充；如果输出比指定的宽度要长，则按实际的长度输出 prec：这是一个数字值，指定了浮点数中小数点后面位数，或文本字符串中显示的最大字符数 -（减号）：指明在向格式化空间中放入数据时采用左对齐而不是右对齐 在之前学习过程中，使用print命令来显示数据行中的数据字段： [root@redhat8 gawk]# cat test3 Bond Huang 123 ZhongXin street ShenZhen,518000 0755-12345678 Bond Huang 321 HongFu street DongGuan,523000 0769-87654321 [root@redhat8 gawk]# gawk 'BEGIN{FS=\"\\n\";RS=\"\"}{print $1,$4}' test3 Bond Huang 0755-12345678 Bond Huang 0769-87654321 使用printf命令来进行格式化输出： [root@redhat8 gawk]# gawk 'BEGIN{FS=\"\\n\";RS=\"\"}{printf \"%s %s\\n\", $1,$4}' test3 Bond Huang 0755-12345678 Bond Huang 0769-87654321 示例说明： 使用printf会产生跟print命令相同的输出，printf命令用%s格式化指定符来作为这两个字符串值的占位符 注意，需要在printf命令末尾手动添加换行符来生成新行，如果没添加，会继续在同一行打印后续输出 如果需要用几个单独的printf名留在同一行打印多个输出，就非常有用： [root@redhat8 gawk]# gawk 'BEGIN{FS=\",\"}{printf \"%s \",$1} END{printf \"\\n\"}' test4 data11 data21 data31 示例说明： 每个printf的输出都出现在同一行 为了终止该行，END部分打印了一个换行符 用装饰符来格式化第一个字符串值： [root@redhat8 gawk]# gawk 'BEGIN{FS=\"\\n\";RS=\"\"}{printf \"%16s %s\\n\", $1,$4}' test3 Bond Huang 0755-12345678 Bond Huang 0769-87654321 示例说明： 通过添加一个值为16的修饰符，强制将第一个字符串的输出宽度位16个字符 默认情况下，printf命令使用右对齐来将数据放到格式化空间中 如果要改成左对齐，只需给修饰符加一个减号即可 示例如下： [root@redhat8 gawk]# gawk 'BEGIN{FS=\"\\n\";RS=\"\"}{printf \"%-16s %s\\n\", $1,$4}' test3 Bond Huang 0755-12345678 Bond Huang 0769-87654321 printf命令处理浮点值也非常方便，： [root@redhat8 gawk]# gawk '{total = 0 > for (i = 1;i {total += $i} > avg = total / 3 > printf \"Average: %5.1f\\n\",avg > }' test6 Average: 135.0 Average: 137.7 Average: 180.3 示例说明： 通过为变量指定一个格式，可以让输出看起来更统一 示例中使用%5.1f格式指定符来强制printf命令将浮点值近似到小数后一位 内建函数 数学函数 gawk中内建的数学函数如下表所示： 函数 描述 atan2(x,y) x/y的反正切，x和y以弧度为单位 cos(x) x的余弦，x以弧度为单位 exp(x) x的指数函数 int(x) x的整数部分，取靠近零一侧的值 log(x) x的自然对数 rand() 比0大比1小的随机浮点值 sin(x) x的正弦，x以弧度为单位 sqrt(x) x的平方根 srand(x) 为计算随机数指定一个种子值 产生较大整数随机数可以使用rand()函数和int()函数创建一个算法： x = int(10 * rand()) gawk对于它能够处理的数值有一个限定区域，示例如下： [root@redhat8 shell]# gawk 'BEGIN{x=exp(100);print x}' 26881171418161356094253400435962903554686976 [root@redhat8 shell]# gawk 'BEGIN{x=exp(1000);print x}' gawk: cmd. line:1: warning: exp: argument 1000 is out of range inf gawk还支持一些按位操作数据的函数： and(v1,v2):执行v1和v2的按位与运算 compl(val):执行val的补运算 lshift(val,count):将val左移count位 or(v1,v2):执行v1和v2的按位或运算 rshift(val,count):将val右移count位 xor(v1,v2):执行v1和v2的按位异或运算 字符串函数 gawk提供的处理字符串的函数如下表所示： 函数 描述 asort(s,[,d]) 将数组s按数据元素值排序。索引值会被替换成表示新的排序顺序的连续数字；如果指定了d则排序后的数组会存储在数组d中 asorti(s,[,d]) 将数组s按索引值排序。生成的数组会将索引值作为数据元素值，用连续数字索引来表明排序顺序；如果指定了d则排序后的数组会存储在数组d中 gensub(r,s,h[,t]) 查找变量$0或目标字符串t(如有指定)来匹配正则表达式r。如果h是一个以g或G开头的字符串，就用s替换掉匹配的文本；如果h是一个数字，则表示要替换掉第h处r匹配的地方 gsub(r,s[,t]) 查找变量$0或目标字符串t(如有指定)来匹配正则表达式r。如果找到了，就全部替换成字符串s index(s,t) 返回字符串t在字符串s中的索引值，如果没找到就返回0 length([s]) 返回字符串s的长度，如果没有指定，则返回$0长度 match(s,r[,a]) 返回字符串s中正则表达式r出现位置的索引，如果指定了数组a，会存储s中匹配的正则表达式的那部分 split(s,a[,r]) 将s用FS字符或正则表达式r(如有指定)分开放到数组a中。返回字符串的总数 sprintf(format,variables) 用提供的format和variables返回一个类似于printf输出的字符串 sub(r,s[,t]) 在变量$0或目标字符串t中查找正则表达式r的匹配，如果找到了，就用字符串s替换掉第一处匹配 substr(s,i[,n]) 返回s中从索引值i开始的n个字符组成的子字符串。如果未提供n，则返回s剩下的部分 tolower(s) 将s中的所有字符转换成小写 toupper(s) 将s中的所有字符转换成大写 toupper(s)和length([s])使用示例： [root@redhat8 shell]# gawk 'BEGIN{ > a = \"superuser\";print toupper(a);print length(a) }' SUPERUSER 9 asort(s,[,d])示例如下： [root@redhat8 shell]# gawk 'BEGIN{ > var[\"a\"] = 1;var[\"d\"] = 2 > var[\"m\"] = 3;var[\"t\"] = 4 > asort(var,test) > for (i in test) > print\"Index:\",i,\" - value:\",test[i]}' Index: 1 - value: 1 Index: 2 - value: 2 Index: 3 - value: 3 Index: 4 - value: 4 split函数是将数据字段放到数组中以供进一步处理好方法： [root@redhat8 gawk]# cat test4 data11,data12,data13,data14,data15 data21,data22,data23,data24,data25 data31,data32,data33,data34,data35 [root@redhat8 gawk]# gawk 'BEGIN{FS=\",\"}{ split($0,var);print var[1],var[5]}' test4 data11 data15 data21 data25 data31 data35 新的数组使用连续数字作为数组索引，从含有第一个数据字段的索引值1开始。 时间函数   gawk包含一些函数来帮助处理时间，时间函数常用于处理日志文件，日志文件常含有需要比较的日期，可以转换成时间戳进行比较。gawk提供的时间函数如下表所示： 函数 描述 mktime(datespec) 将一个按YYYY MM DD HH MM SS[DST[格式指定的日期转换成时间戳 strftime(format [,timestamp[) 将当前时间的时间戳或timestamp（如有提供）转化格式化日期（采用shell函数date()的格式） systime() 返回当前时间的时间戳 使用示例： [root@redhat8 gawk]# gawk 'BEGIN{ > date = systime() > day = strftime(\"%A,%B %d,%Y\",date) > print day}' Saturday,December 19,2020 示例说明： 示例中使用systime函数从系统获取当前的epoch时间戳 然后用strftime函数转换成用户可读的格式，使用了shell命令date的日期格式化字符 自定义函数 定义函数 使用function关键字定义函数（函数名必须唯一）： function neme ([variables]) { statements } 在调用的gawk程序中可以传给这个函数一个或多个变量。 function printchird() { print $3 } 上面示例会打印记录中的第三个数据字段。 function myrand(limit) { return int(limit * rand()) } x = myrand(100) 示例说明： 函数可以使用return语句返回值，值可以是变量，或者是最终能计算处值的算式 可以间该函数的返回值赋给gawk程序中的一个变量，这个变量包含函数的返回值 使用自定义函数 示例如下： [root@redhat8 gawk]# gawk 'function myprint() > {printf \"%-16s - %s\\n\",$1,$4} > BEGIN{FS=\"\\n\";RS=\"\"} > {myprint()}' test3 Bond Huang - 0755-12345678 Bond Huang - 0769-87654321 示例说明： 在定义函数时，它必须出现在所有代码块之前（包括BEGIN代码块） 示例中定义了myeprint()函数，函数会格式化记录中的第一个和第四个数据字段以供打印输出 gawk程序然后用该函数显示输出数据文件中的数据 创建函数库   gawk提供了一种途径来将多个函数放到一个库文件中，就可以在所有的gawk程序中使用了。首先需要创建一个存储所有gawk函数的文件，示例如下： [root@redhat8 gawk]# cat funclib function myprint() { printf \"%-16s - %s\\n\",$1,$4 } function printchird() { print $3 } function myrand(limit) { return int(limit * rand()) } 使用示例： [root@redhat8 gawk]# cat script BEGIN{FS=\"\\n\";RS=\"\"} { myprint() } [root@redhat8 gawk]# gawk -f funclib -f script test3 Bond Huang - 0755-12345678 Bond Huang - 0769-87654321 示例说明： 使用-f命令行参数可以使用函数库中的函数，但是不能将其和内敛gawk脚本在一起使用 需要创建一个包含gawk程序的文件，然后在命令行上同时指定库文件和程序文件 可以在同一个命令行中使用多个-f参数 实例 为方便查阅，收录在以下位置：Shell-sed&gawk实例 "},"09-Shell脚本/01-Shell学习笔记/11-Shell笔记-脚本控制.html":{"url":"09-Shell脚本/01-Shell学习笔记/11-Shell笔记-脚本控制.html","title":"Shell笔记-脚本控制","keywords":"","body":""},"09-Shell脚本/02-Shell脚本快速指南/":{"url":"09-Shell脚本/02-Shell脚本快速指南/","title":"Shell脚本快速指南","keywords":"","body":"Shell脚本快速指南 简介 学习过程中摘自书本《Linux命令行与shell脚本编程大全》中的一些脚本实例及快速指南，方便查阅。 内容 Shell-bash脚本实例 Shell-退出码_test_expr查询表 Shell-Shtool脚本函数库 Shell-正则表达式实例 Shell-sed&gawk实例 Shell-简单的脚本实用工具 Shell-有意思的小脚本 "},"09-Shell脚本/02-Shell脚本快速指南/01-Shell-bash脚本实例.html":{"url":"09-Shell脚本/02-Shell脚本快速指南/01-Shell-bash脚本实例.html","title":"Shell-bash脚本实例","keywords":"","body":"Shell笔记-脚本实例 学习Shell脚本过程中，一些比较有实际意义的脚本实例，统一整理在此方便查阅。 查找可执行文件 想找出系统中有哪些可执行文件可以使用，扫描PATH环境变量中所有目录即可，代码如下： #!/bin/bash IFS=: for folder in $PATH do echo \"$folder:\" for file in $folder/* do if [ -x $file ] then echo \" $file\" fi done done 运行后输出如下（截取部分）： [root@redhat8 instance]# sh test1.sh |more /usr/local/sbin: /usr/local/bin: /usr/sbin: /usr/sbin/accept 创建多个用户账户 创建一个文件，里面写入需要创建的用户： [root@redhat8 instance]# cat users.csv Steve,Captain America Tony,Iron Man 文件中第一个列入两行，每一行两个条目，第一个条目是用户ID，第二个条目是用户的全名，之间中逗号隔开，这形成了一种名为逗号分隔符的文件格式（.csv),这种格式在电子表格中极为常见，文件保存格式为.csv。 #!/bin/bash #process new user accounts input=\"users.csv\" while IFS=',' read -r userid name do echo \"Adding user:$userid\" useradd -c \"$name\" -m $userid done 运行脚本： [root@redhat8 instance]# sh test2.sh Adding user:Steve Adding user:Tony 查看/etc/passwd文件，可以看到用户已经创建了： Steve:x:1001:1001:Captain America:/home/Steve:/bin/bash Tony:x:1002:1002:Iron Man:/home/Tony:/bin/bash 知识点： 将IFS设置成逗号，read会根据格式读取行内容，并将值赋给定义变量，并且迭代一次后自动读取文本的下一行内容，当read读完整个文件时候，也就是读不到数据返回False，while循环就会终止 把数据从文件中送入while命令，只需要在while命令尾部使用一个输入重定向符号 文件重定向实例   文件重定向常见于脚本需要读入文件和输出文件时。例如读取.csv格式表格，然后创建INSERT语句将数据插入MySQL数据库，脚本示例如下： #!/bin/bash outfile='members.sql' IFS=',' while read lname fname address city state zip do cat >> $outfile 读取的文件内容： Captain,America,Fu Tian,Shen Zhen,Guang Dong,518000 Iron,Man,Long Hua,Shen Zhen,Guang Dong,518000 脚本说明： while循环使用read语句从数据中读取文本 在done语句中，当允许程序时，$1代表第一个命令行参数，它指明了待读取数据的文件，read会使用IFS字符解析读入的文本，这里将IFS指定为逗号 在cat语句中，包含一个输出追加重定向（双大于号）和一个输入追加重定向（双小于号），输出重定向将cat命令的输出追加到由$outfile变量指定的文件中。cat命令的输入不再取自标准的输入，而是被重定向到脚本中存储的数据，EOF标记了追加到文件中的数据的岂止 在脚本中，由一个标准的SQL INSERT语句，其中的数据会由变量来替换，变量的内容则是read语句存入的 在脚本中，while循环一次读取一行数据，将这些值放入INSERT语句模板中，然后将结果输出到输出文件中 脚本运行后示例如下： [root@redhat8 function]# sh test1.sh test.csv [root@redhat8 function]# cat members.sql INSERT INTO members (lname,fname,address,city,state,zip) VALUES ('aptain','America','Fu Tian','Shen Zhen','Guang Dong','518000'); INSERT INTO members (lname,fname,address,city,state,zip) VALUES ('Iron','Man','Long Hua','Shen Zhen','Guang Dong','518000'); "},"09-Shell脚本/02-Shell脚本快速指南/02-Shell-退出码_test_expr查询表.html":{"url":"09-Shell脚本/02-Shell脚本快速指南/02-Shell-退出码_test_expr查询表.html","title":"Shell-退出码_test_expr查询表","keywords":"","body":"Shell-退出码_test_expr查询表 整理Linux退出状态码、test命令功能表、双括号命令符号以及运算expr的表格，方便查阅。基本上是摘自书本《Linux命令行与shell脚本编程大全》中的表格。 Linux中退出状态码 Linux中退出状态码： 状态码 描述 0 命令成功结束 1 一般性未知错误 2 不适合的shell命令 126 命令不可执行 127 没找到命令 128 无效的退出参数 128+x 与Linux信号x相关的严重作为 130 通过Ctrl+C终止的命令 255 正常范围之外的退出状态码 test命令比较查询表 数值比较功能对照表 比较方式 描述 n1 -eq n2 检查n1是否与n2相等 n1 -ge n2 检查n1是否大于或等于n2 n1 -gt n2 检查n1是否大于n2 n1 -le n2 检查n1是否小于或等于n2 n1 -lt n2 检查n1是否小于n2 n1 -ne n2 检查n1是否不能于n2 字符串比较测试表 比较方式 描述 str1 = str2 检查str1是否和str2相同 str1 != str2 检查str1是否和str2不同 str1 检查str1是否比str2小 str1 > str2 检查str1是否比str2大 -n str1 检查str1长度是否非0 -z str1 检查str1长度是否为0 test命令文件比较功能 比较方式 描述 -d file 检查file是否存在并是一个目录 -e file 检查file是否存在 -f file 检查file是否存在并是一个文件 -r file 检查file是否存在并可读 -s file 检查file是否存在并非空 -w file 检查file是否存在并可写 -x file 检查file是否存在并可执行 -O file 检查file是否存在并属当前用户所有 -G file 检查file是否存在并且默认组于当前用户相同 file1 -nt file2 检查file1是否比file2新 file1 -ot file2 检查file1是否比file2旧 双括号命令符号 除了test命令提供的标准数学运算符，双括号允许用户再比较过程中使用高级数学表达式。 符号 描述 val++ 后增 val-- 后减 ++val 先增 --val 先减 ! 逻辑求反 ~ 位求反 ** 幂运算 左位移 >> 右位移 & 位布尔和 | 位布尔或 && 逻辑和 || 逻辑或 expr运算查询表 操作符 描述 ARG1 | ARG2 如果ARG1既不是null也不是零值，返回ARG1；否则返回ARG2 ARG1 & ARG2 如果没有参数是null或零值，返回ARG1；否则返回0 ARG1 如果ARG1小于ARG2，返回1；否则返回0 ARG1 如果ARG1小于或等于ARG2，返回1；否则返回0 ARG1 = ARG2 如果ARG1等于ARG2，返回1；否则返回0 ARG1 != ARG2 如果ARG1不等于ARG2，返回1；否则返回0 ARG1 >= ARG2 如果ARG1大于或等于ARG2，返回1；否则返回0 ARG1 > ARG2 如果ARG1大于ARG2，返回1；否则返回0 ARG1 + ARG2 返回ARG1和ARG2的算术运算和 ARG1 - ARG2 返回ARG1和ARG2的算术运算差 ARG1 * ARG2 返回ARG1和ARG2的算术运算乘积 ARG1 / ARG2 返回ARG1和ARG2的算术运算商 ARG1 % ARG2 返回ARG1和ARG2的算术运算余数 STRING : REGEXP 如果REGEXP匹配到STRING中某个模式，返回该模式匹配 match STRING REGEXP 如果REGEXP匹配到STRING中某个模式，返回该模式匹配 substr STRING POS LENGTH 返回起始位置为POS(1开始计数)及长度为LENGTH个字符的子字符串 index STRING CHARS 返回在STRING中找到CHARS字符串的位置；否则返回0 length STRING 返回字符串STRING的数值长度 + TOKEN 将TOKEN解析成字符串，即使是个关键字 (EXPRESSION) 返回EXPRESSION的值 "},"09-Shell脚本/02-Shell脚本快速指南/03-Shell-Shtool脚本函数库.html":{"url":"09-Shell脚本/02-Shell脚本快速指南/03-Shell-Shtool脚本函数库.html","title":"Shell-Shtool脚本函数库","keywords":"","body":"Shell-Shtool脚本函数库   在开源世界中，共享代码才是关键，可以下载大量各式各样的函数，并将其用于自己的应用程序中。本节介绍如何下载、安装、使用GNU shtool shell脚本函数库。 下载及安装 Shtool软件包下载地址：ftp://ftp.gnu.org/gnu/shtool 在RHEL系统中直接下载shtool-2.0.8.tar.gz版本： [root@redhat8 function]# wget ftp://ftp.gnu.org/gnu/shtool/shtool-2.0.8.tar.gz --2020-08-21 11:57:05-- ftp://ftp.gnu.org/gnu/shtool/shtool-2.0.8.tar.gz => ‘shtool-2.0.8.tar.gz’ Resolving ftp.gnu.org (ftp.gnu.org)... 103.116.4.197 Connecting to ftp.gnu.org (ftp.gnu.org)|103.116.4.197|:21... failed: Connection refused. 失败了，用windows浏览器下载了FTP传到RHEL,建议将文件主目录中,然后提取文件： [root@redhat8 function]# cp shtool-2.0.8.tar.gz / [root@redhat8 /]# tar -zxvf shtool-2.0.8.tar.gz [root@redhat8 /]# cd shtool-2.0.8 [root@redhat8 shtool-2.0.8]# ls AUTHORS Makefile.in sh.echo sh.mkshadow sh.scpp shtoolize.pod test.sh ChangeLog NEWS sh.fixperm sh.move sh.slo shtool.m4 THANKS configure RATIONAL sh.install sh.path sh.subst shtool.pod VERSION configure.ac README sh.mdate sh.platform sh.table shtool.spec COPYING sh.arx sh.mkdir sh.prop sh.tarball sh.version INSTALL sh.common sh.mkln sh.rotate shtoolize.in test.db 构建库 源码的安装一般由3个步骤组成：配置(configure)、编译(make)、安装(make install)。 在shtool库文件目录下，使用标准configure和make命令来配置： [root@redhat8 shtool-2.0.8]# ./configure Configuring GNU shtool (Portable Shell Tool), version 2.0.8 (18-Jul-2008) Copyright (c) 1994-2008 Ralf S. Engelschall checking whether make sets $(MAKE)... no checking for perl interpreter... /usr/bin/perl checking for pod2man conversion tool... /usr/bin/pod2man configure: creating ./config.status config.status: creating Makefile config.status: creating shtoolize config.status: executing adjustment commands [root@redhat8 shtool-2.0.8]# make bash: make: command not found... Failed to search for file: /mnt/cdrom/BaseOS was not found 我的RHEL8.0没有make这个命令，需要安装，可以在GNU的主要FTP服务器上找到：ftp://ftp.gnu.org/gnu/make。 我有配置本地yum源，刚开始安装报错，查找也能找到make安装包，是因为光盘没挂载上去，挂载上去即可： [root@redhat8 make-4.3]# mount /dev/cdrom /mnt/cdrom [root@redhat8 make-4.3]# df -m [root@redhat8 make-4.3]# yum install make Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscription -manager to register.Last metadata expiration check: 0:09:32 ago on Fri 21 Aug 2020 12:50:21 PM EDT. Dependencies resolved. ========================================================================================== Package Arch Version Repository Size ========================================================================================== Installing: make x86_64 1:4.2.1-9.el8 redhat8_os 498 k Transaction Summary ========================================================================================== Install 1 Package Total size: 498 k Installed size: 1.4 M Is this ok [y/N]: y Downloading Packages: Running transaction check Transaction check succeeded. Running transaction test Transaction test succeeded. Running transaction Preparing : 1/1 Installing : make-1:4.2.1-9.el8.x86_64 1/1 Running scriptlet: make-1:4.2.1-9.el8.x86_64 1/1 Verifying : make-1:4.2.1-9.el8.x86_64 1/1 Installed products updated. Installed: make-1:4.2.1-9.el8.x86_64 Complete! [root@redhat8 function]# make make: *** No targets specified and no makefile found. Stop. 如果有报错，需要先安装gcc： [root@redhat8 make-4.3]# yum install gcc 回到shtool-2.0.8目录，继续之前步骤： [root@redhat8 /]# cd shtool-2.0.8 [root@redhat8 shtool-2.0.8]# make building program shtool ./shtoolize -o shtool all Use of assignment to $[ is deprecated at ./shtoolize line 60. Generating shtool...(echo 11808/12742 bytes)...(mdate 3695/4690 bytes)...(table 1818/2753 bytes)...(prop 1109/2038 bytes)...(move 2685/3614 bytes)...(install 4567/5495 bytes)...(mkdir 2904/3821 bytes)...(mkln 4429/5361 bytes)...(mkshadow 3260/4193 bytes)...(fixperm 1471/2403 bytes)...(rotate 13425/14331 bytes)...(tarball 5297/6214 bytes)...(subst 5255/6180 bytes)...(platform 21739/22662 bytes)...(arx 2401/3312 bytes)...(slo 4139/5066 bytes)...(scpp 6295/7206 bytes)...(version 10234/11160 bytes)...(path 4041/4952 bytes)building manpage shtoolize.1 ... shtool-mdate.tmp around line 222: You forgot a '=back' before '=head1' POD document had syntax errors at /usr/bin/pod2man line 69. building manpage shtool-table.1 ... building manpage shtool-mkdir.1 shtool-mkdir.tmp around line 186: You forgot a '=back' before '=head1' POD document had syntax errors at /usr/bin/pod2man line 69. building manpage shtool-mkln.1 building manpage shtool-mkshadow.1 shtool-mkshadow.tmp around line 191: You forgot a '=back' before '=head1' POD document had syntax errors at /usr/bin/pod2man line 69. building manpage shtool-fixperm.1 ... building manpage shtool-path.1 有一些报错，表示看不懂，可以用make命令测试这个库文件，测试都是通过的： [root@redhat8 shtool-2.0.8]# make test Running test suite: echo...........ok mdate..........ok table..........ok prop...........ok move...........ok install........ok mkdir..........ok mkln...........ok mkshadow.......ok fixperm........ok rotate.........ok tarball........ok subst..........ok platform.......ok arx............ok slo............ok scpp...........ok version........ok path...........ok OK: passed: 19/19 要完成安装,要用make命令的install选项（需要root用户）： [root@redhat8 shtool-2.0.8]# make install ./shtool mkdir -f -p -m 755 /usr/local ... ./shtool mkdir -f -p -m 755 /usr/local/share/shtool ... ./shtool install -c -m 644 sh.slo /usr/local/share/shtool/sh.slo ./shtool install -c -m 644 sh.scpp /usr/local/share/shtool/sh.scpp ./shtool install -c -m 644 sh.version /usr/local/share/shtool/sh.version ./shtool install -c -m 644 sh.path /usr/local/share/shtool/sh.path shtool库函数 下表列出了可用的库函数： 函数 描述 arx 创建归档文件（包含一些扩展功能） echo 显示字符串，并提供了一些扩展构件 fixperm 改变目录树中的文件权限 mdate 显示文件或目录的修改时间 Table 以表格的形式显示由字段分隔的数据 prop 显示一个带有动画效果的进度条 move 带有替换功能的文件移动 install 安装脚本或文件 mkdir 创建一个或多个目录 mkln 使用相对路径创建链接 mkshadow 创建一颗阴影树 rotate 转置日志文件 tarball 从文件和目录中创建tar文件 subst 使用sed的替换操作 platform 显示平台标识 slo 根据库的类别，分离链接器选项 scpp 共享的C预处理器 version 创建版本信息文件 path 处理程序路径 使用库 使用platform库函数的例子： #!/bin/bash shtool platform 运行后示例如下： [root@redhat8 function]# sh test12.sh os 8.0 (AMD64) 在命令行中使用： [root@redhat8 function]# shtool mdate test12.sh 21 August 2020 [root@redhat8 function]# shtool path make /usr/bin/make [root@redhat8 function]# ls -al | shtool prop -p \"Please waiting...\" Please waiting...   在上面示例中，prop函数可用使用\\、|、/和-等字符创建一个旋转的进度条，可用提示用户正在进行后台处理工作，能看到多少进度条取决于CPU的性能，选项-p运行用户自定义输出文本。 "},"09-Shell脚本/02-Shell脚本快速指南/04-Shell-正则表达式实例.html":{"url":"09-Shell脚本/02-Shell脚本快速指南/04-Shell-正则表达式实例.html","title":"Shell-正则表达式实例","keywords":"","body":"Shell-正则表达式实例 目录文件计数 脚本实例如下： #!bin/bash mypath=$(echo $PATH | sed 's/:/ /g') count=0 for directory in $mypath do check=$(ls $director) for item in $check do count=$[ $count + 1 ] done echo \"$directory - $count\" count=0 done 运行后示例如下： [root@redhat8 regular]# sh test1.sh /usr/local/sbin - 9 /usr/local/bin - 9 /usr/sbin - 9 /usr/bin - 9 /root/bin - 9 说明： 首先获取了到了$PATH中的目录，并且通过正则表达式替换了$PATH变量中的冒号，用空格替代，方便遍历 然后用for循环遍历了$PATH中的目录，并且用ls命令列出了目录中的所有文件 再用另一个for循环来遍历每个文件，并未文件计数器进行增值进行计数 输出了一个目录和其文件计数后，将计数器归零，再继续下一个$PATH中的目录 最后得到了$PATH中的目录下对应的文件数量 验证电话号码 之前打算用中国电话号码，中国号码格式比较简单，美国奇葩点，美国常见电话号码有如下常见的形式： (123)456-7890 (123) 456-7890 123-456-789 123.456.789 从左边开始，匹配思路： 最开始可能有左圆括号，也可能没有，使用模式：^\\(?:脱字符表明数据开始，左圆括号是特殊字符，需要进行转义，问号表明左括号可能有也可能没有，匹配0~1次 接着是三位区号，使用模式：[2-9][0-9]{2}:美国区号以数字2开头，所以第一个是2~9，后面任意两个数字匹配两次，一共就是三位 在区号后，收尾的右圆括号可能存在也可能不存在，使用模式：\\)? 在区号后，可能情况：一个空格，无空格，单破折线或一个点，使用模式：(| |-|\\.):使用管道符来匹配三种情况，点号是特殊字符需要转义，三种情况使用圆括号进行分组 接下来是交换机号码，使用模式：[0-9]{3} 交换机号码后，需要匹配：一个空格、一条单破折线或者一个点，使用模式：(| |-|\\.) 最后是尾部四位本地电话分机号：[0-9]{4}$ 完整格式如下： ^\\(?[2-9][0-9]{2}\\)?(| |-|\\.)[0-9]{3}(| |-|\\.)[0-9]{4}$ 写成脚本后如下（注意在gawk程序在使用正则表达式间隔时候，必须使用--re-interval命令行选项）： #!/bin/bash # script to filter out bad phone numbers gawk --re-interval '/^\\(?[2-9][0-9]{2}\\)?(| |-|\\.)[0-9]{3}(| |-|\\.)[0-9]{4}$/{print $0}' 脚本使用示例如下： [root@redhat8 regular]# echo \"421-777-3249\" |sh isphone.sh 421-777-3249 [root@redhat8 regular]# echo \"123-777-3249\" |sh isphone.sh [root@redhat8 regular]# echo \"(324) 777-3249\" |./isphone.sh (324) 777-3249 [root@redhat8 regular]# cat test9 000-000-0000 324-523-3425 (634) 673-3678 123-456-7890 452.578.7839 [root@redhat8 regular]# cat test9 | ./isphone.sh 324-523-3425 (634) 673-3678 452.578.7839 解析邮件地址 邮件级别格式：username@hostname,username值可以用字母数字字符以及以下特殊字符构成： 点号 单破折号 加号 下划线 邮件地址的hostname部分由一个或多个域名和一个服务器名组成，服务器名只允许字母数字字符以及以下特殊字符： 点号 下划线 正则表达式模式思路： username正则表达式模式：^([a-zA-Z0-9_\\-\\.\\+]+)@:分组指定了username中允许的字符，后面加号表示至少有一个字符，就是匹配一次或多次 hostname使用相同方法匹配服务器名和子域名：([a-zA-Z0-9_\\-\\.]+),这个模式可以匹配： server server.subdomain server.subdomain.subdomain 对于一些顶级域名，只能是字母字符，至少有两个字符，并且长须不得超过5个字符，正则表达式模式：\\.([a-zA-Z]{2,5})$ 整个模式如下： ^([a-zA-Z0-9_\\-\\.\\+]+)@([a-zA-Z0-9_\\-\\.]+)\\.([a-zA-Z]{2,5})$ 写成脚本后如下（注意这里没有使用--re-interval命令行选项）： #!/bin/bash gawk '/^([a-zA-Z0-9_\\-\\.\\+]+)@([a-zA-Z0-9_\\-\\.]+)\\.([a-zA-Z]{2,5})$/{print $0}' 使用示例如下： [root@redhat8 regular]# echo \"test@163.com\" | sh isemail.sh test@163.com [root@redhat8 regular]# echo \"test123@cn.ibm.com\" | ./isemail.sh test123@cn.ibm.com [root@redhat8 regular]# echo \"bond-test@gmail-com\" | ./isemail.sh [root@redhat8 regular]# echo \"bond-test@gmail.com\" | ./isemail.sh bond-test@gmail.com [root@redhat8 regular]# echo \"bond/test@gmail.com\" | ./isemail.sh [root@redhat8 regular]# echo \"bond_test@gmail.com.c\" | ./isemail.sh [root@redhat8 regular]# echo \"bond_test@gmail.com\" | ./isemail.sh bond_test@gmail.com "},"09-Shell脚本/02-Shell脚本快速指南/05-Shell-sed&gawk实例.html":{"url":"09-Shell脚本/02-Shell脚本快速指南/05-Shell-sed&gawk实例.html","title":"Shell-sed&gawk实例","keywords":"","body":"Shell-sed&gawk实例 收录一些实用脚本示例。 sed实例 加倍行间距 在文本的行间插入空白行简单sed脚本: [root@redhat8 sed]# sed 'G' test2 Miracles happen every day ! To make each day count ! Stupid is as stupid does ! [root@redhat8 sed]# sed '$!G' test2 Miracles happen every day ! To make each day count ! Stupid is as stupid does ! 说明： G命令会将保持空间内容附加到模式空间内容后，当启动sed时候，保持空间只有一个空行 第一次示例在最后一行也加入了一个空白行，可以使用排除符号（!）和尾行符号（$）来确定不将空白行加入到数据流最后一行后面 第二个示例中，当sed编辑器到了最后一行时，就会跳过G命令 含有空白行的文件加倍行间距 使用上面的方法，已有的空白行也会倍加倍，示例如下： [root@redhat8 sed]# cat test3 All life is a game of luck! Everything you see exists together in a delicate balance ! [root@redhat8 sed]# sed '$!G' test3 All life is a game of luck! Everything you see exists together in a delicate balance ! 解决办法就是先删除空白行后再添加，示例： [root@redhat8 sed]# sed '/^$/d ; $!G' test3 All life is a game of luck! Everything you see exists together in a delicate balance ! 说明： 首先删除数据流中的所有空白行，然后用G命令在所有行后插入新的空白行 删除已有的空白行，需要将d命令和一个匹配空白行的模式一起使用：/^$/d 给文件中的行编号 之前学过用等号来显示数据流中的行号： [root@redhat8 sed]# sed '=' test2 1 Miracles happen every day ! 2 To make each day count ! 3 Stupid is as stupid does ! 解决方法就是通过N命令放置到同一行： [root@redhat8 sed]# sed '=' test2 | sed 'N; s/\\n/./' 1.Miracles happen every day ! 2.To make each day count ! 3.Stupid is as stupid does ! 说明： 在获得等号的输出后，通过管道将输出传给另一个sed编辑器，使用N命令来合并这两行 示例中，用替换命令将换行符更换成了点号，根据个人喜好更换任意字符 在查看错误消息的行号时候，这个工具很好用 bash shell命令也有添加行号的功能，示例如下： [root@redhat8 sed]# nl test2 1 Miracles happen every day ! 2 To make each day count ! 3 Stupid is as stupid does ! [root@redhat8 sed]# cat -n test2 1 Miracles happen every day ! 2 To make each day count ! 3 Stupid is as stupid does ! 打印末尾行 使用p命令打印数据流末尾行： [root@redhat8 sed]# sed -n '$p' test2 Stupid is as stupid does ! 如果只需要处理一个长输出（比如日志文件）中的末尾几行，可以使用创建滚动窗口方法，示例如下： [root@redhat8 sed]# cat test5 1.Miracles happen every day ! 2.To make each day count ! 3.Stupid is as stupid does ! 4.All life is a game of luck! [root@redhat8 sed]# sed '{ > :start > $q ; N ; 3,$D > b start > }' test5 3.Stupid is as stupid does ! 4.All life is a game of luck! 说明： 滚动窗口是检验模式空间中文本行块的常用方法，使用N命令将这些块合并起来 N命令将下一行文本附加到模式空间中已有的文本后面，示例中模式空间有了2行文本，用美元符号来检查是否处于数据流尾部，如果不在，继续向模式空间增加行，同时删除原来的行（D命令会删除模式空间的第一行） 通过循环N命令和D命令，向模式空间的文本增加新行的同时也删除了旧行， 使循环借宿，识别最后一行文本并用q命令退出即可 示例中先检查这行是不是数据流中的最后一行，如果是，退出命令q会停止循环 N命令会将下一行附加到模式空间中当前行之后，如果当前行在第2行后面，3,$D命令会删除模式空间中的第一行 最后，示例脚本显示了文本的最后2行 删除行 删除数据流中不需要的空白行。 删除连续的空白行 删除连续空白行的方法是用地址区间来检查数据流，示例如下： [root@redhat8 sed]# cat test7 1.Miracles happen every day ! 2.To make each day count ! 3.Stupid is as stupid does ! 4.All life is a game of luck! [root@redhat8 sed]# sed '/./,/^$/!d' test7 1.Miracles happen every day ! 2.To make each day count ! 3.Stupid is as stupid does ! 4.All life is a game of luck! 说明： 删除连续空白行的关键在于创建包含一个非空白行和一个空白行的地址区间 如果sed编辑器遇到了这个地址区间，它不会删除行，对于不匹配这个区间的行（两行或更多空白行），就会删除掉 操作脚本：/./,/^$/!d，其中区间是/./到/^$/，区间开始地址会匹配任何含有一个字符的行，区间结束地址会匹配一个空白行，这区间内的行不会被删除 无论文本的数据行之间出现多个空白行，输出结果只会在行间保留一个空白行 删除开头的空白行 一样使用地址空间来解决那些行要删掉，示例如下： [root@redhat8 sed]# cat test8 To make each day count ! Stupid is as stupid does ! [root@redhat8 sed]# sed '/./,$!d' test8 To make each day count ! Stupid is as stupid does ! 说明： 使用的地址区间从含有字符的行开始，一直到数据流的结束 在此区间的任何行都不会从输出中删除，所有第一行被删除了 不管数据会之前有多少行，都会被删除，而数据行中的空白行会保留 删除结尾的空白行 利用循环来实现，示例如下： [root@redhat8 sed]# cat test9 To make each day count ! Stupid is as stupid does ! [root@redhat8 sed]# sed '{ > :start > /^\\n*$/{$d ; N ; b start } > }' test9 To make each day count ! Stupid is as stupid does ! 说明： 在正常脚本的花括号里还有花括号，这允许在整个命令脚本中将一些命令分组，该命令组会被应用在指定的地址模式上 地址模式能够匹配只含有一个换行符的行，如果匹配到了，而且是最后一行，删除命令就会删除它 如果不是最后一行，N命令会将下一行附加到它后面，分支命令会跳转到循环起始位置重新开始 删除HTML标签   从网站下载文本时，有时其中也包含了用户数据格式化的HTML标签，如果只是查看数据，标签会显得很不方便，例如下面的HTML文件示例： [root@redhat8 sed]# cat test10 This is the page title This is the first line in the web page. This should provide some useful information to use in our sed script. 说明： HTM了标签由小于号和大于号来识别 大多数都是成对出现的：一个起始标签（用来加粗），一个结束标签（用来结束加粗） 如果直接查找并替换小于号和大于号中间的文本字符串，结果出乎意料： [root@redhat8 sed]# sed 's///g' test10 line in the web page. This should provide some information to use in our sed script. 解决方法就是让sed编辑器忽略掉任何嵌入到原始标签中的大于号： [root@redhat8 sed]# sed 's/]*>//g' test10 This is the page title This is the first line in the web page. This should provide some useful information to use in our sed script. [root@redhat8 sed]# sed 's/]*>//g ; /^$/d' test10 This is the page title This is the first line in the web page. This should provide some useful information to use in our sed script. 说明： 示例中中创建一个字符组来排除大于号：s/]*>//g 示例中可以看到需要的数据，但是还是有很多空格，加一条删除命令来删除多余空白行即可 gawk实例   gawk可以用来处理出数据文件中的数据值，例如表格化销售数据或计算保龄球得分等。处理数据文件的关键是把相关的数据放在一起，然后对相关数据进行必要的计算。例如有个数据文件，包含了两只队伍（每队两名选手）的保龄球比赛的分情况： Captain America,MCU,125,113,119 Iron Man,MCU,117,109,127 Batman,DC,120,115,114 Wonder Woman,DC,110,129,121 下面脚本对每队的成绩进行了排序，并计算了总分和平均分： #!/bin/bash for team in $(gawk -F, '{print $2}' scores.txt |uniq) do gawk -v team=$team 'BEGIN{FS=\",\";total=0} { if ($2==team) { total += $3 + $4 + $5; } } END { avg = total / 6 print \"Total for\",team,\"is\",total,\",the average is\",avg }' scores.txt done 说明： for循环中的第一条语句过滤出数据文件中的队名，然后使用uniq命令去重，for循环再对每个队进行迭代 for循环的内部gawk语句进行计算操作： 对每一条记录，首先确定队名是否和正在循环的队名相符 通过利用gawk的-v选项来实现，该选项允许在gawk程序中传递shell变量 如果队名相符，代码会对数据中的三场比赛得分求和，然后将每条记录的值再相加，只要数据记录属于同一队 最后gawk代码会显示出总分以及平均分 运行后输出结果如下： [root@redhat8 gawk]# sh bowling.sh Total for MCU is 710 ,the average is 118.333 Total for DC is 709 ,the average is 118.167 "},"09-Shell脚本/02-Shell脚本快速指南/06-Shell-简单的脚本实用工具.html":{"url":"09-Shell脚本/02-Shell脚本快速指南/06-Shell-简单的脚本实用工具.html","title":"Shell-简单的脚本实用工具","keywords":"","body":"Shell-简单的脚本实用工具 摘自书本《Linux命令行与shell脚本编程大全》中的一些简单的脚本实用工具。 归档 学习两种使用shell脚本备份Linux系统数据的方法。 归档数据文件   例如正在使用Linux系统作为一个重要项目的平台，可以创建一个shell来自动获取特定的目录的快照。在配置文件中指定所涉及的目录，在项目发生改变时，可以做出对应的修改。 需要的功能 用tar命令创建工作目录归档文件示例： [root@redhat8 tool]# tar -cf archive.tar /shell/gawk/*.* tar: Removing leading `/' from member names tar: Removing leading `/' from hard link targets [root@redhat8 tool]# ls -l archive.tar -rw-r--r--. 1 root root 10240 Dec 20 01:22 archive.tar   tar命令会显示一条告警消息，表明删除了路径名开头的斜线，将路径从绝对路径名变成相对路径名，这样可以将tar归档文件解压到文件系统中的任何地方。可以将STDERR重定向到/dev/null文件，就可以不显示了： [root@redhat8 tool]# tar -cf archive.tar /shell/gawk/*.* 2>/dev/null tar归档文件会消耗大量磁盘空间，建议压缩： [root@redhat8 tool]# tar -zcf archive.tar.gz /shell/gawk/*.* 2>/dev/null [root@redhat8 tool]# ls -l archive.tar.gz -rw-r--r--. 1 root root 505 Dec 20 01:29 archive.tar.gz 可以将希望归档的每个目录或文件写入配置文件中： [root@redhat8 tool]# cat Files_To_Backup /shell/gawk /shell/funciton /python/jinja2 /python/fnmatch   可以让脚本读取配置文件，将会每个目录名加到归档列表中。使用read命令来读取该文件中的每一条记录即可，使用exec命令来重定向标准输入STDIN，用法如下： exec   注意，为归档配置文件使用了一个变量：CONFIG_FILE，配置文件中每一条记录都会被读入，read发现还有可读记录，就会在?变量中返回一个表示成功的退出状态码0： while [ $? -eq 0] do [...] read FILE_NAME done 说明： read命令到了配置文件的末尾，就会返回一个非零状态码，就会退出while循环 在while中，必须将目录名加到归档列表中，还要检查那个目录是否存在   有时候会出现删除了一个目录却忘了更新归档配置文件的情况，可以使用if语句来检查目录是否存储，如果存在，就会加入到FILE_LIST中，如果没有就显示告警信息： if [ -f $FILE_NAME -o -d $FILE_NAME ] then # if file exists,add its name to the list. FILE_LIST=\"$FILE_LIST $FILE_NAME\" else # if file doernot exist,issue warning echo echo \"$FILE_NAME,does not exist.\" echo \"Obviously,I will not include it in this archive.\" echo \"It is listed on line $FILE_NO of the config file.\" echo \"Continuing to build archive list...\" echo fi FILE_NO=$[ $FILE_NO + 1 ] #Icrease Line/Flie number by one. 说明： 由于归档配置文件中的记录可能是文件名，也可能是目录名，所以if语句总用-f和-d选项分别测试是否存在 or选项-o则表示只要一个测试为真，那么整个if语句就成立 添加变量FILE_NO可以靠苏用户归档配置文件中哪行中含有不正确或确实的文件或目录 创建逐日归档文件的存放位置 如果要对多个目录进行备份，最好创建一个集中归档仓库目录（注意权限）： [root@redhat8 tool]# mkdir /archive [root@redhat8 tool]# ls -ld /archive drwxr-xr-x. 2 root root 6 Dec 20 02:19 /archive [root@redhat8 tool]# mv Files_To_Backup /archive/ 可以创建一个用户组，为需要在集中归档目录中创建文件的用户授权： [root@redhat8 tool]# groupadd Archivers [root@redhat8 tool]# chgrp Archivers /archive [root@redhat8 tool]# ls -ld /archive drwxr-xr-x. 2 root Archivers 29 Dec 20 02:20 /archive [root@redhat8 tool]# usermod -aG Archivers huang [root@redhat8 tool]# chmod 775 /archive [root@redhat8 tool]# ls -ld /archive drwxrwxr-x. 2 root Archivers 29 Dec 20 02:20 /archive 注意： 将用户添加到Archivers组后，如果当前正在使用此用户，需要登出再登入才能使组成员关系生效 Archivers组中所有用户都可以再归档目录中添加和删除文件，为了避免组用户删除他人的归档文件，最好把目录的粘滞位加上 创建按日归档的脚本 Daily_Archive脚本会自定再指定位置创建一个归档，使用当前日期来唯一标识该文件： DATE=$(date +%y%m%d) # Set Archive File Name FILE=archive$DATE.tar.gz # Set Configuration and Destination File CONFIG_FILE=/archive/Flies_To_Backup DESTINATION=/archive/$FILE 说明： DESTINATION变量会将归档文件的全路径名加上去 CONFIG_FILE变量指向含有待归档目录信息的归档配置文件 将前面内容结合在一起，Daily_Archive脚本如下 #!/bin/bash # Daily_Archive - Archive designated files & directories ######################################################## # Gather Current Date DATE=$(date +%y%m%d) # Set Archive File Name FILE=archive$DATA.tar.gz # Set Configuration and Destination File CONFIG_FILE=/archive/Files_To_Backup DESTINATION=/archive/$FILE ############# Main Script ############################## # Check Backup config file exists if [ -f $CONFIG_FILE ] #Make sure the config file still exists. then # if file exists,do nothing but continue on. echo else # if file doernot exist,issue warning & eit script. echo \"$CONFIG_FILE,does not exist.\" echo \"Backup not completed due to missing Configuration File \" exit fi # Build the names of all the files to backup FILE_NO=1 #Start on line 1 of Config File. exec /dev/null echo \"Archive completed\" echo \"Resulting archive file is: $DESTINATION\" exit 运行按日归档的脚本 首先赋予执行权限： [root@redhat8 tool]# ls -l Daily_Archive.sh -rw-r--r--. 1 root root 1882 Dec 20 04:02 Daily_Archive.sh [root@redhat8 tool]# chmod u+x Daily_Archive.sh [root@redhat8 tool]# ls -l Daily_Archive.sh -rwxr--r--. 1 root root 1882 Dec 20 04:02 Daily_Archive.sh 运行脚本进行测试： [root@redhat8 tool]# ./Daily_Archive.sh /shell/funciton,does not exist. Obviously,I will not include it in this archive. It is listed on line 2 of the config file. Continuing to build archive list... Staring archive... Archive completed Resulting archive file is: /archive/archive.tar.gz [root@redhat8 tool]# ls -l /archive/archive.tar.gz -rw-r--r--. 1 root root 4231 Dec 20 04:10 /archive/archive.tar.gz   在脚本中，发现了一个不存在的目录：/shell/funciton，脚本告诉了这个错误的行在配置文件中的行号，然后继续创建列表和归档数据。 创建按小时归档的脚本   按小时备份文件，如果使用date命令为每个taball文件加入时间戳，文件名会很长，很不方便。可以为归档文件创建一个目录层级，包含了与一年中各个月份对应的目录，将月的序号作为目录名；而每月目录中又包含与当月隔天对应的目录（用天的序号作为目录名）。首先，创建新目录/archive/hourly，并设置适当权限： [root@redhat8 tool]# mkdir /archive/hourly [root@redhat8 tool]# chgrp Archivers /archive/hourly [root@redhat8 tool]# chmod 775 /archive/hourly [root@redhat8 tool]# ls -ld /archive/hourly drwxrwxr-x. 2 root Archivers 6 Dec 20 07:12 /archive/hourly 将按小时归档的配置文件Files_To_Backup移动到该目录： [root@redhat8 hourly]# cat Files_To_Backup /shell/gawk /shell/function /python/jinja2 [root@redhat8 hourly]# pwd /archive/hourly   脚本必须自动创建对应每月和每天的目录，如果目录已经存在，脚本就会报错。可以使用mkdir命令的-p命令行选项，此选项允许在单个命令中创建目录和子目录，就算目录已经存在，也不会产生错误消息。Hourly_Archive.sh脚本的前半部分如下： #!/bin/bash # Hourly_Archive - Every hour create an archive ####################################################### # Set Configuration File CONFIG_FILE=/archive/hourly/Files_To_Backup # Set Base Archive Destination Location BASEDEST=/archive/hourly # Gather Current Day,Month & Time DAY=$(date +%d) MONTH=$(date +%m) TIME=$(date +%H%M) # Greate Archive Destination Directory mkdir -p $BASEDEST/$MONTH/$DAY # Bulid Archive Destination File Name DESTINATION=$BASEDEST/$MONTH/$DAY/archive$TIME.tar.gz ################### Main Script ####################### [...] Main Script部分和Daily_Archive脚本完全一样。 运行按小时归档的脚本 修改好权限后运行如下所示： [root@redhat8 tool]# chmod u+x Hourly_Archive.sh [root@redhat8 tool]# ./Hourly_Archive.sh Staring archive... Archive completed Resulting archive file is: /archive/hourly/12/20/archive0828.tar.gz [root@redhat8 tool]# ls -l /archive/hourly/12/20/ total 5760 -rw-r--r--. 1 root root 5897582 Dec 20 08:28 archive0828.tar.gz   可以将TIME=$(date +%k%M)修改成TIME=$(date +%k0%M)，加入0后，所有的单数字小时数都会被加入一个前导数字0（在RHEL中好像不行，我直接将%k改成%H）。测试下在/archive/hourly/12/20目录存在情况下是否有问题： [root@redhat8 tool]# ./Hourly_Archive.sh Staring archive... Archive completed Resulting archive file is: /archive/hourly/12/20/archive0829.tar.gz [root@redhat8 tool]# ls -l /archive/hourly/12/20/ total 11520 -rw-r--r--. 1 root root 5897582 Dec 20 08:28 archive0828.tar.gz -rw-r--r--. 1 root root 5897582 Dec 20 08:29 archive0829.tar.gz 测试没有问题，可以将脚本放到cron表中。 管理用户账户 管理账户除了添加、修改和删除账户，还需要考虑安全问题、保留工作的需求以及对账户的精确管理。 需要的功能 删除账户时，至少需要四个步骤： 获得正确的待删除用户账户名 杀死正在系统上运行属于该账户的进程 确认系统中属于该账户的所有文件 删除该用户账户 获取正确的账户名 "},"09-Shell脚本/02-Shell脚本快速指南/07-Shell-有意思的小脚本.html":{"url":"09-Shell脚本/02-Shell脚本快速指南/07-Shell-有意思的小脚本.html","title":"Shell-有意思的小脚本","keywords":"","body":""},"09-Shell脚本/02-Shell脚本快速指南/08-Shell-常用方法快速查询.html":{"url":"09-Shell脚本/02-Shell脚本快速指南/08-Shell-常用方法快速查询.html","title":"Shell-常用方法快速查询","keywords":"","body":"Shell-常用方法快速查询 一些简单，但是常用的方法。 数据行处理方法 获取行数据： # 取第一行 sed '1q' head -n 1 awk 'FNR=1 {print}' # 取前十行 sed '10q' head -n 10 awk 'FNR>=1&&FNR 删除行： # 删除第一行 sed '1d' # 删除第2至5行 sed '2,5d' "},"09-Shell脚本/03-Shell_AIX脚本/":{"url":"09-Shell脚本/03-Shell_AIX脚本/","title":"Shell_AIX脚本","keywords":"","body":"Shell_AIX脚本 简介 一些学习过程中写的简单脚本。 内容 Shell-mksysb相关脚本 Shell-PowerHA相关脚本 "},"09-Shell脚本/03-Shell_AIX脚本/01-Shell-mksysb相关脚本.html":{"url":"09-Shell脚本/03-Shell_AIX脚本/01-Shell-mksysb相关脚本.html","title":"Shell-mksysb相关脚本","keywords":"","body":"Shell-mksysb相关脚本 mksysb过程中遇到一些问题写的一些脚本。 修改image.data 修改目的说明   在AIX系统中，对rootvg进行备份使用mksysb时候，默认会在根目录下创建image.data文件，mksysb会根据此文件生成对应的镜像。如果原分区rootvg是两块磁盘做镜像，现在要恢复到新分区上只有一块硬盘，并且只需要一块，多了浪费，如果直接做mksyb，恢复分区时候会报错，提示空间不够，有几种解决方法： 解除原分区的镜像，做mksyb后再重新做镜像（对一些高要求系统来说存在风险） 搞一块新的临时硬盘到新分区（也许配置会比较麻烦，后续可能会删掉概率也大） 修改image.data文件，在做mksysb的时候不创建新的image.data，使用修改的image.data   最简单并且风险比较低的还是修改image.data，仔细认真点改没问题，如果需要这样做的系统很多，就比较耗费时间了，还容易出错，通过脚本修改就比较方便。 脚本使用说明 必须使用root用户或root权限的用户执行脚本 脚本中自动跳转到了根目录，在任何目录有权限运行即可 rootvg中最好不要有自定义未mount的文件系统，不会备份 不能有跨盘的lv（即一个lv一份数据分布在不同盘上）,如果有要提前整合到一块盘中 脚本自动判断了拥有rootvg全部lv的磁盘，根据识别到盘符去修改image.data 不管rootvg有几份镜像，都修改成1了，也就是目标端一块盘即可（多块也没问题） 如果原rootvg有很多磁盘，lv分布很多磁盘，并且难以整合到一个中，那么此脚本没用（一些将数据放置在rootvg里面的系统可能会有这种情况，通常这种是不推荐的） 脚本代码 代码如下所示： #!/bin/ksh # Change the image.data! echo \"Great a new image.data,please wait...\" mkszfile sleep 15 cd / # Change the LV_SOURCE_DISK_LIST! echo \"Change the LV_SOURCE_DISK_LIST...\" hdisk_list=$(lspv | awk '{if($3==\"rootvg\"){print $1}}') for disk in $hdisk_list do lv_count1=`lsvg -l rootvg | wc -l` lv_count2=`lspv -l $disk | wc -l` if [ $lv_count2 -eq $lv_count1 ] then hdisk=$disk fi done sed ' s/LV_SOURCE_DISK_LIST=.*/LV_SOURCE_DISK_LIST= '$hdisk'/ ' image.data > image.data.img mv image.data.img image.data # Change the COPIES! echo \"Change the COPIES...\" sed 's/COPIES= [0-9]*/COPIES= 1/' image.data > image.data.img mv image.data.img image.data # Change the PPs! echo \"Change the PPs...\" sequence=`sed -n '/LPs=/p' image.data|sed -n '/LPs=/='` LPs_vaule=`cat image.data|awk '/LPs=/{print $2}'` PP_rows=$(sed -n '/PP=/=' image.data) for i in $sequence do PP_row=`echo $PP_rows | awk '{print $'$i'}'` PP=`echo $LPs_vaule | awk '{print $'$i'}'` sed ''$PP_row'{ s/PP= [0-9]*/PP= '$PP'/ }' image.data > image.data.img mv image.data.img image.data done echo \"Changes are complete!\" echo \"Please use command to do mksysb without '-i' parameter!\" echo \"Or use 'smit mksysb' set 'Generate new /image.data file?' to 'No'!\" 运行示例 在AIX7100-04-03-1642中使用ksh和bash下都尝试运行： # sh test2.sh Great a new image.data,please wait... Change the LV_SOURCE_DISK_LIST... Change the COPIES... Change the PPs... Changes are complete! Please use command to do mksysb without '-i' parameter! Or use 'smit mksysb' set 'Generate new /image.data file?' to 'No'! bash-5.0# sh test4.sh Great a new image.data,please wait... Change the LV_SOURCE_DISK_LIST... Change the COPIES... Change the PPs... Changes are complete! Please use command to do mksysb without '-i' parameter! Or use 'smit mksysb' set 'Generate new /image.data file?' to 'No'! 原始image.data示例（以hd3为例）： lv_data: VOLUME_GROUP= rootvg LV_SOURCE_DISK_LIST= hdisk0 hdisk2 LV_IDENTIFIER= 00cb4d6e00004c0000000168788002ed.7 LOGICAL_VOLUME= hd3 VG_STAT= active/complete TYPE= jfs2 MAX_LPS= 512 COPIES= 2 LPs= 24 STALE_PPs= 0 INTER_POLICY= minimum INTRA_POLICY= center MOUNT_POINT= /tmp MIRROR_WRITE_CONSISTENCY= on/ACTIVE LV_SEPARATE_PV= yes PERMISSION= read/write LV_STATE= opened/syncd WRITE_VERIFY= off PP_SIZE= 128 SCHED_POLICY= parallel PP= 48 BB_POLICY= relocatable [...] 修改后image.data如下(以hd3为例）： lv_data: VOLUME_GROUP= rootvg LV_SOURCE_DISK_LIST= hdisk2 LV_IDENTIFIER= 00cb4d6e00004c0000000168788002ed.7 LOGICAL_VOLUME= hd3 VG_STAT= active/complete TYPE= jfs2 MAX_LPS= 512 COPIES= 1 LPs= 24 STALE_PPs= 0 INTER_POLICY= minimum INTRA_POLICY= center MOUNT_POINT= /tmp MIRROR_WRITE_CONSISTENCY= on/ACTIVE LV_SEPARATE_PV= yes PERMISSION= read/write LV_STATE= opened/syncd WRITE_VERIFY= off PP_SIZE= 128 SCHED_POLICY= parallel PP= 24 BB_POLICY= relocatable [...] 待补充 "},"09-Shell脚本/03-Shell_AIX脚本/02-Shell-PowerHA相关脚本.html":{"url":"09-Shell脚本/03-Shell_AIX脚本/02-Shell-PowerHA相关脚本.html","title":"Shell-PowerHA相关脚本","keywords":"","body":"Shell-PowerHA相关脚本 PowerHA使用过程中写的一些脚本。 双节点PowerHA切换 使用smit菜单和命令行切换也比较方便快捷，但是有时候想用脚本进行批量切换。 脚本使用说明 脚本使用说明如下： 适用于双节点的PowerHA环境，多节点或多site不支持 适用于单资源组的PowerHA环境，多资源组不支持 适用于PowerHA7.2版本，老版本如HA6.1可能不支持（未测试过） 在任意节点运行脚本都行，脚本中有判断资源组所在的节点 脚本代码 脚本代码如下： #!/bin/ksh # Two nodes PowerHA resource group switch script. Cls_dir=\"/usr/es/sbin/cluster/utilities\" Cls_State=`$Cls_dir/cldump |sed -n '/Cluster State/p' |awk '{print $3}'` Cls_Substate=`$Cls_dir/cldump |sed -n '/Cluster Substate/p' |awk '{print $3}'` echo \"Check the Cluster state,please waiting...\" if [ $Cls_State = \"UP\" ] && [ $Cls_Substate = \"STABLE\" ] then echo \"The Cluster state is STABLE!\" else echo \"The Cluster state is abnormal,please check the cluster!\" exit 1 fi #### echo \"Check the Nodes state,please waiting...\" Node_State=$($Cls_dir/cldump |sed -n '/Node name/p'| awk '{print $5}') for state in $Node_State do if [ $state != \"UP\" ] then echo \"Someone node state is abnormal,please check the cluster!\" exit 1 fi done #### RG=$($Cls_dir/clmgr list rg) RG_Node=`$Cls_dir/cldump |tail -2 |awk '{if($2==\"ONLINE\"){print $1}}'` Standy_Node=`$Cls_dir/cldump |tail -2 |awk '{if($2==\"OFFLINE\"){print $1}}'` #### if [ -n $RG_Node ] && [ -n $Standy_Node ] then echo \"Move the resource group form $RG_Node to $Standy_Node,please waiting...\" $Cls_dir/clRGmove -s 'false' -m -i -g $RG -n $Standy_Node else echo \"RG state is abnormal on someone node,please check the cluster!\" exit 1 fi #### if [ $? -eq 0 ] then echo \"Successfully moved the resource group form $RG_Node to $Standy_Node!\" echo \"Please check the Cluster status and check the application!\" else echo \"Failed to move the resource group form $RG_Node to $Standy_Node!\" echo \"Please check the PowerHA log:/var/hacmp/log/hacmp.out!\" fi 运行示例   在AIX系统7.1.3.7及HA版本7.2.1.2版本中运行示例（发现最后写的判断有点多余了，clRGmove会有成功与否的输出）： # sh HAswtich.sh Check the Cluster state,please waiting... Move the resource group form HQ_test1 to HQ_test2,please waiting... Attempting to move resource group HQrg to node HQ_test2. Waiting for the cluster to process the resource group movement request.... Whit for the cluster to stabilize Resource group movement successful. Resource group HQrg is online on node HQ_test2. Cluster Name: HQ_cls Resource Group name:HQrg Node Group State ----------------------------------------------------------------------------- HQ_test2 ONLINE HQ_test1 OFFLINE Successfully moved the resource group form $RG_Node to $Standy_Node! Please check the Cluster status and check the application! PowerHA检查   PowerHA系统需要定期进行切换演练，有些重要行业例如一些银行放在人行窗口进行切换，在切换前要检查系统，如果需要检查的系统比较多，用脚本就比较方便了。 脚本使用说明 说明如下： 检查了Cluster进程状态，只要有一个不是active就不激活了 检查了HA集群状态，node状态等等 检查了hosts表和rhosts HA6.1和HA7.1(7.2)版本rhosts位置不一样，并且HA6.1里面一般配置IP，在HA7.1中一般配置Boot IP Lable（一般IP Lable和node配置成一致）在脚本中有判断系统版本，根部版本检查不同路径的rhosts 脚本中写了一个同步，并且询问了是否进行同步，根据需求选择yes或no 脚本中加入了一个计数，只有当所有检查项目没有error时候才会提示是否进行同步 脚本代码 #!/bin/ksh # Verify and Synchronize Cluster Configuration. #### count=0 echo \"Check the Cluster src state,please waiting...\" Cls_src_state=`lssrc -g cluster | awk '{if($2==\"cluster\"){print $4}}'| uniq` Caa_src_state=`lssrc -s clcomd | awk '{if($2==\"caa\"){print $4}}'` if [ $Caa_src_state = \"active\" ] && [ $Caa_src_state = \"active\" ] then echo \"The Cluster and caa src state all active!\" count=$(($count + 1)) else echo \"ERROR!Someone Cluster src state is abnormal,please check!\" fi #### Cls_dir=\"/usr/es/sbin/cluster/utilities\" Cls_State=$($Cls_dir/cldump |sed -n '/Cluster State/p' |awk '{print $3}') Cls_Substate=`$Cls_dir/cldump |sed -n '/Cluster Substate/p' |awk '{print $3}'` echo \"Check the Cluster state,please waiting...\" if [ $Cls_State = \"UP\" ] then echo \"The Cluster state is UP!\" count=$(($count + 1)) else echo \"ERROR! The Cluster state is $Cls_State,please check!\" fi #### echo \"Check the Cluster Substate,please waiting...\" if [ $Cls_Substate = \"STABLE\" ] then echo \"The Cluster Substate is STABLE!\" count=$(($count + 1)) else echo \"ERROR! The Cluster Substate is $Cls_State,please check!\" fi #### echo \"Check the Nodes state,please waiting...\" Node_State=`$Cls_dir/cldump |sed -n '/Node Name/p'| awk '{print $5}'` Node_qty=`$Cls_dir/clmgr list node |wc -l` for state in $Node_State do if [ $state != \"UP\" ] then echo \"ERROR! Someone node state is abnormal,please check!\" else echo \"The node state is UP!\" count=$(($count + 1)) fi done #### IP_Label_list=$($Cls_dir/cltopinfo -i |sed -n '/ether/p'|sort |awk '{print $1}' |uniq) IP_Labe1_num=$($Cls_dir/cltopinfo -i |sed -n '/ether/p'|sort |awk '{print $1}' |uniq |sed -n '=') IP_Labe1_qty=`$Cls_dir/cltopinfo -i |sed -n '/ether/p'|sort |awk '{print $1}' |uniq |wc -l` #### echo \"Check the /etc/hosts,please waiting...\" for i in $IP_Labe1_num do IP_Label=`echo $IP_Label_list |awk '{print $'$i'}'` Address=`echo $Add_list |awk '{print $'$i'}'` x=`cat /etc/hosts | sed -n '/'$IP_Label'/p'` y=`cat /etc/hosts | sed -n '/'$Address'/p'` if [ \"$x\" != \"$y\" ] then echo \"ERROR!$IP_Labe1 found the error in /etc/hosts,please check!\" else count=$(($count + 1)) fi done #### HA_version=`lslpp -l |grep cluster.es.server.rte | uniq |awk '{print $2}'` HA_jud=$(echo $HA_version | sed -n '/^7/p') Add_list=$($Cls_dir/cltopinfo -i |sed -n '/ether/p'|sort |awk '{print $5}' |uniq) Add_list_qty=`$Cls_dir/cltopinfo -i |sed -n '/ether/p'|sort |awk '{print $5}' |uniq |wc -l` Node_list=`$Cls_dir/cltopinfo -i |sed -n '/ether/p'|sort |awk '{if($1==$4){print $1}}'` Node_list_qty=`$Cls_dir/cltopinfo -i |sed -n '/ether/p'|sort |awk '{if($1==$4){print $1}}' |wc -l` rhosts_dir=\"/usr/es/sbin/cluster/etc\" #### echo \"Check the rhosts,please waiting...\" if [ -n $HA_jud ] then echo \"The HA version is $HA_version!\" for node in $node_list do vaule1=`cat /etc/cluster/rhosts |sed -n '/'$node'/p'` if [ -z $vaule1 ] then echo \"ERROR!Someone Boot IP Label not in rhosts,Please check!\" else count=$(($count + 1)) fi done else echo \"The HA version is $HA_version!\" for IP_Add in $Add_list do vaule2=`cat $rhosts_dir/rhosts |sed -n '/'$IP_Add'/p'` if [ -z $vaule2 ] then echo \"WARRING!Someone IP not in rhosts,Please check!\" else count=$(($count + 1)) fi done fi ### echo \"Check the netmon.cf,please waiting...\" netmon=`cat /usr/es/sbin/cluster/netmon.cf` netmon_ck=`cat /usr/es/sbin/cluster/netmon.cf |sed -n '/[[:alnum:]]/p'` if [ $? -ne 0 ] || [ -z \"$netmon_ck\" ] then echo \"WARRING!File 'netmon.cf' is missing or empty!\" echo \"If the system running in PowerVM environment,please configure the netmon.cf!\" fi ### count1=$((3 + $Node_qty + $IP_Labe1_qty + $Add_list_qty + $Node_list_qty )) if [ $count -eq $count1 ] then read answer?\"Need to synchronize the Cluster?[Y/N] \" case $answer in Y | y) echo echo \"OK,Synchronize the Cluster now,please waiting...\" ;; N | n) echo echo \"OK,Please synchronize manually if necessary!\" exit ;; esac $Cls_dir/clmgr sync cluster if [ $? -eq 0 ] then echo \"Synchronize the Cluster successful!\" else echo \"Synchronize the Cluster failed!\" echo \"Please check the PowerHA log:/var/hacmp/log/hacmp.out\" fi else echo \"Cluster Configuration check completed but found some errors,please check!\" fi "},"09-Shell脚本/03-Shell_AIX脚本/10-Shell-AIX_ksh小脚本.html":{"url":"09-Shell脚本/03-Shell_AIX脚本/10-Shell-AIX_ksh小脚本.html","title":"Shell-AIX_ksh小脚本","keywords":"","body":"AIX_ksh小脚本 记录学习和使用过程中写的小脚本。 进程相关脚本 记录学习和使用过程中写的小脚本。 杀掉后台进程 例如杀掉下面的后台进程： # (sleep 50;echo \"test\")& [1] 5374152 # kill $! # ps -ef |grep sleep root 12714022 1 0 11:39:27 pts/1 0:00 sleep 50 root 13172928 6881490 0 11:39:57 - 0:00 /usr/bin/sleep 10 [1] + Terminated (sleep 50;echo \"test\")&   直接kill后台运行的进程ID，可以看到后台程序Terminated，但是sleep 50还在运行。这个后台程序在系统中是当前会话作业（jobs），应该是有jobs命令查看，kill也使用杀掉jobs id方式： # (sleep 50;echo \"test\")& [1] 7340274 # jobs [1] + Running (sleep 50;echo \"test\")& # kill -STOP %1 [1] + Stopped (SIGSTOP) (sleep 50;echo \"test\")& # ps -ef |grep sleep root 11665562 7340274 0 12:08:08 pts/1 0:00 sleep 50 root 13172936 6881490 0 12:08:46 - 0:00 /usr/bin/sleep 10 # jobs -l [1] + 7340274 Stopped (SIGSTOP) (sleep 50;echo \"test\")& # kill %1 # ps -ef |grep sleep root 13172984 6881490 0 12:10:06 - 0:00 /usr/bin/sleep 10 [1] + Terminated (sleep 50;echo \"test\")& 通过脚本自动杀掉： (sleep 50;echo \"test\")& pro_pid=$! jobs_id=`jobs -l |awk '/'$pro_pid'/{print $1}'| tr -d \"[]\"` kill %$jobs_id 通常杀掉是带有条件判断的，具体根据实际情况来使用。 其它相关命令： bg：在后台运行作业，可以将后台暂停了的作业在后台继续执行 fg：在前台运行作业，可以将后台作业放到前台执行，暂停的也可以 待补充 "},"09-Shell脚本/04-Shell脚本编写注意/":{"url":"09-Shell脚本/04-Shell脚本编写注意/","title":"Shell脚本编写注意","keywords":"","body":"Shell脚本编写注意 简介 一些学习及编写脚本过程中遇到的注意事项。 内容 Shell-各种shell的区别 Shell-编写脚本注意事项 Shell-sed和gawk差异 "},"09-Shell脚本/04-Shell脚本编写注意/01-Shell-各种shell的区别.html":{"url":"09-Shell脚本/04-Shell脚本编写注意/01-Shell-各种shell的区别.html","title":"Shell-各种shell的区别","keywords":"","body":"Shell-各种shell的区别 记录学习过程中发现的各种shell的区别，主要是AIX的ksh和所学习的bash的差异。 HMC shell的区别   HMC底层是RedHat，hscroot用户使用的shell是hmcbash，应该也是基于bash，只不过是修改过。目前就发现了HMC shell中没有bc计算器，计算方法可以用双括号或者方括号，具体可以参照： HMC-shell脚本使用 AIX shell的区别   AIX和VIOS默认是ksh，AIX也可以安装一个bash，但是使用AIX系统的用户大多数情况下是不会安装的。ksh和bash基本差不多，但是还是有点区别，目前发现了几点，记录下来。 数字范围差别 在RHEL bash中表示数字范围三种方法示例： [root@redhat8 test]# for ((i=0;i在AIX7.1.4.3 ksh中使用上面三种方法示例： # for ((i=0;i在AIX7.1.4.3 bash中使用上面三种方法示例： bash-5.0# for ((i=0;i总结： AIX ksh中三种方法都不行，在没安装bash情况下很不方便，目前我还不知道直接替代方案，都是间接去替代 AIX 安装bash后可以使用前两种方法，第三种方法说明AIX中没有seq命令，前两种已经够用了 数组表示差异 在RHEL8中可以使用圆括号表示数组，并且可以进行切片操作： [root@redhat8 test]# a=(1 2 3) [root@redhat8 test]# b=(4 5 6) [root@redhat8 test]# for i in `seq 0 2`;do > echo \"${a[i]} ${b[i]}\" > done 1 4 2 5 3 6 在AIX7.1.4.3中圆括号不行，改成bash也不行，直接去掉括号改成其它也不行，示例如下： bash-5.0# cat test5.sh #!/bin/ksh a=(1 2 3) b=(4 5 6) for i in 0 1 2 do echo \"${a[i]} ${b[i]}\" done bash-5.0# sh test5.sh test5.sh[2]: 0403-057 Syntax error at line 2 : `(' is not expected. 目前还没找到有效直接替代方法。 case差异 在RHEL的bash中，read命令和case可以结合使用,示例如下： #!/bin/bash read -n1 -p \"Need to synchronize the Cluster?[Y/N] \" answer case $answer in Y | y) echo echo \"OK,Synchronize the Cluster now,please waiting...\" ;; N | n) echo echo \"OK,Please synchronize manually if necessary!\" exit ;; esac 但是在AIX的ksh中，没有-n等，使用示例如下： #!/bin/ksh read answer?\"Need to synchronize the Cluster?[Y/N] \" case $answer in Y | y) echo echo \"OK,Synchronize the Cluster now,please waiting...\" ;; N | n) echo echo \"OK,Please synchronize manually if necessary!\" exit ;; esac 计数方法差异（应该是没有方括号计算方法） 在RHEL中使用如下方法进行计数： #!/bin/bash count=0 for i in 1 2 3 do count=$[ $count + 1 ] done echo $count 运行后示例如下： [root@redhat8 test]# sh test2.sh 3 在AIX 7.1.4.3中运行（使用bash一样不行）： #!/bin/ksh count=0 for i in 1 2 3 do count=$[ $count + 1 ] done echo $count 运行后示例如下： # sh test9.sh test9.sh[5]: 0: not found. test9.sh[5]: 0: not found. test9.sh[5]: 0: not found. 0 可以使用双括号的方法进行解决： #!/bin/ksh count=0 for i in 1 2 3 do count=$(($count + 1)) done echo $count 运行后示例如下： # sh test9.sh 3 其它差异 AIX7.1.4.3中没有mktemp命令，没用lsof命令，可以单独安装 "},"09-Shell脚本/04-Shell脚本编写注意/02-Shell-编写脚本注意事项.html":{"url":"09-Shell脚本/04-Shell脚本编写注意/02-Shell-编写脚本注意事项.html","title":"Shell-编写脚本注意事项","keywords":"","body":"Shell-编写脚本注意事项 记录一些在编写脚本过程中遇到的需要注意的点。 从命令获取值   当将数据通过awk输出某一列内容时候，赋值给遍变量后，再调用变量时候会发现变成一行，在脚本中使用的时候要注意，示例如下： # lspath Enabled hdisk0 vscsi0 Enabled hdisk1 vscsi0 Enabled hdisk0 vscsi1 Enabled hdisk1 vscsi1 Enabled hdisk2 vscsi1 # cat test7.sh #!/bin/ksh a=`lspath |awk '{print $2}'` echo $a echo $a |sed -n '=' echo $a |awk '{print $1}' # sh test7.sh hdisk0 hdisk1 hdisk0 hdisk1 hdisk2 1 hdisk0 字符串比较注意   变量获取了命令的输出，输出中有空格，如果直接调用去做比较，就会报错，例如下面示例： #!/bin/ksh a=`cat /etc/hosts |sed -n '/teacher01/p'` b=`cat /etc/hosts |sed -n '/teacher02/p'` echo $a echo $b if [ $a != $b ] then echo \"We are different!\" fi 运行后示例如下： # sh test8.sh 9.100.103.137 teacher01 9.100.103.138 teacher02 test8.sh[6]: teacher01: 0403-012 A test command parameter is not valid. 在进行test的时候，需要加上冒号，示例如下： #!/bin/ksh a=`cat /etc/hosts |sed -n '/teacher01/p'` b=`cat /etc/hosts |sed -n '/teacher02/p'` echo $a echo $b if [ \"$a\" != \"$b\" ] then echo \"We are different!\" fi 运行后示例如下： # sh test8.sh 9.100.103.137 teacher01 9.100.103.138 teacher02 We are different! 计数注意事项 参考Shell-各种shell的区别章节中的内容。 重定向注意事项   重定向输出可以将命令输出结果指定到某个文件，但是命令执行错误信息不行，示例如下（redhat8中示例）： [root@redhat8 linuxone]# ls -l > mount.log [root@redhat8 linuxone]# cat mount.log total 24 lrwxrwxrwx. 1 root root 9 Oct 31 01:09 link1 -> test1.log -rw-r--r--. 1 root root 44 Oct 31 01:20 ln1 -rwxr-xr-x. 1 root root 0 Oct 31 05:24 mount.log -rw-r--r--. 1 root root 46 Oct 31 01:40 test1.log -rw-r--r--. 1 root root 183 Oct 31 01:50 test2.sh [root@redhat8 linuxone]# mount -a > mount.log mount: /mnt/not-existing: mount point does not exist. mount: /mnt/test: special device /tmp/test does not exist. [root@redhat8 linuxone]# cat mount.log [root@redhat8 linuxone]# mount -a 2>mount.log [root@redhat8 linuxone]# cat mount.log mount: /mnt/not-existing: mount point does not exist. mount: /mnt/test: special device /tmp/test does not exist. STDERR是Linux标准文件描述符，之前学习过长期不用忘记了，再此处再次记录强调下。 STDERR之前学习笔记：Shell笔记-数据呈现 正则表达式调用变量 在正则表达式中调用变量时候，加上单引号即可，但是如果变量中有特殊字符，会报错，示例脚本： #!/bin/bash tmp=$(date +\"%y%m%d\") mount -a 2> mount$tmp.log invalid_list=`cat mount$tmp.log | sed -n '/does not exist/p'|gawk 'BEGIN{FS=\": \"}{print $2}'` echo $invalid_list for i in $invalid_list do echo $i sed -i '/'$i'/ s/^/# /' /etc/fstab done 运行后示例： [root@redhat8 linuxone]# sh test3.sh /mnt/not-existing sed: -e expression #1, char 3: unknown command: `m' /mnt/test sed: -e expression #1, char 3: unknown command: `m' 解决方法就是匹配到/然后在前面都加一个\\： #!/bin/bash tmp=$(date +\"%y%m%d\") mount -a 2> mount$tmp.log invalid_list=`cat mount$tmp.log | sed -n '/does not exist/p'|gawk 'BEGIN{FS=\": \"}{print $2}'` echo $invalid_list for i in $invalid_list do i=`echo $i |sed 's/\\//\\\\\\&/g'` echo $i sed -i '/'$i'/ s/^/# /' /etc/fstab done 运行后示例： [root@redhat8 linuxone]# sh test3.sh \\/mnt\\/not-existing \\/mnt\\/test 知识点巩固： 正则表达式中，/需要转义，&也需要转移，转义字符\\本身也需要转义 &符号可以用来代表替换命令中的匹配的模式，本实例中代表匹配模式/ gawk使用注意 gawk空格注意 使用数据字段符号时候可以使用如下方式： gawk 'BEGIN{FS=\",\"} {print $2}' scores.txt 简单点使用-F参数也可以： gawk -F, '{print $2}' scores.txt 注意，-F参数后面指定了字段分隔符后，一定要空格，不然会报错： [root@redhat8 gawk]# sh bowling.sh gawk: cmd. line:1: scores.txt gawk: cmd. line:1: ^ syntax error 自定义函数 在定义函数时，它必须出现在所有代码块之前（包括BEGIN代码块），示例如下： gawk 'function myprint() { printf \"%-16s - %s\\n\",$1,$4 } BEGIN{FS=\"\\n\";RS=\"\"} { myprint() }' test3 函数库   使用-f命令行参数可以使用函数库中的函数，但是不能将其和内敛gawk脚本在一起使用，需要创建一个包含gawk程序的文件，然后在命令行上同时指定库文件和程序文件；可以在同一个命令行中使用多个-f参数，示例如下： [root@redhat8 gawk]# cat funclib function myprint() { printf \"%-16s - %s\\n\",$1,$4 } [root@redhat8 gawk]# cat script BEGIN{FS=\"\\n\";RS=\"\"} { myprint() } [root@redhat8 gawk]# gawk -f funclib -f script test3 待补充 "},"09-Shell脚本/04-Shell脚本编写注意/03-Shell-sed和gawk差异.html":{"url":"09-Shell脚本/04-Shell脚本编写注意/03-Shell-sed和gawk差异.html","title":"Shell-sed和gawk差异","keywords":"","body":"Shell-sed和gawk差异   在AIX中sed使用和RHEL中基本一致，但是使用过程中还是发现不少差异，差异也可能是我使用的AIX版本比较老了，不管怎样，记录下来，毕竟AIX7.1版本使用的还是比较多。在AIX7.1中没有gawk，有awk使用差异也记录下来。 sed的差别 在编写修改image.data脚本过程中发现不少区别，记录下来避免忘记。 地址使用差别 例如下面同样的文本： bash-5.0# cat test1 PP= 2 PP= 8 PP= 2 PP= 8 PP= 42 在AIX7.1.4.3中使用报错无法解析： bash-5.0# cat test1 | awk '/PP=/{print $0}' | sed '4,/PP=/{s/42/1/}' sed: 0602-404 Function 4,/PP=/{s/42/1/} cannot be parsed. bash-5.0# exit # cd /tmp # cat test1 | awk '/PP=/{print $0}' | sed '4,/PP=/{s/42/1/}' sed: 0602-404 Function 4,/PP=/{s/42/1/} cannot be parsed. 在RHEL8.0中运行示例如下（也可以使用gawk）： [root@redhat8 test]# cat test1 | awk '/PP=/{print $0}' | sed '4,/PP=/{s/42/1/}' PP= 2 PP= 8 PP= 2 PP= 8 PP= 1 换了一个方式，在AIX7.1.4.3中多行可以使用（解决方法目前我发现也就是这种了），使用单行不能解析： # sed '2{ > s/PP=/ls/ > }' test1 PP= 2 ls 8 PP= 2 PP= 8 PP= 42 # sed '2{s/PP=/ls/}' test1 sed: 0602-404 Function 2{s/PP=/ls/} cannot be parsed. bash-5.0# sed '2{s/PP=/ls/}' test1 sed: 0602-404 Function 2{s/PP=/ls/} cannot be parsed. sed中选项差异   sed编辑器一般不会对原文本进行修改，当然有w命令可以将输出保存到某一文件，有时候直接想修改原文件，选项-i就可以起到这个作用，但是-i只是最近才更新的功能，RHEL8中是有的，但是在AIX7.1.4.3（AIX系统更新到7.2.5版本了，不知道后面有没有）中sed编辑器没有-i选项，替换文件并直接保存在RHEL中两种方法示例如下： [root@redhat8 test]# sed -i 's/PP=/ls/' test1 [root@redhat8 test]# cat test1 ls 2 ls 8 ls 2 ls 8 ls 42 [root@redhat8 test]# sed -in-place -e 's/ls/PP=/' test1 [root@redhat8 test]# cat test1 PP= 2 PP= 8 PP= 2 PP= 8 PP= 42 在AIX7.1.4.3中运行示例如下： bash-5.0# sed -i 's/PP=/ls/' test1 sed: Not a recognized flag: i Usage: sed [-n] [-u] Script [File ...] sed [-n] [-u] [-e Script] ... [-f Script_file] ... [File ...] bash-5.0# sed -in-place -e 's/PP=/ls/' test1 sed: Not a recognized flag: i Usage: sed [-n] [-u] Script [File ...] sed [-n] [-u] [-e Script] ... [-f Script_file] ... [File ...] 解决方法：将输出重定向到一个文件中，然后覆盖掉原文件： bash-5.0# sed 's/PP=/ls/' test1 >test1.tmp bash-5.0# mv test1.tmp test1 bash-5.0# cat test1 ls 2 ls 8 ls 2 ls 8 ls 42 列数据转换成行差异 RHEL8中把一列数据转换成一行： [root@redhat8 test]# cat test2 | awk '/LPs=/{print $2}' | sed ':a;N;s/\\n/ /g;ta' 1 4 1 4 21 4 24 1 8 1 2 2 在AIX7.1.4.3中使用示例: # cat image.data | awk '/LPs=/{print $2}' | sed ':a;N;s/\\n/ /g;ta' sed: 0602-417 The label :a;N;s/\\n/ /g;ta is greater than eight characters.# bash-5.0# cat image.data | awk '/LPs=/{print $2}' | sed ':a;N;s/\\n/ /g;ta' sed: 0602-417 The label :a;N;s/\\n/ /g;ta is greater than eight characters.bash-5.0# 使用tr命令可以解决，示例如下： # cat image.data | awk '/LPs=/{print $2}' | tr \"\\n\" \" \" 1 4 1 4 21 4 24 1 8 1 2 2 # bash-5.0# cat image.data | awk '/LPs=/{print $2}' | tr \"\\n\" \" \" 1 4 1 4 21 4 24 1 8 1 2 2 bash-5.0# RHEL8中也可以，示例如下： [root@redhat8 test]# cat test2 | awk '/LPs=/{print $2}' | tr \"\\n\" \" \" 1 4 1 4 21 4 24 1 8 1 2 2 [root@redhat8 test]# next命令差异   在RHEL中，学习next命令时候，小写的n命令会告诉sed编辑器移动到数据流中的下一行文本，具体可以参考Shell笔记-sed编辑器中的内容，但是在AIX7.1.4.3中，同样命令使用不行，会报错： bash-5.0# cat test3 Miracles happen every day ! To make each day count ! Stupid is as stupid does ! bash-5.0# sed '/happen/{n;d}' test3 sed: 0602-404 Function /happen/{n;d} cannot be parsed.   没有有效解决方法，但是在实例总找到了替代方案。实际应用中是想在iostat命令输出中，输出adapter下面的一行，取适配器的编号，但是用上述方法会报错： bash-5.0# iostat -a |sed '/Vadapter:/{n;p}' sed: 0602-404 Function /Vadapter:/{n;p} cannot be parsed. 使用的替代方案： bash-5.0# iostat -a |awk '{RS=\"\"}{ > if ($1 == \"Vadapter:\" || $1 == \"Adapter:\") > print $0}'|sed '/dapter:/d' vscsi2 0.0 0.7 0.0 0.7 1 vscsi3 0.0 0.0 0.0 0.0 2 gawk差异   AIX7.1.4.3中默认没有gawk，有awk程序，使用方法差不多，目前发现awk中没用-mr选项，使用会报错，应该也没有-mr和-W选项： # lparstat -i |awk -mr 6 '/Entitled Capacity/{print $4}' awk: Not a recognized flag: m Usage: awk [-u] [-F Character][-v Variable=Value][-f File|Commands][Variable=Value|File .. .] "},"10-Git/":{"url":"10-Git/","title":"Git","keywords":"","body":"Git 主要记录的是本博客用到的一些工具时候学习的笔记。 简介 Git是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。Git官网:https://git-scm.com/ 内容 GitHub&Git Markdown Travis-CI "},"10-Git/01-GitHub&Git/":{"url":"10-Git/01-GitHub&Git/","title":"GitHub&Git","keywords":"","body":"GitHub&Git 简介 GitHub 是一个面向开源及私有软件项目的托管平台，只支持Git作为唯一的版本库格式进行托管。 本ebook就是将代码托管于Github，此章节介绍一些个人在使用中基本操作和遇到的一些问题 GitHub官网：https://github.com/ 内容 GitHub-使用命令行 GitHub-常用操作 "},"10-Git/01-GitHub&Git/01-GitHub-使用命令行.html":{"url":"10-Git/01-GitHub&Git/01-GitHub-使用命令行.html","title":"GitHub-使用命令行","keywords":"","body":"GitHub-使用命令行   刚接触的一般会使用GitHub的web界面对自己的Repositories进行操作，简单方便。但是有些操作在web界面是无法完成的，例如就遇到想改文件夹名字，发现没找到，只能用命令行进行；在大批量的修改上传代码的时候，用命令行操作也能体现优势。 安装Git 官方安装文档：https://git-scm.com/book/zh/v2/%E8%B5%B7%E6%AD%A5-%E5%AE%89%E8%A3%85-Git Debian和Ubuntu安装 官方下载链接:https://git-scm.com/downloadsWindows下直接运行安装文件即可。Debian和Ubuntu中安装方法如下： apt-get install git RHEL安装   RHEL可以下载tarball并从源代码进行构建：https://www.kernel.org/pub/software/scm/git/， 或从GitHub网站上的镜像来获得：https://github.com/git/git/releases 下载的最新版本（git-2.29.2.tar.gz）上传到服务器并解压,安装步骤如下： [root@redhat8 python]# tar -zxvf git-2.29.2.tar.gz [root@redhat8 python]# ls git-2.29.2 git-2.29.2.tar.gz test_pdb.py [root@redhat8 python]# cd git-2.29.2 [root@redhat8 git-2.29.2]# ./configure ... checking for POSIX Threads with '-pthread'... yes configure: creating ./config.status config.status: creating config.mak.autogen config.status: executing config.mak.autogen commands [root@redhat8 git-2.29.2]# make CC fuzz-commit-graph.o In file included from object-store.h:4, from commit-graph.h:5, from fuzz-commit-graph.c:1: cache.h:21:10: fatal error: zlib.h: No such file or directory #include ^~~~~~~~ compilation terminated. make: *** [Makefile:2433: fuzz-commit-graph.o] Error 1 [root@redhat8 git-2.29.2]# rpm -qa|grep zlib zlib-1.2.11-10.el8.x86_64 查询可能是缺少zlib-devel,我配置的yum源里面没有： [root@redhat8 git-2.29.2]# yum install zlib-devel -y Updating Subscription Management repositories. Unable to read consumer identity This system is not registered to Red Hat Subscription Management. You can use subscription -manager to register.redhat8_app 0.0 B/s | 0 B 00:00 redhat8_os 0.0 B/s | 0 B 00:00 Failed to synchronize cache for repo 'redhat8_app', ignoring this repo. Failed to synchronize cache for repo 'redhat8_os', ignoring this repo. No match for argument: zlib-devel Error: Unable to find a match 官网下载最新rpm包然后安装： [root@redhat8 python]# ls git-2.29.2 git-2.29.2.tar.gz test_pdb.py zlib-devel-1.2.11-23.fc33.x86_64.rpm [root@redhat8 python]# rpm -ivh zlib-devel-1.2.11-23.fc33.x86_64.rpm warning: zlib-devel-1.2.11-23.fc33.x86_64.rpm: Header V4 RSA/SHA256 Signature, key ID 9570 ff31: NOKEYerror: Failed dependencies: rpmlib(PayloadIsZstd)   版本还是没变，然后下载了zlib-1.2.11-13.el8.x86_64.rpm，直接安装版本还是不会变，重启也没用，尝试升级就可以了，如下所示： [root@redhat8 python]# rpm -Uvh zlib-1.2.11-13.el8.x86_64.rpm warning: zlib-1.2.11-13.el8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 8483c65d: N OKEYVerifying... ################################# [100%] Preparing... ################################# [100%] Updating / installing... 1:zlib-1.2.11-13.el8 ################################# [ 50%] Cleaning up / removing... 2:zlib-1.2.11-10.el8 ################################# [100%] [root@redhat8 python]# rpm -qa |grep zlib zlib-1.2.11-13.el8.x86_64 [root@redhat8 python]# rpm -ivh zlib-devel-1.2.11-13.el8.x86_64.rpm warning: zlib-devel-1.2.11-13.el8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 8483c 65d: NOKEYVerifying... ################################# [100%] Preparing... ################################# [100%] Updating / installing... 1:zlib-devel-1.2.11-13.el8 ################################# [100%] [root@redhat8 python]# rpm -qa |grep zlib zlib-devel-1.2.11-13.el8.x86_64 zlib-1.2.11-13.el8.x86_64 继续安装git： [root@redhat8 git-2.29.2]# make ... CC t/helper/test-trace2.o CC t/helper/test-urlmatch-normalization.o CC t/helper/test-wildmatch.o ... GEN bin-wrappers/git-cvsserver GEN bin-wrappers/test-fake-ssh GEN bin-wrappers/test-tool [root@redhat8 git-2.29.2]# make install [root@redhat8 git-2.29.2]# make install SUBDIR git-gui SUBDIR gitk-git SUBDIR templates install -d -m 755 '/usr/local/bin' install -d -m 755 '/usr/local/libexec/git-core' ... 安装成功后尝试使用git命令： [root@redhat8 git-2.29.2]# git version git version 2.29.2 [root@redhat8 git-2.29.2]# git usage: git [--version] [--help] [-C ] [-c =] [--exec-path[=]] [--html-path] [--man-path] [--info-path] [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--bare] [--git-dir=] [--work-tree=] [--namespace=] [] ... 参考博客：安装失败：error: zlib.h: No such file or directorygzip网站：http://www.gzip.org/zlib官网：http://www.zlib.net/zlib各版本下载链接：[http://rpmfind.net/linux/rpm2html/search.php?query=zlib(x86-64)] (http://rpmfind.net/linux/rpm2html/search.php?query=zlib(x86-64))zlib-devel下载链接：http://rpmfind.net/linux/rpm2html/search.php?query=zlib-devel 其它系统安装 其它Linux或者Unix参考官方链接：https://git-scm.com/download/linux 配置Git 我使用的是Windows，安装成功后点击开始菜单，找到Git Bash点击打开命令行 依次输入如下命令： #初始化 git init #生成密钥，输入GitHub注册邮箱 ssh–keygen –t rsa –C 生成的密钥在目录/.ssh下面，打开.pub的文件，复制里面的所有内容。 在GitHub WEB界面依次进行如下操作： 点击右上角头像，选择选项“setting” 点击左边导航栏“SSH and GPG keys\" 点击选项“New SSH key” “Title”自定义，“Kek”栏里把刚才复制的内容粘贴上去 点击选项“Add SSH key” 添加成功后回到Git Bash，输入如下命令进行验证： ssh -T git@github.com 提示成功即可以了。 克隆仓库 我是预先再GitHub已经有Repositories了，所以不需要新建，直接clone过来即可。 再GitHub WEB界面依次进行如下操作： 进入对应需要clone的Repositories界面 点击绿色“Code”选项 如果显示“Clone with HTTPS”，则点击右边“Use SSH\" 显示为“Clone with SSH”时，在链接右边有复制按钮，点击复制链接 进入到Git，输入如下命令进行克隆： git clone git@github.com:bond-huang/huang.git 等待片刻，即克隆到本地了，输入ls命令也查看目录，有Repositories名字的目录，CD进入目录，就可以对远程Repositories进行相应操作。 "},"10-Git/01-GitHub&Git/02-GitHub-常用操作.html":{"url":"10-Git/01-GitHub&Git/02-GitHub-常用操作.html","title":"GitHub-常用操作","keywords":"","body":"GitHub-常用操作 目前大部分都是在WEB进行完成，命令行用的少，但是有些时候必须用到。 修改或添加目录 最近想修改下目录名字，GitHub的WEB管理界面找了半天没找到，查了下确实没有，需要通过命令行来操作。 建议最好Git上远程仓库和GitHub上保持一致再作修改目录操作，不一致可以可以把远程仓库更新同步到本地。 同步到本地 使用命令git pull,作用是从另外个仓库或者本地分支获取内容并合并，格式如下： git pull [] [ […​]] 首先查看所在的分支: $ git branch * master 我就一个master分支，不需要加参数直接输入命令即可： $ git pull Already up to date. 修改目录名 同步完成后进行修改，使用命令git mv，示例如下 $ git mv -f 14-IBM_Hybrid_Cloud 07-IBM_Hybrid_Cloud #然后查看下 $ ls 01-IBM_Power_System/ 08-Python/ deploy.sh* 02-IBM_Z_System/ 09-Shell脚本/ license 03-IBM_Storage_System/ 10-Git/ README.md 04-IBM_Virtualization/ 11-常用操作系统/ SUMMARY.md 05-IBM_Operating_System/ 12-虚拟化平台/ summary_crt.sh* '06-IBM_Database&Middleware&Other'/ 13-X86_System/ 07-IBM_Hybrid_Cloud/ book.json 如果目录中有&这种符号，目录名前后需要有引号 记录对repository的更改 使用git commit命令： $ git commit -m \"changed the foldername\" [master 739ab96] changed the foldername 1 file changed, 0 insertions(+), 0 deletions(-) rename {14-IBM_Hybrid_Cloud => 07-IBM_Hybrid_Cloud}/README.md (100%) 同步 使用git push命令，就一个master分支，直接输入即可： $ git push Enumerating objects: 3, done. Counting objects: 100% (3/3), done. Delta compression using up to 4 threads Compressing objects: 100% (2/2), done. Writing objects: 100% (2/2), 262 bytes | 131.00 KiB/s, done. Total 2 (delta 1), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (1/1), completed with 1 local object. To github.com:bond-huang/huang.git f21bfa4..c51279c master -> master 在WEB界面刷新下，可以看到更改成功了。 上面命令更多使用方法可以参考官方：https://git-scm.com/docs 设置Custom domain 在仓库根目录创建CNAME文件，写入自己的域名： big1000.com 然后配点击Setting,在Custom domain选项中写入自己的地址，然后点击save,可以看到如下提示： Your site is ready to be published at http://big1000.com/. 然后登录到自己的域名管理网站（我是阿里云万网），添加一条解析记录： 记录类型选择：CNAME 主机记录默认空着（创建两条解析记录，第二条写入www） 解析线路默认 在记录值里面输入对应的github地址：bond-huang.github.io 设置完成后，在浏览器输入链接可以访问：https://big1000.com/ 配置参考链接：https://blankj.com/gitbook/gitbook/配置参考链接：https://www.cnblogs.com/liangmingshen/p/9561994.html 修改git用户名及提交邮箱 刚开始本地git使用的用户名和邮箱和远程不一致，想改成一致，输入如下命令即可： $ git config --global user.name $ git config --global user.email 说明：不加--global就是更改当前的project的信息。 修改后查看配置： $ git config user.name $ git config user.email 或者直接改文件：vi ~/.gitconfig。 参考链接：https://www.cnblogs.com/shenxiaolin/p/7896489.html "},"10-Git/01-GitHub&Git/03-GitHub-常见问题.html":{"url":"10-Git/01-GitHub&Git/03-GitHub-常见问题.html","title":"GitHub-常见问题","keywords":"","body":"GitHub-常见问题 记录使用过程中遇到的问题。 Git Bash问题 提交问题 使用git add .时候报错如下： The file will have its original line endings in your working directory warning: LF will be replaced by CRLF in src/plugins/element.js. 原因是我一直在本地写代码，后面才在GitHub创建的仓库，执行下面命令： $ git rm -r --cached . rm '.gitignore' rm 'README.md' rm 'babel.config.js' rm 'package-lock.json' rm 'package.json' ... $ git config core.autocrlf false 然后查看状态： $ git status On branch master Changes to be committed: (use \"git restore --staged ...\" to unstage) deleted: .gitignore deleted: README.md deleted: babel.config.js ... Untracked files: (use \"git add ...\" to include in what will be committed) .gitignore README.md babel.config.js package-lock.json package.json public/ src/ 根据提示添加file并查看状态： $ git add . $ git status On branch master Changes to be committed: (use \"git restore --staged ...\" to unstage) modified: package-lock.json modified: package.json modified: src/App.vue new file: src/api/demo.js new file: src/api/login.js new file: src/api/menu.js ... 提交到GitHub： $ git commit -m \"First commit\" [master 9e1f8ee] First commit 41 files changed, 2111 insertions(+), 235 deletions(-) rewrite src/App.vue (94%) create mode 100644 src/api/demo.js create mode 100644 src/api/login.js ... 去GitHub上看发现并没有提交，shm是我的仓库名称： $ git push shm fatal: The current branch master has no upstream branch. To push the current branch and set the remote as upstream, use git push --set-upstream shm master 使用命令git remote -v查看指向的repository，是空的： $ git remote -v 原因是没有将本地与远程仓库关联，使用下面命令关联： $ git remote add origin git@github.com:bond-huang/shm.git 再次push： $ git push fatal: The current branch master has no upstream branch. To push the current branch and set the remote as upstream, use git push --set-upstream origin master $ git push --set-upstream origin master Enumerating objects: 79, done. Counting objects: 100% (79/79), done. Delta compression using up to 4 threads Compressing objects: 100% (72/72), done. Writing objects: 100% (79/79), 260.74 KiB | 953.00 KiB/s, done. Total 79 (delta 6), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (6/6), done. remote: remote: Create a pull request for 'master' on GitHub by visiting: remote: https://github.com/bond-huang/shm/pull/new/master remote: To github.com:bond-huang/shm.git * [new branch] master -> master Branch 'master' set up to track remote branch 'master' from 'origin'. 打开GitHub，会有如下提示： master had recent pushes 2 minutes ago 查看状态： $ git status On branch master Your branch is up to date with 'origin/master'. nothing to commit, working tree clean   进入GitHub，代码就在master分支下面。如果master不是默认的分支，在图形界面切换一下即可Switch default branch to another branch。 ssl问题   最近换了新电脑，从github上克隆下来的仓库，配置好keygen后，运行命令git commit后提示需要设置用户名和邮箱，设置即可。运行命令git push后弹出对话框要输入用户密码，选择网页认证成功后，报错如下： $ git push fatal: 发送请求时出错。 fatal: 无法连接到远程服务器 fatal: 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。 13.229.188.59:443 fatal: unable to access 'https://github.com/bond-huang/ebook.git/': OpenSSL SSL_read: Connection was reset, errno 10054 网上查说要解除ssl认证，运行了如下命令： $ git config --global http.sslVerify \"false\" 参考链接：fatal: unable to access ‘xxx.git/‘: OpenSSL SSL_read: Connection was reset, errno 10054 然后再次尝试，在弹出对话框成功认证后，push成功： warning: ----------------- SECURITY WARNING ---------------- warning: | TLS certificate verification has been disabled! | warning: --------------------------------------------------- warning: HTTPS connections may not be secure. See https://aka.ms/gcmcore-tlsverify for more information. warning: ----------------- SECURITY WARNING ---------------- warning: | TLS certificate verification has been disabled! | warning: --------------------------------------------------- warning: HTTPS connections may not be secure. See https://aka.ms/gcmcore-tlsverify for more information. Enumerating objects: 37, done. Counting objects: 100% (37/37), done. Delta compression using up to 12 threads Compressing objects: 100% (20/20), done. Writing objects: 100% (20/20), 9.90 KiB | 3.30 MiB/s, done. Total 20 (delta 15), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (15/15), completed with 15 local objects. To https://github.com/bond-huang/ebook.git 3a23091..2a40d1a master -> master 下次再push时候就不会弹出认证的对话框了： $ git push Enumerating objects: 11, done. Counting objects: 100% (11/11), done. Delta compression using up to 12 threads Compressing objects: 100% (6/6), done. Writing objects: 100% (6/6), 1.53 KiB | 1.53 MiB/s, done. Total 6 (delta 5), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (5/5), completed with 5 local objects. To https://github.com/bond-huang/ebook.git 2a40d1a..bd14a23 master -> master 还查到一个方法,下次再遇到试试看，命令如下： $ git config --global http.sslBackend \"openssl\" VScode中标记   将本地项目连接到远程GitHub仓库时候，使用VScode编辑代码后文件后面会有相应的字母信息，文件名称也会显示对应的颜色，代码中也有标记的代码行，说明如下： M modified 在github中添加过该文件，然后对在VScode中对文件进行了修改，文件后标记M，并且文件名显示黄色 在代码中，修改后的代码行前面有个蓝色标记，点开可以查看到修改前后的对比信息 U untracked 在本地新建了文件，还未提交到GitHub上，就会标记U D delete 删除了的文件，VScode会记录下这个状态 3,M 表示有3个错误，并且是modified的 参考博客：vscode-git中的U,M和D文件标记含义 待补充 "},"10-Git/02-Markdown/":{"url":"10-Git/02-Markdown/","title":"Markdown","keywords":"","body":"Markdown 简介 刚开始学习MarkDown基本到处查，网上写的很杂也不全面，后来找到一个文档不错，推荐下:Markdown 中文文档本blog基本都是Markdown写的，用到的语法都比较简单，个人觉得够用了，个人也记录下使用心得和常用方法方便查阅。 内容 Markdown-基础用法 Markdown-查询表 "},"10-Git/02-Markdown/01-Markdown-基础用法.html":{"url":"10-Git/02-Markdown/01-Markdown-基础用法.html","title":"Markdown-基础用法","keywords":"","body":"Markdown-基础用法 目前只有一些本blog用到的用法，后续学到新的了再添加。 标题 一共有六号标题，用\"#\"表示，增加一个代表一级，示例： # 标题1 ；## 标题2显示结果示例就是本文上面两个标题。 序列 用符号\"*\"、\"+\"、\"-\"效果是一样的，\"1.\"就是带序号的用法，需要可以随便遍。个人用\"-\"的比较多，用缩进来区别序列级别，显示的符号类型也会发生改变，示例输入如下内容如下 * 符号\"*\"用法 + 符号\"+\"用法 - 符号\"-\"用法 - 符号\"-\"缩进区别级别 显示效果： 符号\"*\"用法 符号\"+\"用法 符号\"-\"用法 符号\"-\"缩进区别级别 注意事项：序列完成后建议空一行,或者在用换行方法也行，我喜欢直接空一行。 代码块 单行代码采用反引号\"`\",代码块就是用三个反引号，引用前\"```\"在后面可以加上引用类型，就可以根据代码语言类型显示代码元素颜色，例如加上python或python关键字py，示例(代码结尾还有\"```\"没显示出来)： ```python class classname(object): pass def __init__(self): pass 显示结果如下： class classname(object): pass def __init__(self): pass 支持的代码引用以及关键字后期有空整理到查询章节中方便查阅：Markdown-查询表 链接 网站链接格式：[标题](网站链接)示例：AS/400-数据收集 图片插入 网站链接格式：![图片标题](图片路径或图片链接) 换行 在编辑Markdown过程中，回车可以看到换行了，但是显示的时候是没有换行的，需要行尾加上两个及以上的空格, 然后换行，解析显示的时候就会换行了。 首行缩进 有几种表示空格的方法，本人用的比较多的就是使用两个&#8195;,示例如下： &#8195;&#8195;首行缩进演示首行缩进演示首行缩进演示首行缩进演示首行缩进演示首行缩进演示首行缩进演示首行缩进演示首行缩进演示首行缩进演示 效果如下：  首行缩进演示首行缩进演示首行缩进演示首行缩进演示首行缩进演示首行缩进演示首行缩进演示首行缩进演示首行缩进演示首行缩进演示 水平线 如果一行中只有三个以上的连字符:\"*\"或者\"-\", 会在该位置生成一个 ;\"*\"或者\"-\"之间的空格也行. 示例如下: * * * *** ***** - - - --------------------------------------- 生成示例如下： 表格 常用格式如下 标题1|标题2|标题3|标题4 :---|:---|:---|:--- 内容1|内容2|内容3|内容4 示例： 标题1 标题2 标题3 标题4 内容1 内容2 内容3 内容3 说明： \":---\"是左对齐，\":---:\"是居中，\"---:\"是右对齐，\"-\"写多少关系不大 表格前建议加一行空行，或者在用换行方法也行，但是说实话编辑的时候不知道自己有没有换行，我习惯加一行空行。 字体 使用\"*\"和\"**\"表示斜体和粗体,使用\"~~\"表示删除线。个人很少用，但是在写markdown的过程中经常和原意混淆，导致输入的内容各种无规律斜体粗体，所以个人不常用，一般用转义字符转义：\"*\"、\"**\"。 示例: *斜体示例* **粗体示例** ~~删除线示例~~ 显示示例如下：斜体示例粗体示例删除线示例 对于特定字体选择，例如微软雅黑啊，华文行楷例如字体颜色，我个人表示懒得用也用的少，简洁为主，以后需要用到了再看怎么用。 转义字符 通常使用符号\"\\\"进行转义。有时候有些转不了，需要用到ASCII码去代表字符原有的意思，ASCII码对照表后期整理到查询章节中方便查阅：Markdown-查询表 流程图和序列图和甘特图 等用到了再写示例，先收藏几个链接：序列图：https://bramp.github.io/js-sequence-diagrams/流程图：http://flowchart.js.org/甘特图：https://mermaid-js.github.io/mermaid/#/ "},"10-Git/02-Markdown/02-Markdown-查询表.html":{"url":"10-Git/02-Markdown/02-Markdown-查询表.html","title":"Markdown-查询表","keywords":"","body":"Markdown-查询表 收录一些快速查询表，例如ASCII码表、文字格式表、Emoji表和算数运算的公式表等，方便查阅。 HTML ASCII码 在编写Markdown中，经常有些字符和Markdown中的字符冲突，需要用到转义字符，但是有些时候转义字符解决不了问题，Markdown和HTML兼容，可以使用HTML中的ASCII代码来代替字符，避免冲突。 关于更多HTML的用法，可以参考网站（表格也是截取自此网站）：http://www.w3chtml.com/html/ref/ascii.html 字母和数字就省略了，很少用到，主要是各种符号： 结果 描述 实体编号 space &#32; ! exclamation mark &#33; \" quotation mark &#34; # number sign &#35; $ dollar sign &#36; % percent sign &#37; & ampersand &#38; ' apostrophe &#39; ( left parenthesis &#40; ) right parenthesis &#41; * asterisk &#42; + plus sign &#43; , comma &#44; - hyphen &#45; . period &#46; / slash &#47; : colon &#58; ; semicolon &#59; less-than &#60; = equals-to &#61; > greater-than &#62; ? question mark &#63; @ at sign &#64; [ left square bracket &#91; \\ backslash &#92; ] right square bracket &#93; ^ caret &#94; _ underscore &#95; ` grave accent &#96; { left curly brace &#123; | vertical bar &#124; } right curly brace &#125; ~ tilde &#126; Emoji表 推荐一个网站，emoji很全：https://www.webfx.com/tools/emoji-cheat-sheet/ 用的不多，有需要直接这里面查找。 各种格式 文本字体 文本颜色 "},"10-Git/03-Travis-CI/":{"url":"10-Git/03-Travis-CI/","title":"Travis-CI","keywords":"","body":"Travis-CI 简介 Travis CI是目前新兴的开源持续集成构建项目。 Travis CI官网（收费）：https://www.travis-ci.com/ Travis CI官网（免费）：https://www.travis-ci.org/ Travis CI官方教程：https://docs.travis-ci.com/ 内容 TravisCI-基础操作 "},"10-Git/03-Travis-CI/01-TravisCI-基础操作.html":{"url":"10-Git/03-Travis-CI/01-TravisCI-基础操作.html","title":"TravisCI-基础操作","keywords":"","body":"TravisCI-基础操作   配置Travis-CI自动构建步骤不难，目前用到的知识也不多，以为后期不会再用到了，就没打算写，结果后来由于一些原因又搞了两次，还是记下来避免忘记。记录一些构建过程中的问题，以及记录我配置好后出现问题后（被GitHub撤销访问）重新配置，对于完整构建可以参考Lyon的分享：GitHub Pages&Gitbook&Travis CI持续构建博客 Travis-CI重新配置   近期收到GitHub的邮件，主要内容是：As a precautionary measure, we have revoked the OAuth token. A new token will need to be generated in order to continue using OAuth to authenticate to GitHub. 被GitHub撤销了访问，需要重新配置。 GitHub生成Personal access tokens 步骤如下： 登录到GitHub，点击右上角头像，选择选项\"Settings\" 选择选项\"Developer settings\" 选择选项\"Personal access tokens\" 点击选项\"Generate new token\",如果有之前的用不了的就\"Delete\"删除掉 在\"Note\"选项中输入自定义的名字,权限选择里面勾上\"repo\"所有 点击选项\"Generate token\" 复制生成的token，忘了复制就重新来一遍 Travis-CI配置 步骤如下： 登录到Travis-CI，进入到个人仓库页面 点击右边的选项\"More options\",选择选项\"Settings\" \"General\"里面我勾选了\"Build pushed branches\"和\"Build pushed pull requests\" \"Auto Cancellation\"里面我全勾选了，说实话作为小白对描述不是很理解 在\"Environment Varialbes\"中\"NAME\"选项里面写入名字，名字跟脚本deploy.sh里面写入的一样 在\"Environment Varialbes\"中\"VALUE\"选项里粘贴之前复制的token 然后点击右边的\"Add\"选项 添加成功后，点击右边的选项\"More options\",选择选项\"Trigger build\"开始构建 之前构建成功过的，这次一般都会成功的，因为出问题只是GitHub取消了访问。 Travis-CI初始配置问题   在第一次用Travis-CI配置自动构建的时候，\"Trigger build\"后各种问题，调试了好久第32次才通过。忘了作详细记录，目前记得的简单记录下。 gitbook版本问题   在.travis.yml中，有安装gitbook版本，但是试了好几个版本在那一项都过不了，提示内容忘了截取，最后没有指定版本并且强制安装： install: - \"npm install -g gitbook\" - \"npm install -g gitbook-cli --force\" JS版本问题 改了上面后发现JS版本也不过，高低版本都不行好像，最后改成了8： node_js: - \"8\" Travis-CI更新异常 问题描述：能运行但是不能自动添加新的内容报错及日志如下： The command bash deploy.sh exited with 1. log: Switched to a new branch 'gitbook' On branch gitbook Changes not staged for commit: (use \"git add ...\" to update what will be committed) (use \"git restore ...\" to discard changes in working directory) modified: SUMMARY.md Untracked files: (use \"git add ...\" to include in what will be committed) node_modules/ travis_wait_2044.log no changes added to commit (use \"git add\" and/or \"git commit -a\") 查了下应该是分支冲突了，SUMMARY.md文件提交不了，修改几次脚本都不行，直接用绝招：   在GitHub里面master-->View all branches-->删掉所有由Travis创建的分支，travis-ci上的缓存也清理了，但是还是不行。后来把出错当天更新的文档删掉了，然后gitbook分支也删了，再重新运行就好了。当天可疑操作就是文件名后缀写重复了，当然不是这个原因；  后来发现，那些SUMMARY.md提示无关紧要，deploy.sh exited with 1这个才是关键，检查脚本中有个条件语句判断上一条命令的退出状态码，执行失败脚本就exited with 1，也就是gitbook build .执行出现了问题，问题就在最新加的markdown中有html的代码，虽然我使用了代码注释但是估计gitbook还是识别有问题，GitHub识别没什么问题；  最后弄明白了，代码块引用没什么问题，但是在说明描述中单反引号引用html相关代码时候不行，用对应的HTML ASCII码替代即可。 构建问题排查 官方常见构建问题说明： Common Build Problems Build Config Validation Branch not included per configuration 官方描述： please make sure your branch is not explicitly excluded or not included in your .travis.yml file. 我遇到的报错： Branch \"main\" not included per configuration 原因是在.travis.yml写错了： language: python python: - \"3.8\" # command to install dependencies install: - pip install Flask branches: only: - master script: - travis_wait 10 bash start.sh 主分支应该是main，把master改成main即可。 10分钟超时 使用arm64和ppc64le构建我的ebook时候报错如下： No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself. Check the details on how to adjust your build configuration on: https://docs.travis-ci.com/user/common-build-problems/#build-times-out-because-no-output-was-received The build has been terminated 把node.js改成14版本后，不会超时，但是报错： TypeError: cb.apply is not a function at /home/travis/.nvm/versions/node/v14.17.1/lib/node_modules/gitbook-cli/node_modules/npm/node_modules/graceful-fs/polyfills.js:287:18 at FSReqCallback.oncomplete (fs.js:193:5) Installing GitBook 3.2.3 /home/travis/.nvm/versions/node/v14.17.1/lib/node_modules/gitbook-cli/node_modules/npm/node_modules/graceful-fs/polyfills.js:287 if (cb) cb.apply(this, arguments) 参照方法进行处理报错没解决：Gitbook-cli install error TypeError: cb.apply is not a function inside graceful-fs 把node.js改成10版本后，报错： Error: shasum check failed for /tmp/npm-3441-2b05e04f/registry.npmjs.org/acorn/-/acorn-0.9.0.tgz Error: Couldn't locate plugins \"advanced-emoji, toggle-chapters, splitter, github, search-plus, anchor-navigation-ex-toc, editlink, copy-code-button, theme-comscore\", Run 'gitbook install' to install plugins from registry. /home/travis/.travis/functions: line 607: 3425 Terminated travis_jigger \"${!}\" \"${timeout}\" \"${cmd[@]}\" The command \"travis_wait 100 bash deploy.sh\" exited with 1. 网上有注释掉三行代码解决问题的： Gitbook错误\"cb.apply is not a function\"的解决办法 How I fixed a \"cb.apply is not a function\" error while using Gitbook 根据此方法，在.travis.yml和deploy.sh里面都试过了不行一样有报错，下面这个报错删掉前面bash即可： $ bash sed -i 's/^fs.*stat = statFix(fs.*stat)/\\/\\/ &/g' /home/travis/.nvm/versions/node/v14.17.1/lib/node_modules/gitbook-cli/node_modules/npm/node_modules/graceful-fs/polyfills.js /bin/sed: /bin/sed: cannot execute binary file 后来在deploy.sh里面cat了这个文件： cat /home/travis/.nvm/versions/node/v14.17.1/lib/node_modules/gitbook-cli/node_modules/npm/node_modules/graceful-fs/polyfills.js 多此一举从行首开始匹配，去掉^符号，继续构建报错： $ npm install -g gitbook 2.31s$ npm install -g gitbook-cli --force npm WARN using --force I sure hope you know what you are doing. npm ERR! cb() never called! npm ERR! This is an error with npm itself. Please report this error at: npm ERR! npm ERR! A complete log of this run can be found in: npm ERR! /home/travis/.npm/_logs/2021-06-22T16_31_00_790Z-debug.log The command \"npm install -g gitbook-cli --force\" failed and exited with 1 during . 改成了12版本，接近成功但是还是有报错： *** Please tell me who you are. Run git config --global user.email \"you@example.com\" git config --global user.name \"Your Name\" to set your account's default identity. Omit --global to set the identity only in this repository. fatal: empty ident name (for ) not allowed error: src refspec gh-pages does not match any. error: failed to push some refs to 'https://[secure]@github.com/bond-huang/ebook.git' /home/travis/.travis/functions: line 607: 3416 Terminated travis_jigger \"${!}\" \"${timeout}\" \"${cmd[@]}\" The command \"travis_wait 100 bash deploy.sh\" exited with 1. cache.2 store build cache 根据提示要设置用户信息，将deploy.sh中对应代码修改成： git config --global user.name \"huang\" git config --global user.email \"huang19891023@163.com\" 不设置成全局的也可以在创建gh-pages分支前设置，修改后继续报错： Error: Couldn't locate plugins \"advanced-emoji, toggle-chapters, splitter, github, search-plus, anchor-navigation-ex-toc, editlink, copy-code-button, theme-comscore\", Run 'gitbook install' to install plugins from registry. /home/travis/.travis/functions: line 607: 3423 Terminated travis_jigger \"${!}\" \"${timeout}\" \"${cmd[@]}\" The command \"travis_wait 100 bash deploy.sh\" exited with 1. cache.2 store build cache 在.travis.yml加入如下代码： before_install: - \"npm cache clean --force\" 然后构建，超时了几次，多尝试了几次构建成功了。 其它参考链接： Gitbook build stopped to work in node 12.18.3 #110 TypeError: cb.apply is not a function node v12.18.3 doesn't work with npm v6.9.2 and below #34491 All my react-native projects shows error TypeError: cb.apply is not a function 迁移问题   2021年6约15号之后，travis-ci.org将停止服务，不能进行构建了，转向travis-ci.com，需要把仓库迁移到travis-ci.com，迁移比较简单，travis-ci.org上发起，邮箱确认后在travis-ci.com点击迁移即可。 error while trying to fetch the log 问题描述 迁移完成后，在travis-ci.com上构建，提示或报错如下： Oh no! You tried to trigger a build for bond-huang/ebook but the request was rejected. There was an error while trying to fetch the log.   原因是travis-ci.com上策略更改了一下，在主页中，有个Plan选项，第一个是Free Plan,其它都是付费的，当然我选择了Free，有10000积分，构建了一次花掉了60积分，看来以后得省着点用了。 解决方案   合作伙伴队列解决方案是由Travis-CI的合作伙伴赞助的基础架构解决方案，可以完全免费使用（仅适用于开源软件仓库）。目前有： IBM CPU在IBM Cloud中构建（由 IBM 赞助） ARM64 CPU构建在Equinix Metal（前 Packet）基础架构中（由ARM赞助） 要使用Partner Queue Solution运行作业，在公共仓库中.travis.yml使用以下标签： os: linux arch: - arm64 - ppc64le - s390x 尝试使用了IBM Power平台ppc64le构建了我的navigator,用s390x构建了我的ebook没有扣积分。 参考链接 参考链接： Oh no! You tried to trigger a build for orgName/project but the request was rejected Travis-CI Billing Overview Building on Multiple CPU Architectures 用户密码问题 构建时候报错： remote: Invalid username or password. fatal: Authentication failed for 'https://[secure]@github.com/bond-huang/ebook.git/' 一般都是GitHub上的Personal access tokens没了，重新创建一个即可。 构建超时 默认构建超过10分钟没有输出，就会超时报错： No output has been received in the last 10m0s, this potentially indicates a stalled build or something wrong with the build itself. Check the details on how to adjust your build configuration on: https://docs.travis-ci.com/user/common-build-problems/#build-times-out-because-no-output-was-received The build has been terminated 如果有超过10分钟不产生输出的命令，可以在它前面加上前缀，这travis_wait是构建环境导出的函数。例如： install: travis_wait mvn install 将等待时间延长至30分钟（如果是npm，把mvn改成npm即可）： install: travis_wait 30 mvn install 官方参考链接：Common Build Problems-build-times-out-because-no-output-was-received npm版本问题 构建时候报错示例如下： npm WARN deprecated graceful-fs@3.0.5: please upgrade to graceful-fs 4 for compatibility with current and future versions of Node.js npm WARN deprecated chokidar@1.0.6: Chokidar 2 will break on node v14+. Upgrade to chokidar 3 with 15x less dependencies. npm WARN deprecated nunjucks@2.2.0: potential XSS vulnerability in autoescape mode, and with escape filter was fixed in v2.4.3 npm WARN deprecated request@2.51.0: request has been deprecated, see https://github.com/request/request/issues/3142 npm WARN deprecated fsevents@0.3.8: \"Please update to latest v2.3 or v2.2\" npm WARN deprecated minimatch@0.2.14: Please update to minimatch 3.0.2 or higher to avoid a RegExp DoS issue ... 不知道啥时候开始报的，网上查可能是版本问题，但是多试几次还是可以构建成功。暂时不知道有效解决方法。 平台切换 ppc64le切换 在.travis.yml中删掉： arch: - ppc64le 报错： remote: Support for password authentication was removed on August 13, 2021. Please use a personal access token instead. remote: Please see https://github.blog/2020-12-15-token-authentication-requirements-for-git-operations/ for more information. fatal: Authentication failed for 'https://github.com/bond-huang/ebook.git/' /home/travis/.travis/functions: line 611: 5754 Terminated travis_jigger \"${!}\" \"${timeout}\" \"${cmd[@]}\" The command \"travis_wait 100 bash deploy.sh\" exited with 128.   应该是GitHub上的Personal access tokens不行了，重新创建一个即可。此次失败扣了70 credits。ppc64le不用扣除credits，但经常失败，credits有限，日常小更新继续使用ppc64le。 待补充 "},"10-Git/03-Travis-CI/02-TravisCI-构建Flask项目.html":{"url":"10-Git/03-Travis-CI/02-TravisCI-构建Flask项目.html","title":"TravisCI-构建Flask项目","keywords":"","body":"TravisCI-构建Flask项目 以个人写的navigator为例，代码托管在GitHub，参考官方文档一步一步进行。相关链接： Navigator GitHub：https://github.com/bond-huang/navigator 官方参考文档：https://docs.travis-ci.com/user/languages/python/ 配置参考链接：https://github.com/travis-ci-examples/python-example 基础配置   首先在项目根目录下创建.travis.yml文件，其它配置比如获取GitHub Access Token，注册配置TravisCI，参考前面做的笔记：TravisCI-基础操作 部署Python项目 指定python版本 在.travis.yml文件中写入： language: python python: - \"3.8\" Travis CI使用隔离的virtualenvs   CI环境为每个Python版本使用单独的virtualenv实例。只要language: python在.travis.yml中指定，就可以在virtualenv内部运行。如果需要安装Python软件包，通过pip而不是apt: 依赖管理 默认情况下，Travis CI用于pip管理Python依赖关系。如果项目目录下右requirements.txt文件，Travis CI运行pip install -r requirements.txt在install构建阶段： language: python python: - \"3.8\" # command to install dependencies install: - pip install -r requirements.txt 此次项目没什么依赖，直接写入： language: python python: - \"3.8\" # command to install dependencies install: - pip install Flask 指定分支 可以指定分支提交时才运行： language: python python: - \"3.8\" # command to install dependencies install: - pip install Flask branches: only: - master 设置脚本 Python项目需要script在其项目中提供密钥，.travis.yml以指定用于运行测试的命令。 例如，如果项目使用pytest： # command to run tests script: pytest 我使用pytest+coverage language: python python: - \"3.8\" # command to install dependencies install: - pip install Flask - pip install pytest coverage branches: only: - main script: - coverage run -m pytest - coverage report 在项目中还使用了waitress： language: python python: - \"3.8\" # command to install dependencies install: - pip install Flask - pip install waitress - pip install pytest coverage branches: only: - main env: global: - GH_REF: github.com/bond-huang/navigator.git script: - coverage run -m pytest - coverage report 环境变量 环境变量可以像加GitHub Access Token一样在Travis CI配置页面添加，可以在此添加 language: python python: - \"3.8\" # command to install dependencies install: - pip install Flask - pip install waitress - pip install pytest coverage branches: only: - main env: global: - GH_REF: github.com/bond-huang/navigator.git script: - coverage run -m pytest - coverage report 测试构建结果： Setting environment variables from repository settings $ export GH_TOKEN=[secure] $ export M_NAME=[secure] $ export M_EMAIL=[secure] 0.01s $ source ~/virtualenv/python3.8/bin/activate $ python --version Python 3.8.7 $ pip --version pip 20.3.3 from /home/travis/virtualenv/python3.8.7/lib/python3.8/site-packages/pip (python 3.8) install.1 1.45s $ pip install Flask install.2 0.71s $ pip install waitress install.3 1.24s $ pip install pytest coverage 0.51s $ coverage run -m pytest ============================= test session starts ============================== platform linux -- Python 3.8.7, pytest-6.2.1, py-1.10.0, pluggy-0.13.1 rootdir: /home/travis/build/bond-[secure]/navigator, configfile: setup.cfg, testpaths: tests collected 8 items tests/test_db.py .. [ 25%] tests/test_factory.py .. [ 50%] tests/test_navigator.py .... [100%] ============================== 8 passed in 0.20s =============================== The command \"coverage run -m pytest\" exited with 0. 0.12s$ coverage report Name Stmts Miss Branch BrPart Cover ------------------------------------------------------------- nav/__init__.py 21 0 2 0 100% nav/db.py 25 0 4 0 100% nav/navigation.py 76 12 28 12 77% nav/templates/footer.html 0 0 0 0 100% ------------------------------------------------------------- TOTAL 122 12 34 12 85% The command \"coverage report\" exited with 0. Done. Your build exited with 0. pytest和coverage好像自带了，最终我使用配置文件： language: python python: - \"3.8\" # command to install dependencies install: - pip install Flask - pip install waitress - pip install -q -e . branches: only: - main env: global: - GH_REF: github.com/bond-huang/navigator.git script: - python setup.py test gh-pages分支 也可在Travis CI以新建一个gh-pages分支： after_script: - git config user.name \"${M_NAME}\" - git config user.email \"${M_EMAIL}\" - git config --global core.quotepath false - git init - git checkout --orphan gh-pages - git status - sleep 5 - git add . - git commit -m \"Update gh-pages\" - git push --force --quiet \"https://${GH_TOKEN}@${GH_REF}\" gh-pages:gh-pages 待补充 "},"10-Git/04-YAML/":{"url":"10-Git/04-YAML/","title":"YAML","keywords":"","body":"YAML 简介   YAML是YAML Ain't Markup Language的递归首字母缩写词，是一种人性化的数据序列化语言，适用于所有编程语言。 主页：https://yaml.org/ Github主页：The YAML Project 最新版本文档：YAML version 1.2 内容 "},"10-Git/04-YAML/01-YAML-基础学习.html":{"url":"10-Git/04-YAML/01-YAML-基础学习.html","title":"YAML-基础学习","keywords":"","body":"YAML-基础学习 学习参考链接： YAML version 1.2 YAML Syntax runoob.com YAML入门教程 基本语法 基本语法如下： 大小写敏感 使用缩进表示层级关系 缩进不允许使用tab，只允许空格 缩进的空格数不重要，只要相同层级的元素左对齐即可 #表示注释 扩展名为yml 语言概述 Collections   YAML的Block Collection使用Indentation来表示范围，并在每个条目自的开头。详细说明如下： Block sequences用破折号和空格-表示每个条目 映射使用冒号和空格:来标记每个键/值对 注释以octothorpe开头(也称为hash、sharp、pound或数字符号#) 标量序列示例： - Thor - America Captain - Thanos 将标量映射到标量示例： - Asgard: Thor # King of Asgard - Earth: America Captain # Avengers captain - Titan: Thanos # Love snaps fingers 将标量映射到序列示例： Marvel: - Thor - America Captain - Thanos Detective Comics: - Batman - Catwoman - Wonder Woman 映射序列示例： - name: America Captain from: New York power: 9999 - name: Wonder Woman from: Amazon power: 9998 流样式   YAML也有流样式，使用显式指示符而不是缩进来表示范围。流序列写为方括号内的逗号分隔列表。以类似的方式，流映射使用花括号。 序列中的序列示例： - [name , from, power ] - [America Captain, New York, 9999] - [Wonder Woman , Amazon, 9998] 映射中的映射示例： America Captain: {from: New York, power: 9999} Wonder Woman: { from: Amazon, power: 9998, } 结构 "},"11-常用操作系统/":{"url":"11-常用操作系统/","title":"常用操作系统","keywords":"","body":"常用操作系统 简介 日常用到的操作系统一些问题和操作，记录下来避免忘记。 内容 Windows Ubuntu "},"11-常用操作系统/01-Windows/":{"url":"11-常用操作系统/01-Windows/","title":"Windows","keywords":"","body":"Windows 简介 Windows操作系统日常遇到一些问题和操作，记录下来避免忘记。 关于Windows系统推荐一个网站：I tell you 很不错的网站，最近换了新链接：I tell you 内容 Windows-常见问题 Windows-SQL08R2完全卸载&安装 Windows-Excel购房贷款计算器 Windows-Excel常用函数 Photoshop-基础操作 "},"11-常用操作系统/01-Windows/01-Windows-常见问题.html":{"url":"11-常用操作系统/01-Windows/01-Windows-常见问题.html","title":"Windows-常见问题","keywords":"","body":"Windows-常见问题   以前经常倒腾自己电脑，觉得简单没记录下来，发现Windows很多问题解决方法都忘记了，记录下现在还记得的，避免后面忘记更多。 安装系统问题 无法创建新的分区   我一般喜欢用原版ISO镜像直接点setup.exe安装系统，用PE安装也是。有时候系统挂了，不得不重装，在使用PE安装原版镜像的时候，选择系统分区的时候经常会报错：我们无法创建新的分区，也找不到现有分区，有关详细信息，请参阅安装日志文件。 重新分区（删除分区）和用PE的工具安装方式我个人一般不用，个人屡试不爽方法： 将iso镜像解压或者用虚拟光驱打开 拷贝boot和sources文件夹以及bootmgr和bootmgr.efi文件到需要安装系统的磁盘 重启电脑，从硬盘启动 说明：这种一般是分区表类型为MBR格式时候安装方法和出现的问题，GUID格式个人用的少。 系统启动问题 如果下面问题中的方法都解决不了问题，那么拆开机箱，抠下主板纽扣电池，短接十多秒，还不行就可能是硬件问题，要送修。 系统启动一半就重启 现象：启动系统到Windows窗口一半的时候就卡住，然后系统立即重启，反反复复。解决方法，先采用第一种: 一般是硬盘模式设置问题，进入BIOS，找到设置项，模式换一下就可以了，模式有：SATA模式、AHCI硬盘接口模式、IDE或者 compatible（兼容）模式 Windows7系统对UEFI支持性不是很好，需要CSM(Compatibility Support Module)也就是Legacy BIOS的支持：进入BIOS，将BIOS中OS Optimized设置为Others或Disabled，将CSM Support设置为Yes。 开机后进入Windows错误恢复 现象：开机后进入到Windows窗口界面时候窗户加载完了等几秒钟就黑屏，然后等几秒到Windows错误恢复界面，如果正常启动就会又到Windows错误恢复界面，解决方法： 一般是有不兼容的软件或者新安装了补丁啥的，进入安全模式，删掉近期安装软件或补丁 或者还原系统到某个还原点 开机有画面，但是进到bios 现象：启动系统到后都是直接进入到bios界面。一般是系统找不到引导硬盘，解决方法： 检查下硬盘线路，重新插一下硬盘线，或者换一根 硬盘引导有问题，进入PE，如果能看到硬盘，正常显示打开Diskgenius分区工具，选择硬盘，然后点击：重建主引导记录（MBR)，MBR格式这样搞，其它引导的参照其它方式 如果PE 里面也看不到硬盘，那估计是硬盘挂了 开机后就显示一个字符 现象：开机后可以看到一些正常流程显示，但是到应该启动系统时候只一个字母或这光标。一般也是引导问题，解决方法： 可能插了U盘或者其它介质（并且没有引导的）在电脑上，有的话拔掉再试，不想拔掉就手动选择引导 硬盘引导有问题，进入PE，如果能看到硬盘，正常显示打开diskgenius分区工具，选择硬盘，然后点击：重建主引导记录（MBR)，MBR格式这样搞，其它引导的参照其它方式 开机显示器没反应 现象：开机后电源指示灯风扇都正常，但是显示器没任何反应，鼠标键盘上有灯。一般是内存问题，解决方法： 拔出内存，清理下灰尘，用橡皮擦擦一下金手指 清理下机箱灰尘，内存条换一个槽位或者换一个内存条试试 多试几次，还不行并且主板有滴滴声，根据滴滴声查一下什么问题，实在不行就送修 开机后突然关机 现象：开机后没几分钟电脑就突然关机了，再开的话就可以开。一般是扇热问题，解决方法： 打开机箱看看风扇转了没，感觉转的慢试试拆下来清灰上点油； 完全不转了就换个新的风扇 按几次电源键才开机 现象：电源键按几次才开机，或者是按重启键是开机。一般是开关或线路问题，解决方法： 按几次才开机或者要用力开机，换个电源开关吧 重启键是开机那就是线接错了，安装主板上提示接对就行了 系统启动不了其它情况 现象：操作系统启动不了，有的提示修复系统一般是最近做了啥操作，安装软件驱动什么的，导致不兼容，解决方法： F8进入安全模式，卸载掉最近安装的软件或者驱动，特别是一些杀毒的 也是F8，有修复计算机选项，修复下就行了 修复不了有备份恢复，系统做了备份的话从最近备份的点恢复 密码问题 密码忘记了可以通过PE去清除，一般PE工具都带这个功能。 U盘引导进入PE菜单选择界面，选择关于密码的菜单（如果主页有，主页没有就进入到PE里面，在工具里面找） 打开密码清除的程序后，选择搜索存在SAM文件的分区和硬盘 会找到SAM文件，选择要清除的系统密码所在的SAM文件 选择需要清除密码的用户，然后选择清除此用户的密码，确定清除 还有更高级的方法，本人没试过，链接Windows修改密码 数据问题 现象：电脑上D盘突然访问不了，显示不了容量，双击提示需要格式化。解决方法： 以管理员运行CMD，输入命令（D盘问题所以示例为D）CHKDSK D: /f 上面方法不行的话，可以采用恢复数据的方法，我个人用过Diskgenius，数据恢复比较全，但是这个功能是收费的 如果不小心格式化了，磁盘是可以用了，但是数据看到不了，还想要数据的话就千万不要往里面写入新的数据。我没记错的话我以前做过测试，格式化后还是可以用Diskgenius恢复数据 建议：建议U盘移动硬盘什么的都采用标准弹出流程，系统提示可以拔了后就拔，不要强行拔，虽然大多数情况下没事，但是出一次就够头疼的了。 登录问题 无法加载用户配置文件 现象：Windows能正常启动，但是到登录用户界面时候点击登录提示： User Profile Service服务登录失败。 无法加载用户配置文件。 解决方法： 进入安全模式 同时按windows+R键，输入services.msc/s 进入本地服务设置，找到User profile service服务 将其设置为自动 Windows7启动时候按F8可以进入维护模式，Windows10进入方法： 开机进入系统时长按电源键开机，重复3次左右进入高级恢复 依次点击疑难解答->高级选项 点击启动设置->重启，选择安全模式   最近遇到一次这种情况，重启了几次Windows进行了更新操作（提示不要关闭计算机），更新完成后就可以进入系统了。 待补充 "},"11-常用操作系统/01-Windows/02-Windows-SQL08完全卸载&安装.html":{"url":"11-常用操作系统/01-Windows/02-Windows-SQL08完全卸载&安装.html","title":"Windows-SQL08完全卸载&安装","keywords":"","body":"Windows-SQLR2完全卸载&安装 文章是较早时候写的，放在百度文库上，阅读量两万多，下载量过一千（下载赚的积分够用好几年），说明需求还是有不少的，文章有点实际意义，所以搬到这里来，以后新版的Microsoft SQL server的问题说不定可以参考下。 本blog追求精简，和之前文章一样不喜欢贴图，图文的文档可以参考百度文库链接：Microsoft SQL server 2008 R2完全卸载再安装手册 Microsoft SQL Server 2008 R2安装后，可能一些原因导致程序故障，需要重新安装，但是卸载后，很难再进行安装，基本都会报错，导致程序无法正常安装使用，以下是亲测记录过程，屡试不爽，以及一些其它可能出现的问题，如参照以下方法仍旧不能解决，建议重新安装系统，再安装数据库，这是最简单最有效的方法。 完全卸载Microsoft SQL server 2008 R2 卸载应用程序 步骤如下： 进入控制面板-->选择程序和功能 找到Microsoft SQL Server 2008 R2，点击右键，选择卸载/更改 弹出对话框中选择“删除”选项 弹出对话框会进行检测，通过才能继续，一般“重启计算机”选项会不过，重启下计算机通过后继续 弹出对话框选择要删除的实例，然后点击下一步 选择要删除的功能，全选，然后下一步 弹出对话框会进行检测，全部通过即没问题，选择下一步 点击删除开始删除 等待删除完成 然后进入控制面板-->选择程序和功能，右键删除里面所有有关Microsoft SQL server的项目: Microsoft SQL server 2008 R2 Native Client Microsoft SQL server 2008 R2 安装程序（简体中文） Microsoft SQL server 2008 R2 策略 Microsoft SQL server 2008 R2 联机丛书 Microsoft SQL server 2008 安装程序支持文件 Microsoft SQL server Browser Microsoft SQL server Compact 3.5 SP2 CHS Microsoft SQL server Compact 3.5 SP2 Query Tools CHS Microsoft SQL server System CLR Types(x64) Microsoft SQL server VSS Writer 使用工具卸载 有些机器的数据库可能因为某些原因，导致不能如上正常卸载，可以运用Windows Install Clean Up 进行删除程序 一般系统自带，如没有，下载地址：http://pan.baidu.com/s/1qWG37T6 下载安装后运行程序，找到关于Microsoft SQL Server 的选项，全部选择，然后点击Remove，需要时间，请耐心等待，完成后根据上面的介绍，删除文件夹和注册表的残余项目。 文件删除 删除安装盘中残余文件，本次安装默认在C盘，路径如下所示， C:\\Program Files\\Microsoft SQL Server C:\\Program Files (x86)\\Microsoft SQL Server（64位操作系统有此项） C:\\Program Files (x86)\\Microsoft SQL Server Compact Edition（64位操作系统） C:\\Users\\Administrator\\AppData\\Local\\Microsoft C:\\Users\\Administrator\\AppData\\Roaming\\Microsoft 说明： Users 即windows 7 的C盘下“用户”文件夹，windows 8显示为Users，Administrator即计算机管理员账户，具体根据电脑自定义的名称 如果找不到administrator文件夹下面的AppData文件夹，说明被隐藏了，显示隐藏文件即可 如果再删除文件夹的时候，发现删除不掉，提示被占用，可以选择重启计算机试试，如果还是不行，可以用强制的方法，可以采取一些软件自带的粉碎文件的操作 注册表信息删除 删除注册表残余项目，运行regedit注册表，删除如下项（如果有的话，有些项目跟个人电脑安装软件有关联），路径具体操作如下： HKEY_CURRENT_USER\\Software\\Microsoft\\Microsoft SQL Server HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\Microsoft SQL Server HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\MSSQLServer HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Contorl\\Session Manager\\PendingfileRename* 到此就删除完成了，亲测有效，下面安装过程就是在此处卸载完成后进行的。 再次安装Microsoft SQL server 2008 R2 介质下载 下载Microsoft SQL Server 2008 R2，打开安装文件夹，运行setup.exeMicrosoft SQL Server 2008 R2下载地址：http://pan.baidu.com/s/1nthxNxn 此文件为.iso格式，下载后解压即可，或者用虚拟光驱，下载安装虚拟光驱后，右键点击文件，选择加载虚拟光驱下载地址：http://pan.baidu.com/s/1mg5Mt5I 安装 如果运行安装程序中发现如下错误，请参照下面描述进行处理，如没有，跳过此步: 打开C:\\Users\\Administrator\\AppData\\Local, 打开Local后，找到Microsoft_Corporation文件夹下的LandingPage.exe_StrongName_ryspccglaxmt4nhllj5z3thycltsvyyx这个文件夹，删除此文件夹即可正常运行安装程序。 继续下面步骤： 弹出安装程序界面，选择安装，全新安装或向现有安装添加功能 进行检测，全部通过即可，卸载干净情况下一般都是通过的，如有失败的，请再参照上面进行删除 输入产品秘钥，然后下一步 接受许可条款，然后下一步 安装支持文件 如果SQL Server 2008 R2在此处安装过程中提示Could not open key请参照如下解决方案，如没有报错，请跳过此步， 此问题为权限设置有问题，导致程序无法访问，修改权限即可。首先找到提示的位置，报错信息中写的UNKNOWN，地址未知，根据后面的路径，可以找到具体位置。 解决方法一： 以管理员身份运行CMD命令提示符，输入以下语句并运行就OK了 secedit /configure /cfg %windir%\\inf\\defltbase.inf /db defltbase.sdb /verbose 如方法一无法解决，请参照解决方法二： 注册表位置： HKEY_LOCAL_MACHINE\\SOFTWARE\\Microsoft\\ Windows\\CurrentVersion\\ Installer\\ UserData\\ S-1-5-18\\ Components 选中Components右键，选择权限，然后选择everyone，点击添加 选择用户或组界面点击高级 然后点击立即查找，找到everyone，点击确定 可以看到用户或租里面有everyone了，点击确定 在Components的权限对话框中选择everyone，勾上完全控制和读写权限，然后点击高级选项 点击所有者，选择其它用户或组，然后点击高级，添加上everyone 选择好Everyone后，点击确定，在高级设置里面勾上：替换子容器和对象所有者 在刚刚错误界面点击确定就可以了，安装程序会继续，如果继续报错，继续刚才步骤，没报错会进行下面操作： 安装程序支持规则，全通过了就下一步 设置角色（根据需求） 选择功能，全选或根据需求，目录可以根据自己意愿更改，点击下一步 安装规则，全部通过，跳过就没问题 实例配置，默认实例或根据需求 磁盘空间需求 服务器配置，根据需求配置 数据库引擎配置，选择混合模式（或根据需求），指定SQL Server 管理员添加当前用户 Analysis Services 配置，添加当前用户，然后下一步 Reporting Services 配置，按照本机模式默认配置（或根据需求） 错误报告页面，点击下一步 安装配置规则，通过跳过就没问题 开始安装，理论上，前面删除干净了，检测都通过，没有报错，就静静的等待安装程序进行即可。但是有时候也会在此处报错，目前在此处只遇到过一个因为系统windows installer服务未开启导致的安装报错。 "},"11-常用操作系统/01-Windows/03-Windows-Excel购房贷款计算器.html":{"url":"11-常用操作系统/01-Windows/03-Windows-Excel购房贷款计算器.html","title":"Windows-Excel购房贷款计算器","keywords":"","body":"Windows-Excel购房贷款计算器 分享一个小工具，Excel做的一个购房贷款计算器，很简单，但是很实用，目前只做了等额本息的模式，分享下。 看房子时候，置业顾问和中介在那里用手机和笔算感觉效率比较低，还经常算错，对于新房同户型不通楼层价格也不一样，所以结果也会不一样，一般他们也就只会算一个供参考，其实有些楼层价格差距还是很大的；对于二手房，不同二手房也经常需要对比下，所以自己搞了个Excel去计算，方便快捷，并且可以进行全方位对比。 Excel中一共有三个表格：新房贷款计算表、二手房贷款计算表和列表简略版链接：https://pan.baidu.com/s/18o1hj_QaEwHPE48vx6Ls1w提取码：e836 新房贷款计算表 表格中红色的选项根据实际情况填入或选择对应选项即可，后面几行的内容都会自动算出来。图表示例： 二手房贷款计算表 表格中红色选项需填入，选项有点多，因为个地方政策或中介的收费不一样，蓝色选择值即可。图表示例： 列表简略版 这款就比较简洁，一列就是一套房的贷款明细，填入面积、毛胚单价和精装价格即可，列表形式显示，适合对比整栋楼和多套，适合售楼部卖房的直接统计多栋楼的价格。图表示例： "},"11-常用操作系统/01-Windows/04-Windows-Excel常用函数.html":{"url":"11-常用操作系统/01-Windows/04-Windows-Excel常用函数.html","title":"Windows-Excel常用函数","keywords":"","body":"Windows-Excel常用函数   日常工作中经常用到Excel，偶尔需要用到里面函数去处理表格，用的不多容易忘记，把用到的记录下来，避免下次忘了再到处查询。 IF & OR & ISNUMBER & FIND函数 主要是IF函数，IF函数标准格式： if(logical_test,[value_if_ture],[value_if_false])   例如在一个单元格，我输入对应的内容，指定的单元格就显示指定的内容，这就需要用到Exel的if函数。用个实例说明，可以一次性用到IF、OR、ISNUMBER和FIND这几个，如下图所示,要求： D列选择“地铁票、公交票、飞机票、火车票、住宿费、差旅补贴”，E列自动显示“差旅费” D列选择“办公及交通费”，E列显示“市内交通费” D列选择“误餐费”，E列显示“误餐费” D列选择“快递费”，E列显示“快递费” D列选择“通讯费”，E列显示“通讯费” D列选择“其它费用”，E列显示“其它费用” D列设置list 首先设置可以选择值的list，步骤如下： 选中D2单元格，在主菜单栏点击“数据(data)”选项 在子工具分类栏中找到“数据工具(Data Toos)” 然后找到“数据验证(data validation)”，点击进入“数据验证”对话框 默认是“设置(settings)\"选项，在\"Allow\"选项中选择list，并勾上后面两项，“数据”选项是默认的 在“源(Source)\"中输入数据，地铁费及公交费这些，要用英文字符的逗号隔开 点击确认，可以看到D2单元格右边有选择项，任意选择即可，下拉应用到同列其它单元格即可 E列设置条件 在E列设置对应的条件，根据同行D列的值自动填入相应的值，就用到if函数，简略的来解释下用法： =IF(OR(ISNUMBER(FIND({\"长途车\";\"出租车\"},D2))),\"差旅费\",\"其它费用\") 说明如下： 第一层FIND就是在D2中查找大括号里面的值，长途车和出租车 第二次ISNUMBER就是个值得判断，判断是否是数字，返回的是false 然后是用OR，就是满足其中一个条件即可，OR和ISNUMBER都是给IF作bool判断用的 最后就是IF，前面都是bool值判断，\"差旅费\"是判断为True时输出的值，\"其它费用\"是判断false时输出的值   然后加入其它条件进行嵌套，那么E2中输入的完整内容如下（不要换行，这里是为了查看方便换行显示的，其它列同类单元格下拉即可）： =IF(OR(ISNUMBER(FIND({\"长途车\";\"出租车\";\"火车票\";\"住宿费\";\"飞机票\";\"地铁票\";\"公交票\";\"差旅补贴\";\"火车票\"},D2))),\"差旅费\", IF(OR(ISNUMBER(FIND(\"办公及交通费\",D2))),\"市内交通费\", IF(OR(ISNUMBER(FIND(\"误餐费\",D2))),\"误餐费\", IF(OR(ISNUMBER(FIND(\"通讯费\",D2))),\"通讯费\", IF(OR(ISNUMBER(FIND(\"快递费\",D2))),\"快递费\",\"其它费用\"))))) SUMIF函数   上面的示例中还有一个统计表。E列中有差旅费、快递费和其它费用等，比较分散不是连在一起，并且有很多，F列是对应费用的金额，如何根据E列中的数据的类型，去对应统计F列中的数据和，需要用到SUMIF函数来解决。SUMIF函数的标准格式： SUMIF(range,criteria,[sum_range]) 示例图统计表中的差旅费后面的单元格输入的数据如下所示（其它列同类单元格下拉即可）： =SUMIF(E2:E9, E11, F2:F9) 说明如下： E2:E9表示去判断的范围 E11就是去匹配的值，E11是“差旅费”，也就是去E2:E9中匹配“差旅费” F2:F9就是值统计范围，统计的值是根据前面的判断来的 VLOOKUP函数   VLOOKUP主要用途是进行数据匹配，举个简单例子，表格1中A对应的B，表格2中B对应的C，两个表格中很多个这种对应关系，并且序号都是杂乱无章，如何将A准确对应上C，用VLOOKUP就很方便。VLOOKUP标准格式如下： VLOOKUP(lookup_vaule,table_array,col_index_num,[range_lookup]) 例如下面示例中，查找匹配的内容： =VLOOKUP(U2,Sheet1!U:V,2,0) 说明： U2是需要查找单元格的值，此示例中是在Sheet2中 Sheet1!U:V表示查找匹配的范围是在Sheet1中的U列到V列 2就是col_index_num,列索引号，就是在U列到V列中，你需要的值的在匹配范围相对位置是在哪一列，从1开始编号，2就是第二列，U列开始，第二列就是V列的值 最后[range_lookup]可以输入布尔值： TRUE 表示近似匹配，也可以输入0 FALSE表示精准匹配，也可以输入1 设置好一个单元格后，下拉格式即可用于同列其它单元格 "},"11-常用操作系统/01-Windows/05-Windows-常用软件操作.html":{"url":"11-常用操作系统/01-Windows/05-Windows-常用软件操作.html","title":"Windows-常用软件操作","keywords":"","body":"Windows-常用软件操作 Notepad++ Notepad++文件比对 安装Compare插件： 打开Notepad++软件 主菜单选择选项插件，然后点击插件管理 在插件管理界面列表中找到并选中Compare 然后点击右上角安装按钮进行安装，安装会重启Notepad++ 使用Compare插件： 打开两份需要比对的文档，分别放置在左右不同的视图中 主菜单选择选项插件，然后点击Compare 在Compare展开列表中点击Compare，比对结果显现 或直接Ctrl+Alt+C 待补充 "},"11-常用操作系统/01-Windows/11-Photoshop-基础操作.html":{"url":"11-常用操作系统/01-Windows/11-Photoshop-基础操作.html","title":"Photoshop-基础操作","keywords":"","body":"Photoshop-基础操作   日常工作中或生活中偶尔用到Photoshop，以前还抠过白云这种边界很模糊的图像，在目标端融合很好，没做记录现在已经忘了怎么搞，所以做记录是好习惯，目前用到的一些简单操作记录下来。 抠图 抠图方式有很多。 钢笔工具 常用的抠图工具，示例步骤： 将图像尽量调大，但是不要太模糊了 在左侧钢笔工具中选择“钢笔工具” 使用钢笔工具沿着需要抠取图像区域外缘创建锚点，直到形成一个闭环 右键选择“建立选区”，弹出对话框： 羽化半径根据需求选择 消除锯齿可以默认 点击确定 Ctrl+Shift+i反向选择，然后按Backspace删除，就只有抠的图像了 可以对图像进行调整，点击主菜单“选择”选项，选择“修改M”可以对抠取图像进行调整：边界、羽化等 使用拖拽工具拖到要放置的目标图片 右侧图层选项中选中之前抠取拖拽过来的图层，Crtl+t可以对图层大小进行调整 魔棒工具 做个电子签名直接贴到文档或者图片中还是很方便的，使用魔棒工具制作比较简单： 在一张白纸上写下签名，用手机拍照图片传到电脑用PS打开 将图片放大裁剪一下 在任务栏右键点击“新建文档” 大小默认也行，根据签名裁剪后大小最好 背景内容选项默认是白色，改成透明 使用拖拽工具将签名图片拖到新建的透明文档中 在左侧工具栏中的魔棒工具中选择“魔棒工具” 使用“魔棒工具”点击签名，多个字分开就多点几次，直到选中了所有 直接点击Backspace删除，就可以删除多余的部分 组合键Crtl+t取消选择 如果太大了可以裁剪下，保存为PNG格式图像即可   有些签名例如带“口”或者带“田”等字的，里面的背景第一次使用“魔棒工具”后可能没删掉，Crtl+t调整大点，用“魔棒工具”点击需要删掉区域，就会自动选中，按Backspace删除即可，当然也可以使用其它抠图方法。 铅笔工具 画直线   可以使用铅笔工具来画线，手动拖动鼠标经常不直，使用铅笔工具，按住shift键，点一下，再点一下远点，就自动连成一条线了。 马赛克 添加马赛克 使用PhotoShop添加马赛克步骤如下： 左边菜单栏选择“矩形选框工具”，框住需要打马赛克的区域 上边菜单栏依次选择：滤镜>像素化>马赛克 根据需求设置点击确认即可 待补充 "},"11-常用操作系统/02-Ubuntu/":{"url":"11-常用操作系统/02-Ubuntu/","title":"Ubuntu","keywords":"","body":"Ubuntu 简介   Ubuntu is the modern, open source operating system on Linux for the enterprise server, desktop, cloud, and IoT. 内容 Ubuntu-系统安装. "},"11-常用操作系统/02-Ubuntu/01-Ubuntu-系统安装.html":{"url":"11-常用操作系统/02-Ubuntu/01-Ubuntu-系统安装.html","title":"Ubuntu-系统安装","keywords":"","body":"Ubuntu-系统安装 记录常用安装方法。 Windows下Ubuntu应用   在Microsoft Store中有Ubuntu应用程序，免费下载使用，下载后直接启动应用即可使用，使用起来比较方便，也不用虚拟机去安装那么麻烦。 安装步骤 首先打开Windows虚拟机平台： 控制面板-程序和功能 启动或关闭Windows功能 选中适用于Linux的Windows子系统和虚拟机平台后确定 等待功能开启并重启系统 如果不开启，启动Ubuntu会报错，如下所示： Installing, this may take a few minutes... WslRegisterDistribution failed with error: 0x8007019e The Windows Subsystem for Linux optional component is not enabled. Please enable it and try again. See https://aka.ms/wslinstall for details. Press any key to continue... 下载安装步骤： Microsoft Store搜索Ubuntu 根据需求选择安装的版本，获取后下载安装应用 运行应用显示正在安装，等待若干分钟即可 提升新建一个用户，并且和Windows不一样的，新建即可 Windows下Ubuntu目录 例如用户huang的根目录在Windows下路径： C:\\Users\\admin\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\\LocalState\\rootfs\\home\\huang 制作U盘引导安装Ubuntu "},"12-虚拟化平台/":{"url":"12-虚拟化平台/","title":"虚拟化平台","keywords":"","body":"虚拟化平台 内容 VMware Proxmox_VE QEMU KVM "},"12-虚拟化平台/01-VMware/":{"url":"12-虚拟化平台/01-VMware/","title":"VMware","keywords":"","body":"VMware 简介 VMware是全球桌面到数据中心虚拟化领先平台。VMware官网：https://www.vmware.com/cn.html 内容 VMware-基础操作 "},"12-虚拟化平台/01-VMware/01-VMware-基础操作.html":{"url":"12-虚拟化平台/01-VMware/01-VMware-基础操作.html","title":"VMware-基础操作","keywords":"","body":"VMware-基础操作 个人版用的比较多，企业版用的比较少，一些简单操作记录下来避免忘记。 存储迁移   VMware平台上一台物理机上有多个虚拟机，一块分配过来的存储盘也经常给多个虚拟机使用。在替换后端存储的时候，可以通过VMware上的虚拟机迁移功能去迁移虚拟机的存储盘（只改变存储盘，不改变虚拟机所在的物理机），优点就是在线迁移，单个虚拟机也很快；缺点就是如果比较多虚拟机太慢了，并发量也需要控制，避免I/O过高产生影响。 具体迁移步骤如下： 将新存储跟集群物理机划分好zone，将新磁盘分配给集群， 登录VMware的vSphere client，选择对应的集群 右键，在Storage选择中选择Rescan Storage 在弹出的“重新扫描存储”对话框中，选择“扫描新的存储设备”，不选中“扫描新的VMFS卷” 弹出对话框“新建数据存储”: 类型：选择VMFS 名称和设备选择：自定义数据存储名称（例如叫VOLnew）；选择集群中任意一个主机，然后可以看到扫描到的磁盘，选择需要添加的磁盘 VMFS版本：有些版本会有此步骤，选择对应的即可 分区配置：默认使用过所有可用分区 即将完成：检查配置，没问题就点击FINISH 在左侧集群菜单里面可用看到新分配的存储盘：VOLnew 点击选择就旧存储盘，例如叫：VOLold，查看存储盘下所有Virtual Machines 选中需要迁移得虚拟机，右键，选择Migrate(会提示兼容性）： 选择迁移类型：仅更改存储（根据需求选择） 选择存储：磁盘格式选择精简置配；虚拟机存储策略选择保留现有得虚拟机存储策略；勾上禁用此虚拟机得存储DRS;最后选中目标磁盘VOLnew 即将完成：检查配置，没问题就点击FINISH 然后可以看到精度条，迁移完成后进行检查 注意事项： 可以一次选择多个虚拟机进行迁移，但是批量迁移的虚拟机都必须处于同一电源状态 批量迁移注意I/O量，一次性过多可能会影响到其它虚拟机正常运行，存储端的性能同样需要关注 有些虚拟机可能迁移不了，重启下物理机可能就解决了 有些集群开启了自动均衡功能，就是他会自动迁移虚拟机到比较闲的磁盘，可以更改此策略或者对于不打算用的旧盘标记成维护模式 确认不要的盘建议核实清楚没有了虚拟机在上面后再删除，最好先标记成维护模式（很多卷名称可能差不多，标记成维护模式的图标会发生改变，区别正在使用磁盘比较明显），过后再删除 待补充 "},"12-虚拟化平台/01-VMware/02-VMware-常见问题.html":{"url":"12-虚拟化平台/01-VMware/02-VMware-常见问题.html","title":"VMware-常见问题","keywords":"","body":"VMware-常见问题 VMware Workstation问题 兼容性问题 Windows10系统，报错描述： VMware Workstation与Device/Credential Guard不兼容。在禁用Device/Credential Guard后，可以运行VMware Workstation 我曾经Windows10里面安装了Ubuntu的子系统使用过，处理方法： 控制面板-->程序和功能 启用或关闭Windows功能 关闭如下功能： 适用于Linux的Windows子系统 虚拟机平台 Hyper-V（不一定有） 重启电脑 官方参考链接：VMware Workstation and Device/Credential Guard are not compatible\" error in VMware Workstation on Windows 10 host (2146361) 网络问题 虚拟机通过NAT模式连接不了网络，检查： 在Windows计算机管理 服务下面查看VMware相关服务是否开启 检查Workstation中VMnet8的配置是否正确： VMware Workstation主菜单编辑-->虚拟网络编辑器 VMnet8是否有加入某个网桥，如果有，会有影响 VMnet信息如下： 桥接模式（将虚拟机直接连接到外部网络） NAT模式（与虚拟机共享主机的IP地址） 仅主机模式（再专用网络内连接虚拟机） 待补充 "},"12-虚拟化平台/02-Proxmox_VE/":{"url":"12-虚拟化平台/02-Proxmox_VE/","title":"Proxmox_VE","keywords":"","body":""},"12-虚拟化平台/03-QEMU/":{"url":"12-虚拟化平台/03-QEMU/","title":"QEMU","keywords":"","body":"简介 QEMU是一种通用的开源计算机仿真器和虚拟器。 QEMU官网：https://www.qemu.org/ 内容 QEMU-虚拟AIX系统 "},"12-虚拟化平台/03-QEMU/01-QEMU-虚拟AIX系统.html":{"url":"12-虚拟化平台/03-QEMU/01-QEMU-虚拟AIX系统.html","title":"QEMU-虚拟AIX系统","keywords":"","body":"QEMU-虚拟AIX系统 AIX系统运行在IBM Power小型机上，由于底层架构上的区别，很少有平台可以去虚拟。QEMU很强大，可以模拟Power环境虚拟AIX系统，当然也有限制，不过用来学习AIX系统还是很方便的，有兴趣的可以联系我进行学习交流。 各平台简介 之前跟着大佬学习了Linux下用QEMU虚拟AIX，Linux下安装步骤：安装VMware、安装Linux、安装QEMU、最后虚拟AIX。安装特麻烦，个人电脑一般是Windows系统，对机器性能和使用上都很不方便。 后来尝试在Windows下用QEMU虚拟AIX，感觉学习起来很方便。但是AIX安装也是比较麻烦，很耗时间（顺利的话也要好几个小时），各种问题。所以这里分享一个直接用已安装配置好的虚拟磁盘拉起来的方法，好比VMware的.ova文件，直接恢复虚拟机。 准备文件 搭建系统和QEMU版本应该区别不大，我使用版本如下： 机器及系统版本：ThinkPad X250 Windows 10 QUME版本：QEMU 4.1.0 tap-windows版本：9.21.1 HAXM版本：haxm-windows_v7_5_4 AIX系统版本：AIX7.2.3.1 安装包： qemu-w64-setup-20200201.exe:官网下载 tap-windows-9.21.1.exe：网上找 haxm-windows_v7_5_4.zip：网上找 AIX72.img：已安装配置好的QEMU虚拟机磁盘镜像 安装配置 安装软件 步骤如下 安装HAXM，全称Hardware Accelerated Execution Manager，intel的硬件加速执行管理器。 安装QUEMU 安装tap-windows：用来搭建网桥让AIX访问外网 将AIX72.img放置到QEMU安装文件夹的根目录下 启动AIX 管理员运行Windows的CMD，cd到QEMU的安装目录，运行如下命令启动AIX: qemu-system-ppc64.exe -cpu POWER7 -machine pseries -m 2048 -serial mon:stdio -drive file=AIX72.img,if=none,id=drive-virtio-disk0 -device virtio-scsi-pci,id=scsi0 -device scsi-hd,drive=drive-virtio-disk0 --net nic -net tap,ifname=tap0 没几分钟就启动了，很快： AIX Version 7 Copyright IBM Corporation, 1982, 2018. Console login: The '/usr/lpp/diagnostics/bin/diagd' command is not supported on this system. diag命令主要是硬件诊断，所以虚拟AIX不支持这个命令。 网络配置 在cmd下敲命令很不方便，smit命令完全乱码，并且没外网学习也很不方便，所以用tap-windows搭一个网桥。TAP网卡名字和注意和ifname一致，示例如下： AIX系统配置IP此处不作详述。 系统演示 网络配通后可以用xshell等终端软件进入，操作演示如下： # lspv hdisk0 00000000f9d61667 rootvg active hdisk1 none None # lscfg -vpl hdisk0 hdisk0 qemu_virtio-scsi-pci:0000:00:02.0-LW_0 MPIO Other Virtio SCSI Disk Dri ve Manufacturer................QEMU Machine Type and Model......QEMU HARDDISK # prtconf System Model: IBM pSeries (emulated by qemu) Machine Serial Number: Not Available Processor Type: PowerPC_POWER7 Processor Implementation Mode: POWER 7 Processor Version: PV_7_Compat Number Of Processors: 1 Processor Clock Speed: 1000 MHz CPU Type: 64-bit Kernel Type: 64-bit LPAR Info: 0 aix_on_kvm Memory Size: 2048 MB Good Memory Size: 2048 MB Platform Firmware level: Not Available 可以看到处理器只有1000MHz，所以用来学习操作系统就行了，想跑啥应用测试还是算了。 连接了外网，就可以配置YUM，安装Python，学习还是很方便的。 IBM 官方一些AIX 软件下载地址：AIX Toolbox for Linux Applications "},"12-虚拟化平台/04-KVM/":{"url":"12-虚拟化平台/04-KVM/","title":"KVM","keywords":"","body":"简介 全称是Kernel-based Virtual Machine，是Linux下x86硬件平台上的全功能虚拟化解决方案。 KVM官方主页：http://www.linux-kvm.org/page/Main_Page 内容 KVM-RHEL安装部署 KVM-常用操作 "},"12-虚拟化平台/04-KVM/01-KVM-RHEL安装部署.html":{"url":"12-虚拟化平台/04-KVM/01-KVM-RHEL安装部署.html","title":"KVM-RHEL安装部署","keywords":"","body":"KVM-RHEL8安装部署 参考文档：Virtualization Deployment and Administration Guide 系统要求 我使用系统是Red Hat Enterprise Linux 8.0，笔记本通过VMware虚拟的。 主机系统要求 要求如下： 6 GB可用磁盘空间 2 GB RAMKVM虚拟机监控程序要求 CPU需要有虚拟功能并开启了，VMware开启步骤： 停机状态选中虚拟机，进入设置选项 选中处理器，在虚拟化选项中勾选：虚拟化Intel VT-x/EPT或AMD-V/RVI(V) 验证方法： [root@redhat8 ~]# grep -E 'svm|vmx' /proc/cpuinfo flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 invpcid rtm rdseed adx smap xsaveopt arat flush_l1d arch_capabilitiesflags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq vmx ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp tpr_shadow vnmi ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 invpcid rtm rdseed adx smap xsaveopt arat flush_l1d arch_capabilities 附加检查，验证模块是否已加载到内核中： [root@redhat8 ~]# lsmod | grep kvm kvm_intel 245760 0 kvm 745472 1 kvm_intel irqbypass 16384 1 kvm KVM GUEST虚拟机兼容性 以下URL解释了Red Hat Enterprise Linux的处理器和内存量限制： 对于主机系统：https://access.redhat.com/articles/rhel-limits 对于KVM虚拟机管理程序：https://access.redhat.com/articles/rhel-kvm-limits 支持GUEST虚拟机CPU型号 在cpu_map.xml文件中 包含受支持的CPU型号和功能的完整列表: # cat /usr/share/libvirt/cpu_map.xml 安装虚拟化软件包 在RHEL安装过程中安装虚拟化软件包 跳过，系统已经安装了，如果没安装RHEL，参考官方文档进行。 在现有RHEL上安装虚拟化软件包 安装虚拟化软件包 在RHEL上使用虚拟化，至少需要安装以下软件包： qemu-kvm：此软件包提供了用户级KVM仿真器，并促进了主机与guest虚拟机之间的通信 qemu-img：该软件包为来宾虚拟机提供磁盘管理。qemu-img包安装为的依赖QEMU的KVM包 libvirt：此软件包提供用于与虚拟机管理程序和主机系统进行交互的服务器和主机端库，以及libvirtd用于处理库调用，管理虚拟机和控制虚拟机管理程序的守护程序 之前已经配置好了本地YUM源，挂载虚拟光驱即可： [root@redhat8 /]# mount /dev/cdrom /mnt/cdrom mount: /mnt/cdrom: WARNING: device write-protected, mounted read-only. 安装： [root@redhat8 /]# yum install qemu-kvm libvirt ... Package qemu-kvm-15:2.12.0-63.module+el8+2833+c7d6d092.x86_64 is already installed. ... Installed: libvirt-4.5.0-23.module+el8+2800+2d311f65.x86_64 autogen-libopts-5.18.12-7.el8.x86_64 gnutls-dane-3.6.5-2.el8.x86_64 gnutls-utils-3.6.5-2.el8.x86_64 libvirt-bash-completion-4.5.0-23.module+el8+2800+2d311f65.x86_64 libvirt-client-4.5.0-23.module+el8+2800+2d311f65.x86_64 libvirt-daemon-config-nwfilter-4.5.0-23.module+el8+2800+2d311f65.x86_64 Complete! 附加的虚拟化管理程序包，在使用虚拟化时推荐使用这些软件包： virt-install：该软件包提供了virt-install用于从命令行创建虚拟机的命令 libvirt-python：该软件包包含一个模块，该模块允许以Python编程语言编写的应用程序使用libvirt API提供的接口 virt-manager：该软件包提供了virt-manager工具，也称为Virtual Machine Manager。这是用于管理虚拟机的图形工具。它使用libvirt-client库作为管理API libvirt-client：此软件包提供用于访问libvirt服务器的客户端API和库。所述libvirt的客户端包包括virsh命令行工具来管理和从命令行或特殊的虚拟化壳控制虚拟机和管理程序 安装： [root@redhat8 /]# yum install virt-install ... Installed: virt-install-2.0.0-5.el8.noarch python3-libvirt-4.5.0-1.module+el8+2529+a9686a4d.x86_64 virt-manager-common-2.0.0-5.el8.noarch Complete! [root@redhat8 /]# yum install libvirt-python No match for argument: libvirt-python Error: Unable to find a match [root@redhat8 /]# yum install virt-manager ... Installed: virt-manager-2.0.0-5.el8.noarch Complete! [root@redhat8 /]# yum install libvirt-client Package libvirt-client-4.5.0-23.module+el8+2800+2d311f65.x86_64 is already installed. libvirt-python没有找到，查找一下应该是这个： [root@redhat8 /]# yum search libvirt python3-libvirt.x86_64 : The libvirt virtualization API python3 binding python3-libvirt.x86_64 : The libvirt virtualization API python3 binding [root@redhat8 /]# yum install python3-libvirt ... Package python3-libvirt-4.5.0-1.module+el8+2529+a9686a4d.x86_64 is already installed. Dependencies resolved. Nothing to do. Complete! 安装虚拟化软件包组   虚拟化软件包也可以从软件包组中安装。各软件包组包含内容参考官方文档。命令：yum groupinstall package_group示例如下： # yum groupinstall \"Virtualization Tools\" --optional 选项--optional选将可选软件包安装在软件包组中。 创建虚拟机   在安装虚拟化软件包之后，可以使用virt-manager界面创建虚拟机并安装guest操作系统。或者通过参数列表或脚本使用virt-install命令行实用程序。 Guest虚拟机部署注意事项 省略，详细参考官方说明。 通过VIRT-INSTALL创建虚拟机   使用virt-install命令从命令行创建虚拟机并在这些虚拟机上安装操作系统。virt-install可以交互使用或作为脚本的一部分使用，以自动创建虚拟机。如果使用交互式图形安装，则必须先安装virt-viewer，然后再运行virt-install。此外，可以virt-install与kickstart文件一起使用来启动虚拟机操作系统的无人值守安装。 virt-install命令行选项 虚拟客户机安装的主要必需选项： --name：虚拟机的名称 --memory：以MiB为单位分配给Guest的内存（RAM） Guest存储 使用以下选项之一： --disk：虚拟机的存储配置详细信息。如果使用--disk none，则虚拟机将没有磁盘空间 --filesystem：guest虚拟机的文件系统路径 安装方式 使用以下安装方法之一： --location：安装介质的位置 --cdrom：用作虚拟CD-ROM设备的文件或设备。可以是ISO映像的路径，也可以是从中获取或访问最小引导ISO映像的URL。但不能是物理主机CD-ROM或DVD-ROM设备 --pxe：使用PXE引导协议加载初始ramdisk和内核，以启动虚拟机安装过程 --import：跳过操作系统安装过程，并围绕现有磁盘映像构建虚拟机。用于引导的设备是由disk或filesystem选项指定的第一个设备 --boot：安装后VM的启动配置。此选项允许指定启动设备顺序，使用可选的内核参数永久启动内核和initrd并启用BIOS引导菜单 查看帮助 查看选项的完整列表： [root@redhat8 /]# virt-install --help 要查看选项属性的完整列表： [root@redhat8 /]# virt-install --option=? usage: virt-install --name NAME --memory MB STORAGE INSTALL [options] virt-install: error: unrecognized arguments: --option=? 在运行之前virt-install，可能还需要使用qemu-img来配置存储选项。参考链接：Using qemu-img 从ISO映像安装虚拟机 从ISO映像安装虚拟机示例： # virt-install \\ --name guest1-rhel7 \\ --memory 2048 \\ --vcpus 2 \\ --disk size=8 \\ --cdrom /path/to/rhel7.iso \\ --os-variant rhel7 导入虚拟机image 从虚拟磁盘映像导入虚拟机示例： # virt-install \\ --name guest1-rhel7 \\ --memory 2048 \\ --vcpus 2 \\ --disk /path/to/imported/disk.qcow \\ --import \\ --os-variant rhel7 选项--import从该选项指定的虚拟磁盘image导入虚拟机--disk /path/to/imported/disk.qcow。 从网络安装虚拟机 从网络位置安装虚拟机示例： # virt-install \\ --name guest1-rhel7 \\ --memory 2048 \\ --vcpus 2 \\ --disk size=8 \\ --location http://example.com/path/to/os \\ --os-variant rhel7 使用PXE安装虚拟机 使用PXE引导协议安装虚拟机时，必须指定用于指定桥接网络的--network选项和--pxe选项： # virt-install \\ --name guest1-rhel7 \\ --memory 2048 \\ --vcpus 2 \\ --disk size=8 \\ --network=bridge:br0 \\ --pxe \\ --os-variant rhel7 使用Kickstart安装虚拟机 使用kickstart文件安装虚拟机示例： # virt-install \\ --name guest1-rhel7 \\ --memory 2048 \\ --vcpus 2 \\ --disk size=8 \\ --location http://example.com/path/to/os \\ --os-variant rhel7 \\ --initrd-inject /path/to/ks.cfg \\ --extra-args=\"ks=file:/ks.cfg console=tty0 console=ttyS0,115200n8\" initrd-inject和extra-args选项指定使用Kickstarter文件安装虚拟机。 在Guest创建期间配置虚拟机网络 创建Guest虚拟机时，可以为虚拟机指定和配置网络。 带有NAT的默认网络 默认网络使用libvirtd的网络地址转换（NAT）虚拟网络交换机， 在使用带有NAT的默认网络创建来宾虚拟机之前，请确保已安装libvirt-daemon-config-network软件包 要为来宾虚拟机配置NAT网络，在virt-install中使用选项：--network default 如果未network指定任何选项，则为来宾虚拟机配置具有NAT的默认网络 官方更多参考：Network Address Translation (NAT) with libvirt 带DHCP的桥接网络 当配置为桥接网络时，guest虚拟机将使用外部DHCP服务器 如果主机具有静态网络配置，并且guest需要与局域网（LAN）的完全入站和出站连接，则应使用此选项 如果将使用guest虚拟机执行实时迁移，则应使用它 要为guest宾虚拟机使用DHCP配置桥接网络，使用选项：--network br0 在运行之前，必须单独创建网桥virt-install。 有关创建网桥的详细信息:Configuring Bridged Networking on a Red Hat Enterprise Linux 7 Host 具有静态IP地址的桥接网络 桥接网络也可以用于将访客配置为使用静态IP地址 要为guest虚拟机配置具有静态IP地址的桥接网络，请使用以下选项：--network br0 \\ --extra-args \"ip=192.168.1.2::192.168.1.1:255.255.255.0:test.example.com:eth0:none\" 有关网络引导选项的更多信息：Red Hat Enterprise Linux 7 Installation Guide. 要配置没有网络接口的guest虚拟机，请使用以下选项：--network=none 安装示例 机器性能有限，磁盘空间有限，安装个两百多兆的debian系统，导入虚拟机image方式： 从虚拟磁盘映像导入虚拟机示例： # virt-install \\ --name debian \\ --memory 1024 \\ --vcpus 1 \\ --disk /images/debian_wheezy_amd64_standard.qcow2 \\ --import \\ 运行： [root@redhat8 images]# virt-install --name debian --memory 1024 --vcpus 1 --disk /images/d ebian_wheezy_amd64_standard.qcow2 --importWARNING KVM acceleration not available, using 'qemu' WARNING No operating system detected, VM performance may suffer. Specify an OS with --os- variant for optimal results.WARNING Unable to connect to graphical console: virt-viewer not installed. Please install the 'virt-viewer' package.WARNING No console to launch for the guest, defaulting to --wait -1 Starting install... Domain installation still in progress. Waiting for installation to complete. shell卡在这里了，但是通过virt-manager打开图形界面可用看到是运行状态。 或者通过命令行查看是运行状态： [root@redhat8 ~]# virsh Welcome to virsh, the virtualization interactive terminal. Type: 'help' for help with commands 'quit' to quit virsh # list Id Name State ---------------------------------------------------- 1 debian running 卡住的shell Ctrl+C掉，提示： Domain install interrupted. Installation aborted at user request 尝试进入虚拟机是可以进去的： [root@redhat8 ~]# virsh console 1 Connected to domain debian Escape character is ^] Debian GNU/Linux 7 debian-amd64 ttyS0 debian-amd64 login: root Password: Linux debian-amd64 3.2.0-4-amd64 #1 SMP Debian 3.2.51-1 x86_64 The programs included with the Debian GNU/Linux system are free software; the exact distribution terms for each program are described in the individual files in /usr/share/doc/*/copyright. Debian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent permitted by applicable law. root@debian-amd64:~# hostname debian-amd64 卡住原因可能是我之前没有开启CPU的虚拟化功能，KVM模块没有加载进去。 使用VIRT-MANAGER创建虚拟机 New Virtual Machine向导创建虚拟机过程分为五个步骤： 选择系统管理程序和安装类型 查找和配置安装介质 配置内存和CPU选项 配置虚拟机的存储 配置虚拟机名称，网络，体系结构和其他硬件设置 安装RHEL7   RHEL7至少需要1GB的存储空间。但是，对于RHEL7安装和本指南中的过程，Red Hat建议至少有5GB的存储空间。我使用版本是RHEL-server-7.8，物理机磁盘空间严重不足，不想把ISO拷贝到虚拟机中，打算直接从虚拟光驱安装试试，选中光驱后，提示找不到operating system，官网有说使用主机CD-ROM或DVD-ROM设备是不行的，放弃了。 安装几种途径和命令行一样，通过镜像步骤如下： 首先把RHEL7镜像拷贝到RHEL8中，默认的文件夹：/var/lib/libvirt/images 打开Virtual Machine Manager： 通过超级用户virt-manager执行命令 图形打开应用程序→系统工具→虚拟机管理器来打开virt-manager 如果用命令的话，并且使用的shell终端没有图形界面，应在本地执行命令开启，我使用Xmanager，有图形终端 点击新建虚拟机图标，或者依次选择：File--New Virtual Machine 弹出New VM对话框，选择Local install media(ISO image or CDROM)，然后下一步 Choose ISO输入框边点击Browse，选择RHEL-7.8_Server.x86_64.iso，回到New VM对话框 手动或者自动选择操作系统（我的自动显示None detected，手动也没用RHEL7.8，选了个Generic default)，然后下一步 设置内存和CPU，然后下一步 设置磁盘大小（我设置6G），然后下一步 设置虚拟机名字和网络，网络默认NAT，然后下一步 弹出新的图形界面，选择安装或者测试 开始安装后等待到选择语言对话框，选择语言后下一步 进入自定义设置界面，例如磁盘和软件安装设置，我选择了minmal install 点击begin install开始安装，中途可以设置设root密码或者用户 Reboot选项出来后重启系统，安装完成 查看： [root@redhat8 ~]# virsh list Id Name State ---------------------------------------------------- 2 RHEL78 running virt-install和virt-manager安装选项的比较 参考官方说明：virt-install和virt-manager安装选项的比较 "},"12-虚拟化平台/04-KVM/02-KVM-常用操作.html":{"url":"12-虚拟化平台/04-KVM/02-KVM-常用操作.html","title":"KVM-常用操作","keywords":"","body":"KVM-常用操作 磁盘管理 创建磁盘 在/var/lib/images/下创建一个名为mycentos.img的10GB大小，raw格式，空白虚拟机磁盘镜像文件： qemu-img create -f raw /var/lib/images/mycentos.img 10G 使用示例： [root@redhat8 ~]# qemu-img create -f raw /var/lib/images/mycentos.img 0.1G Formatting '/var/lib/images/mycentos.img', fmt=raw size=107374182 [root@redhat8 ~]# ls -l /var/lib/images total 0 -rw-r--r--. 1 root root 107374592 Apr 8 04:23 mycentos.img 克隆虚拟机 准备工作   为了使创建的克隆正常工作，通常须在克隆之前删除要克隆的虚拟机所独有的信息和配置： 虚拟机平台配置信息，例如网络接口卡（NIC）的数量及其MAC地址等 虚拟机系统配置，例如SSH密钥等 应用程序级别信息和配置，例如激活码和注册信息等 删除网络配置 删除所有udev规则（如步删除则第一个NIC的名称可能是eth1而不是eth0）： rm -f /etc/udev/rules.d/70-persistent-net.rules 通过编辑/etc/sysconfig/network-scripts/ifcfg-eth[x]从ifcfg脚本中删除唯一的网络详细信息。 删除HWADDR和静态线（如果HWADDR与新guest的MAC地址不匹配，则将忽略ifcfg）： DEVICE = eth [x] BOOTPROTO =无 ONBOOT =是 # NETWORK = 10.0.1.0 确保保留不包含HWADDR或任何唯一信息的DHCP配置: DEVICE = eth [x] BOOTPROTO = DHCP ONBOOT =是 确保文件包含以下几行： DEVICE = eth [x] ONBOOT =是 如果存在以下文件，请确保它们包含相同的内容： /etc/sysconfig/networking/devices/ifcfg-eth[x] /etc/sysconfig/networking/profiles/default/ifcfg-eth[x] 如果虚拟机使用了NetworkManager或任何特殊设置，确保从ifcfg脚本中删除了所有其他唯一信息。 删除注册详细信息 对于红帽网络（RHN）注册的虚拟机，请使用以下命令： # rm /etc/sysconfig/rhn/systemid 对于Red Hat Subscription Manager（RHSM）注册的虚拟机： 如果将不使用原始虚拟机，请使用以下命令： # subscription-manager unsubscribe --all # subscription-manager unregister # subscription-manager clean 如果将使用原始虚拟机，则仅运行以下命令： # subscription-manager clean 要在克隆后在虚拟机上重新激活RHSM注册。获取您的客户身份代码： # subscription-manager identity subscription-manager identity: 71rd64fx-6216-4409-bf3a-e4b7c7bd8ac9 使用获取的ID代码注册虚拟机： # subscription-manager register --consumerid=71rd64fx-6216-4409-bf3a-e4b7c7bd8ac9 sshd公钥/私钥 使用以下命令删除所有sshd公钥/私钥对： # rm -rf /etc/ssh/ssh_host_* 配置虚拟机在下次启动时运行配置向导 对于RHEL6和更低版本，使用以下命令在名为.unconfigured的根文件系统上创建一个空文件： # touch /.unconfigured 对于RHEL7，通过运行以下命令来启用首次引导和初始设置向导： # sed -ie 's/RUN_FIRSTBOOT=NO/RUN_FIRSTBOOT=YES/' /etc/sysconfig/firstboot # systemctl enable firstboot-graphical # systemctl enable initial-setup-graphical 说明：在首次启动克隆虚拟机时，建议更改主机名。 关于克隆虚拟机红帽官方文档：CHAPTER 4. CLONING VIRTUAL MACHINES 管理快照 快速创建并查看快照： [root@redhat8 ~]# virsh snapshot-create-as debian debian-snap Domain snapshot debian-snap created [root@redhat8 ~]# virsh snapshot-list debian Name Creation Time State ------------------------------------------------------------ debian-snap 2021-04-08 05:22:33 -0400 running 删除快照： [root@redhat8 ~]# virsh snapshot-delete debian debian-snap Domain snapshot debian-snap deleted 更多描述参考RHEL官方文档：20.39 MANAGING SNAPSHOTS 虚拟机备份 系统备份方式有克隆，快照，导出等等。 快速备份 完整快速备份步骤： 备份虚拟机对应的xml文件 备份虚拟机的磁盘镜像文件 备份虚拟机对应的网络定义xml文件 备份示例   示例快速备份方法，并且新旧两个虚拟机同时运行，修改了name，uuid删除 disk image文件路径进行了修改 5网卡的mac删除了： [root@redhat8 qemu]# cp debian.xml debian1.xml [root@redhat8 qemu]# ls debian1.xml debian.xml networks RHEL78.xml [root@redhat8 /]# cd images [root@redhat8 images]# ls debian_wheezy_amd64_standard.qcow2 [root@redhat8 images]# cp debian_wheezy_amd64_standard.qcow2 debian1_wheezy_amd64_standard .qcow2 [root@redhat8 qemu]# virsh define debian1.xml Domain debian1 defined from debian1.xml [root@redhat8 qemu]# virsh define debian1.xml Domain debian1 defined from debian1.xml 运行虚拟机： [root@redhat8 qemu]# virsh start debian1 Domain debian1 started [root@redhat8 qemu]# virsh list Id Name State ---------------------------------------------------- 3 RHEL78 running 4 debian running 5 debian1 running root@debian-amd64:~# blkid /dev/sda5: UUID=\"166ef3ed-f1f6-4be6-8368-d07589692992\" TYPE=\"swap\" /dev/sda1: UUID=\"8bf5feb2-6f3a-4842-a242-70aad1afeb98\" TYPE=\"ext4\"   新的虚拟机MAC地址和ip变了，但是hostname没变，如果是生产环境，同时运行可能会产生很多冲突，不推荐，只是作为备份演示。 待补充 "},"12-虚拟化平台/04-KVM/03-KVM-虚拟机自动安装.html":{"url":"12-虚拟化平台/04-KVM/03-KVM-虚拟机自动安装.html","title":"KVM-虚拟机自动安装","keywords":"","body":"KVM-虚拟机自动安装 之前有学习安装方式，这里继续学习记录自动安装的方法。 PXE方式自动安装 参考文档： 3.3. PREPARING INSTALLATION SOURCES Chapter 4.2 Automatic Installation PART I.AMD64,INTEL 64,AND ARM 64-INSTALLATION AND BOOTING CHAPTER 24. PREPARING FOR A NETWORK INSTALLATION 环境准备 安装vsftpd 宿主系统上安装vsftpd: [root@redhat8 tmp]# rpm -ivh vsftpd-3.0.3-32.el8.x86_64.rpm warning: vsftpd-3.0.3-32.el8.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 8483c65d: NOKEYVerifying... ################################# [100%] Preparing... ################################# [100%] Updating / installing... 1:vsftpd-3.0.3-32.el8 ################################# [100%] 如果yum源里面有： yum install -y vsftpd 启用vsftpd服务： [root@redhat8 tmp]# systemctl enable vsftpd Created symlink /etc/systemd/system/multi-user.target.wants/vsftpd.service → /usr/lib/sys temd/system/vsftpd.service. [root@redhat8 tmp]# systemctl start vsftpd 将RHEL7安装文件拷贝到系统中，或者挂载光驱，空间有限我使用光驱： [root@redhat8 /]# mount /dev/cdrom /mnt/cdrom mount: /mnt/cdrom: WARNING: device write-protected, mounted read-only. 将文件复制到FTP目录： [root@redhat8 rhel7]# cp -r /mnt/cdrom/ /var/ftp/ 或者直接将光盘挂载到ftp服务作为FTP安装源，更加节省空间： [root@redhat8 /]# mkdir -p /var/ftp/pub/rhel7 /var/ftp/pub/pxeboot /var/ftp/pub/ks [root@redhat8 /]# echo \"/dev/sr0 /var/ftp/pub/rhel7 iso9660 loop 0 0\" >> /etc/fstab [root@redhat8 /]# mount -a [root@redhat8 /]# cd /var/ftp/pub/rhel7 [root@redhat8 rhel7]# ls addons extra_files.json isolinux Packages RPM-GPG-KEY-redhat-release EFI GPL LiveOS repodata TRANS.TBL EULA images media.repo RPM-GPG-KEY-redhat-beta 准备PXE启动目录和文件 准备PXE启动目录和文件: [root@redhat8 tmp]# rpm2cpio /var/ftp/pub/rhel7/Packages/syslinux-4.05-15.el7.x86_64.rpm | cpio -dimv [root@redhat8 syslinux]# cd /tmp [root@redhat8 tmp]# cp ./usr/share/syslinux/vesamenu.c32 /var/ftp/pub/pxeboot/ [root@redhat8 tmp]# cp ./usr/share/syslinux/pxelinux.0 /var/ftp/pub/pxeboot/ [root@redhat8 tmp]# cp /var/ftp/pub/rhel7/images/pxeboot/* /var/ftp/pub/pxeboot/ [root@redhat8 tmp]# mkdir /var/ftp/pub/pxeboot/pxelinux.cfg 配置文件/var/lib/tftpboot/pxelinux/pxelinux.cfg/default，内容： default vesamenu.c32 timeout 600 display boot.msg label linux menu label ^Install RHEL 7.8 menu default kernel vmlinuz append initrd=initrd.img inst.ks=ftp://192.168.122.1/pub/ks/rhel7_minimal.cfg ip=192.168.122.110:::255.255.255.0:node1:eth0:off console=tty0 console=ttyS0,19200n8 配置libvirtd自带的TFTP服务作为PXE启动服务器 ，命令： [root@redhat8 tmp]# virsh net-edit default Network default XML configuration edited 内容如下： default 00e869b2-4147-40e3-ad93-38aa7ff5a914 启动配置但是报错了： [root@redhat8 tmp]# virsh net-destroy default Network default destroyed [root@redhat8 tmp]# virsh net-start default error: Failed to start network default error: internal error: Child process (VIR_BRIDGE_NAME=virbr0 /usr/sbin/dnsmasq --conf-file =/var/lib/libvirt/dnsmasq/default.conf --leasefile-ro --dhcp-script=/usr/libexec/libvirt_leaseshelper) unexpected exit status 3: dnsmasq: TFTP directory /var/ftp/pub/pxeboot/ inaccessible: Permission denied 提示权限不够，查了下解决方法： [root@redhat8 pxelinux.cfg]# setenforce 0 [root@redhat8 pxelinux.cfg]# virsh net-destroy default Network default destroyed [root@redhat8 pxelinux.cfg]# virsh net-start default Network default started 参考文档：dnsmasq TFTP directory /tftpd inaccessible: Permission denied kickstart自动安装文件 修改生成kickstart自动安装文件，从host中拷贝然后修改 [root@redhat8 ~]# cp /root/anaconda-ks.cfg /var/ftp/pub/ks/rhel7_minimal.cfg [root@redhat8 ks]# vi /var/ftp/pub/ks/rhel7_minimal.cfg 修改后文件如下： #version=RHEL8 ignoredisk --only-use=nvme0n1 autopart --type=lvm # Partition clearing information clearpart --none --initlabel # Use graphical install # graphical repo --name=\"AppStream\" --baseurl=file:///run/install/repo/AppStream # Use CDROM installation media # cdrom # Keyboard layouts keyboard --vckeymap=us --xlayouts='us' # System language lang en_US.UTF-8 # cmdline ignoredisk --only-use=vda # Network information network --bootproto=static --device=eth0 --ip=192.168.122.110 --netmask=255.255.255.0 --gateway=192.168.122.1.1 --ipv6=auto --activate network --hostname=node1 bootloader --append=\" crashkernel=auto\" --location=mbr --boot-drive=vda clearpart --all --initlabel --drives=vda part /boot --fstype=\"xfs\" --ondisk=vda --size=1024 part pv.614 --fstype=\"lvmpv\" --ondisk=vda --grow volgroup node1 --pesize=4096 pv.614 logvol / --fstype=\"xfs\" --size=4096 --grow --name=root --vgname=node1 # Root password rootpw --iscrypted $6$Q9tSQSFpjwq0eOZ7$SxPBLdnUyPHGbhLXfGEomqwfH5cRiImcPB6Y07Mu8PfAKjjMLMh mW2XhbHAEqMtQ./y0n5dGEPa3E.YqY/nVQ.# X Window System configuration information # xconfig --startxonboot # Run the Setup Agent on first boot firstboot --enable # System services services --enabled=\"chronyd\" # System timezone timezone America/New_York --isUtc user --name=huang --password=$6$TwYrj0gr3EMjRAlU$N3aIbs/Dq7cT4hGMavXQjgCY9w/QmhFXlnZDs0vXL M3YlHdyPBKjqpqyR6G86wu9APHoVvvf31ffPULETrXO7/ --iscrypted --gecos=\"huang\" %packages @^minimal kexec-tools curl wget net-tools ftp telnet %end %addon com_redhat_kdump --enable --reserve-mb='auto' %end %anaconda pwpolicy root --minlen=6 --minquality=1 --notstrict --nochanges --notempty pwpolicy user --minlen=6 --minquality=1 --notstrict --nochanges --emptyok pwpolicy luks --minlen=6 --minquality=1 --notstrict --nochanges --notempty %end url --url=\"ftp://192.168.122.1/pub/rhel7 firewall --disabled selinux --disabled eula --agreed reboot 创建虚拟机 创建新的xml文件: [root@redhat8 qemu]# pwd /etc/libvirt/qemu [root@redhat8 qemu]# vi rhel7.xml 内容如下： 1048576 1048576 1 node1 hvm destroy restart destroy /usr/libexec/qemu-kvm 创建磁盘： [root@redhat8 qemu]# qemu-img create -f qcow2 /var/lib/images/node1.qcow2 10G Formatting '/var/lib/images/node1.qcow2', fmt=qcow2 size=10737418240 cluster_size=65536 la zy_refcounts=off refcount_bits=16 执行定义： [root@redhat8 qemu]# virsh define node1.xml Domain node1 defined from node1.xml 启动安装 启动虚拟机，进入控制台观察安装进度： [root@redhat8 qemu]# virsh list Id Name State ---------------------------------------------------- 4 node1 running "},"13-X86_System/":{"url":"13-X86_System/","title":"X86_System","keywords":"","body":"X86_System 简介   X86架构（The X86 architecture）是微处理器执行的计算机语言指令集，指一个intel通用计算机系列的标准编号缩写，也标识一套通用的计算机指令集合。 内容 Lenovo X86 HuaWei_X86 "},"13-X86_System/01-Lenovo X86/":{"url":"13-X86_System/01-Lenovo X86/","title":"Lenovo X86","keywords":"","body":"Lenovo_X86 简介 联想数据中心产品官网：https://dcg.lenovo.com.cn/ 内容 SystemX-ASU使用 "},"13-X86_System/01-Lenovo X86/01-SystemX-ASU使用.html":{"url":"13-X86_System/01-Lenovo X86/01-SystemX-ASU使用.html","title":"SystemX-ASU使用","keywords":"","body":"SystemX-ASU使用 在System X系列服务器中是一个很强大很有用的工具，目前主要接触用来改序列号等操作。 ASU基本使用 下载及说明 IBM介绍和下载地址：https://www.ibm.com/support/pages/node/811842 Lenovo介绍和下载地址：https://support.lenovo.com/gb/en/solutions/lnvo-asu IBM官方使用说明：https://www.ibm.com/support/pages/node/823076 使用方法   根据自己客户端类型下载对应软件包，一般是Windows系统，使用客户端（个人笔记本或者其它终端设备）连接至X系列服务器的IMM管理端口，保证终端和服务器之间网络是连通的（如果是直连配置同一网段IP即可），在客户端打开CMD 窗口，进入ASU 所在目录，即可进行操作。 查看服务器基本信息 按照以上方法连接到服务器后，使用命令如下命令： D:\\ASU\\asu show --host 192.168.70.125 说明： 示例中是直接把ASU软件所在的目录ASU目录放在D盘根目录下 X系列服务器IMM口默认IP一般是192.168.70.125 能够连接上回车后会显示很多设备信息 更改服务器的序列号 在更换完主板后，通常需要进行更改，使用命令如下命令更改服务器的型号： D:\\ASU\\asu sed SYSTEM_PROD_DATA.SysInfoSerialNum 7835HNY --host 192.168.70.125 说明： 其实就是更改在asu show 中查看到的SYSTEM_PROD_DATA.SysInfoSerialNum属性的值 注意序列号是7位字母和数字的组合 修改该完成后通过asu show查看确认 更改服务器的型号 上面能正常查看服务器基本信息后，使用命令如下命令更改服务器的型号： D:\\ASU\\asu sed SYSTEM_PROD_DATA.SysInfoName 6241GAC--host 192.168.70.125 说明： 其实就是更改在asu show中查看到的SYSTEM_PROD_DATA.SysInfoName属性的值 6241GAC是服务器型号，对应就是X3950 X6 修改该完成后通过asu show查看确认 更改服务器的固定资产号 在更换完主板后，通常需要进行更改，使用命令如下命令更改服务器的型号： D:\\ASU\\asu sed SYSTEM_PROD_DATA.SysEncloseAssetTag tysv08110042 --host 192.168.70.125 说明： 其实就是更改在asu show中查看到的SYSTEM_PROD_DATA.SysEncloseAssetTag属性的值 注意AssetTag的格式，可以参照修改签asu show查看到的 修改该完成后通过asu show查看确认 "},"13-X86_System/02-HuaWei_X86/":{"url":"13-X86_System/02-HuaWei_X86/","title":"HuaWei_X86","keywords":"","body":"HuaWei_X86 简介 华为服务器官网：https://e.huawei.com/cn/solutions/hic 内容 HuaWei-系统安装 "},"13-X86_System/02-HuaWei_X86/01-HuaWei-系统安装.html":{"url":"13-X86_System/02-HuaWei_X86/01-HuaWei-系统安装.html","title":"HuaWei-系统安装","keywords":"","body":"HuaWei-系统安装 使用比较少，记录下避免忘记。 远程虚拟光驱安装 以RH2288H V2-8S服务器为例安装RHEL7.8，步骤如下： 登录到服务器iMana，用户root 左侧菜单点击“远程控制” 点击最下面“远程虚拟控制台（独占模式）” 虚拟控制台启动后（需要java），点击上部菜单栏中的光驱选项 选择镜像文件夹，浏览对应的iso安装包，此处采用定制auto安装包 启动or重启系统 启动时候按F11进入boot manager 在boot选项中选择HUAWEI DVD-ROM VM 1.1.0 两个选项，Select CD-ROM Boot Type：1 选择AutoInstall（根据需求选择，此处测试是为了快速安装，没特别要求） Identify network Device显示出此机器的网络 设置网络，设置hostname，ip掩码网关等，DNS服务器根据需求配置，配置完成后会显示配置，并提示是否correct 设置磁盘，根据需求选择对应的磁盘，配置完成后会显示配置，并提示是否correct 确认后开始安装，安装成功后自动重启，等待系统引导完成 登录采用定制auto里面预设的用户密码登录即可。 待补充 "},"13-X86_System/03-HP_X86/":{"url":"13-X86_System/03-HP_X86/","title":"HP_X86","keywords":"","body":"HP_X86 简介 惠普支持中心： HPE Support Center HPE支持中心 内容 "},"13-X86_System/03-HP_X86/01-HP_iLO使用.html":{"url":"13-X86_System/03-HP_X86/01-HP_iLO使用.html","title":"HP_iLO使用","keywords":"","body":"HP_iLO使用   iLO是Integrated Ligths-out的简称,是HP服务器上集成的远程管理端口,它是一组芯片内部集成vxworks嵌入式操作系统,通过一个标准RJ45接口连接到工作环境的交换机。 iLO基础使用 iLO IP配置   iLO管理口默认是开启了DHCP，需要路由器DHCP分发IP或者用Laptop通过软件(例如dhcpsrv)分发IP。iLO的IP配置或修改说明如下： 如果是新机器，默认开启DHCP，开机按指定的键进入iLO进行修改 如果已经开机（不能关）并且没有改过iLO的IP，使用DHCP服务分发IP进入iLO，可以修改iLO的IP 如果已经开机，并且改过iLO的IP忘记了，只能重启设备，在启动时会提示iLO的IP，或者进入iLO查看 相关参考链接： HP iLO-Discover the IP address HP iLO-Password recovery dhcpsrv使用 确认iLO是DHCP开启状态下： 用Laptop网线直连到机器后面iLO端口上 在Laptop上配置IP，例如：192.168.120.2 使用dhcpwiz.exe进行配置，或者直接编辑dhcpsrc.ini文件进行配置，示例见后续 使用管理员权限打开dhcpsrv.exe 首先点击Install 然后点击Start开启服务 长ping IP池里面的IP： 能ping通然后通过网页打开管理终端 如果不能ping通重新配置下Laptop上的IP 配置文件dhcpsrc.ini(后面DNS和HTTP服务不重要)示例： [SETTINGS] IPPOOL_1=192.168.120.3-4 IPBIND_1=192.168.120.2 AssociateBindsToPools=1 Trace=1 DeleteOnRelease=0 ExpiredLeaseTimeout=3600 [GENERAL] LEASETIME=86400 NODETYPE=8 SUBNETMASK=255.255.255.0 NEXTSERVER=192.168.120.2 ROUTER_0=192.168.120.1 说明： Laptop配置成192.168.120.2，掩码255.255.255.0，网关和DNS不需要配置 IPPOOL配置成192.168.120.3-4，给服务器分配会是这两个IP，ping这两个ip即可 配置固定IP 以DL580 G7为例，版本为iLO3： 开机根据提示按F8进入iLO 在选项Network中选中DNS/DHCP,回车确认，将DHCP选项设置成OFF，按F10保存 在选项Network中选中NIC and TCP/IP，在里面配置IP信息，按F10保存 官方参考链接：HP ProLiant DL580 G7服务器-开启ilo功能的方法 iLO登录   默认用户Administrator，默认密码在机器前面的铭牌标签上有写。如果登录密码忘记，需要进入iLO进行重置（重置iLO）或者修改。 修改Administrator密码 以DL580 G7为例，版本为iLO3： 开机时候根据提示F8进入iLO 在选项User中选中Administrator 选择Edit User对用户进行编辑 在密码处输入新的密码，然后验证再输一次，按F10保存 提示使用过期或者不安全的TLS安全设置   使用网页登录管理界面时，打不开网页，提示无法安全地连接到此页面，可能是使用过期或者不安全的TLS安全设置，，需要进行设置： 打开Internet选项，选择高级选项 将TLS 1.3取消掉，保留1.0、1.1及1.2 再次尝试，如果不行再去掉几个 iLO重置 以DL580 G7为例，版本为iLO3： 开机时候根据提示F8进入iLO 在选项File中选中Set Defaults 回车确认即reset了iLO 重置说明： 重置后DHCP开启，IP地址等信息为空 用户Administrator密码恢复为默认，其他之前建立的用户会删除 iLO里面关于机器的日志等信息都会重置 其他用户自定义配置都会重置 iLO设备管理 "},"13-X86_System/03-HP_X86/20-HP_常见故障.html":{"url":"13-X86_System/03-HP_X86/20-HP_常见故障.html","title":"HP_常见故障","keywords":"","body":"HP_常见故障 服务器常见故障 Uncorrectable Machine Check Exception 遇到机型为DL580 G7，会导致机器重启，报错信息： Uncorrectable Machine Check Exception (Board 0, Processor 1, APIC ID 0x00000022, Bank 0x0000000E, Status 0xA6000000'00000932, Address 0x00000000'00000000, Misc 0x00000000'00000000) 故障相关链接： DL380 G7 Uncorrectable Machine Check Exception System May Reboot Without Warning and May Not Log an IML Event HP服务器Uncorrectable Machine Check Exception报错处理方法 raid Failed但磁盘状态正常   raid状态为Failed，但是所有磁盘状态均是OK，硬盘上数据指示灯也没亮，raid应该无法访问了。检查近期是否有更换某块硬盘，检查硬盘微码是否一致，如果有块有差异，需要更换为和其它同版本的。例如这次发现大部分是HPD2微码，有一块是HPD6，更换掉HPD6的就可以了。事件里面也会有相关报错信息，示例： Severity:Repaired Class:Drive Array Internal Storage Enclosure Device Failure(Bay8,Box2,Port2,Slot0) 待补充 "},"14-存储设备/":{"url":"14-存储设备/","title":"存储设备","keywords":"","body":"存储设备 简介 集中式存储或分布式存储。 内容 华为存储系列 "},"14-存储设备/01-华为存储系列/":{"url":"14-存储设备/01-华为存储系列/","title":"华为存储系列","keywords":"","body":"华为存储系列 简介 华为公司存储设备。 内容 "},"14-存储设备/01-华为存储系列/01-HuaWei-用户基本操作.html":{"url":"14-存储设备/01-华为存储系列/01-HuaWei-用户基本操作.html","title":"HuaWei-用户基本操作","keywords":"","body":"用户及密码 华为存储用户相关操作。 默认登录方式 OceanStor 5310 V5管理口 端口：每个控制器上的管理端口默认IP：A控192.168.128.101 B控192.168.128.102登录地址：https://192.168.128.102:8088默认用户：admin默认密码：Admin@Storage 修改管理IP 以OceanStor 5310 V5为例： 选择“系统 > 控制器CTE0 > 控制器A或B > 管理端口 系统标记管理端口，鼠标指向管理端口，左键单击列出管理端口信息，点击右下角“修改“选项 密码重置方式 非超级用户重置密码   当管理员或只读用户忘记密码时，超级管理员可以通过DeviceManager或者CLI管理界面重置当前用户的密码。通过DeviceManager初始化用户密码（LDAP用户不能初始化密码）： 以超级管理员身份登录DeviceManager。系统初始的超级管理员用户名为admin，密码为Admin@storage 选择“设置 > 权限设置 > 用户管理” 在中间信息展示区，选择需要初始化密码的用户名并单击“修改” 系统弹出“修改用户”对话框。 选择“初始化密码”。输入“当前登录用户密码”、“新密码”和“确认密码”。 单击“确定” 系统弹出“执行结果”提示框，提示操作成功 单击“关闭”。 通过CLI管理界面重置用户密码。 以超级管理员身份登录CLI管理界面 执行change user user_name=? action=reset_password命令，重置用户的登录密码 示例重置“testuser”用户的登录密码： admin:/>change user user_name=testuser action=reset_password New password:********** Reenter password:********** Password:********** Command executed successfully. 超级管理员忘记密码。   如果默认用户名为“admin”的超级管理员忘记密码，需使用“_super_admin”超级管理员通过串口登录CLI管理界面，执行initpasswd命令重置密码： 以用户名为_super_admin的超级管理员身份通过串口登录CLI管理界面。用户名为_super_admin的“超级管理员”，系统初始密码为Admin@revive。 执行initpasswd命令，重置超级管理员的登录密码。 Storage: _super_admin> initpasswd please input username:admin init admin passwd,wait a moment please... *****please enter new password for admin :***** *****please re-enter new password for admin :***** Init admin passwd succeeded 待补充 "},"15-网络交换机/":{"url":"15-网络交换机/","title":"网络交换机","keywords":"","body":"网络交换机 简介 网络交换机。 内容 Cisco交换机 H3C交换机 华为交换机 SMC交换机 "},"15-网络交换机/04-SMC交换机/":{"url":"15-网络交换机/04-SMC交换机/","title":"SMC交换机","keywords":"","body":"SMC交换机 简介 SMC交换机。 内容 SMC-基本操作 "},"15-网络交换机/04-SMC交换机/01-SMC-基本操作.html":{"url":"15-网络交换机/04-SMC交换机/01-SMC-基本操作.html","title":"SMC-基本操作","keywords":"","body":"SMC-基本操作 使用交换机型号： SMC8126L2 SMC TigerSwitch 26-Ports 10/100/1000 用户登录 管理网口登录 没有默认IP，默认是DHCP获取IP，示例使用dhcpsrv通过Laptop进行DHCP： 用Laptop网线直连到机器上管理网口(示例型号是25号口) 在Laptop上配置IP，例如：192.168.120.2 使用dhcpwiz.exe进行配置，或者直接编辑dhcpsrc.ini文件进行配置，示例见后续 使用管理员权限打开dhcpsrv.exe 首先点击Install 然后点击Start开启服务 长ping IP池里面的IP： 能ping通然后通过网页打开管理终端 如果不能ping通重新配置下Laptop上的IP 配置文件dhcpsrc.ini(后面DNS和HTTP服务不重要)示例： [SETTINGS] IPPOOL_1=192.168.120.3-4 IPBIND_1=192.168.120.2 AssociateBindsToPools=1 Trace=1 DeleteOnRelease=0 ExpiredLeaseTimeout=3600 [GENERAL] LEASETIME=86400 NODETYPE=8 SUBNETMASK=255.255.255.0 NEXTSERVER=192.168.120.2 ROUTER_0=192.168.120.1 说明： Laptop配置成192.168.120.2，掩码255.255.255.0，网关和DNS不需要配置 IPPOOL配置成192.168.120.3-4，给服务器分配会是这两个IP中之一 Ping成功后，通过telnet或者WEB访问即可（直接输入IP，不需要端口号） 默认用户admin,默认密码admin 串口登录 RS-232串行口配置如下： 速率设置为9600 数据格式为8个数据位，1个停止位，无奇偶 流量控制设为无 仿真模式设为VT100 使用超级终端时，选择Terminal，不是Windowns键 待补充 "},"16-云平台/":{"url":"16-云平台/","title":"云平台","keywords":"","body":"云平台 内容 OpenShift Docker "},"16-云平台/01-OpenShift/":{"url":"16-云平台/01-OpenShift/","title":"OpenShift","keywords":"","body":"OpenShift OpenShift是红帽的云开发平台即服务（PaaS）。 官方网站：https://www.openshift.com/ 学习链接:OpenShift 容器平台简介和离线裸机安装步骤 内容 OpenShift-简介 OpenShift-安装 OpenShift-应用部署 "},"16-云平台/01-OpenShift/01-OpenShift-简介.html":{"url":"16-云平台/01-OpenShift/01-OpenShift-简介.html","title":"OpenShift-简介","keywords":"","body":"OpenShift-简介 内容来自学习的IBM在线实验室发布的学习链接：OpenShift 容器平台简介和离线裸机安装步骤 简介 OpenShift容器平台简介   OpenShift是容器平台以Kubernetes为基础由红帽（Red Hat）开发的容器化软件解决方案，是用于开发和运行容器化应用程序的平台。它旨在允许支持它们的应用程序和数据中心从仅几台机器和应用程序扩展到为数百万个客户提供服务的数千台机器。 关于Kubernetes   Kubernetes是一个开源容器编排引擎，用于自动化容器化应用程序的部署，扩展和管理。Kubernetes的一般概念非常简单： 从一个或多个工作程序节点开始运行容器工作负载 从一个或多个主节点管理这些工作负载的部署 将容器包装在称为吊舱的部署单元中。使用pod可以为容器提供额外的元数据，并可以在单个部署实体中对多个容器进行分组 创建特殊种类的资产。例如，服务由一组Pod以及定义访问方式的策略表示。即使容器没有用于服务的特定IP地址，此策略也可以使容器连接到所需的服务。复制控制器是另一项特殊资产，它指示一次需要运行多少个Pod副本。您可以使用此功能来自动扩展应用程序以适应其当前需求。 容器化应用程序的优势   与使用传统部署方法相比，使用容器化应用程序具有许多优势。曾经期望将应用程序安装在包含所有依赖项的操作系统上的地方，容器让应用程序随身携带其依赖项。创建容器化的应用程序有很多好处。 操作系统的好处   容器使用没有内核的小型专用Linux操作系统。它们的文件系统，网络，cgroup，进程表和名称空间与主机Linux系统是分开的，但是容器可以在必要时与主机无缝集成。基于Linux，容器可以利用快速创新的开源开发模型附带的所有优势。  因为每个容器都使用专用的操作系统，所以您可以在同一主机上部署需要冲突软件依赖关系的应用程序。每个容器都带有自己的从属软件，并管理自己的接口，例如网络和文件系统，因此应用程序无需竞争这些资产。 部署和扩展优势   如果在应用程序的主要版本之间进行滚动升级，则可以在不停机的情况下不断改进应用程序，并仍保持与当前版本的兼容性。  您还可以在现有版本旁边部署和测试应用程序的新版本。除当前版本外，还部署新的应用程序版本。如果容器通过了测试，则只需部署更多新容器并删除旧容器即可。 OpenShift容器平台的增强功能 OpenShift容器平台的增强功能： 混合云部署。可以将OpenShift Container Platform集群部署到各种公共云平台或数据中心中。 集成的R​​ed Hat技术。OpenShift容器平台的主要组件来自Red Hat Enterprise Linux（RHEL）和相关的Red Hat技术。OpenShift容器平台受益于Red Hat企业质量软件的严格测试和认证计划。 开源开发模型。开发已经公开完成，其源代码可从公共软件存储库中获得。这种开放式的合作促进了快速的创新和发展。 Red Hat Enterprise Linux CoreOS   OpenShift容器平台使用Red Hat Enterprise Linux CoreOS（RHCOS），这是一种面向容器的操作系统，结合了CoreOS和Red Hat Atomic Host操作系统的一些最佳功能。RHCOS是专门为从OpenShift Container Platform运行容器化应用程序而设计的，并且与新工具一起使用以提供快速安装，基于操作员的管理和简化的升级。 RHCOS包括： 点火，OpenShift容器平台将其用作首次启动和配置计算机的firstboot系统配置。 CRI-O是Kubernetes的本机容器运行时实现，与操作系统紧密集成以提供高效和优化的Kubernetes体验。CRI-O提供了用于运行，停止和重新启动容器的工具。它完全替代了OpenShift Container Platform 3中使用的Docker Container Engine。 Kubelet，Kubernetes的主要节点代理，负责启动和监视容器。   在OpenShift Container Platform 4.6中，必须将RHCOS用于所有控制平面计算机，但是可以将Red Hat Enterprise Linux（RHEL）用作计算机（也称为工作计算机）的操作系统。如果您选择使用RHEL worker，则与所有群集计算机上使用RHCOS相比，您必须执行更多的系统维护。 其他主要特点 其他主要特点： Operator 既是OpenShift Container Platform 4.6代码库的基本单元，也是部署应用程序和软件组件以供您使用的便捷方法。在OpenShift容器平台中，操作员充当平台的基础，无需手动升级操作系统和控制平面应用程序。OpenShift容器平台操作员（例如群集版本操作员和计算机配置操作员）允许对这些关键组件进行简化的群集范围内的管理。 Operator Lifecycle Manager（OLM）和OperatorHub提供了用于将操作员存储和分发给开发和部署应用程序的人员的工具。 Red Hat Quay容器注册表是Quay.io容器注册表，它为OpenShift容器平台集群提供大多数容器映像和操作员。Quay.io是Red Hat Quay的公共注册表版本，可存储数百万个图像和标签。 OpenShift容器平台中Kubernetes的其他增强功能包括软件定义网络（SDN），身份验证，日志聚合，监视和路由方面的改进。OpenShift容器平台还提供了一个全面的Web控制台和自定义的OpenShift CLI（oc）界面。 OpenShift容器平台生命周期 下图说明了基本的OpenShift容器平台生命周期： 创建一个OpenShift容器平台集群 管理集群 开发和部署应用程序 扩大应用程序 OpenShift容器平台安装概述   OpenShift容器平台安装程序为您提供了灵活性。可以使用安装程序在安装程序配置和维护的基础结构上部署集群，也可以在准备和维护的基础结构上部署集群。这两种基本类型的OpenShift Container Platform集群通常称为安装程序提供的基础结构集群和用户提供的基础结构集群。 两种类型的集群都具有以下特征： 默认情况下，没有单点故障的高可用性基础结构可用 管理员可以控制应用什么更新以及何时应用   您使用相同的安装程序来部署两种类型的群集。安装程序生成的主要资产是用于引导计算机，主计算机和工作计算机的Ignition配置文件。通过这三种配置和正确配置的基础结构，您可以启动OpenShift容器平台集群。   OpenShift Container Platform安装程序使用一组目标和依赖项来管理集群安装。安装程序具有必须实现的一组目标，并且每个目标都有一组依赖性。因为每个目标仅关注其自身的依赖性，所以安装程序可以采取措施并行实现多个目标。最终目标是运行中的集群。通过满足依赖性而不是运行命令，安装程序能够识别和使用现有组件，而不必运行命令来再次创建它们。   安装后，每台群集计算机都将Red Hat Enterprise Linux CoreOS（RHCOS）用作操作系统。RHCOS是Red Hat Enterprise Linux（RHEL）的不可变容器主机版本，具有默认情况下启用SELinux的RHEL内核。它包括kubelet，它是Kubernetes节点代理，以及为Kubernetes优化的CRI-O容器运行时。  OpenShift Container Platform 4.6集群中的每个控制平面计算机都必须使用RHCOS，其中包括一个称为Ignition的关键的首次启动配置工具。该工具使集群可以配置计算机。操作系统更新作为Atomic OSTree存储库提供，该存储库嵌入在容器映像中，该映像由操作员在整个群集中推出。实际的操作系统更改通过使用rpm-ostree在每台计算机上作为原子操作就地进行。通过结合使用这些技术，OpenShift Container Platform可以通过就地升级使整个平台保持最新状态，从而像管理集群上的任何其他应用程序一样管理操作系统。这些就地更新可以减轻操作团队的负担。   如果将RHCOS用作所有群集计算机的操作系统，则群集将管理其组件和计算机的所有方面，包括操作系统。因此，只有安装程序和Machine Config Operator才能更改机器。安装程序使用Ignition配置文件来设置每台计算机的确切状态，并且在安装后，Machine Config Operator完成对计算机的更多更改，例如新证书或密钥的应用。 下图显示了安装目标和依赖项的子集： 可用平台 可用平台： AWS Azure GCP RHOSP RHV VMware vSphere Bare metal IBM Z or LinuxONE IBM Power Systems   对于这些集群，所有机器（包括在其上运行安装过程的计算机）都必须具有直接的Internet访问权限，才能为平台容器提取图像并将遥测数据提供给Red Hat。 "},"16-云平台/01-OpenShift/02-Openshift-安装.html":{"url":"16-云平台/01-OpenShift/02-Openshift-安装.html","title":"Openshift-安装","keywords":"","body":"OpenShift-安装 内容来自学习的IBM在线实验室发布的学习链接：OpenShift 容器平台简介和离线裸机安装步骤 安装过程简介   安装OpenShift Container Platform集群时，可以从Red Hat OpenShift Cluster Manager站点上相应的Infrastructure Provider页面下载安装程序 。该网站管理： 帐户的REST API 注册表令牌，这是您用于获取必需组件的拉式机密 集群注册，它将集群标识与您的Red Hat帐户相关联，以方便收集使用情况指标   在OpenShift Container Platform 4.6中，安装程序是Go二进制文件，该文件对一组资产执行一系列文件转换。与安装程序交互的方式因安装类型而异。 对于具有由安装程序提供的基础结构的集群，您可以将基础结构引导和供应委派给安装程序，而不是自己进行。安装程序将创建支持集群所需的所有网络，机器和操作系统。 如果为群集配置和管理基础架构，则必须提供所有群集基础架构和资源，包括引导计算机，网络，负载平衡，存储和单个群集计算机。   在安装期间，使用三组文件：名为的安装配置文件install-config.yaml，Kubernetes清单和适用于用户机器类型的Ignition配置文件。  将安装配置文件转换为Kubernetes清单，然后将清单包装到Ignition配置文件中。安装程序使用这些Ignition配置文件来创建集群。运行安装程序时，将删除所有的配置文件，因此请确保备份所有要再次使用的配置文件。 构成集群的控制平面和计算机的基础架构 负载均衡器 群集网络，包括DNS记录和所需的子网 集群基础架构和应用程序的存储 安装过程详细信息   由于群集中的每台计算机在配置时都需要有关群集的信息，因此OpenShift容器平台在初始配置期间会使用临时引导计算机将所需信息提供给永久控制平面。它通过使用描述如何创建群集的点火配置文件来启动。引导计算机将创建组成控制平面的主计算机。然后，控制平面计算机创建计算机，也称为工作计算机。下图说明了此过程：   集群计算机初始化之后，引导计算机将被销毁。所有群集都使用引导过程来初始化群集，但是，如果为群集配置基础结构，则必须手动完成许多步骤。对群集进行引导涉及以下步骤： 导计算机引导并开始托管主计算机引导所需的远程资源。（如果您配置基础架构，则需要人工干预） 主计算机从引导计算机获取远程资源并完成引导。（如果您配置基础架构，则需要人工干预） 主计算机使用引导计算机来形成etcd集群。 引导机器使用新的etcd集群启动临时Kubernetes控制平面。 临时控制平面将生产控制平面调度到主机。 临时控制平面关闭，并将控制权交给生产控制平面。 引导机将OpenShift容器平台组件注入生产控制平面。 安装程序将关闭引导计算机。（如果您配置基础架构，则需要人工干预） 控制平面设置工作节点。 控制平面以一组操作员的形式安装其他服务。   该引导过程的结果是一个完全运行的OpenShift Container Platform集群。然后，集群下载并配置日常操作所需的其余组件，包括在受支持的环境中创建工作机。 Openshift Topology 离线裸机安装环境要求 安装最小的OpenShift容器平台集群需要以下主机： 1个引导计算机 3个控制平面或主机 2个或更多计算节点 1个堡垒 具体如下下表所示： 类型 数量 操作系统 vCPU 内存 硬盘 引导节点Master Nodes 1 RHCOS 4 16GB 120GB 主节点Master Nodes 3 RHCOS 4 16GB 120GB 工作节点Worker Nodes 2 RHCOS or RHEL 7.6+ 2 8GB 120GB 堡垒Bastion Node 1 RHEL 2 4GB 25GB 堡垒机的角色： DNS和DHCP服务器 私有Docker registry 负载均衡服务器 Web服务器 执行oc命令的客户端 Openshift离线Bare metal安装步骤 步骤如下： 堡垒机准备： DNS & DHCP:dnsmasq Web服务器：Niginx LB服务器:haproxy Mirror Registry:Registry docker using podman Openshift-install & Oc命令行 创建虚拟机（根据需求创建）： 1 bootstrap 3 master 2 worker 1 bastion 生成点火文件：使用openshift-install生成的点火文件 开始安装：从操作系统引导开始自动安装 监视安装完成：观察安装进度，批准证书，配置失败的operator 在裸机上部署安装程序置备的集群   以上内容均摘自IBM在线实验室教程。原版也参考红帽官方《在裸机上部署安装程序置备的集群》和《在 vSphere 上安装》安装手册的基础上，结合了IBM实验室各方同仁在vSphere上以裸机方式安装OpenShift Container Platform的配置经验，尽量简化了安装步骤，屏蔽了安装过程中各种可能导致安装失败的配置错误,以更加贴近生产集群部署实践的方式体验OpenShift Container Platform安装过程。 相关链接如下： 在裸机上部署安装程序置备的集群：在裸机上部署安装程序置备的集群在vSphere上安装：安装 OpenShift Container Platform vSphere 集群IBM上机实验地址：Openshift container Platfom (OCP) bare metal installation "},"16-云平台/01-OpenShift/03-OpenShift-应用部署.html":{"url":"16-云平台/01-OpenShift/03-OpenShift-应用部署.html","title":"OpenShift-应用部署","keywords":"","body":"OpenShift-应用部署   OpenShift是由红帽（Red Hat）开发的容器化软件解决方案，这是基于企业级 Kubernetes 管理的平台即服务（PaaS）。OpenShift支持通过Operators，通过Git使用S2I，使用Dockerfile，直接使用Image Registry的镜像等方式部署应用。 学习过程中整理的笔记，内容来自IBM在线实验室发布的学习链接： 在OpenShift平台上部署应用 OpenShift开发应用平台自动化部署 OpenShift容器平台高权限自由体验 部署Git服务器   部署背景：某企业准备启动一个新的项目，需要为该项目准备一套环境供开发、测试使用。基于安全的考虑，需要使该项目独立于已有的产品环境。目前该项目已经在OpenShift平台上创建，接下来在这个平台上快速部署服务以支持项目的开发。 查看项目 操作步骤： 登录OpenShift图形界面 在左侧导航栏，选择Projects，在右侧列表可以看到一个项目(PR)cscdemoXX 点击cscdemoXX项目后，通过Overview查看项目的概要信息 点击Workloads可以查看项目中部署的应用情况，目前为空 部署Git服务器 操作步骤： 点击左侧导航栏顶部的Administrator下拉菜单，切换到Developer视图 在右侧的部署方式中选择From Catalog 在可部署的项目中选择Git Server (Ephemeral) 点击Instantiate Template准备部署 在Application Hostname中填入git-(Project Name).apps.kvm-ocp.example.com 确认正确后点击Create开始部署 点击左侧导航栏的Events可以查看部署过程中的重要事件 查看部署的Git服务器 操作步骤： 在左侧导航栏顶部的从Developer切换到Administrator视图 点击Projects后在右侧点击cscdemoXX项目 点击Workloads打开该选项卡 点击git-server-example下面列出的DC项目可以看到刚刚部署的Git服务器应用信息 点击对应DC项目，然后点击Resources选项卡，确认Pods组里的P资源是Running状态，表示部署成功 在Resources最下部可以看到Routes组信息，其中Location即是我们刚刚部署时输入的Application Hostname 点击Location里面链接打开页面，可以看到403 Forbidden的页面，表示正常工作 部署Node.JS MongoDB应用   部署背景：开发人员已经完成了该项目中的一个NodeJS应用，并且提交到了git服务器上，现在需要部署该应用到OpenShift环境供测试，该应用在git服务器上的位置是/git/nodejs.git。 部署Node.JS MongoDB 操作步骤： 在左侧导航栏顶部的从Administrator切换到Developer视图 点击+Add菜单项，在右侧的部署方式中选择From Catalog 选中TYPE下的Template过滤条件，仅显示模板项目 在可部署的项目中选择Node.js + MongoDB (Ephemeral) 点击Instantiate Template准备部署 在Git Repository URL中填入http://git-(Project Name).apps.kvm-ocp.example.com/git/nodejs.git 确认正确后点击Create开始部署 查看部署的Node.JS MongoDB 操作步骤： 在左侧导航栏顶部的从Developer切换到Administrator视图 点击Projects后在右侧点击cscdemoXX项目 点击Workloads打开该选项卡 点击(DC) nodejs-mongodb-example项目可以看到刚刚部署的Node.JS应用信息 点击Resources选项卡，可以看到Builds组下面Build任务的运行状态 点击Build任务后面的View Logs可以查看Build任务的运行日志 几分钟后，最后一行将出现Push successful表示成功； 返回到Resources选项卡页，确认Pods组里的P资源是Running状态 在资源的最下部可以看到Routes组信息，点击Location中的链接，确认页面最上方出现“Welcome to your Node.js....”表示部署成功 部署Java MySQL应用   部署背景：开发人员已经完成了该项目中的一个Java应用，并且提交到了我们的git服务器上，现在需要部署该应用到OpenShift环境供测试，该应用在git服务器上的位置是/git/java.git。 部署Java MySQL 操作步骤： 在左侧导航栏顶部的从Administrator切换到Developer视图 点击+Add菜单项，在右侧的部署方式中选择From Catalog 选中TYPE下的Template过滤条件，仅显示模板项目 在可部署的项目中选择OpenJDK + MySQL (Ephemeral) 点击Instantiate Template准备部署， 在Git Repository URL中填入http://git-(Project Name).apps.kvm-ocp.example.com/git/java.gitCopy to clipboard 将Context Directory项内容清空 确认正确后，点击Create开始部署 查看部署的Java MySQL 操作步骤： 在左侧导航栏顶部的从Developer切换到Administrator视图 点击Projects后在右侧点击cscdemoXX项目 点击Workloads打开该选项卡 点击(DC) openjdk-app-mysql项目可以看到刚刚部署的Java应用信息 点击Resources选项卡，可以看到Builds组下面Build任务的运行状态 点击Build任务后面的View Logs可以查看Build任务的运行日志 几分钟后，最后一行将出现Push successful，表示成功 返回到Resources选项卡页，确认Pods组里的P资源是Running状态 在资源的最下部可以看到Routes组信息，点击Location中给出的链接，确认页面最上方出现“Number for user 'NONE' is not found”表示部署成功 代码更改后的自动化部署   实验背景：因为代码的快速迭代，为了加快开发速度，希望可以在代码提交后，可以自动实现新代码的部署而不需要人工干预。在 OpenShift 中只需要通过Webhook的方式触发这一功能，下面的实验是用来演示如何获得Webhook的URL及自动部署的过程。操作步骤如下： 点击桌面左上方Applcations，选择Terminal Emulator启动终端窗口 并运行如下命令来克隆java代码库，并确认克隆成功。 ls git clone http://git-(Project Name).apps.kvm-ocp.example.com/git/java.git ls cd java 回到OpenShift的Administrator界面中 在左侧导航栏选择Builds下面的Build Configs项 在右侧页面中点击openjdk-app-mysql项目 在页面的底部可以看到Webhooks组 点击Generic的Copy URL with Secret复制Webhook的URL 回到终端窗口，用vi创建webhook文件，并将拷贝的URL粘贴在文件中保存退出 再用vi修改java源文件src/main/java/org/openshift/quickstarts/undertow/servlet/PhoneBookServlet.java文件 vi src/main/java/org/openshift/quickstarts/undertow/servlet/PhoneBookServlet.java 将第 87 行的 name = \"NONE\"; 改为 name = \"NULL\"; 修改完成后，运行以下命令提交修改: git add . git commit -m \"Test auto build\" git push 如果提示用户名和密码，请输入用户名：git，密码：demo 返回OpenShift的Administrator界面 选择Projects下的cscdemoXX 打开Workloads选项卡 选择(DC) openjdk-app-mysql后 打开Resources选项卡，查看Builds组下面的任务项，这时会看到有一个新的Build任务在运行 待其运行完成后，Pods组里的Running状态项目会被停止并重新生成新的项目 当新项目变成Running状态后，点击底部的Routes组的Location链接，页面输出已经从 Number for user 'NONE' is not found变成了Number for user 'NULL' is not found 部署Python 再次在OpenShift上部署应用进行学习，这次选择部署Python。操作步骤如下： 登录OpenShift图形界面，进入到Developer视图 在Topology点击Samples，选择希望部署的应用，此处我选择的Python 如果初次部署应用，直接点击Create即可开始部署 部署开始后，一般需要几分钟，可以看到圆形的应用，点击圆形图标可以查看详情 当Builds #1状态由running变为completed后，表示部署完成 点击圆形图标右上角的Open URL，可以打开应用的Welcome页面，至此该应用部署成功 接下来，可以通过左导航的+Add，然后在右侧点击Samples，继续添加其他应用 Build失败 记录下bulid失败几种情况。 Git Repository URL填写错误 部署应用的步骤不多，最容易出现错误的就是Git Repository URL写错了。 日志查看步骤： 在左侧导航栏顶部选择Administrator视图 点击Projects后在右侧点击cscdemoXX项目 点击Workloads打开该选项卡 点击(DC) nodejs-mongodb-example项目可以看到刚刚部署的Node.JS应用信息 点击Build任务后面的View Logs可以查看Build任务的运行日志 修改配置步骤： 点击右上角Action展开下拉菜单 选择Edit Build Config选项 在YAML选项中会显示配置文件，找到type:Git,下面uri中有之前输入的Git Repository URL 检查修改成正确地址后，点击左下角save保存 点击右上角Action展开下拉菜单 选择Start Build选项重新开始build 通过上面的查看步骤查看状态 红帽官方链接 更多操作参考红帽官方：GETTING STARTED GUIDE "},"16-云平台/02-Docker/":{"url":"16-云平台/02-Docker/","title":"Docker","keywords":"","body":"Docker Docker 是一个开源的应用容器引擎。 Docker官方网站：https://www.docker.com/Docker官方文档：https://docs.docker.com/Docker GitHub：https://github.com/docker/docker-ceDocker中文社区：https://www.docker.org.cn/index.htmlDocker runoob教程：https://www.runoob.com/docker/docker-tutorial.html 内容 Docker-安装配置 Docker-部署Flask应用 "},"16-云平台/02-Docker/01-Docker-安装配置.html":{"url":"16-云平台/02-Docker/01-Docker-安装配置.html","title":"Docker-安装配置","keywords":"","body":"Docker-安装配置 安装配置笔记，参考教程链接： Docker runoob网站教程 CentOS安装 系统环境： Centos 7.5 配置YUM源 查看配置文件： [root@VM-0-6-centos ~]# ll /etc/yum.repos.d/ total 8 -rw-r--r-- 1 root root 614 Mar 15 20:04 CentOS-Base.repo -rw-r--r-- 1 root root 230 Mar 15 20:04 CentOS-Epel.repo 腾讯云服务器，看了下配置基本都是TX的，直接安装找不到包，说明没配置： [root@VM-0-6-centos ~]# yum install docker-ce docker-ce-cli containerd.io Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile No package docker-ce available. No package docker-ce-cli available. No package containerd.io available. Error: Nothing to do 设置仓库   yum-utils提供了yum-config-manager，并且device mapper存储驱动程序需要device-mapper-persistent-data和lvm2，安装如下所示： # yum install -y yum-utils device-mapper-persistent-data lvm2 配置官方源地址: # yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo Loaded plugins: fastestmirror, langpacks adding repo from: https://download.docker.com/linux/centos/docker-ce.repo grabbing file https://download.docker.com/linux/centos/docker-ce.repo to /etc/yum.repos.d/ docker-ce.reporepo saved to /etc/yum.repos.d/docker-ce.repo 或者使用阿里云和清华大学地址： # yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo # yum-config-manager --add-repo https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.repo 安装Docker Engine-Community 安装最新版本的Docker Engine-Community和containerd： [root@VM-0-6-centos ~]# yum install docker-ce docker-ce-cli containerd.io Loaded plugins: fastestmirror, langpacks Loading mirror speeds from cached hostfile docker-ce-stable | 3.5 kB 00:00:00 (1/2): docker-ce-stable/7/x86_64/updateinfo | 55 B 00:00:00 (2/2): docker-ce-stable/7/x86_64/primary_db | 58 kB 00:00:00 ... Install 3 Packages (+12 Dependent packages) Total download size: 104 M Installed size: 430 M Is this ok [y/d/N]: y ... Retrieving key from https://download.docker.com/linux/centos/gpg Importing GPG key 0x621E9F35: Userid : \"Docker Release (CE rpm) \" Fingerprint: 060a 61c5 1b55 8a7f 742b 77aa c52f eb6b 621e 9f35 From : https://download.docker.com/linux/centos/gpg Is this ok [y/N]: y Running transaction check Running transaction test Transaction test succeeded ... Installed: containerd.io.x86_64 0:1.4.4-3.1.el7 docker-ce.x86_64 3:20.10.5-3.el7 docker-ce-cli.x86_64 1:20.10.5-3.el7 Dependency Installed: audit-libs-python.x86_64 0:2.8.5-4.el7 checkpolicy.x86_64 0:2.5-8.el7 container-selinux.noarch 2:2.119.2-1.911c772.el7_8 docker-ce-rootless-extras.x86_64 0:20.10.5-3.el7 fuse-overlayfs.x86_64 0:0.7.2-6.el7_8 fuse3-libs.x86_64 0:3.6.1-4.el7 libcgroup.x86_64 0:0.41-21.el7 libsemanage-python.x86_64 0:2.5-14.el7 policycoreutils-python.x86_64 0:2.5-34.el7 python-IPy.noarch 0:0.75-6.el7 setools-libs.x86_64 0:3.3.8-4.el7 slirp4netns.x86_64 0:0.4.3-4.el7_8 Complete! 指定版本安装 如果需要指定版本，先查看版本： [root@VM-0-6-centos ~]# yum list docker-ce --showduplicates | sort -r Loading mirror speeds from cached hostfile Loaded plugins: fastestmirror, langpacks Installed Packages docker-ce.x86_64 3:20.10.5-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.5-3.el7 @docker-ce-stable docker-ce.x86_64 3:20.10.4-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.3-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.2-3.el7 docker-ce-stable docker-ce.x86_64 3:20.10.1-3.el7 docker-ce-stable ... 命令示例： # yum install docker-ce- docker-ce-cli- containerd.io 说明： 是完整软件包名称，格式是：软件包名称（docker-ce）加上版本字符串（第二列，从第一个冒号（:）一直到第一个连字符），并用连字符（-）分隔 例如示例中第一条记录完整版本号就是：docker-ce-20.10.5 启动测试 启动Docker： [root@VM-0-6-centos ~]# systemctl start docker 运行hello-world映像： [root@VM-0-6-centos ~]# docker run hello-world Unable to find image 'hello-world:latest' locally latest: Pulling from library/hello-world b8dfde127a29: Pull complete Digest: sha256:308866a43596e83578c7dfa15e27a73011bdd402185a84c5cd7f32a88b501a24 Status: Downloaded newer image for hello-world:lates ... 找不到，但是自动下载了，然后执行了，可以再来一次： Hello from Docker! This message shows that your installation appears to be working correctly. ... 说明安装成功。 待补充 "},"16-云平台/02-Docker/10-Docker-部署Flask应用.html":{"url":"16-云平台/02-Docker/10-Docker-部署Flask应用.html","title":"Docker-部署Flask应用","keywords":"","body":"Docker-部署Flask应用 以写的一个导航工具为例，代码托管在GitHub：https://github.com/bond-huang/navigator 配置参考链接： Docker runoob网站教程 uWSGI文档 Flask部署方式 ngix官方安装文档 Python uWSGI 安装配置 安装CentOS 安装CentOS7： [root@VM-0-6-centos ~]# docker pull centos:7 7: Pulling from library/centos 2d473b07cdd5: Pull complete Digest: sha256:0f4ec88e21daf75124b8a9e5ca03c37a5e937e0e108a255d890492430789b60e Status: Downloaded newer image for centos:7 docker.io/library/centos:7 查看镜像： [root@VM-0-6-centos ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE hello-world latest d1165f221234 9 days ago 13.3kB centos centos7 8652b9f0cb4c 4 months ago 204MB 运行容器并进入CentOS容器： [root@VM-0-6-centos ~]# docker run -itd --name navigator centos:centos7 554b9bc044751e94f5e9f9802bdfc49f05ff55d0bc0f05913b0f27fd3e0be512 [root@VM-0-6-centos ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 554b9bc04475 centos:centos7 \"/bin/bash\" 2 minutes ago Up 2 minutes navigator [root@VM-0-6-centos ~]# docker exec -it navigator /bin/bash [root@554b9bc04475 /]# 说明： -i: 交互式操作 -t: 终端 /bin/bash:shell类型 拷贝项目文件 首先将项目文件拷贝到操作系统中： [root@VM-0-6-centos navigator]# ls instance LICENSE MANIFEST.in nav README.md setup.cfg setup.py tests 文件拷贝到容器中： # docker cp ./navigator/ 554b9bc04475:/navigator [root@VM-0-6-centos ~]# docker exec -it navigator /bin/bash [root@554b9bc04475 navigator]# ls LICENSE MANIFEST.in README.md instance nav setup.cfg setup.py tests 安装基础软件 安装python3 安装示例： [root@554b9bc04475 /]# yum install python3 ... Running transaction Installing : libtirpc-0.2.4-0.16.el7.x86_64 1/5 Installing : python3-setuptools-39.2.0-10.el7.noarch 2/5 Installing : python3-pip-9.0.3-8.el7.noarch 3/5 Installing : python3-3.6.8-18.el7.x86_64 4/5 Installing : python3-libs-3.6.8-18.el7.x86_64 5/5 ... [root@554b9bc04475 /]# python3 Python 3.6.8 (default, Nov 16 2020, 16:55:22) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linux Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. pip3那些都自动安装了。 安装项目需求包 安装Flask（不推荐用root）： [root@554b9bc04475 /]# pip3 install Flask WARNING: Running pip install with root privileges is generally not a good idea. Try `pip3 install --user` instead.Collecting Flask ... Flask需要的例如jinja2和click都安装了。 安装waitress 安装waitress： [root@554b9bc04475 /]# pip3 install waitress WARNING: Running pip install with root privileges is generally not a good idea. Try `pip3 install --user` instead.Collecting waitress Downloading https://files.pythonhosted.org/packages/a8/cf/a9e9590023684dbf4e7861e261b0cf d6498a62396c748e661577ca720a29/waitress-2.0.0-py3-none-any.whl (56kB) 100% |################################| 61kB 486kB/s Installing collected packages: waitress Successfully installed waitress-2.0.0 安装pytest和coverage 安装pytest和coverage： [root@554b9bc04475 /]# pip3 install pytest coverage WARNING: Running pip install with root privileges is generally not a good idea. Try `pip3 install --user` instead. ... 安装环境： [root@554b9bc04475 navigator]# pip3 install -q -e . 运行测试 运行测试： [root@554b9bc04475 navigator]# python3 setup.py test ... E AssertionError: assert 'Initialized' in '' E + where '' = .output ... 设置下环境变量： [root@554b9bc04475 navigator]# export LC_ALL=en_US.utf-8 [root@554b9bc04475 navigator]# export LANG=en_US.utf-8 参考链接：Click will abort further execution because Python 3 was configured to use ASCII as encoding for the environment 再次运行： [root@554b9bc04475 navigator]# python3 setup.py test running test ================================== test session starts =================================== platform linux -- Python 3.6.8, pytest-6.2.2, py-1.10.0, pluggy-0.13.1 rootdir: /navigator, configfile: setup.cfg, testpaths: tests collected 8 items tests/test_db.py .. [ 25%] tests/test_factory.py .. [ 50%] tests/test_navigator.py .... [100%] =================================== 8 passed in 0.34s ==================================== 使用pytest和coverage： [root@554b9bc04475 navigator]# coverage run -m pytest ================================== test session starts =================================== platform linux -- Python 3.6.8, pytest-6.2.2, py-1.10.0, pluggy-0.13.1 rootdir: /navigator, configfile: setup.cfg, testpaths: tests collected 8 items tests/test_db.py .. [ 25%] tests/test_factory.py .. [ 50%] tests/test_navigator.py .... [100%] =================================== 8 passed in 0.31s ==================================== [root@554b9bc04475 navigator]# coverage report Name Stmts Miss Branch BrPart Cover ------------------------------------------------------------- nav/__init__.py 20 0 2 0 100% nav/db.py 24 0 4 0 100% nav/navigation.py 72 12 28 12 76% nav/templates/footer.html 0 0 0 0 100% ------------------------------------------------------------- TOTAL 116 12 34 12 84% 运行应用 通过nohup后台运行： [root@554b9bc04475 navigator]# nohup waitress-serve --call 'nav:create_app' > nohup.log 2> &1 & [1] 175 [root@554b9bc04475 navigator]# ps -ef |grep waitress root 175 46 0 16:55 pts/1 00:00:00 /usr/bin/python3 /usr/local/bin/waitress-s 网络端口映射 外部访问容器中可以运行的网络应用，可以通过-P或-p参数来指定端口映射。 首先创建一个镜像： [root@VM-0-6-centos huang]# docker commit 554b9bc04475 nav sha256:3bddebade85b20fcd3a86ec3157c71d2f4f1b5a82154a5e7c70d2cd3e86d5066 查看镜像： [root@VM-0-6-centos huang]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE nav latest 3bddebade85b 28 seconds ago 365MB 运行镜像： [root@VM-0-6-centos huang]# docker run -itd -p 8080:8080 --name nav nav:latest [root@VM-0-6-centos huang]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES cd414072bc2b nav:latest \"/bin/bash\" 2 minutes ago Up 2 minutes 0.0.0.0:8080->8080/tcp nav 进入容器启动服务： [root@VM-0-6-centos huang]# docker exec -it nav /bin/bash [root@cd414072bc2b /]# cd navigator [root@cd414072bc2b navigator]# [root@cd414072bc2b navigator]# nohup waitress-serve --call 'nav:create_app' > nohup.log 2> &1 & [1] 29 然后就可以宿主机器IP加端口访问此项目，如果是外网，加一个域名解析可以用域名访问示例：http://nav.big1000.com:8080/ uWSGI部署应用 安装软件 安装uWSGI： [root@cd414072bc2b navigator]# pip3 install uwsgi WARNING: Running pip install with root privileges is generally not a good idea. Try `pip3 install --user` instead.Collecting uwsgi Downloading https://files.pythonhosted.org/packages/c7/75/45234f7b441c59b1eefd31ba3d1041 a7e3c89602af24488e2a22e11e7259/uWSGI-2.0.19.1.tar.gz (803kB) 100% |################################| 808kB 29kB/s Installing collected packages: uwsgi Running setup.py install for uwsgi ... error ... Command \"/usr/bin/python3 -u -c \"import setuptools, tokenize;__file__='/tmp/pip-build-5uni whic/uwsgi/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-n1gtdb69-record/install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in /tmp/pip-build-5uniwhic/uwsgi/ 报错解决方法： [root@cd414072bc2b navigator]# yum install gcc python36-devel ... Package python3-devel-3.6.8-18.el7.x86_64 already installed and latest version ... Installed: gcc.x86_64 0:4.8.5-44.el7 Dependency Installed: cpp.x86_64 0:4.8.5-44.el7 glibc-devel.x86_64 0:2.17-323.el7_9 glibc-headers.x86_64 0:2.17-323.el7_9 kernel-headers.x86_64 0:3.10.0-1160.15.2.el7 libgomp.x86_64 0:4.8.5-44.el7 libmpc.x86_64 0:1.0.1-3.el7 mpfr.x86_64 0:3.1.1-4.el7 Dependency Updated: glibc.x86_64 0:2.17-323.el7_9 glibc-common.x86_64 0:2.17-323.el7_9 Complete! 参考链接：Compile failed with error code 1 in /tmp/pip_build_root/uwsgi 再次安装： [root@cd414072bc2b navigator]# pip3 install uwsgi WARNING: Running pip install with root privileges is generally not a good idea. Try `pip3 install --user` instead.Collecting uwsgi Using cached https://files.pythonhosted.org/packages/c7/75/45234f7b441c59b1eefd31ba3d104 1a7e3c89602af24488e2a22e11e7259/uWSGI-2.0.19.1.tar.gzInstalling collected packages: uwsgi Running setup.py install for uwsgi ... done Successfully installed uwsgi-2.0.19.1 [root@cd414072bc2b navigator]# pip3 list uWSGI (2.0.19.1) 运行： [root@8a5f9985230a navigator]# uwsgi --http 127.0.0.1:5000 --module nav:create_app ... WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x1cc1100 pid: 132 (default a pp) ... 如果有如下提示表示未成功： unable to load app 0 (mountpoint='') (callable not found or import error) *** no app loaded. going in full dynamic mode *** 使用nginx nginx安装 /etc/yum.repos.d/目录下新建文件nginx.repo： [root@cd414072bc2b yum.repos.d]# touch nginx.repo 写入如下内容： [nginx-stable] name=nginx stable repo baseurl=http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck=1 enabled=1 gpgkey=https://nginx.org/keys/nginx_signing.key module_hotfixes=true [nginx-mainline] name=nginx mainline repo baseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/ gpgcheck=1 enabled=0 gpgkey=https://nginx.org/keys/nginx_signing.key module_hotfixes=true 安装nginx： [root@cd414072bc2b yum.repos.d]# yum install nginx ... Installed: nginx.x86_64 1:1.18.0-2.el7.ngx Dependency Installed: make.x86_64 1:3.82-24.el7 openssl.x86_64 1:1.0.2k-21.el7_9 Dependency Updated: openssl-libs.x86_64 1:1.0.2k-21.el7_9 Complete! 测试nginx 查看位置： [root@cd414072bc2b /]# whereis nginx nginx: /usr/sbin/nginx /usr/lib64/nginx /etc/nginx /usr/share/nginx 启动测试： [root@cd414072bc2b nginx]# /usr/sbin/nginx [root@cd414072bc2b nginx]# ps -ef |grep nginx root 744 0 0 07:58 ? 00:00:00 nginx: master process /usr/sbin/nginx nginx 745 744 0 07:58 ? 00:00:00 nginx: worker process 建一个镜像： [root@VM-0-6-centos ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMEScd414072bc2b nav:latest \"/bin/bash\" 14 hours ago Up 14 hours 0.0.0.0:8080->8080/ tcp nav[root@VM-0-6-centos ~]# docker commit cd414072bc2b navigator sha256:9024cf1a2a9e05eff724c1748d4861dc6a171eca95150565e867ae0989ae2ab6 启动并进入容器并启动nginx： [root@VM-0-6-centos ~]# docker run -itd -p 80:80 --name navigator navigator:latest 8a5f9985230aeafd1df70c0b1c434da20761f34df0f99a2502c0f32a9990fac3 [root@VM-0-6-centos ~]# docker exec -it navigator /bin/bash [root@8a5f9985230a /]# /usr/sbin/nginx 在浏览器输入宿主机器的IP即可访问nginx的默认页面。 配置nginx 配置文件位置： [root@8a5f9985230a conf.d]# pwd /etc/nginx/conf.d [root@8a5f9985230a conf.d]# ls default.conf 默认配置文件： [root@8a5f9985230a conf.d]# cat default.conf server { listen 80; server_name localhost; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location / { root /usr/share/nginx/html; index index.html index.htm; } 修改配置： [root@8a5f9985230a conf.d]# cat default.conf server { listen 80; server_name localhost; charset utf-8; client_max_body_size 80M; #access_log /var/log/nginx/host.access.log main; location / { include uwsgi_params; uwsgi_pass 0.0.0.0:8080; } 停止服务： [root@8a5f9985230a conf.d]# /usr/sbin/nginx -s stop [root@8a5f9985230a conf.d]# ps -ef |grep nginx root 70 15 0 08:34 pts/1 00:00:00 grep --color=auto nginx 启动nginx和uwsgi： [root@8a5f9985230a conf.d]# /usr/sbin/nginx [root@8a5f9985230a conf.d]# uwsgi --http 0.0.0.0:8080 --module nav:create_app 使用url去测试，发现是空的： [root@8a5f9985230a /]# curl localhost:8080/gump curl: (52) Empty reply from server uwsgi报错： TypeError: create_app() takes from 0 to 1 positional arguments but 2 were given [pid: 210|app: 0|req: 1/1] 127.0.0.1 () {28 vars in 302 bytes} [Tue Mar 16 14:37:02 2021] GET /gump => generated 0 bytes in 0 msecs (HTTP/1.1 500) 0 headers in 0 bytes (0 switches on core 0) 写一个启动文件： import os from nav import create_app myapp = create_app() if __name__ == \"__main__\": myapp.run(host='0.0.0.0', port=8080) 运行测试可以看到请求正常： [root@8a5f9985230a navigator]# python3 start.py * Serving Flask app \"nav\" (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://0.0.0.0:8080/ (Press CTRL+C to quit) 127.0.0.1 - - [16/Mar/2021 16:10:37] \"GET /gump HTTP/1.1\" 200 - 再次运行： [root@8a5f9985230a navigator]# uwsgi --http 0.0.0.0:8080 --module start:myapp 测试成功： [root@8a5f9985230a /]# curl localhost:8080/gump Life was like a box of chocolates,you never know what you're gonna get. 问题解决参考链接：https://www.pythonanywhere.com/forums/topic/8397/ 启动nginx打开网页报错： An error occurred. Sorry, the page you are looking for is currently unavailable. Please try again later. If you are the system administrator of this resource then you should check the error log for details. Faithfully yours, nginx. 查看宿主机开启端口： [root@VM-0-6-centos ~]# netstat -tnlp Active Internet connections (only servers) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 5398/docker-proxy tcp 0 0 0.0.0.0:8080 0.0.0.0:* LISTEN 14735/docker-proxy tcp 0 0 0.0.0.0:38002 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN 1387/sshd tcp6 0 0 :::44916 :::* LISTEN - 重头开始   看了一些网上资料，内容比较杂，各不相同，照着试还是各种失败，最后回到runoob教程，写的很简单，但是运行成功了，链接：Python uWSGI 安装配置 start.py内容： import os from nav import create_app myapp = create_app() if __name__ == \"__main__\": myapp.run() nginx配置： server { listen 80; server_name localhost; #charset utf-8; client_max_body_size 80M; access_log /navigator/logs/access.log; error_log /navigator/logs/error.log; location / { include uwsgi_params; uwsgi_pass 127.0.0.1:3031; } uwsgi启动命令： uwsgi --socket 127.0.0.1:3031 --wsgi-file start.py --callable myapp --processes 4 --threads 2 --stats 127.0.0.1:9191 容器中测试： [root@8a5f9985230a conf.d]# curl 127.0.0.1:80/gump Life was like a box of chocolates,you never know what you're gonna get. 宿主机测试： [root@VM-0-6-centos ~]# curl 127.0.0.1:80/gump Life was like a box of chocolates,you never know what you're gonna get. 外网访问正常： [pid: 615|app: 0|req: 2/11] 223.73.220.199 () {40 vars in 578 bytes} [Wed Mar 17 16:32:52 2021] GET /static/nav.js => generated 698 bytes in 2 msecs via sendfile() (HTTP/1.1 200) 7 headers in 291 bytes (0 switches on core 0) 保持后台运行，在项目目录下的文件uwsgi.ini: [uwsgi] socket = 127.0.0.1:3031 wsgi-file = start.py callable = myapp processes = 4 threads = 2 stats = 127.0.0.1:9191 daemonize = /navigator/logs/server.log 启动uwsgi： [root@8a5f9985230a navigator]# uwsgi uwsgi.ini [uWSGI] getting INI configuration from uwsgi.ini 容器中测试： Internal Server Error[root@8a5f9985230a conf.d]# curl 127.0.0.1:80/gump Life was like a box of chocolates,you never know what you're gonna get. 宿主机测试： [root@VM-0-6-centos ~]# curl 127.0.0.1:80/gump Life was like a box of chocolates,you never know what you're gonna get. 补充说明 注意事项 注意事项： 示例中日志文件的文件夹要存在，不然会报错 如果使用nginx来把请求发送给uwsgi，使用socket方式（为tcp协议）进行通信 之前没有使用nginx示例中，打开浏览器访问uwsgi指定的端口，请求uwsgi的方式为http协议 如果设置成socket，没启动nginx直接访问会报错：invalid request block size nginx常用命令 常用命令： /usr/sbin/nginx /usr/sbin/nginx -s stop /usr/sbin/nginx -s quit /usr/sbin/nginx -s reload "},"16-云平台/03-IBM_Hybrid_Cloud/":{"url":"16-云平台/03-IBM_Hybrid_Cloud/","title":"IBM_Hybrid_Cloud","keywords":"","body":"IBM_Hybrid_Cloud 简介 混合云 混合云是面向应用程序和基础架构的平台，由公共云、私有云和本地IT中的两个或更多元素构成。所有形式的混合云都可以为应用程序和数据提供灵活性和可移植性。 IBM混合云的优势 混合云通过提供更好的灵活性和平衡性，在公共云和私有云的基础上实现了更大的改进。通过混合云，企业可以更有效地管理速度和安全性，缩短延迟等待时间并提高性能。每个应用程序和服务都可以在最能发挥作用的位置进行部署和管理。 官方链接：IBM Hybrid Cloud IBM混合云团队在YouKu上有个视频专栏进行介绍， 视频链接：IBM_Hybrid_Cloud_Support 内容 暂无 "},"17-HTML+CSS+JavaScript/":{"url":"17-HTML+CSS+JavaScript/","title":"HTML+CSS+JavaScript","keywords":"","body":"HTML+CSS+JavaScript 主要学习书籍：《HTML5+CSS3+JavaScript从入门到精通(标准版)》未来科技编著。 HTML/CSS/JS 在线工具：https://c.runoob.com/front-end/61 内容 HTML5 CSS JavaScript Bootstrap "},"17-HTML+CSS+JavaScript/01-HTML5/":{"url":"17-HTML+CSS+JavaScript/01-HTML5/","title":"HTML5","keywords":"","body":"HTML5 简介   HTML5是HyperText Markup Language 5的缩写，是构建Web内容的一种语言描述方式。HTML5是互联网的下一代标准，是构建以及呈现互联网内容的一种语言方式，被认为是互联网的核心技术之一。 学习书籍：《HTML5+CSS3+JavaScript从入门到精通(标准版)》未来科技编著。 W3school网站教程：W3school HTML 5 教程 HTML runoob网站教程:runoob.com网站HTML教程 html颜色代码：https://encycolorpedia.cn/html HTML/CSS/JS 在线工具：https://c.runoob.com/front-end/61 内容 HTML5-基础知识 "},"17-HTML+CSS+JavaScript/01-HTML5/01-HTML5-基础知识.html":{"url":"17-HTML+CSS+JavaScript/01-HTML5/01-HTML5-基础知识.html","title":"HTML5-基础知识","keywords":"","body":"HTML5-基础知识 HTML5学习笔记，主要学习教程：《HTML5+CSS3+JavaScript从入门到精通(标准版)》未来科技编著。 HTML5文档基本结构   HTML5文档省略了,,等元素，使用HTML5的DOCTYPE声明文档类型，简化元素的charset属性值，省略元素的结束标记，使用的方式来结束元素，以及元素等语法知识要点。一个简单的HTML5文档基本结构如下： HTML5文档基本结构 HTML 的目标 HTML5的目标是为了能够创建简单的WEB程序，书写出更简洁的HTML代码。 例如，为了使WEB应用程序的开发变得更容易，提供了很多API；为了使HTML变得更简洁，开发出新的属性、新的元素等。 HTML5基本语法 与HTML4相比，HTML5在语法上发生了很大的变化。 内容类型 扩展名仍为“.html”或“.htm”，内容类型（ContentType）仍然为“text/html”。 文档类型   DOCTYPE命令声明文档的类型，它是HTML文档必须部分，且必须位于代码第一行。在HTML5中，文档类型声明方法如下： 使用工具时，可以在DOCTYPE声明中加入SYSTEM识别符： 说明及注意： 在HTML5中，DOCTYPE声明方式不区分大小写，引号也不区分单引号或双引号 使用HTML5的DOCTYPE会触发浏览器以标准模式显示页面 字符编码 在HTML4中，使用meta元素定义文档的字符编码： 在HTML5中，简化了charset属性写法： 说明及注意： 以上两种方法在HTML5中都有效，但是不能混用 从HTML5开始，对于文件的字符编码推荐使用UTF-8 标记省略 在HTML5中，元素的标记可以省略，分三种类型： 不允许写结束标记的元素：area,base,br,col,command,embed,hr,img,input,keygen,link,meta,param,source,track,wbr 可以省略结束标记的元素：li,dt,dd,p,rt,rp,optgroup,option,colgroup,thead,tbody,tfoot,tr,td,th 可以省略全部标记的元素：html,head,body,colgroup,tbody   不允许写结束标记的元素指不允许使用开始标记与结束标记将元素括起来形式，只允许使用形式书写，示例如下： 在HTML5中正确书写方式：   可以省略全部标记的元素是指该元素可以完全被省略，但该元素还是以隐式的方式存在，例如body元素省略了，在文档结构中还是存在，可以使用document.body进行访问。 布尔值 示例说明如下： 属性值   属性值两边可以用双引号，也可以用单引号。在HTML5中，当属性值不包括空字符串、、=、单引号、双引号等字符时，属性值两边的引号可以省略，示例： HTML4元素 这些元素基本在HTML5中通用。 结构元素 结构元素用于构建网页的结构，多指块状元素： 元素 说明 div 在文档中定义一块区域，即包含框、容器 ol 根据一定排序进行的列表 ul 没有排序的列表 li 每条列表项 dl 以定义的方式进行列表 dt 定义列表中的词条 dd 对定义的词条进行解释 del 定义删除的文本 ins 定义插入的文本 h1-h6 标题1到标题6，定义不同级别标题 p 定义段落结构 hr 定义水平线 内容元素 内容元素定义了元素在文本中表示内容的语义，一般指文本格式化元素，多是行内元素： 元素 说明 span 在文本中定义一个区域，即行内包含框 a 定义超链接 abbr 定义缩写词 address 定义地址 dfn 定义术语，以斜体显示 kbd 定义键盘键 samp 定义样本 var 定义变量 tt 定义打印机字体 code 定义计算机源代码 pre 定义预定义格式文本，保留源代码格式 bolckquote 定义大块内容引用 cite 定义引文 q 定义引用短语 strong 定义重要文本 em 定义文本为重要 修饰元素 修饰元素定义了文本的显示效果： 元素 说明 b 视觉提醒，显示为粗体 i 语气强调，显示为斜体 big 定义较大文本 small 表示细则一类的旁注，文本缩小显示 sup 定义上标 sub 定义下标 bdi和bdo 定义文本显示方向 br 定义换行 u 非文本注解，显示下划线 HTML4属性 核心属性 核心属性主要包括以下三个，此三个属性为大部分元素所拥有： class：定义类规则或样式规则 id：定义元素的唯一标识 style：定义元素的样式声明 语言属性 语言属性主要定义元素的语言类型，包括两个属性： lang：定义元素的语言代码或编码 dir：定义文本的方向，包括ltr和rtl取值，分别标识从左向右和从右向左 键盘属性 键盘属性定义元素的键盘访问方法，包括两个属性： accesskey：定义访问某元素的键盘快捷键 tabindex：定义元素的Tab键索引编号 例如在文档中插入3个超链接，并分别定义tabindex属性，可以通过Tab键快速切换超链接： Tab 1 Tab 2 Tab 3 内容属性   内容属性定义元素包含内容的附加信息，可以避免元素本身包含信息不全而被误解，内容语义包括五个属性： alt：定义元素的替换文本 title：定义元素的提示文本 longdesc：定义元素包含内容的大段描述信息 cite：定义元素包含内容的引用信息 datetime：定义元素包含内容的日期和时间 alt和title比较常用，示例： 超链接   当图像无法显示时，必须准备替换的文本来替换无法显示的图像，alt属性只能用在img、area和input元素中（包括applet元素）。对于input元素，alt属性用来替换提交按钮的图片：   当浏览器被禁止显示、不支持或者无法下载图像时，通过替换文本可以给看不到图片的浏览者提供文本说明，这是一个很重要的预防和补救措施。如果是修饰性的图片，可以使用空值。 其它属性 两个比较实用的其它属性： rel：定义当前页面与其它页面的关系。表示从源文档到目标文档的关系 rev：定义其它页面与当前页面之间的连接关系。表示从目标文档到源文档的关系   下面示例链接到同一个文件夹中的前一个文档，当搜索引擎检索到rel=\"prev\"信息后，就知道当前文档与所连接的目标文档是平等关系，并处于相同的文件夹中： 链接到集合中的前一个文档 HTML5元素 HTML5在HTML4基础上新增了很多元素。 结构元素 HTML5定义了一组新的语义化结构来描述网页内容。新增的语义化标记元素如下所示： 元素 说明 header 表示页面中一个内容区块或整个页面的标题 footer 表示整个页面或页面中一个内容区块的脚注。一般包含创作者姓名、创作日期及联系信息等 section 表示页面中的一个内容区块，如章节、页眉、页脚或页面中其它部分。可以与h1等标题元素结合使用，标识文档结构 article 表示页面中的一块与上下文不相关的独立内容，如博客中的一篇文章或报纸中的一篇文章 aside 表示article元素的内容之外的、与article元素的内容相关的辅助信息 nav 表示页面总导航链接的部分 main 表示网页中的主要内容。主要内容区域指与网页标题或应用程序中本页面主要功能直接相关或进行扩展的内容 figure 表示一段独立的流内容，一般表示文档主体流内容中的一个独立单元 功能元素 HTML5新增了很多专用元素，简单说明如下。 hgourp元素 用于对整个页面或页面中一个内容区块的标题进行组合。在HTML5.1中废除： Welcome to my blog AIX system check 在HTML4中表示为： ... video元素 定义视频，例如电源片段或其它视频流： video 元素 在HTML4中使用object元素表示。 audio元素 定义音频，比如音乐或其它音频流： audio 元素 在HTML4中使用object元素表示。 embed元素 用来插入各种多媒体，格式可以是Midi、Wav、AIFF、AU、MP3等： 在HTML4中使用object元素表示。 marky元素 用来在视觉上向用户呈现那些需要突出显示或高亮的显示文本，例如在搜索结构中高亮关键字： 在HTML4中表示为： dialog元素 定义对话框或窗口： 这是打开的对话窗口 在HTML4中表示为： 这是打开的对话窗口 bdi元素 定义文本的文本方向，使其脱离其周围文本的方向设置： Username Thor:80 prints Username Batman:78 prints figcaption元素 定义figure元素的标题： 这是一个图片 在HTML4中表示为： 这是一个图片 time元素 表示日期或时间，也可以同时表示： 在HTML4中表示为： canvas元素   表示图形，如图表和其它图像。此元素本身没有行为，仅提供一块画布，但是可以把一个绘图API展现给客户端JavaScript，使脚本能够把想绘制的东西绘制到此画布上： 在HTML4中表示为： output元素 表示不同类型的输出，比如脚本的输出： > 在HTML4中表示为： source元素 为媒介元素（例如video和audio）定义媒介资源： 在HTML4中表示为： menu元素 表示菜单列表。当希望列出表单控件时使用该标签： Green Red 在HTML4中，menu元素不推荐使用。 reby元素 表示ruby注释（中文注音或字符）： 美(ㄇㄟˇ) rt元素 表示字符（中文注音或字符）的解释或发音： 美ㄇㄟˇ rp元素 在ruby注释中使用，以定义不支持ruby元素的浏览器所显示的内容： 美(ㄇㄟˇ) wbr元素   表示软换行。br元素表示必须换行，wbr意思是浏览器窗口或父级元素的宽度足够宽时（没必要换行）不进行换行，宽度不够时主动换行。 command元素 表示命令按钮，如单选按钮、复选框或按钮： 目前只有Internet Explorer支持command标签。 details和summary元素   表示用户要求得到并且可以得到的细节信息，与summary元素配合使用。summary元素提供标题或图例，标题是可见的，用户单击标题时，会显示出细节信息： Shawshank Redemption You know some birds are not meant to be caged, their feathers are just too bright. datalist元素 表示可选数据的列表，与input元素配合使用，可以制作输入值的下拉列表： datagrid元素 表示可选数据的列表，以树形列表的形式显示： 此标签好像很少用或者废除了。 keygen标签 表示生成密钥： 主流浏览器一般都支持keygen标签，除了Internet Explorer和Safari。 progress标签 表示运行中的进程，可以使用progress元素来显示JavaScript中耗费的时间的函数的进程： meter元素 度量给定范围（gauge）内的数据： 十分之三 60% track元素 定义用在媒体播放器中的文本轨道。 表单元素 通过type属性，HTML5为input元素新增了很多类型，如下表所示： 类型 格式 说明 tel 表示必须输入电话号码的文本框 search 表示搜索文本框 url 表示必须输入URL地址的文本框 email 表示必须输入电子邮件地址的文本框 datetime 表示日期和时间的文本框 date 表示日期文本框 month 表示月份文本框 week 表示星期文本框 time 表示时间文本框 datetime-local 表示本地时间和日期文本框 number 表示必须输入数字的文本框 range 表示范围文本框 color 表示颜色文本框 HTML5属性 "},"17-HTML+CSS+JavaScript/02-CSS/":{"url":"17-HTML+CSS+JavaScript/02-CSS/","title":"CSS","keywords":"","body":"CSS 简介   层叠样式表(英文全称：Cascading Style Sheets)是一种用来表现HTML（标准通用标记语言的一个应用）或XML（标准通用标记语言的一个子集）等文件样式的计算机语言。 学习书籍：《HTML5+CSS3+JavaScript从入门到精通(标准版)》未来科技编著。 CSS W3school网站教程：W3school CSS3 教程 CSS runoob网站教程:https://www.runoob.com/css/css-tutorial.html CSS文档：https://developer.mozilla.org/en-US/docs/Web/CSS HTML/CSS/JS 在线工具：https://c.runoob.com/front-end/61 内容 CSS3-基础 CSS3-选择器 "},"17-HTML+CSS+JavaScript/02-CSS/01-CSS3-基础.html":{"url":"17-HTML+CSS+JavaScript/02-CSS/01-CSS3-基础.html","title":"CSS3-基础","keywords":"","body":"CSS3-基础 CSS3基本用法 CSS3学习笔记，主要学习教程：《HTML5+CSS3+JavaScript从入门到精通(标准版)》未来科技编著。 CSS样式 样式是CSS最小语法单元，每个样式包含两部分内容：选择器和声明。示例如下： body{font-size:10px;color:#660099;} 此示例定义网页字体大小为10像素，字体颜色为#660099，具体说明： 选择器（Selcoter）：即示例中的body。选择器告诉浏览器该样式将作用于页面中的哪些对象，这些对象可以是某个标签、所有网页对象、指定Class或ID值等 声明（Declaration）:即示例中的font-size:10px;和color:#660099;。这些声明命令浏览器如何去渲染选择器指定的对象。声明必须包含两个部分：属性和属性值。说明： 属性（Property）：即示例声明中的font-size和color。属性是CSS提供的设置好的样式选项，可以是一个单词或多个，多个单吃直接通过连字符相连 属性值（Value）：即示例声明中的10px和#660099。属性值是用来显示属性效果的参数，包括数值和单位，或者关键字 使用分号来表示一个声明的结束，在一个样式中最后一个声明可以省略分号 所有的声明放置在一个大括号内，大括号称为样式分隔符，然后整体紧邻选择器的后面 定义段落文本的背景色为紫色，示例如下： body{font-size:10px;color:#660099;} p{background-color:#FF00FF} CSS语言忽略空格（除选择器内部的空格外），可以将代码优化： body { width: 756px; height: 1086px; background: #F0F8FF } p{background-color:#FF00FF} 在HTML中使用来进行注释，CSS使用/*注释语句*/来进行注释，示例如下： body {/*页面基本属性*/ width: 756px; height: 1086px; background: #F0F8FF } /*段落文本基本属性*/ p{background-color:#FF00FF} CSS应用   CSS样式代码需保存在.css类型的文本文件中，也可以放在网页内标签中，或者插在网页标签的style属性中。CSS样式应用方法主要有：行内样式、内嵌式、链接式及导入式。 行内样式 行内样式就是把CSS样式直接放在代码行内标签中，一般放入标签的style属性中。示例： AIX System Health Check Report Host Name:teacher02 System Information The system information is follow: 行内元素，strong比em效果要强 行内元素，div块级元素 行内元素，em强调 优点是编写简单，但是也有不少缺点： 每一个标签要设置样式都需要添加style属性 维护成本高，修改页面时需要逐个打开每个页面一一修改，看不到CSS所起到的作用 添加过多的行内样式，页面提交较大，可能会浪费服务器带宽和浏览 内嵌式   内嵌式通过将CSS写在网页源文件的头部，即在和之间，通过使用HTML标签中的标签将其包围，特点时只能在此页使用，解决行内样式多次书写的弊端。示例如下： Test Web p { text-align: left; /* 文本左对齐 */ font-size: 20px; /* 字体大小20像素 */ line-height: 25px; /* 行高25像素 */ text-indent: 2em; /* 首行缩进2个文字大小空间 */ width: 600px; /* 段落宽度600像素 */ margin: 0 auto; /* 浏览器居中 */ margin-bottom: 20px;/* 段落下边距20像素 */ } I figure life is a gift and I don't intend on wasting it. You never know what hand you're going to get dealt next. You learn to take life as it comes at you. I love waking up in the morning and not knowing what's going to happen, or who I'm going to meet, where I'm going to wind up.　 style不仅可以定义CSS样式，还可以定义JavaScript脚本，使用时需要注意： 当style的type值为text/css时，内部编写CSS样式 当style的type值为test/javascript时，内部编写JavaScript脚本 style中有一个比较特殊的属性title，可以为不同样式设置一个标题，示例： Test Web p { text-align: left; /* 文本左对齐 */ font-size: 15px; /* 字体大小15像素 */ text-indent: 2em; /* 首行缩进2个文字大小空间 */ } p { text-align: left; /* 文本左对齐 */ font-size: 20px; /* 字体大小20像素 */ text-indent: 2em; /* 首行缩进2个文字大小空间 */ } I figure life is a gift and I don't intend on wasting it. You never know what hand you're going to get dealt next. You learn to take life as it comes at you.   浏览器可以根据标题选择不同的样式达到浏览器中的切换效果，但是IE浏览器不支持，Firefox浏览器支持此效果。在火狐浏览器中，通过“查看”菜单进入“页面风格”选项进行选择切换。 链接式   链接是式通过HTML的标签，将外部样式表文件链接到HTML文档中，这是使用最多的方式，也是最实用的方式。此方法将HTML文档和CSS文件完全分离，实现结构层和表示层彻底分离，增强网页结构的扩展性和CSS样式的可维护性。示例： Test Web Forrest Gump Life was like a box of chocolates, you never know what you're gonna get. style.css文件代码如下： h3 { font-weight: normal; /* 取消标题默认加粗效果 */ height: 50px; /* 设置标签的高度 */ line-height:50px; /* 设置标签的行高 */ background-color:#660099; /* 设置背景颜色 */ } span { color: #F0F8FF; /* 字体颜色 */ font-weight: bold; /* 字体加粗 */ } style-1.css文件代码如下： p { color: #FF00FF; /* 字体颜色设置 */ font-weight: bold; /* 字体加粗 */ border-bottom:3px dashed #009933; /* 设置下边框线 */ line-height:30px; /* 设置行高 */ }   CSS文件可以放在不同的HTML文件中，使网站所有页面样式统一；方便管理，并且可以减少代码维护时间，当修改CSS文件时，所有应用此CSS文件的HTML文件都将更新。 导入样式 导入样式使用@import命令导入外部样式表，有六种书写方式： @import test.css; @import 'test.css'; @import \"test.css\"; @import url(test.css); @import url('test.css'); @import url(\"test.css\"); 示例如下： Test Web @import url(test.css); @import url(test1.css); body{ background-color:#660099; } Forrest Gump Life was like a box of chocolates, you never know what you're gonna get. 注意：导入样式和样式标签的前后不可颠倒，@import放在前面。 CSS样式表 一个或多个CSS样式可以组成一个样式表，样式表包括内部样式表和外部样式表。 内部样式表   内部样式表包含在标签内，一个标签就表示一个内部样式表。而通过标签的style属性定义的样式属性就不是样式表。 外部样式表   如果CSS样式被放置在网页文档外部的文件种，则称为外部样式表，一个CSS样式表文档就表示一个外部样式表。外部样式表也就是一个文本文件，扩展名为.css。可以在外部样式表文件顶部定义CSS源代码的字符编码，例如： @charset \"gb2312\"; 如果不设置，可以保留默认设置，浏览器会根据HTML文件的字符编码来解析CSS代码。 导入外部样式表 可以通过两种方式导入，之前有学习到。 使用标签导入 示例如下： 定义标签时有三个属性，href时必须设置属性： href：定义样式表文件url，即外部样式表文件的地址，可以是相对地址，也可以是绝对地址 rel：用于定义文档关联，这里表示关联样式表 type：定义导入文件类型，同style元素一样 title：这是可选样式表的标题，可选属性，当一个网页文档导入了多个样式表后，可以通过title属性值选择所要应用的样式表文件 使用@import关键字导入 在标签内使用@import关键字导入外部样式表，示例： @import url(test.css); @import url(test1.css); 二者比较 两种导入样式表的方法比较： link属性HTML标签，而@import是CSS提供的 页面被加载时，link会同时被加载，而@import引用的CSS会等到页面被加载完后在加载 @import只在IE5以上才能识别，link是HTML标签，无兼容性问题 link方式的样式表权重高于@import的权重 一般推荐link导入样式表方法，@import可以作为补充方法使用 CSS注释 比较简单，之前学习并示例过，不作过多学习。 CSS特性 层叠和继承是CSS样式两个最基本的特性。 CSS层叠性 CSS样式表的优先级 CSS可以将网页定义样式分为4种，优先级从高到低如下： 作者定义的样式：作者即创建人定义的样式，创建网站所编辑的CSS 用户定义的样式：用户也就是浏览网页的人所设置的样式 浏览器默认样式：就是浏览器默认的样式 HTML样式：表示元素的默认样式 在CSS2中，用户设置的样式设置了!important命令声明后，优先级高于作者声明的!important命令。 CSS样式的优先级 不同位置的样式其优先级也不同： 行内样式会优先于内嵌样式 内部样式表会优先于外部样式表 附加了!important关键字的声明拥有最高的优先级 同等条件下，距离应用对象的距离越近优先级越大，所以行内样式优先于内部样式和外部样式 在实际浏览器中，用户更改页面样式： 作者设计的样式能够覆盖浏览器默认设置的样式 用户在浏览器里设置的样式可以覆盖作者的样式 多个不同类型选择器同时为一个对象设置样式时，使用优先级加权值来确定优先级： 标签选择器：优先级加权值为1 伪元素或伪对象选择器：优先级加权值为1 类选择器：优先级加权值为10 属性选择器：优先级加权值为10 ID选择器：优先级加权值为100 其它选择器：优先级加权值为0，如通配选择器 计算规则如下： 统计选择器中ID选择器的个数，然后乘以100 统计选择器中类选择器的格式，然后乘以10 同期选择器中的标签选择器的个数，然后乘以1 根据上面计算规则，计算下面示例样式的加权值： h3{color:#FF00FF;} /* 加权值1分 */ .f14{font-size:15px;} /* 加权值10分 */ #head{width:960px;} /* 加权值100分 */ h3 .f14{font-weight:bold;} /* 加权值1+10分 */ #head h2{border:1px solid #ff73;} /* 加权值100+1分 */ div p{padding:0 10px;} /* 加权值1+1分 */ div #head{margin:0 auto;} /* 加权值1+100分 */ #head h2 span{float:right;} /* 加权值100+1+1分 */ #head .f14 em{float:right;} /* 加权值100+10+1分 */ #head .f14 span em{float:right;} /* 加权值100+10+1+1分 */ #head div h2 .f12 span em{color:#000;} /* 加权值100+1+1+10+1+1分 */   调整优先级还可以使用!important命令，表示最大优先级，拥有最终的样式控制权。必须把!important命令放在声明语句与分号之间，否则无效，示例如下： span{ font-size:40px !important;} 在特殊逻辑框架下，被继承的值具有特殊性0。示例如下： span{color:Gray;} #header{ color:Black;} Miracles happen every day.   示例中，虽然div具有100的加权值，但被span继承，特殊性就为0，而span选择器的特殊性虽然为1，单大于继承样式的特殊性，所以元素最后显示颜色为灰色。 CSS继承性 继承性指被包含的元素拥有外层元素的样式效果。 "},"17-HTML+CSS+JavaScript/02-CSS/02-CSS3-选择器.html":{"url":"17-HTML+CSS+JavaScript/02-CSS/02-CSS3-选择器.html","title":"CSS3-选择器","keywords":"","body":"CSS3-选择器 CSS3学习笔记，主要学习教程：《HTML5+CSS3+JavaScript从入门到精通(标准版)》未来科技编著。 CSS3选择器分类   根据所获取页面中元素的不同，可以把CSS3选择器分为5大类：基本选择器、组合选择器、伪类选择器、伪元素和属性选择器。其中伪类选择器分为6种：动态伪类选择器、目标伪类选择器、语言伪类、UI元素状态伪类选择器、结构伪类选择器和否定伪类选择器。 基本选择器 基本选择器分为：标签选择器、类选择器、ID选择器和通配选择器。 标签选择器   标签选择器直接引用HTML标签名称，也称为类型选择器。标签选择器可以快速、方便的控制页面标签的默认显示效果。如下示例演示如何在文档中定义标签样式： p { font-size:12px; /* 字体大小12像素 */ color:blue; /* 字体颜色伪蓝色 */ } 类选择器   类选择器能够为网页对象定义不同的样式，实现不同元素拥有相同的样式，相同元素的不同对象拥有不同的样式。类选择器以一个点.前缀开头，然后跟随随一个自定义的类名。应用类样式可以使用class属性来实现。示例如下： 类选择器 p {/* 段落默认样式 */ font-size:12px; /* 字体大小为12像素 */ color:red; /* 字体颜色为红色 */ } .font18px {/* 字体大小类 */ font-size:18px; /* 字体大小为18像素 */ } .underline {/* 下划线类 */ text-decoration:underline; /* 字体修饰为下划线 */ } .italic {/* 斜体类 */ font-style:italic; /* 字体样式为斜体 */ } Stupid is as stupid does. Miracles happen every day. You can not change the past. 示例说明： 示例中，在内部样式表中定义了3个类：font18px、underline和italic 段落文本中，第一段文本引用了underline，第二段文本标签引用了3个类，第三段引用了italic   如果把标签与类捆绑在一起来定义选择器，则可以限定类的使用范围，这样可以指定该类仅适用于特定的标签范围内，这种做法也称为指定类选择器。示例如下： p {/* 段落样式 */ font-size:12px; /* 字体大小为12像素 */ } .font18px {/* 类样式 */ font-size:18px; /* 字体大小为18像素 */ } p.font18px {/* 指定段落的类样式 */ font-size:24px; /* 字体大小为24像素 */ } Stupid is as stupid does. Miracles happen every day. You can not change the past. 在浏览器中显示结果：第一段字体大小为18px，第二段为24px，第三代为12px。 ID选择器   ID选择器以井号#作为前缀，然后是一个自定义ID名。应用ID选择器可以使用id属性来实现。示例如下： test #box {/* ID样式 */ background:url(images/2.jpg) center bottom; /* 定义背景图像并居中、底部对齐 */ height:400px; /* 固定盒子的高度 */ width:600px; /* 固定盒子的宽度 */ border:solid 2px red; /* 边框样式 */ padding:100px; /* 增加内边距 */ } To make each day count. 如果在上面示例中ID选择器前面加一个div标签，div#box选择器的优先级会大于#box选择器的优先级。 通配选择器   如果HTML所有元素都需要定义相同的样式，可以使用通配选择器，通配选择器用星号*表示。针对上面的示例，如果要清除边距样式，可以使用下面方法定义： * { margin:0; padding:0; } 组合选择器   把两个或多个基本选择器组合在一起，就形成了组合选择器，通过组合选择器可以精确匹配页面元素。 包含选择器 "},"17-HTML+CSS+JavaScript/02-CSS/05-CSS3-美化图像.html":{"url":"17-HTML+CSS+JavaScript/02-CSS/05-CSS3-美化图像.html","title":"CSS3-美化图像","keywords":"","body":"CSS3-美化图像 CSS3学习笔记，主要学习教程：《HTML5+CSS3+JavaScript从入门到精通(标准版)》未来科技编著。 设置背景图像 CSS3允许在同一个元素内叠加多个背景图像。backgroup属性有八个子属性： backgroup-image：定义背景图像 backgroup-color：定义背景颜色 backgroup-origin：指定背景的显示区域 backgroup-clip：指定背景的裁剪区域 backgroup-repeat：设置背景图像是否及如何重复铺排 backgroup-size：定义背景图像的大小 backgroup-position：设置背景图像的位置 backgroup-attachment：定义背景图像的显示方式 定义背景图像 示例如下： test .bg { background:url(images/1.jpg) no-repeat center 0px; background-size:cover; } Background test 定义显示方式 CSS使用backgroup-repeat属性控制背景图像的显示： repeat-x：背景图像在横向上平铺 repeat-y：背景图像在纵向上平铺 repeat：背景图像在横向和纵向平铺 no-repeat：背景图像不平铺 round：背景图像自动缩放直到适应且填充满整个容器 space：背景图像以相同的间距平铺且填充满整个容器或某个方向 示例： test .bg { background-image:url(images/1.jpg); background-repeat:no-repeat; background-size:contain; width:600px; height:100px; } Background test 定义显示位置   属性backgroup-position取值包括两个值，分别用来定位背景图像的x轴、y轴坐标，取值的单位没有限制。具体用法如下所示： backgroup-position:[left | center | right | top | bottom | | ] | [left | center | right | | ] [top | center | bottom | | ] | [center | [left | right] [ | ]? ]&& [center | [top | bottom] [ | ]? ] 示例： test .bg { background-image:url(images/1.jpg); background-repeat:no-repeat; background-size:contain; background-position:center; } Background test 定义固定背景 "},"17-HTML+CSS+JavaScript/02-CSS/15-CSS3-常用样式笔记.html":{"url":"17-HTML+CSS+JavaScript/02-CSS/15-CSS3-常用样式笔记.html","title":"CSS3-常用样式笔记","keywords":"","body":"CSS3-常用样式笔记 使用过程中遇到的一些样式记录。 CSS选择器 hover选择器 选择鼠标移到链接上的样式： ahover { background-color:yellow; } 可以用此来让一个图片隐藏，鼠标指向就显现设置样式，示例： .delete i { color: rgba(255, 255, 255, 0); } .delete i:hover { color: red; } 我是一个垃圾桶： 说明： 首先给标签i内容使用rgba(255, 255, 255, 0)设定了一个背景色为透明的 然后通过:hover选择器设置鼠标指向的颜色是红色，这样就达到了鼠标指向就显示的效果 同时在示例中使用Tooltip提示工具给样式增加了一个提示 学习参考链接：CSS :hover 选择器 待补充 "},"17-HTML+CSS+JavaScript/03-JavaScript/":{"url":"17-HTML+CSS+JavaScript/03-JavaScript/","title":"JavaScript","keywords":"","body":"JavaScript 简介   JavaScript（简称“JS”）是一种具有函数优先的轻量级，解释型或即时编译型的编程语言。 JavaScript官网：https://www.javascript.com/ JavaScript W3school网站教程：https://www.w3school.com.cn/js/index.asp JavaScript runoob网站教程:https://www.runoob.com/js/js-tutorial.html jQuery官方网站：https://jquery.com/ jQuery官方下载链接：https://jquery.com/download/ jQuery W3school网站教程：https://www.w3school.com.cn/jquery/index.asp jQuery runoob网站教程:https://www.runoob.com/jquery/jquery-tutorial.html Vue.js官网：https://cn.vuejs.org/ Vue.js官方文档：https://cn.vuejs.org/v2/api/ Vue.js官方中文文档：https://cn.vuejs.org/v2/guide/syntax.html Vue.js runoob网站教程:https://www.runoob.com/vue2/vue-tutorial.html Vue.js bootcss网站教程：https://vuejs.bootcss.com/guide/syntax.html HTML/CSS/JS 在线工具：https://c.runoob.com/front-end/61 内容 JavaScript-基础知识 Vue-基础知识 Vue-模板语法 Vue-条件和列表渲染 Vue-注意事项 "},"17-HTML+CSS+JavaScript/03-JavaScript/01-JavaScript-基础知识.html":{"url":"17-HTML+CSS+JavaScript/03-JavaScript/01-JavaScript-基础知识.html","title":"JavaScript-基础知识","keywords":"","body":"JavaScript-基础知识 "},"17-HTML+CSS+JavaScript/03-JavaScript/10-Vue-基础知识.html":{"url":"17-HTML+CSS+JavaScript/03-JavaScript/10-Vue-基础知识.html","title":"Vue-基础知识","keywords":"","body":"Vue-基础知识 学习过程中记录的笔记，学习教程及参考链接： Vue.js官方中文文档：https://cn.vuejs.org/v2/guide/syntax.html Vue.js runoob网站教程:https://www.runoob.com/vue2/vue-tutorial.html 使用在线工具： runoob.com菜鸟教程在线编辑器 安装及使用方法 安装 安装说明：https://cn.vuejs.org/v2/guide/installation.html 使用方法 可以下载安装后使用，也可以直接在线调用： 浏览器JavaScript控制台 打开及使用方法： FireFox和Chrome浏览器可以按F12打开JavaScript控制台，或者按Ctrl+Shift+i组合键。 打开后点击Console选项，即可进入JavaScript控制台 在JavaScript控制台可以输入相应的命令，例如输入app1.message='New message'可以改变app1中message的内容 在Accessibility选项中可以查看网页整体架构 声明式渲染 绑定文本 Vue.js的核心是允许采用简洁的模板语法来声明式地将数据渲染进DOM的系统： Vue声明式渲染示例 {{ message }} new Vue({ el:'#app', data: { message: 'Miracles happen every day!' } }) 示例说明： 示例中，script中的Vue的V需要大写，否则无效 修改app.message的值，HTML中``相应的更新 绑定元素 示例如下： Vue声明式渲染示例2 鼠标悬停几秒钟查看动态绑定的提示信息 var app1 = new Vue({ el:'#app-1', data: { message: '页面加载于 ' + new Date().toLocaleString() } }) 示例说明： 示例中鼠标指向文本，悬停几秒就可以看到提示信息 提示信息中new Date().toLocaleString()是获取的页面加载日期和时间 注意，id选择器选择时候选择script中el里面的内容 打开浏览器的JavaScript控制台，输入app1.message='New message'，可以看到绑定了title attribute的HTML已经进行了更新 条件与循环 条件 例如控制一个元素是否可见： Vue条件示例 不可见的 var app2 = new Vue({ el:'#app-2', data: { seen: false } }) 示例说明： 示例中的元素是不可见的，data中修改成seen:true，就可见了 在浏览器的JavaScript控制台，输入app2.seen= true也可以让元素可见 循环 指令v-for可以绑定数组的数据来渲染一个项目列表： Vue循环示例 {{ item.name }} var app3 = new Vue({ el:'#app-3', data: { items:[ { name:'Captain America'}, { name:'Wonder Woman'}, { name:'Iron Man'} ] } }) 示例说明： 在items列表中，每一项间隔注意加上逗号 在浏览器的JavaScript控制台，输入app3.items.push({ name: 'Thor' })，浏览器输出列表最后添加了一个新项目 处理用户输入 指令v-on 为了让用户和应用进行交互，可以用v-on指令添加一个事件监视器，通过它调用在Vue实例中定义的方法： Vue反转消息示例 {{ message }} 反转消息 var app4 = new Vue({ el:'#app-4', data: { message: 'Miracles happen every day.' }, methods:{ reverseMessage: function(){ this.message = this.message.split('').reverse().join('') } } }) 示例说明： 同样需要注意script每个项之间需要逗号隔开 点击反转消息按钮后，文本会显示成：.yad yreve neppah selcariM 在reverseMessage方法中，更新了应用的状态，但没有触碰DOM，所有的DOM操作都由Vue来处理，编写的代码只需要关注逻辑层面 指令v-model 指令v-model能实现表单输入和应用状态之间的双向绑定，示例： Vue v-model示例 {{ message }} var app5 = new Vue({ el:'#app-5', data: { message: 'Batman' } }) 示例说明： 在input对话框中输入啥内容，上面文本就显示啥内容 组件化应用构建   组件系统是Vue的一个重要概念，允许开发者使用小型、独立和通常可复用的组件构建大型应用。在Vue中，一个组件本质上是一个拥有预定义选项的Vue实例。Vue中注册组件很简单： //定义名为toto-item的新组件 Vue.component('todo-item',{ template:'这是个代办项' }) var app = new Vue(...) 创建一个todo-item组件的实例：   这样会为每个代办项渲染同样的文本，功能需求能从父作用域将数据传到子组件。修改一下组件的定义，使之能够接受一个prop： Vue.component('todo-item', { //todo-item组件现在接受一个\"prop\"，名为todo,类似于一个自定义attribute。 props: ['todo'], template: '{{ todo.text }}' }) 使用v-bind指令将待办项传到循环输出的每个组件中： Vue 组件构建示例 Vue.component('todo-item',{ props:['todo'], template: '{{ todo.name }}' }) var app6 = new Vue({ el:'#app-6', data: { heroList: [ {id:0,name:'Captain America'}, {id:1,name:'Iron Man'}, {id:2,name:'Wonder Woman'} ] } }) 示例说明： 示例中设法将应用分割成了两个更小的单元，子单元通过prop接口与父单元进行了良好的解耦 可以进一步改进todo-item组件，提供更为复杂的模板和逻辑，而不会影响到父单元 对比之前的v-for示例，效果看起来一样，不同的是HTML通过prop接口获取数据 "},"17-HTML+CSS+JavaScript/03-JavaScript/11-Vue-模板语法.html":{"url":"17-HTML+CSS+JavaScript/03-JavaScript/11-Vue-模板语法.html","title":"Vue-模板语法","keywords":"","body":"Vue-模板语法   Vue.js使用了基于HTML的模板语法，允许开发者声明式地将DOM绑定至底层Vue实例的数据。在底层的实现上，Vue将模板编译成虚拟DOM渲染函数。结合响应系统，Vue能够智能地计算出最少需要重新渲染多少组件，并把DOM操作次数减到最少。 学习过程中记录的笔记，学习教程及参考链接： Vue.js官方中文文档：https://cn.vuejs.org/v2/guide/syntax.html Vue.js runoob网站教程:https://www.runoob.com/vue2/vue-tutorial.html 使用在线工具： runoob.com菜鸟教程在线编辑器 插值 文本 使用“Mustache”语法(双大括号)的文本插值方式： Message: {{ message }} Message: {{ message }} 示例说明： Mustache标签将会被替代为对应数据对象上message的值，当绑定的数据对象上message发生了改变，插值处的内容都会更新 使用v-once指令，能执行一次性地插值，当数据改变时插值处的内容不会更新。注意这会影响到该节点上的其它数据绑定 原始HTML   双大括号会将数据解释为普通文本，而非HTML代码，如果是为了输出HTML代码，需要使用v-html指令。例如rawHtml内容为I am blue，示例如下： Using mustaches: {{ rawHtml }} Using v-html directive: Attribute Mustache语法不能作用在HTML attribute上，遇到这种情况应该使用v-bind指令： 对于布尔attribute(存在值就为true)，v-bind工作起来略有不同： Button   如果isButtonDisabled的值是null、undefined或false，则disabled attribute甚至不会被包含在渲染出来的button元素中。 使用JavaScript表达式   目前学习的只绑定简单的property键值。对于所有的数据绑定，Vue.js提供了完全的JavaScript表达式支持，示例如下: {{ number + 1 }} {{ ok ? 'YES' : 'NO' }} {{ message.split('').reverse().join('') }} 无效的情况示例： {{ var a = 1 }} {{ if (ok) { return message } }}   每个绑定都只能包含单个表达式，所以上面两个例子不会生效。这些表达式会在所属Vue实例的数据作用域下作为JavaScript被解析。 指令   指令(Directives)是带有v-前缀的特殊attribute。指令attribute的值预期是单个JavaScript表达式 (v-for是例外情况)。指令的作用是，当表达式的值改变时，将其产生的连带影响，响应式地作用于DOM。例如之前学习的v-if和v-bind等。 参数   一些指令能够接收一个参数，在指令名称之后以冒号表示。例如v-bind指令可以用于响应式地更新HTML attribute： ... ... 动态参数 从2.6.0开始，可以用方括号括起来的JavaScript表达式作为一个指令的参数： ... ... 示例说明： 示例中attributeName会被作为一个JavaScript表达式进行动态求值，求得的值将会作为最终的参数来使用 例如，如果你的Vue实例有一个data property attributeName，其值为\"href\"，那么这个绑定将等价于 v-bind:href 第二个示例中，当eventName的值为\"focus\"时，v-on:[eventName]等价于v-on:focus 对动态参数的值的约束   动态参数预期会求出一个字符串，异常情况下值为null。这个特殊的null值可以被显性地用于移除绑定。任何其它非字符串类型的值都将会触发一个警告。 对动态参数表达式的约束   某些字符，如空格和引号，放在HTML attribute名里是无效的。变通的办法是使用没有空格或引号的表达式，或用计算属性替代这种复杂表达式。例如： ... 在DOM中使用模板时，需避免使用大写字符来命名键名，因为浏览器会把attribute名全部强制转为小写： ... 修饰符   修饰符(modifier)是以半角句号.指明的特殊后缀，用于指出一个指令应该以特殊方式绑定。例如.prevent修饰符告诉v-on指令对于触发的事件调用event.preventDefault()： ... 缩写 v-前缀作为一种视觉提示，用来识别模板中Vue特定的attribute。 v-bind缩写 示例如下： ... ... ... v-on缩写 示例如下： ... ... ... "},"17-HTML+CSS+JavaScript/03-JavaScript/12-Vue-条件和列表渲染.html":{"url":"17-HTML+CSS+JavaScript/03-JavaScript/12-Vue-条件和列表渲染.html","title":"Vue-条件和列表渲染","keywords":"","body":"Vue-条件和列表渲染 学习过程中记录的笔记，学习教程及参考链接： Vue.js官方中文文档：https://cn.vuejs.org/v2/guide/syntax.html Vue.js runoob网站教程:https://www.runoob.com/vue2/vue-tutorial.html 使用在线工具： runoob.com菜鸟教程在线编辑器 条件渲染 v-if   指令v-if用于条件性地渲染一块内容，此块内容只会在指令的表达式返回truthy值的时候被渲染。可以搭配v-else使用，在2.1版本后还支持v-else-if。示例如下： username telephone email 在元素上使用v-if条件渲染分组   v-if是一个指令，必须将它添加到一个元素上。如果想切换多个元素，可以把一个元素当做不可见的包裹元素，并在上面使用v-if。最终的渲染结果将不包含元素。 Forrest Gump Stupid is as stupid does! Miracles happen every day! Shawshank Redemption 用key管理可复用的元素 示例如下： Vue v-if示例 Username: Email: Toggle login type var app = new Vue({ el:'#app', data: { loginType: 'username', }, methods:{ chinput:function(){ if(this.loginType == 'username'){ this.loginType = 'email' }else{ this.loginType = 'username' } } } }) 示例说明： 每次点击Toggle login type按钮，就会切换不同内容，即元素里面内容 示例中每次切换时，输入框都将被重新渲染。如果在input里面输入了内容，切换后重新渲染内容没有了 如果不使用key，用户在input里面输入了内容，点击切换，内容会保留，不会重新渲染 v-show   v-show指令是根据条件展示元素的选项。用法大致一样，不同的是带有v-show的元素始终会被渲染并保留在DOM中。v-show只是简单地切换元素的CSS property display。v-show不支持元素。格式如下 Hello! v-show使用示例如下： Vue v-show示例 {{ message }} 表格内容 图表内容 var app = new Vue({ el:'#app', data: { isShowTable: true, isShowChart: false, message: '切换图表', }, methods:{ click:function(){ if(this.isShowTable){ this.message = '切换表格'; }else{ this.message = '切换图表'; } this.isShowTable = !this.isShowTable; this.isShowChart = !this.isShowChart; } } }) 示例说明： 示例中data数据中的逗号必须要有（除最后一项），函数中的那个四个分号可有可无 之前不是用的click而用的switch，执行后通过浏览器F12看到了错误代码：avoid using JavaScript keyword as property name: \"switch\" 此示例参考了CSDN博客：https://blog.csdn.net/dadada_youzi/article/details/110238197 列表渲染 用v-for把一个数组对应为一组元素 可以用v-for指令基于一个数组来渲染一个列表，示例如下： Vue v-for {{ item.superhero }} var example1 = new Vue({ el: '#example-1', data: { items: [ { superhero: 'Batman' }, { superhero: 'Wonder Woman' } ] } }) 在v-for中，可以访问父作用域的property，还支持当前项的索引作为第二个参数，示例如下： Vue v-for {{ parentMessage }} : {{ index }} -- {{ item.superhero }} var example2 = new Vue({ el: '#example-2', data: { parentMessage:'DC', items: [ { superhero:'Batman' }, { superhero:'Wonder Woman' } ] } }) 说明： 当前项的索引作为第二个参数是可选的 也可以用of替代in作为分隔符 在v-for里使用对象 用v-for来遍历一个对象的property，示例如下： Vue v-for new Vue({ el: '#v-for-object', data: { object: { Superhero: 'Batman', Superpower: 'Rich', Address: 'Gotham ', } } }) 输出示例： · Batman · Rich · Gotham 也可以提供第二个的参数为property名称 (也就是键名),或者索引作为第三个参数： . : 输出示例： ``` Superhero: Batman Superpower: Rich Address: Gotham ```待补充 "},"17-HTML+CSS+JavaScript/03-JavaScript/13-Vue-组件_深入了解.html":{"url":"17-HTML+CSS+JavaScript/03-JavaScript/13-Vue-组件_深入了解.html","title":"Vue-组件_深入了解","keywords":"","body":"组件_深入了解 学习官方文档过程中记录的笔记。 组件_边界情况 官方参考文档链接：处理边界情况 循环引用 使用到实例：在System-Health-Management项目中的Aside.vue和ChildrenMenu.vue组件中使用到了。 递归组件 组件是可以在它们自己的模板中调用自身的，必需要设置name属性： export default { name: 'TestComponent' } 使用Vue.component全局注册一个组件时，这个全局的ID会自动设置为该组件的name选项: Vue.component('TestComponent', { // ... })   需要确保递归调用是条件性的 (例如使用最终会得到false的v-if)。直接引用不加条件时候，会导致max stack size exceeded错误，陷入死循环。 实例 "},"17-HTML+CSS+JavaScript/03-JavaScript/20-Vue-注意事项.html":{"url":"17-HTML+CSS+JavaScript/03-JavaScript/20-Vue-注意事项.html","title":"Vue-注意事项","keywords":"","body":"Vue-注意事项 学习过程中记录的一些注意事项。 插值符注意事项   Vue中，插值符号用两个双括号表示：{{ value }}，如果使用Python开发，可能会用到jinja2，在jinja2中，变量表示方法也是两个双扩号：{{ value }}。可以通过Vue的delimiters修改插值符号，避免冲突。也可以修改jinja2的变量表示方法，这里示例修改Vue，例如学习基础知识时候示例： Vue声明式渲染示例 {{ message }} new Vue({ el:'#app', data: { message: 'Miracles happen every day!' } }) 修改后如下： Vue声明式渲染示例 {[ message ]} new Vue({ el:'#app', data: { message: 'Miracles happen every day!' }, delimiters:['{[', ']}'] }) 注意事项： delimiters可以插在同级别任意位置，可以在el或data前，或者在其后面 注意如果是插在最后一项的后面，注意在此项后面加上逗号，示例中插在data后面，data结束增加了逗号 如果是插在最前面或者中间，注意在delimiters结尾加上逗号：delimiters:['{[', ']}'], "},"17-HTML+CSS+JavaScript/03-JavaScript/21-Vue-代码调试.html":{"url":"17-HTML+CSS+JavaScript/03-JavaScript/21-Vue-代码调试.html","title":"Vue-代码调试","keywords":"","body":"Vue-代码调试 参考官方文档学习及使用过程中记录的笔记。 VScode中调试 参考文档： Vue.js官方文档-在VS Code中调试 先决条件 在VScode中安装相应插件,我使用的Firefox，链接： Debugger for Firefox 在浏览器中展示源代码   在VS Code调试Vue组件之前，需要更新webpack配置以构建source map。之后，调试器就有机会将一个被压缩的文件中的代码对应回其源文件相应的位置。项目根目录下创建vue.config.js文件，写入代码示例如下： module.exports = { configureWebpack: { devtool: 'source-map' } } 如果写错到了bable.config.js文件里面，运行项目会报错： ERROR Error: Unknown option: .configureWebpack. Check out https://babeljs.io/docs/en/babel-core/#options for more information about options. 从VS Code启动应用   点击左侧Activity Bar里的Run and Debug图标来到Debug视图(Ctrl Shift D)，然后点击Create a launch.json file来配置一个launch.json的文件，选择Firefox环境。然后将生成的launch.json的内容替换成为相应的配置： { \"version\": \"0.2.0\", \"configurations\": [ { \"type\": \"firefox\", \"request\": \"launch\", \"name\": \"vuejs: firefox\", \"url\": \"http://localhost:8080\", \"webRoot\": \"${workspaceFolder}/src\", \"pathMappings\": [{ \"url\": \"webpack:///src/\", \"path\": \"${webRoot}/\" }] } ] } 使用示例 以System-Health-Management项目为例，出现问题时获取不到菜单数据。 设置断点 在ChildrenMenu.vue组件中，第二行代码： 在其前面设置代码，看看children内容，设置后运行项目： $ npm run serve   回到Debug视图，选择vuejs:firefox配置，然后按F5或点击绿色的play按钮。会自动弹出新的浏览器实例打开http://localhost:8080，设置的断点现在被命中了。 故障排查   在Debug视图的右下方的DEBUG CONSOLE中，会有相关的信息，看是否满足代码的需求的数据。如果此处判断不了故障原因，设置其它断点，继续排查。 此次断点看到的内容： Array(1) [\"1\"] 0:\"1\" length:1 __proto__:Array(0) 再次设置断点，运行后感觉卡住不动DEBUG CONSOLE中会有如下信息： [HMR] Waiting for update signal from WDS... 找到node_modules->webpack->hot文件夹下log.js文件，使用Ctrl+/注释部分内容，示例： module.exports = function(level, msg) { // if (shouldLog(level)) { // if (level === \"info\") { // console.log(msg); // } else if (level === \"warning\") { // console.warn(msg); // } else if (level === \"error\") { // console.error(msg); // } // } }; 参考链接：[HMR] Waiting for update signal from WDS…   设置后这条等待信息没有了，运行后有时可以看到输出有时等半天也没结果。后来又查了查，这个不是错误，只是说当您保存文件时它已准备好刷新，因此无需手动刷新。 当然我试了试手动刷新，好像也行。 参考链接： Waiting for update signal from WDS Vue.js官方文档:runtimeCompiler 获取菜单问题最后排查到了原因，是因为把mounted()写到了methods里面，错误代码示例： methods: { openPage(url) { this.$router.push(url); }, handleOpen(key, keyPath) { console.log(key, keyPath); }, handleClose(key, keyPath) { console.log(key, keyPath); }, click:function(){ if(this.isCollapse){ this.foldicon = 'el-icon-s-fold'; }else{ this.foldicon = 'el-icon-s-unfold'; } this.isCollapse = !this.isCollapse; }, mounted(){ getMenu().then(resp => { this.sideMenuList = resp }) } } Vue Devtools 待补充 "},"17-HTML+CSS+JavaScript/04-Bootstrap/":{"url":"17-HTML+CSS+JavaScript/04-Bootstrap/","title":"Bootstrap","keywords":"","body":"Bootstrap 简介   Bootstrap来自Twitter，是目前最受欢迎的前端框架。Bootstrap是基于HTML、CSS、JAVASCRIPT，用于开发响应式布局、移动设备优先的WEB项目。 官方网站：https://getbootstrap.com/ 官方文档：https://getbootstrap.com/docs/5.0/getting-started/introduction/ Bootstrap GitHum：https://github.com/twbs/bootstrap Bootstrap中文网：https://www.bootcss.com/ Bootstrap文档：https://v3.bootcss.com/ Bootstrap GitHub：https://github.com/twbs/bootstrap Bootstrap图标库：https://icons.bootcss.com/ Bootstrap runoob教程：runoob.com 中文教程 Bootstrap可视化布局系统：https://www.bootcss.com/p/layoutit/ 内容 Bootstrap-下载及使用 Bootstrap-布局组件 Bootstrap-插件 "},"17-HTML+CSS+JavaScript/04-Bootstrap/01-Bootstrap-下载及使用.html":{"url":"17-HTML+CSS+JavaScript/04-Bootstrap/01-Bootstrap-下载及使用.html","title":"Bootstrap-下载及使用","keywords":"","body":"Bootstrap-下载及使用 学习过程中记录的笔记，学习教程及参考链接： runoob.com Bootstrap教程 bootcss.com Bootstrap教程 bootcss.com Bootstrap教程 Bootstrap官方教程 bootcss.com 图标使用 简介   Bootstrap是一个用于快速开发Web应用程序和网站的前端框架。Bootstrap是基于HTML、CSS、JAVASCRIPT的。Bootstrap包的内容： 基本结构：提供了一个带有网格系统、链接样式、背景的基本结构 CSS：全局的CSS设置、定义基本的HTML元素样式、可扩展的class，以及一个先进的网格系统 组件：包含了多个可重用的组件，用于创建图像、下拉菜单、导航、警告框、弹出框等等 JavaScript插件：包含了多个自定义的jQuery插件 定制：可以定制Bootstrap的组件、LESS变量和 Query插件来得到自己的版本 下载 相关下载链接： Bootstrap官方下载地址：Bootstrap官方下载链接 jQuery官方下载链接：https://jquery.com/download/ Bootstrap下载说明： 下载已编译的版本：bootstrap-5.0.0-beta2-dist.zip 解压后即可使用，一共两个文件夹：css和js 文件中bootstrap.*是已编译的CSS和JS 文件中bootstrap.min.*是已编译及压缩的CSS和JS jQuery下载说明同上，还有其它下载安装方法，可以参考官方文档说明。 使用方法 通过下载文件使用 根据上面方法下载文件后，直接拷贝到文件夹中即可使用，示例： 通过CDN服务使用 其实就是在线引用，不需要下载，官方文档示例如下： 国内推荐使用Staticfile CDN上的库，使用示例： 国内推荐CDN服务：http://staticfile.org/国外推荐CDN服务：https://cdnjs.com/官方文档使用CDN：https://www.jsdelivr.com/ bootstrap图标 Bootstrap图标库：https://icons.bootcss.com/下载地址：https://github.com/twbs/icons/releases/tag/v1.4.0 使用同样可以下载后在HTML中加载，也可以通过公共CDN加载，示例: @import url(\"https://cdn.jsdelivr.net/npm/bootstrap-icons@1.4.0/font/bootstrap-icons.css\"); 使用方法示例 内嵌方式： 利用SVG sprite和元素即可插入任何图标: 作为外部图片引用： 使用HTML标签添加对应的class名称： CSS方式,在CSS中使用SVG图标： .bi::before { display: inline-block; content: \"\"; vertical-align: -.125em; background-image: url(\"data:image/svg+xml,\"); background-repeat: no-repeat; background-size: 1rem 1rem; } 可访问性：如果图标不是纯装饰性的，确保提供适当的替代性文本: 当图标获取不到时候，就会显示文本Bootstrap。 使用示例及说明 使用示例一 使用示例如下： Bootstrap使用测试 示例表格 The system disk performance is follow: Disk kbps tps max avg max avg hdisk2 1.4 1.1 5 1.7 图标示例 这是一棵树： 这是一棵大绿树： 闹钟图标： 示例说明： 示例中使用的是加载本地的CSS文件和JS文件，图标也是单独下载的图标库 示例中使用了响应式Web设计，是一个让用户通过各种尺寸的设备浏览网站获得良好的视觉效果的方法 示例中使用了thead和tbody元素，默认不会影响表格的布局，可以使用CSS来为这些元素定义样式，从而改变表格的外观 务必在bootstrap.js之前引入jQuery文件，Bootstrap的所有JavaScript插件都依赖jQuery 关于响应式设计的说明：Bootstrap响应式设计 使用示例二 示例代码如下： Bootstrap使用测试 图像示例 图片以椭圆型展示： 图标示例 云图标: 信件图标: 搜索图标: 打印图标: 下载图标： 示例说明： 示例中采用线上加载CSS和JS文件的，版本有点老 示例中加载的CSS文件中有一些图标，可以直接使用 "},"17-HTML+CSS+JavaScript/04-Bootstrap/02-Bootstrap-布局组件.html":{"url":"17-HTML+CSS+JavaScript/04-Bootstrap/02-Bootstrap-布局组件.html","title":"Bootstrap-布局组件","keywords":"","body":"Bootstrap-下载及使用 学习过程中记录的笔记，学习教程及参考链接： runoob.com Bootstrap教程 bootcss.com Bootstrap教程 bootcss.com Bootstrap教程 Bootstrap官方教程 bootcss.com 图标使用 使用在线工具： HTML/CSS/JS 在线工具 Bootstrap可视化布局系统 导航 示例一 根据教程写了一个简单网页头部导航： WEB导航器 网站导航器 说明： 前面是一个导航图标：bi-cursor-fill 然后是网页名称，用列表形式做的 最后是github图标，在导航栏最右边，点击转向指定网站 示例二 同样是横向的导航，增加了一个搜索框： WEB导航器 Home Profile Messages More About License Other Contact us Search 示例说明： 示例中采用横向显示的导航菜单，最后一个元素带下拉菜单 增加了一个搜索框在最右边 示例三 垂直导航示例： WEB导航器 分类列表 小型机 存储设备 交换机 功能列表 添加 导入 帮助 Forrest Gump Life was like a box of chocolates, you never know what you're gonna get. 查看更多 » 示例说明： 导航菜单采用垂直显示方式，并且使用.col-md-*栅格类分配了2格位置 右边分配了10格位置，用于显示正文 导航条 导航条是在网站中作为导航页头的响应式基础组件，导航条示例如下： 网页导航 Toggle navigation &nbsp;&nbsp;My Navigator &nbsp;&nbsp;Home(current) Profile Message Action &nbsp;&nbsp;Add &nbsp;&nbsp;Import &nbsp;&nbsp;Delete &nbsp;&nbsp;Refresh &nbsp;&nbsp;Download About &nbsp;&nbsp;Share &nbsp;&nbsp;GitHub &nbsp;&nbsp;Email &nbsp;&nbsp;View License &nbsp;&nbsp;Search "},"17-HTML+CSS+JavaScript/04-Bootstrap/03-Bootstrap-插件.html":{"url":"17-HTML+CSS+JavaScript/04-Bootstrap/03-Bootstrap-插件.html","title":"Bootstrap-插件","keywords":"","body":"Bootstrap-插件 学习过程中记录的笔记，学习教程及参考链接： runoob.com Bootstrap教程 bootcss.com Bootstrap教程 Bootstrap官方教程 bootcss.com 图标使用 使用在线工具： HTML/CSS/JS 在线工具 Bootstrap可视化布局系统 模态框   模态框（Modal）是覆盖在父窗体上的子窗体。目的是显示来自一个单独的源的内容，可以在不离开父窗体的情况下有一些互动，子窗体可提供信息、交互等。 简单模态框 示例代码如下： 模态框示例 &nbsp;&nbsp;Share &times; Share this website Share link: Close 示例中采用button按钮方式出发，同样，可以采用链接方式进行触发,将button标签修改为： &nbsp;&nbsp;Share 示例说明： 使用按钮和链接方式几乎一样，除了样式有所差异 在标签中，data-target=\"#myModal\"是想要在页面上加载的模态框的目标 在标签中，href=\"#myModal\"是想要在页面上加载的模态框的目标 在class=\"modal fade\"中： .modal，用来把 的内容识别为模态框 .fade类，当模态框被切换时，它会引起内容淡入淡出，不想要删掉即可 属性aria-labelledby=\"myModalLabel\"：引用模态框的标题 属性aria-hidden=\"true\"：用于保持模态窗口不可见，直到触发器被触发为止 中modal-header是为模态窗口的头部定义样式的类 class=\"close\"，close是一个CSS class，用于为模态窗口的关闭按钮设置样式 data-dismiss=\"modal\"是一个自定义的HTML5 data属性,在这里用于关闭模态窗口 class=\"modal-body\"是Bootstrap的一个CSS class，用于为模态窗口的主体设置样式 class=\"modal-footer\"是Bootstrap的一个CSS class，用于为模态窗口的底部设置样式 data-toggle=\"modal\"是HTML5自定义的data 属性data-toggle用于打开模态窗口 数据交互模态框 示例代码如下： 模态框示例 &nbsp;&nbsp;Add &times; Add Data Class Name Type Name Name Location Close &nbsp;&nbsp;Save 示例说明： 此示例采用链接方式触发模态框，和按钮没什么区别 示例中增加了一些输入选项，底部按钮增加提交保存按钮 提示工具   提示工具（Tooltip）插件根据需求生成内容和标记，默认情况下是把提示工具（tooltip）放在它们的触发元素后面。两种方式添加提示工具： 鼠标悬停 $('#identifier').tooltip(options) 示例如下： 提示工具示例 Tooltip on bottom Tooltip on bottom Tooltip on top Tooltip on left $(function(){ $('[data-toggle=\"tooltip\"]').tooltip() }) 进一步使用JavaScript触发提示工具示例： Tooltip方法show I'am Header2\"> Tooltip方法options. $(function () { $('.tooltip-show').tooltip('show');}); $(function () { $(\".tooltip-options a\").tooltip({html : true });}); 示例说明： 注意要留有空间，要不然不会弹出来，达不到预期效果 Tooltip插件不是纯CSS插件，如需使用该插件，必须用jQuery激活它（读取js）。示例中的JS脚本即是激活方法 标签页（Tab）插件   标签页（Tab）通过结合一些data属性，可以创建一个标签页界面。通过这个插件您可以把内容放置在标签页或者是胶囊式标签页甚至是下拉菜单标签页中。 用法 通过data属性：需要添加data-toggle=\"tab\"或data-toggle=\"pill\"到锚文本链接中: Home ... 可以使用Javascript来启用标签页，如下所示： $('#myTab a').click(function (e) { e.preventDefault() $(this).tab('show') }) 示例 示例如下： 标签页tab插件 Main Category IBM Python IBM Home Page IBM官方中文网站 IBM Knowledge Center IBM Fix Central IBM Ecurep Python Panel content flask Panel content 示例说明： 示例中，第一个里面有class=\"active\"，其它的添加了会不生效 示例中，点击不同的按钮，就会切换对应的内容块 待补充 "},"17-HTML+CSS+JavaScript/04-Bootstrap/10-Bootstrap-使用实例.html":{"url":"17-HTML+CSS+JavaScript/04-Bootstrap/10-Bootstrap-使用实例.html","title":"Bootstrap-使用实例","keywords":"","body":"Bootstrap-使用实例 使用过程中遇到的一些需求，实现方法记录下来。 模态框相关 模态框&提示工具混用 使用示例代码如下： 模态框&提示工具混用 .deleteicon i { color: rgba(255, 255, 255, 0); } .deleteicon i:hover { color: red; } 垃圾桶： &times; No infomation Infomation is adding... Close 示例说明： 示例中，使用CSS样式将图标隐藏，使用:hover选择器设置鼠标指向的颜色是红色 鼠标指向图标后不仅显示了，还弹出提示框 点击图标，就会弹出对应的模态框 提示工具可以结合JavaScript做出更多样式或者效果 向模态框传入数据 代码示例如下： 向模态框传入数据 Delele Share GitHub &times; New message Recipient: Message: Close Send message $('#exampleModal').on('show.bs.modal', function (event) { var button = $(event.relatedTarget) // Button that triggered the modal var recipient = button.data('whatever') // Extract information from data-* attributes var modal = $(this) modal.find('.modal-title').text('New message to ' + recipient) modal.find('.modal-body input').val(recipient) }) 示例说明: 示例中，exampleModal可以自定义，按钮中、模态框中及JS中要对应一致 示例中，data-whatever=\"@github\"中的whatever可以自定义，同样需要和JS中对应 如果需要传入多个数据，可以继续加data属性,例如data-test=\"license\"，需要在JS中增加对应内容：var test = button.data('test') 通过jinja2传入了一个数据，是从一个字典对象通过key截取而来的数据，尝试直接传入字典对象，显示的只是个对象 参考及详细用法说明链接：https://v3.bootcss.com/javascript/#modals-related-target 以上示例结合到一起 要求效果就是： 是一个图标，例如垃圾桶图标 图标不显示，鼠标指向就显示出来并且指定颜色，例如红色 鼠标指向图标后出现提示工具提示相应内容 点击图标后，弹出对应的模态框 弹出的模态框中，有通过图标那边传入的数据 满足以上需求的图标HTML写法示例如下（其它全省略参考上面示例）： 待补充 "},"17-HTML+CSS+JavaScript/05-网页导航实例/":{"url":"17-HTML+CSS+JavaScript/05-网页导航实例/","title":"网页导航实例","keywords":"","body":"网页导航   近期学习了一些网站开发基础知识，参考了客户一个机房设备导航工具，然后用Flask搭建了一个个人导航工具，用来整理我多个浏览器中种类繁多、混乱不堪的bookmarks。 效果预览： "},"17-HTML+CSS+JavaScript/05-网页导航实例/01-Navigator-基础环境.html":{"url":"17-HTML+CSS+JavaScript/05-网页导航实例/01-Navigator-基础环境.html","title":"Navigator-基础环境","keywords":"","body":"Navigator-基础环境 基础环境搭建简介。 效果预览 选择一个主项目： 添加： 编辑： 删除： 基础环境准备 使用的windows系统，需要环境及使用版本： Python：Python 3.8.3 Flask：Flask 1.1.2 Jinja2：2.11.2 sqlite3 GitHub创建项目 创建了名为navigator的Repository，添加了.gitignore、LICENSE及README文件。 克隆到本地 克隆到本地： $ git clone git@github.com:bond-huang/navigator.git Cloning into 'navigator'... remote: Enumerating objects: 8, done. remote: Counting objects: 100% (8/8), done. remote: Compressing objects: 100% (6/6), done. remote: Total 8 (delta 1), reused 0 (delta 0), pack-reused 0 Receiving objects: 100% (8/8), 6.12 KiB | 783.00 KiB/s, done. Resolving deltas: 100% (1/1), done. 创建虚拟环境 git bash命令如下： $ python -m venv venv $ ls LICENSE README.md venv/ 打开cmd激活环境： D:\\navigator>venv\\Scripts\\activate (venv) D:\\navigator\\venv\\Scripts> 项目布局 布局如下： -- navigator |-- instance | `-- nav.sqlite |-- LICENSE |-- MANIFEST.in |-- nav | |-- db.py | |-- __init__.py | |-- navigation.py | |-- schema.sql | |-- static | | |-- nav.js | | `-- style.css | `-- templates | |-- base.html | |-- footer.html | |-- header.html | |-- index.html | `-- modal | |-- add.html | |-- edit.html | |-- empty.html | `-- license.html |-- README.md |-- setup.cfg |-- setup.py `-- tests |-- conftest.py |-- data.sql |-- test_db.py |-- test_factory.py `-- test_navigator.py 创建应用 创建目录nav并添加__init__.py文件，写入内容： import os from flask import Flask def create_app(test_config=None): # create and configure the app app = Flask(__name__,instance_relative_config=True) app.config.from_mapping( SECRET_KEY='dev', DATABASE=os.path.join(app.instance_path,'nav.sqlite'), ) if test_config is None: # load the instance config, if it exists, when not testing app.config.from_pyfile('config.py',silent=True) else: # load the test config if passed in app.config.from_mapping(test_config) # ensure the instance folder exists try: os.makedirs(app.instance_path) except OSError: pass # a simple page that says gump @app.route('/home') def home(): return 'Life was like a box of chocolates, \\ you never know what you\\'re gonna get.' return app 环境测试 测试环境是否可用： $ export FLASK_APP=nav $ export FLASK_ENV=development $ flask run * Serving Flask app \"nav\" (lazy loading) * Environment: development * Debug mode: on * Restarting with stat * Debugger is active! * Debugger PIN: 142-805-651 * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) 打开浏览器，输入地址http://127.0.0.1:5000/home看到__init__.py中home函数里面return内容表示正常。 定义数据库 连接数据库 在nav目录下创建db.py文件，写入内容： import sqlite3 import click from flask import current_app, g from flask.cli import with_appcontext def get_db(): if 'db' not in g: g.db = sqlite3.connect( current_app.config['DATABASE'], detect_types=sqlite3.PARSE_DECLTYPES ) g.db.row_factory = sqlite3.Row return g.db def close_db(e=None): db = g.pop('db',None) if db is not None: db.close() def init_db(): db = get_db() with current_app.open_resource('schema.sql') as f: db.executescript(f.read().decode('utf8')) @click.command('init-db') @with_appcontext def init_db_command(): # Clear the existing data and create new tables. init_db() click.echo('Initialized the database') def init_app(app): app.teardown_appcontext(close_db) app.cli.add_command(init_db_command) 创建表 在nav目录下创建schema.sql文件，写入内容： DROP TABLE IF EXISTS links; CREATE TABLE links ( id INTEGER PRIMARY KEY AUTOINCREMENT, maincategory TEXT NOT NULL, subcategory TEXT NOT NULL, urlname TEXT UNIQUE NOT NULL, urllocation TEXT NOT NULL ); 在应用中注册 写一个函数，把应用作为参数，在函数中进行注册（db.py文件中）： def init_app(app): app.teardown_appcontext(close_db) app.cli.add_command(init_db_command) 在__init__.py中导入并调用这个函数: ... from . import db db.init_app(app) return app 初始化数据库文件 停止之前的虚拟环境，然后激活环境： (venv) D:\\navigator\\venv\\Scripts>deactivate D:\\navigator\\venv\\Scripts>activate (venv) D:\\navigator\\venv\\Scripts> 设置FLASK_APP和FLASK_ENV并运行init-db命令： $ export FLASK_APP=nav $ export FLASK_ENV=development $ flask init-db Initialized the database Blueprints和视图 创建Blueprints   导航网站不需要认证，做个页面管理Blueprints即可。定义blueprints并注册到应用工厂，在nav目录下创建文件navigation.py并写入如下内容： from flask import( Blueprint,flash,g,redirect,render_template,request,url_for ) from werkzeug.exceptions import abort from nav.db import get_db bp = Blueprint('navigation',__name__) 在工厂中导入和注册蓝图，将新代码放在__init__.py的尾部，返回应用之前: from . import navigation app.register_blueprint(main.bp) app.add_url_rule('/',endpoint='index') 静态文件   存放图片，CSS及JS等，计划使用Bootstrap，Vue和jQuery，直接从网上获取，CSS全部用Bootstrap，JS会写一点东西，新建一个文件即可。在nav目录下新建目录static并创建文件nav.js。 删除和编辑图标使用了自定义样式： .editicon i { color: rgba(255, 255, 255, 0); } .editicon i:hover { color: green; } .deleteicon i { color: rgba(255, 255, 255, 0); } .deleteicon i:hover { color: red; } 编辑模态框使用的js： // editModal $('#editModal').on('show.bs.modal', function (event) { var button = $(event.relatedTarget) // Button that triggered the modal var link_id = button.data('link_id') // Extract information from data-* attributes var link_mcg = button.data('link_mcg') var link_scg = button.data('link_scg') var link_name = button.data('link_name') var link_url = button.data('link_url') var modal = $(this) $(\"#linkid\").attr(\"action\", link_id); $(\"#linkmcg\").attr(\"value\", link_mcg); $(\"#linkscg\").attr(\"value\", link_scg); $(\"#linkname\").attr(\"value\", link_name); $(\"#linkurl\").attr(\"value\", link_url); }) 索引 索引会显示所有内容，在navigation.py中继续写入一下内容： @bp.route('/') def index(): db = get_db() links = db.execute( 'SELECT * FROM links' ).fetchall() maincg_list = db.execute( 'SELECT distinct maincategory FROM links' ).fetchall() links_list = [] links.sort(key=itemgetter('maincategory')) for i,j in groupby(links,key=itemgetter('maincategory')): j = list(j) j.sort(key=itemgetter('subcategory')) sub_list = [] for x,y in groupby(j,key=itemgetter('subcategory')): y = list(y) subdict = {'sub_cg':x,'link':y} sub_list.append(subdict) maindict = {'main_cg':i,'sub_cg_list':sub_list} links_list.append(maindict) return render_template('index.html',links=links_list,maincg_list=maincg_list) 说明： 示例中红从数据库取出两个内容，第一个是表中所有内容，第二个只是取maincategory值并去重 示例中对数据进行了处理，其实就是分类处理，方便jinja2进行渲染 "},"17-HTML+CSS+JavaScript/05-网页导航实例/02-Navigator-网页模板.html":{"url":"17-HTML+CSS+JavaScript/05-网页导航实例/02-Navigator-网页模板.html","title":"Navigator-网页模板","keywords":"","body":"Navigator-网页模板 网页模板内容简介。 基础模板 base.html 在nav目录下新建目录templates并创建文件base.html，内容如下： Navigator-{% block title %}{% endblock %} {% block css %} {% endblock %} {% include \"header.html\" %} {% block category %} {% endblock %} {% block content %} {% endblock %} {% include \"modal/add.html\" %} {% include \"modal/edit.html\" %} {% include \"modal/license.html\" %} {% include \"modal/empty.html\" %} {% include \"footer.html\" %} {% block scripts %} {% endblock %} 创建index.html文件,在index.html文件中写入如下内容： {% extends 'base.html' %} {% block header %} {% block title %}Home{% endblock %} {% endblock %} {% block category %} Main Category {% for item in maincg_list %} {{ item['maincategory'] }} {% endfor %} {% endblock %} {% block content %} {% for maincg in links %} {% for subcg in maincg['sub_cg_list'] %} {{ subcg['sub_cg'] }} {% for link in subcg['link'] %} {{ link['urlname'] }}&nbsp; {% endfor %} {% endfor %} {% endfor %} {% endblock %} 创建头部文件 头部文件head.html： Toggle navigation &nbsp;&nbsp;My Navigator &nbsp;&nbsp;Home(current) Profile Message Action &nbsp;&nbsp;Add &nbsp;&nbsp;Import &nbsp;&nbsp;Refresh &nbsp;&nbsp;Download More &nbsp;&nbsp;Share &nbsp;&nbsp;GitHub &nbsp;&nbsp;Email &nbsp;&nbsp;Help View License &nbsp;&nbsp;Search 创建底部文件 底部文件footer.html，暂时没写内容。 模态框 添加模态框： 添加模态框内容如下： &times; Add Data Main Category Sub Category Name Location Cancel 编辑模态框： 编辑模态框内容如下： &times; Edit the record Main Category Sub Category Name Location Cancel 空模态框： 空模态框内容如下： &times; No infomation Infomation is adding... Close "},"17-HTML+CSS+JavaScript/05-网页导航实例/03-Navigator-数据交互.html":{"url":"17-HTML+CSS+JavaScript/05-网页导航实例/03-Navigator-数据交互.html","title":"Navigator-数据交互","keywords":"","body":"Navigator-数据交互 目前只写了三个功能:添加，编辑和删除。 模板渲染 将数据库中的数据传入到HTML中，是用过jinja2模板实现，即前面介绍的索引内容，此处不作详述。 数据交互 添加 用于处理POST请求在数据库中添加数据，navigator.py文件中添加： @bp.route('/', methods=('POST',)) def add(): if request.method == 'POST': maincategory = request.form['maincategory'] subcategory = request.form['subcategory'] urlname = request.form['urlname'] urllocation = request.form['urllocation'] error = None if not maincategory: error = 'Main Category is required.' elif not subcategory: error = 'Sub Category is required.' elif not urlname: error = 'URL Name is required.' elif not urllocation: error = 'URL Location is required.' if error is not None: flash(error) else: db = get_db() db.execute( 'INSERT INTO links (maincategory, subcategory, urlname, urllocation)' ' VALUES (?, ?, ?, ?)', (maincategory, subcategory, urlname, urllocation) ) db.commit() return redirect(url_for('navigation.index')) return render_template('index.html') 说明： POST请求是通过添加模态框（）发起的，此处接收默认的POST请求 示例中检查了是否获取的数据为空，如果都不为空，则调用数据库并插入数据 编辑 用于处理POST请求在数据库中编辑数据，navigator.py文件中添加： @bp.route('/', methods=('GET', 'POST')) def edit(id): if request.method == 'POST': maincategory = request.form['maincategory'] subcategory = request.form['subcategory'] urlname = request.form['urlname'] urllocation = request.form['urllocation'] error = None if not maincategory: error = 'Main Category is required.' elif not subcategory: error = 'Sub Category is required.' elif not urlname: error = 'URL Name is required.' elif not urllocation: error = 'URL Location is required.' if error is not None: flash(error) else: db = get_db() db.execute( 'UPDATE links SET maincategory = ? , subcategory = ?, urlname = ?, urllocation = ?' ' WHERE id = ?', (maincategory, subcategory, urlname, urllocation, id) ) db.commit() return redirect(url_for('navigation.index')) return render_template('index.html') 编辑同样采用POST请求，但是指定了一个ID，这样发起的POST就不会默认到添加视图中去了: 对应的action属性，id是获取JS的内容传入到aciton中： $(\"#linkid\").attr(\"action\", link_id); JS中的link_id变量获取： var link_id = button.data('link_id') 上面data内容中的link_id通过HTML中的data属性获取的： data-link_id=\"{{ link['id'] }}\" 最后数据是通过jinja2模板渲染从数据库中获取的。 删除 用于处理POST请求在数据库中删除数据，navigator.py文件中添加： @bp.route('//delete', methods=('GET', 'POST')) def delete(id): db = get_db() db.execute('DELETE FROM links WHERE id = ?', (id,)) db.commit() return redirect(url_for('navigation.index'))   删除数据同样获取了数据的ID进行对应，如果只有ID，POST请求会先到编辑视图里面，所以此处指向了一个页面，但是此页面是不存在的，对应HMTL中内容如下： href=\"{{ url_for('navigation.delete', id=link['id']) }}\" 待补充 "},"18-简单WEB项目/":{"url":"18-简单WEB项目/","title":"简单WEB项目","keywords":"","body":"简单WEB项目 一边学习一边做，记录做的简单项目。 内容 System-Health-Management "},"18-简单WEB项目/01-System-Health-Management/":{"url":"18-简单WEB项目/01-System-Health-Management/","title":"System-Health-Management","keywords":"","body":"System-Health-Management   之前此项目使用Flask+Jinja2框架写了不少HTML代码，后来想想之前学了几天的Vue.js没用到，Vue.js目前也比较流行，决定使用Vue.js，并实现前后端分离，边学边做。 内容 SHM-基础环境准备 "},"18-简单WEB项目/01-System-Health-Management/01-SHM-基础环境准备.html":{"url":"18-简单WEB项目/01-System-Health-Management/01-SHM-基础环境准备.html","title":"SHM-基础环境准备","keywords":"","body":"SHM-基础环境准备 边学边做，学习参考文档和链接： Vue CLI官方文档：https://cli.vuejs.org/zh/ CSDN博客(Python之简)：Flask-Vue前后端分离 node.js官网：https://nodejs.org/en/ bootcss网站Bootstrap文档：https://v3.bootcss.com/ 软件安装 使用windows环境下的git bash，代码用VS code编写。 软件类型及版本 需要的软件及版本： Python:Python 3.8.3 Flask:Flask-1.1.2 Flask-Cors:Flask-Cors-3.0.10 Vue.js:@vue/cli 4.5.12 Node.js:v14.16.1 npm:6.14.12 Bootstrap:bootstrap@3.3.7 jQuery:jquery@2.2.4 构建虚环境 构建虚拟环境： $ mkdir flask-vue-shm $ cd flask-vue-shm $ python -m venv venv $ source venv/Scripts/activate (venv) $ ls venv/ (venv) 测试flask项目 安装Flask-Cors： $ pip install Flask Flask-Cors ... Successfully installed Flask-1.1.2 Flask-Cors-3.0.10 Jinja2-2.11.3 MarkupSafe-1.1.1 Six-1.15.0 Werkzeug-1.0.1 click-7.1.2 itsdangerous-1.1.0 创建测试flask项目，在根目录下创建app.py文件并写入如下内容： from flask import Flask,jsonify from flask_cors import CORS app = Flask(__name__) CORS(app) @app.route('/gump') def Forrest_Gump(): return jsonify('Life was like a box of chocolates, you never know what you\\'re gonna get.') if __name__ == '__main__': app.run() 运行项目进行测试： $ python app.py * Serving Flask app \"app\" (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) 在浏览器中输入http://127.0.0.1:5000/gump可以看到json格式的内容。 安装@vue/cli 下载安装node.js，版本node-v14.16.1-x64,安装完成后查看版本，然后全局安装@vue/cli： C:\\Users\\QianHuang>node -v v14.16.1 C:\\Users\\QianHuang>npm -v 6.14.12 C:\\Users\\QianHuang>npm install -g @vue/cli C:\\Users\\QianHuang>vue --version @vue/cli 4.5.12   发现目前在git bash的虚拟环境中，运行不了node和vue命令，重启虚拟环境不行，重启下git bash，然后进入虚拟环境，就可以运行vue相关命令。 新建项目 UI创建项目 新建项目步骤如下： 运行vue ui命令打开UI界面Vue Project Manager 选择Create选项并选择Create a new project hear 在Details页面中输入项目名称，Package manager选择默认，Git repository建议开启 在Presets页面中我选择了Default preset(Vue 3 preview) 点击Create Project 等待几分钟后，创建成功，进入Project dashboard页面 回到Vue Project Manager界面，在项目后面点击Open in editor可以打开VS code进行编辑 添加插件   默认安装了一些插件。在Vue Project Manager管理界面Plugins菜单中我添加了cli-plugin-router插件，在src目录下生成了router文件夹和views文件夹。启动服务时候报错： $ npm run serve > shm@0.1.0 serve D:\\flask-vue-shm\\shm > vue-cli-service serve INFO Starting development server... 98% after emitting CopyPlugin ERROR Failed to compile with 1 error 下午10:24:51 This dependency was not found: * vue-router in ./src/router/index.js To install it, you can run: npm install --save vue-router 根据提示运行命令即可。 启动项目 运行下面命令启动项目： $ npm run serve > shm@0.1.0 serve D:\\flask-vue-shm\\shm > vue-cli-service serve INFO Starting development server... 98% after emitting CopyPlugin DONE Compiled successfully in 4938ms 下午8:47:44 App running at: - Local: http://localhost:8080/ - Network: http://192.168.1.4:8080/ Note that the development build is not optimized. To create a production build, run npm run build. 我使用Vue3，如果运行下面命令会报错： $ npm run dev npm ERR! missing script: dev 打开浏览器可以看到Vue项目默认主页：Welcome to Your Vue.js App 添加组件 在VS code中添加文件shm/scr/components/gump.vue，内容如下： {{ msg }} export default { name : 'Gump', data() { return { msg: 'Miracles happen every day.' } } } 更新shm/scr/router/index.js，将/gump映射到Gump组件： import { createRouter, createWebHashHistory } from 'vue-router' import Home from '../views/Home.vue' import Gump from '../components/gump.vue' const routes = [ { path: '/', name: 'Home', component: Home }, { path: '/gump', name: 'Gump', component: Gump }, { path: '/about', name: 'About', // route level code-splitting // this generates a separate chunk (about.[hash].js) for this route // which is lazy-loaded when the route is visited. component: () => import(/* webpackChunkName: \"about\" */ '../views/About.vue') } ] const router = createRouter({ history: createWebHashHistory(), routes }) export default router 在APP.vue中加入gump内容： Home | About | Gump 保存后刷新页面，可以看到默认的导航后有Gump链接，点击进入http://localhost:8080/#/gump页面。 连接前后端 安装axios 安装axios： $ npm install axios --save 更新组件 更新gump.vue组件，示例如下： {{ msg }} import axios from 'axios'; export default { name : 'Gump', data() { return { msg: 'Miracles happen every day.' } }, methods: { getMessage() { const path = 'http://127.0.0.1:5000/gump'; axios.get(path) .then((res) => { this.msg = res.data; }) .catch((error) => { // eslint-disable-next-line console.error(error); }) } }, created() { this.getMessage(); } } 运行测试 启动flask： $ python app.py * Serving Flask app \"app\" (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit) 启动serve： $ npm run serve > shm@0.1.0 serve D:\\flask-vue-shm\\shm > vue-cli-service serve INFO Starting development server... 98% after emitting CopyPlugin DONE Compiled successfully in 6519ms 下午11:52:57 App running at: - Local: http://localhost:8080/ - Network: http://192.168.1.2:8080/ 打开http://127.0.0.1:5000/gump可以看到的之前app.py返回的json内容： Life was like a box of chocolates, you never know what you're gonna get. 打开http://localhost:8080,点击导航跳转到http://localhost:8080/#/gump,内容同上，也就是呈现了后端返回的数据，实现了数据交互。 引入Bootstrap   之前搞这个小项目Flask+Jinja2写了一部分，没有使用Vue.js，HTML代码也写了点，之前用的bootstrap版本是3.3.7，不知道新版有啥差异，这里还是使用3.3.7，安装示例： $ npm install jquery@2.2.4 + jquery@2.2.4 added 1 package from 1 contributor and audited 1346 packages in 18.735s $ npm install bootstrap@3.3.7 + bootstrap@3.3.7 added 1 package from 1 contributor and audited 1345 packages in 15.19s $ npm install bootstrap-icons + bootstrap-icons@1.4.1 added 1 package from 1 contributor and audited 1347 packages in 18.91s 在app的入口文件shm/src/main.js中导入boorstrap： import 'bootstrap/dist/css/bootstrap.css' import 'bootstrap-icons/font/bootstrap-icons.css' import { createApp } from 'vue' import App from './App.vue' import router from './router' createApp(App).use(router).mount('#app') 删除App.vue中多余的样式，或者在gump.vue中添加样式测试： Gump {{ msg }} 可以看到网页样式发生了改变。 SHM-Vuex及ElementUI组件 前面内容参考CSDN博客(Python之简)，后面参考hzwy23分享的文档及各官方文档： Vue.js官方中文文档：https://cn.vuejs.org/v2/guide/syntax.html Vue CLI官方文档：https://cli.vuejs.org/zh/ Vuex官方文档：https://vuex.vuejs.org/zh/ Vue Router官方文档：https://router.vuejs.org/zh/installation.html Element UI官方地址:https://element-plus.gitee.io/#/zh-CN Element UI官方中文文档:https://element-plus.gitee.io/#/zh-CN/component/installation 大佬hzwy23分享文档的github地址：https://github.com/hzwy23/vue-admin 集成Vuex组件   Vuex是一个专为Vue.js应用程序开发的状态管理模式。它采用集中式存储管理应用的所有组件的状态，并以相应的规则保证状态以一种可预测的方式发生变化。模块工作流程图如下： Vuex模块核心概念 核心概念如下： State：存储状态变量，https://vuex.vuejs.org/zh/guide/state.html Getter：获取状态变量，接受state作为其第一个参数，https://vuex.vuejs.org/zh/guide/getters.html Mutation：更改Vuex的store中的状态的唯一方法是提交mutation，https://vuex.vuejs.org/zh/guide/mutations.html Action：提供入口方法，修改存储状态的值，https://vuex.vuejs.org/zh/guide/actions.html Module：状态模块化管理，每个模块拥有自己的state、mutation、action、getter、甚至是嵌套子模块，https://vuex.vuejs.org/zh/guide/modules.html 集成Vuex 使用nmp安装，安装在当前项目node_modules目录下： $ npm install vuex --save + vuex@3.6.2 added 1 package from 1 contributor and audited 1348 packages in 17.303s   或者在Vue UI的Vue Project Manager管理界面Plugins菜单中添加cli-plugin-Vuex插件，在src目录下生成了store文件夹，文件夹中包含文件index.js。 在main.js中会自动加入或者修改如下内容： import store from './store' createApp(App).use(store).use(router).mount('#app') Vuex使用 设置state值 示例如下： //格式示例 this.$store.dispatch('action名称','state新值') //使用示例 this.$store.dispatch('authHeight', '100px') 说明： 第一个参数是action中定义的方法，第二个参数是state新的值 需要调整height这个变量的值为100px。假设action中定义了一个方法autoHeight 获取state值 通过mapGetters方法获取到state中height这个变量，或者从data中读取clientHeight变量: import { mapGetters } from \"vuex\"; export devault { computed: { //从vuex中获取浏览器高度，实时更新，保持左侧菜单栏高度与浏览器高度一致 ...mapGetters{[\"height\"]} }, data(){ return { //从vuex读取state状态的第二种方法 clientHight: this.$store.getters.hight } } } 集成ElementUI组件   Element Plus，一套为开发者、设计师和产品经理准备的基于Vue 3.0的桌面端组件库。集成了ElementUI 后，可以方便我们更快的开发出更漂亮的 Web 页面。 集成ElementUI组件方法 使用npm安装： $ npm install element-plus --save + element-plus@1.0.2-beta.41 added 8 packages from 13 contributors and audited 1344 packages in 41.515s   或者在Vue UI的Vue Project Manager管理界面Plugins菜单中查找并添加vue-cli-plugin-element-plus插件，下载后记得invoke，然后在src目录下生成了plugins文件夹，文件夹中包含文件element.js文件。 在main.js中会自动加入或者修改如下内容： import installElementPlus from './plugins/element' const app = createApp(App) installElementPlus(app) app.use(store).use(router).mount('#app') 在App.vue中会加入如下代码： If Element Plus is successfully added to this project, you'll see an '\"> below el-button import HelloWorld from './components/HelloWorld.vue' export default { name: 'App', components: { HelloWorld } }   运行后打开主页可以看到样式，示例了Element Plus的代码片段和按钮样式。 页面布局   之前做测试引入了bootstrap，使用也比较方便，大佬推荐了element-plus，是基于Vue 3.0的桌面端组件库，配合Vue可能更好，并且看起来比较容易上手，决定后面也没布局采用element-plus。 页面整体布局   整体布局之前是参考bootcss中模板：https://v3.bootcss.com/examples/dashboard/，使用element-plus后整体布局模式不变： Header:头部logo和导航等 Aside:侧边菜单显示 Main:主要内容显示区域 Footer:底部信息 整体布局示例   把之前测试的Home.vue修改成了Vuehome.vue，然后在views目录下新建Home.vue文件，作为项目页面主页，将路由添加到router文件夹下的index.js中。在ElementPlus官方选取了一个模板，写入Home.vue中： Header Aside Main Footer .el-header, .el-footer { background-color: #B3C0D1; color: #333; text-align: center; line-height: 60px; } .el-aside { background-color: #D3DCE6; color: #333; text-align: center; line-height: 300px; } .el-main { background-color: #E9EEF3; color: #333; text-align: center; line-height: 440px; } body > .el-container { margin-bottom: 40px; } .el-container:nth-child(5) .el-aside, .el-container:nth-child(6) .el-aside { line-height: 260px; } .el-container:nth-child(7) .el-aside { line-height: 320px; } 运行查看初步效果，页面布局以次为基准，然后依次设计各模块。 "},"18-简单WEB项目/01-System-Health-Management/02-SHM-Container初步设计.html":{"url":"18-简单WEB项目/01-System-Health-Management/02-SHM-Container初步设计.html","title":"SHM-Container初步设计","keywords":"","body":"SHM-Container初步设计 边学边做，学习参考文档和链接： Vue.js官方中文文档：https://cn.vuejs.org/v2/guide/syntax.html Vue CLI官方文档：https://cli.vuejs.org/zh/ Bootstrap图标库：https://icons.bootcss.com/ Element-Plus官方中文文档:https://element-plus.gitee.io/#/zh-CN/component/installation Element-Plus component：https://element-plus.gitee.io/#/zh-CN/component/container 大佬hzwy23分享文档的github地址：https://github.com/hzwy23/vue-admin Header设计 在component目录下新建了Header目录，用于存放header相关的组件，目录内容如下： Header.vue：Header的主组件，集成其它子组件 Logo.vue：header左侧项目logo或者主标题等 Menu.vue：header中间的主菜单 Tools.vue：header右侧的登录信息或其它信息 Header.vue设计 组件Header.vue代码示例如下： import Logo from '@/components/Header/Logo.vue' import Menu from '@/components/Header/Menu.vue' import Tools from '@/components/Header/Tools.vue' export default { name: 'Header', components: { Logo, Menu, Tools } } .shm-header { height: 50px; width: 100%; padding: 2px 0px; line-height: 50px; background-color:#337ab7; } 说明： 使用el-col将header按6、12、6分成了三份 示例中import了三个子组件，同时将Headerexport 高度50px个人觉得差不多了，同时line-height也要设置对应的值，否则文字内容不居中 背景采用经典深蓝色#337ab7;，文字颜色在各子模块中定义 Logo.vueS设计 组件Logo.vue代码示例如下： System Health Management export default { name: 'Logo' }; .shm-logo { float: left; padding-left: 20px; font-family: \"Microsoft YaHei\"; font-size: 2rem; color: #FFFFFF; } 说明： 暂时没想到用啥logo，只写了项目名称，并加粗显示 靠左对齐，左边空20px，字体为微软雅黑，大小为2rem，颜色为纯白色 Menu.vue设计 组件Menu.vue代码示例如下： Home export default { name: 'Menu' }; .shm-menu { float: left; padding-left: 20px; color: #FFFFFF; font-size: 15px; } 说明： 目前只有一个Home的选项，后期在添加 Tools.vueS设计 组件Tools.vue代码示例如下： {{userInfo.nickname}} User Admin Logout &nbsp;&nbsp; More &nbsp;Vuehome Gump &nbsp;GitHub &nbsp;License import { mapGetters } from 'vuex'; export default { name: 'Tools', computed: { ...mapGetters([\"userInfo\"]) }, methods: { handleCommand(command) { console.log(command) switch(command) { case \"1\": break; case \"2\": this.logout(); } }, logout() { this.$confirm('Are you sure logout?', 'Prompt information', { confirmButtonText: 'Confirm', cancelButtonText: 'Cancel', type: 'warning' }).then(() => { this.$store.dispatch('loginStatus', false) this.$router.push('/login') }); } } }; .shm-tools { float: right; padding-right: 20px; color: #FFFFFF; font-size: 15px; } .el-dropdown-link { cursor: pointer; color: #FFFFFF; } 说明： 在使用超链接时候，刚开始打算用Element-plus的el-link，但是我想点击后打开新的页面，target属性使用不行，可能有其它的但是我不知道，官方文档找了下没找到，最后还是使用a标签 使用el-link无下划线的格式示例：el-link :underline=\"false\" href=\"https://github.com/bond-huang\" 代码中使用mapGetters获取了登录用户信息，后续再添加用户管理界面 主页导入Header 原本的header样式el-header去掉，加入如下内容： import Header from '@/components/Header/Header.vue' export default { name: 'Home', components: { Header } } 将下面代码删除，替换成对应Header组件： Header   替换后刷新页面发现布局混乱，原因在官方文档Container Attributes中有说明：子元素中有 el-header或el-footer时为vertical，否则为horizontal，加上属性direction=\"vertical\"即可。 Aside菜单栏设计   在component目录下新建了Aside目录，用于存放侧边导航的相关组件。由两个组件组成，分别是： Side.vue：左侧菜单栏主要布局，建构一个紧靠浏览器左侧，可以通过按钮展开或者收起，垂直方向自适应浏览器高度的区域 ChildrenMenu.vue：显示具体的菜单信息，嵌套在Side.vue组件中 Side.vue设计 组件Side.vue代码示例如下： Systems Class System Admin All Systems System Class Setting User Setting Other Setting Document Help import { mapGetters } from \"vuex\"; import { getMenu } from '@/api/menu.js'; import ChildrenMenu from '@/components/Aside/ChildrenMenu.vue'; export default { name: 'Aside', computed: { ...mapGetters([\"height\"]) }, components: { ChildrenMenu }, data() { return { sideMenuList: [], isCollapse: true, foldicon:'el-icon-s-unfold' }; }, methods: { openPage(url) { this.$router.push(url); }, handleOpen(key, keyPath) { console.log(key, keyPath); }, handleClose(key, keyPath) { console.log(key, keyPath); }, click:function(){ if(this.isCollapse){ this.foldicon = 'el-icon-s-fold'; }else{ this.foldicon = 'el-icon-s-unfold'; } this.isCollapse = !this.isCollapse; } }, mounted(){ getMenu().then(resp => { this.sideMenuList = resp }) } } .shm-aside { float: left; text-align: left; padding: 2px 0px; line-height: 30px; background-color: #545c64; } .el-menu-vertical-demo:not(.el-menu--collapse) { width: 200px; overflow-y: auto; overflow-x: hidden; } 说明： 示例中从vuex中获取浏览器高度，实时更新，保持左侧菜单栏高度与浏览器高度一致 示例中mounted()作用是定时获取后台菜单信息 菜单展开收起的按钮比较小，颜色也不顺眼，回头有空再调整 ChildrenMenu.vue设计 组件ChildrenMenu.vue代码示例如下： {{ item.menuName }} {{ item.menuName }} export default { props: [\"menuData\"], name: 'ChildrenMenu', methods: { openPage(url) { this.$router.push(url); } } } 说明： ChildrenMenu组件用来渲染树形层级菜单 刚开始树形菜单采用递归渲染的方式实现，即在ChildrenMenu组件内嵌套使用组件自身，从而实现递归渲染树形菜单的效果，后来改用简单便于理解的两个for循环 如果Vue.js中组件采用递归时，该组件一定要设置name属性，否则递归无效 通过Axios组件向后台服务发起请求，获取左侧菜单栏信息 主页导入Aside 参照之前方法导入即可，后面再统一示例代码。 Main Content部分设计 Content.vue设计 组件Content.vue代码示例如下： import { mapGetters } from \"vuex\"; import Breadcrumb from \"@/components/Main/Breadcrumb.vue\"; export default { name: \"Content\", components: { Breadcrumb }, computed: { ...mapGetters([\"height\"]) }, } .shm-content { border: #f6f3f3 solid 1px; background-color: #f6f3f3; overflow-y: auto; padding: 6px 6px; } 说明： 在MaContent中加入了DOM元素。当左侧菜单栏点击打开相应页面后，其对应的组件将会在Main Content中DOM元素内显示 示例中我手动加了一个表格进行演示，表格数据重复了10次，后期放在其它页面 示例中导入了Breadcrumb组件，是面包屑导航功能，后面介绍 通过给table传入span-method方法实现合并行或列，示例中使用arraySpanMethod方法合并了行 Breadcrumb.vue设计 组件Breadcrumb.vue代码示例如下： Home {{item.title}} export default { data() { return { breadcrumb: [] }; }, watch: { $route(to) { const routers = to.matched; this.breadcrumb = []; if (routers && routers.length > 0) { for (let i = 1; i 说明： 内容基本copy大佬hzwy23内容，个人喜欢使用图标分隔符，后续再根据需要更改内容 前端路由往往由多层路由组成，在页面跳转过程中，引入面包屑导航功能后，可以很方便的知道当下所在的页面 watch用来监听路由跳转，每次发生路由跳转时，$route中的值都会发生变化，to.matched用来获取匹配成功的路由信息 Footer部分设计 在component目录下新建了Footer目录，用于存放Footer相关组件，Footer.vue内容如下： Copyright © 2021 @vue/cli+ElementUI export default { name: \"Footer\" }; 说明： Footer主要显示一些版权信息等 样式放在主页实现了，主页中el-footer样式即是 在此次项目中，演示完Footer后删除了，没什么用，占位置 结束 后期根据自己的需求调整样式及数据类型等。 "},"18-简单WEB项目/01-System-Health-Management/03-SHM-API和route.html":{"url":"18-简单WEB项目/01-System-Health-Management/03-SHM-API和route.html","title":"SHM-API和route","keywords":"","body":"SHM-API和route 边学边做，学习参考文档和链接： Vue.js官方中文文档：https://cn.vuejs.org/v2/guide/syntax.html Vue CLI官方文档：https://cli.vuejs.org/zh/ Bootstrap图标库：https://icons.bootcss.com/ Element-Plus官方中文文档:https://element-plus.gitee.io/#/zh-CN/component/installation Element-Plus component：https://element-plus.gitee.io/#/zh-CN/component/container 大佬hzwy23分享文档的github地址：https://github.com/hzwy23/vue-admin 集成Axios   Axios是一个基于promise的HTTP库,可以用在浏览器和node.js中，之前基础环境准备中已经安装和演示了。安装不作介绍，再次学习演示下。 安装Axios   （后面卸载了此插件）在Vue UI的Vue Project Manager管理界面Plugins菜单中添加vue-cli-plugin-axios插件，在src目录下plugins文件夹中生成文件axios.js。文件内容如下： \"use strict\"; import Vue from 'vue'; import axios from \"axios\"; // Full config: https://github.com/axios/axios#request-config // axios.defaults.baseURL = process.env.baseURL || process.env.apiUrl || ''; // axios.defaults.headers.common['Authorization'] = AUTH_TOKEN; // axios.defaults.headers.post['Content-Type'] = 'application/x-www-form-urlencoded'; let config = { // baseURL: process.env.baseURL || process.env.apiUrl || \"\" // timeout: 60 * 1000, // Timeout // withCredentials: true, // Check cross-site Access-Control }; const _axios = axios.create(config); _axios.interceptors.request.use( function(config) { // Do something before request is sent return config; }, function(error) { // Do something with request error return Promise.reject(error); } ); // Add a response interceptor _axios.interceptors.response.use( function(response) { // Do something with response data return response; }, function(error) { // Do something with response error return Promise.reject(error); } ); Plugin.install = function(Vue, options) { Vue.axios = _axios; window.axios = _axios; Object.defineProperties(Vue.prototype, { axios: { get() { return _axios; } }, $axios: { get() { return _axios; } }, }); }; Vue.use(Plugin) export default Plugin; 同时，修改了文件main.js里面内容： import './plugins/axios' import 'bootstrap/dist/css/bootstrap.css' import 'bootstrap-icons/font/bootstrap-icons.css' import { createApp } from 'vue' import App from './App.vue' import router from './router' import store from './store' import installElementPlus from './plugins/element' const app = createApp(App) installElementPlus(app) app.use(store).use(router).mount('#app') 运行项目后报了一个错： error 'options' is defined but never used no-unused-vars 暂时删掉options，又报了一个： \"export 'default' (imported as 'Vue') was not found in 'vue' 版本原因，使用格式应该是： import { createApp } from 'vue'   版本不匹配，最后放弃了此插件，卸载了vue-cli-plugin-axios插件，使用之前安装的，根据大佬的文档指导内容写入Axios代码初始化，在plugins文件夹中axios.js文件写入代码示例： import axios from 'axios'; import { ElMessage } from 'element-plus'; // axios.defaults.baseURL = process.env.VUE_APP_BASE_API; // axios.defaults.headers.common['Authorization'] = AUTH_TOKEN; axios.defaults.headers.post['Content-Type'] = 'application/x-www-form-urlencoded'; axios.interceptors.request.use(config => { return config; }, error => { ElMessage.error(error) }) axios.interceptors.response.use(response => { if (response && response.status == 200) { if (response.data.statusCode == \"200\") { return response.data.data; } else { ElMessage.error(response.data.statusMessage) return false; } } ElMessage.error('Request API failed'); }, error => { ElMessage.error(error) return false; }) 权限拦截管理   权限管理就是不同用户拥有不同执行权限，在系统管理中很重要，不作详细介绍，权限管理通常分为几个形式： API权限控制 数据权限控制 前端页面权限控制 在每个页面中加入判断，校验用户是否登录 全局校验用户是否登录 页面按钮权限控制   可以使用Vue Router导航守卫功能来设置全局的用户登录校验。导航守卫主要在如下几个阶段来拦截请求。分别是： beforeEach 全局前置守卫，在导航路由触发前拦截 beforeRouteUpdate beforeEnter beforeRouteEnter beforeResolve afterEach 使用beforeEach实现登录校验的判断，在src目录下新建文件permission.js，代码示例如下： import router from '@/router/index.js'; import store from '@/store/index.js'; function checkLogin() { // todo 校验用户是否登录，以及用户 token 令牌是否过期 return !store.getters.loginStatus; } // @param to 到哪里去，跳转到哪个路由 // @param from 从哪里来，从哪个路由跳转过来的 // @param next 执行跳转 router.beforeEach((to, from, next) => { // 判断用户是否登录， // 如果用户已经登录，执行 next() 方法， // 如果用户未登录，则跳转到登录页面 if (to.path != '/login' && checkLogin()) { next({ path: '/login' }) } else { next() } }) 说明： 每次触发路由导航时，都会执行这个判断逻辑，当发现用户未登录，或登录的token失效后，将会被引导进入登录页面。注意一定要判断目标地址是否为登录地址，否则出现死循环。 checkLogin方法现在只是读取了保存在vuex中的用户登录状态，这种处理方式并不适合生产环境。：在浏览器执行F5刷新时，Vuex存储的状态值会丢失，用户要重新登录 通常生产环境中，会将token信息存储到Cookies中，登录状态存储在Vuex中，判断用户是否登录要结合Cookies中的token与Vuex中的登录状态一起判断。如用户登录状态为false时，从Cookies中读取用户token值，向后台服务请求验证token有效性，如果token有效，则设置Vuex中用户登录状态为true，然后跳转到目标路由地址。否则跳转到登录页面 再次运行项目，发现路由已经跳转到之前做测试的登录页面中去了 菜单后台加载设计 字段介绍 menuId菜单编码，每个菜单必须对应一个唯一的菜单编码。 menuName 菜单名称。 menuType 菜单类型。1 表示目录类型，2 表示叶子菜单，目录类型菜单，表示其下还有菜单信息，叶子类型菜单，表示达到树底部。 path 前端路由值，叶子菜单被点击时，将会跳转到该路由。目录菜单设置path值将会被忽略。 iconCLass 目录类型菜单前边的小图标。 children 表示目录类型菜单下的子菜单信息。 示例创建一个目录菜单，目录菜单下边挂载两个叶子菜单： 'GET /menu': { statusCode: \"200\", statusMessage: \"succcess\", data: [{ menuId: \"1-1\", menuType: 1, menuName: 'AIX system', children: [ { menuId: \"1-1-1\", menuType: 2, menuName: 'AIXtest1', path: '/allsystems', }, { menuId: \"1-1-2\", menuType: 2, menuName: 'AIXtest2', path: '/allsystems', }] }, { menuId: \"1-2\", menuType: 2, menuName: 'Linux system', children: [ { menuId: \"1-2-1\", menuType: 2, menuName: 'Linuxtest1', path: '/allsystems', }, { menuId: \"1-2-2\", menuType: 2, menuName: 'LinuxXtest2', path: '/allsystems', }] }] } 在Web中向后台请求菜单信息的方式： // api/menu.js import axios from \"axios\" export function getMenu(){ return axios.get('/menu') } 前端路由设计   在router目录下index.js文件中，有之前做测试的路由，全段路由一般由下面几个部分组成： path：路由地址 name：路由名称 component：路由对应的组件 meta：路由元数据，如路由标签等 children：子路由信息 在程序中便可以调用路由跳转方法进行路由切换操作： // 字符串 router.push('/foo') // 对象 router.push({ path: '/foo' }) // 命名的路由 router.push({ name: 'foo', params: { userId: '123' }}) // 带查询参数，变成 /register?plan=private router.push({ path: '/foo', query: { plan: 'private' }}) 在HTML页面元素中实现路由跳转的方法： Go to Foo 在浏览历史记录中切换跳转方法： router.go(n) // n 表示第几个历史记录，n 必须是整数 基础页面   我在组件目录下新建了layout目录，里面包含BaseLayout.vue和EmptyLayout.vue两个组件，BaseLayout.vue内容如下： import Header from '@/components/Header/Header.vue' import Aside from '@/components/Aside/Aside.vue' import Content from '@/components/Main/Content.vue' export default { name: 'BaseLayout', components: { Header, Aside, Content } } .el-main { background-color: #E9EEF3; color: #333; text-align: center; } body > .el-container { margin-bottom: 40px; } .el-container:nth-child(5) .el-aside, .el-container:nth-child(6) .el-aside { line-height: 260px; } .el-container:nth-child(7) .el-aside { line-height: 320px; } 即之前测试中Home.vue页面中内容，EmptyLayout.vue内容如下： 前端路由 前端路由往往嵌套多层，router目录下index.js文件写入路由信息，路由信息如下所示： import { createRouter, createWebHashHistory } from 'vue-router' import BaseLayout from '@/components/layout/BaseLayout' import EmptyLayout from '@/components/layout/EmptyRouter' import Dashboard from '@/views/Dashboard' import Login from '@/views/Login' import Vuehome from '@/views/Vuehome.vue' import Gump from '@/views/Gump.vue' import Allsystems from '@/views/allsystems/AllSystems' import HostUpdate from '@/views/allsystems/HostUpdate' const routes = [{ path: '', component: EmptyLayout, redirect: 'dashboard', children: [{ path: '/login', component: Login, name: 'login', meta: { title: 'login' } }] }, { path: '', component: BaseLayout, redirect: 'dashboard', children: [{ path: 'dashboard', component: Dashboard, name: 'dashboard', meta: { title: 'home' } }] }, { path: '/gump', component: BaseLayout, children: [{ path: '/gump', component: Gump, name: 'gump', meta: { title: 'gump' } }] }, { path: '/vuehome', component: BaseLayout, children: [{ path: '/vuehome', component: Vuehome, name: 'vuehome', meta: { title: 'vuehome' } }] }, { path: '/allsystems', component: BaseLayout, children: [{ path: '/allsystems', component: Allsystems, name: 'allsystems', meta: { title: 'All Systems' } }, { path: '/allsystems', component: EmptyLayout, meta: { title: 'All Systems' }, children: [ { path: 'update', name: 'update', component: HostUpdate, meta: { title: 'Update Host', } }, ] }] }, ] const router = createRouter({ history: createWebHashHistory(), routes }) export default router 说明： 首先打开BaseLayout组件，然后在这个组件中找到 然后打开EmptyLayout组件，EmptyLayout组件被嵌入BaseLayout组件的内 最后打开Allsystems组件，此时其上级组件EmptyLayout组件内查找，然后将Allsystems组件嵌入到EmptyLayout组件的内 前端路由定义时，如果路由中包含了children属性，那么这个组件内一定带有 DOM元素 ，否则children内的组件无处安放 整个项目的入口组件App.vue,里边就是一个，代码如下： 结束 "},"18-简单WEB项目/01-System-Health-Management/04-SHM-Login模块及Mock后台.html":{"url":"18-简单WEB项目/01-System-Health-Management/04-SHM-Login模块及Mock后台.html","title":"SHM-Login模块及Mock后台","keywords":"","body":"SHM-Login模块及Mock后台 边学边做，学习参考文档和链接： Vue.js官方中文文档：https://cn.vuejs.org/v2/guide/syntax.html Vue CLI官方文档：https://cli.vuejs.org/zh/ Bootstrap图标库：https://icons.bootcss.com/ Element-Plus官方中文文档:https://element-plus.gitee.io/#/zh-CN/component/installation Element-Plus component：https://element-plus.gitee.io/#/zh-CN/component/container mockjs官方：http://mockjs.com/ mockjs官方文档：https://github.com/nuysoft/Mock/wiki 大佬hzwy23分享文档的github地址：https://github.com/hzwy23/vue-admin 登录入口设计   登录入口主要负责接收用户账号和密码，校验用户身份。当用户身份校验通过后，进入系统。常见的几种登录方式如下所示： 微信扫码登录 支付宝扫码登录 手机验证码登录 用户账号密码登录 微博授权登录   本项目采用简单账号密码登录，后台校验用户账号和密码是否正确，如果正确，则返回有效的token信息， Web端上携带token信息请求后台服务。 views目录下login.vue代码如下： System Health Management Sign in import { login } from '@/api/login.js'; export default { name: \"login\", data() { return { username: \"admin\", password: \"123456\" }; }, methods: { loginSubmit() { login(this.username, this.password).then(resp => { if (resp) { this.$store.dispatch('loginStatus', true); this.$router.push('/dashboard') } }); } } }; .auth-body { background:url(../assets/background.jpg) repeat center 0px; background-size: cover; font-family: sans-serif; padding-top: 100px; padding-bottom: 150px; } .form-auth { max-width: 400px; padding: 15px; margin: 0 auto; background:rgba(255,255,255,0.3); /* 背景颜色和透明度 */ border-radius: 10px; /* 边角弧度 */ } .form-auth .checkbox { font-weight: normal; } 登录的API代码如下： // @api/login.js import axios from \"axios\" import qs from 'qs' export function login(username, password){ return axios.post('/login', qs.stringify({ username: username, password: password })) } Mock数据设计   当开发前端Web服务时，可能后台服务尚未开发完成，此时可以借助于Mock服务来模拟后台服务，当Web端使用Axios向后台服务发起请求时，请求将会被Mock服务拦截，Mock服务返回预先定义的数据。当后台服务开发完成后，只需关闭对应的Mock服务，此时请求将会被转发到真正的后台服务。 安装mockjs 使用nmp安装，安装在当前项目node_modules目录下： $ $ npm install mockjs --save + mockjs@1.1.0 updated 1 package and audited 1346 packages in 15.92s 使用mockjs 在src目录下新建文件夹mock，新建文件mock.js和data文件夹，mock.js文件内容代码如下： import Mock from 'mockjs' const mock_source = ['biz.js', 'sys.js'] function load(mock_source) { for (let i = 0; i { if (content && content.default) { initMock(content.default) } }) } } function initMock(rules) { for (let [rule, resp] of Object.entries(rules)) { const element = rule.split(\" \") if (element && element.length == 2) { const rtype = element[0].trim() const rurl = element[1].trim() Mock.mock(rurl, rtype.toLowerCase(), resp) } else { Mock.mock(rule, resp) } } } if (mock_source && mock_source.length > 0) { load(mock_source) } Mock数据   在data文件夹下新建文件sys.js和biz.js文件，sys.js文件中主要是登录信息以及侧边导航的数据，内容如下所示： import qs from 'qs' const menu = { 'POST /login': function(params){ const param = qs.parse(params.body) if (param.username == 'admin' && param.password == '123456') { return { statusCode: \"200\", statusMessage: 'Successful', data: { accessToken: 'xxx', refreshToken: 'xxx' } } } else { return { statusCode: \"403\", statusMessage: 'Login failed', data: { accessToken: '-', refreshToken: '-' } } } }, 'GET /menu': { statusCode: \"200\", statusMessage: \"succcess\", data: [{ menuId: \"1-1\", menuType: 1, menuName: 'AIX system', children: [ { menuId: \"1-1-1\", menuType: 2, menuName: 'AIXtest1', path: '/allsystems', }, { menuId: \"1-1-2\", menuType: 2, menuName: 'AIXtest2', path: '/allsystems', }] }, { menuId: \"1-2\", menuType: 2, menuName: 'Linux system', children: [ { menuId: \"1-2-1\", menuType: 2, menuName: 'Linuxtest1', path: '/allsystems', }, { menuId: \"1-2-2\", menuType: 2, menuName: 'LinuxXtest2', path: '/allsystems', }] }] } } export default menu; biz.js文件中主要是Allsystems.vue组件中需要获取的数据： const modeller = { 'GET /allsystems': { statusCode: \"200\", statusMessage: \"succcess\", data: { total: 12, pages: 2, content: [{ HostId: 1, HostType: \"AIX\", HostName: \"AIXtest1\", IPadd: \"192.168.100.100\", Description: \"IBM AIX test system\", }, { HostId: 2, HostType: \"AIX\", HostName: \"AIXtest2\", IPadd: \"192.168.100.101\", Description: \"IBM AIX test system\", }, { HostId: 3, HostType: \"AIX\", HostName: \"AIXtest3\", IPadd: \"192.168.100.102\", Description: \"IBM AIX test system\", }, { HostId: 4, HostType: \"AIX\", HostName: \"AIXtest4\", IPadd: \"192.168.100.103\", Description: \"IBM AIX test system\", }, { HostId: 5, HostType: \"AIX\", HostName: \"AIXtest5\", IPadd: \"192.168.100.104\", Description: \"IBM AIX test system\", }, { HostId: 6, HostType: \"AIX\", HostName: \"AIXtest6\", IPadd: \"192.168.100.105\", Description: \"IBM AIX test system\", }, { HostId: 7, HostType: \"AIX\", HostName: \"AIXtest7\", IPadd: \"192.168.100.106\", Description: \"IBM AIX test system\", }, { HostId: 8, HostType: \"Linux\", HostName: \"Linuxtest1\", IPadd: \"192.168.100.107\", Description: \"Red Hat Enterprise Linux\", }, { HostId: 9, HostType: \"Linux\", HostName: \"Linuxtest2\", IPadd: \"192.168.100.108\", Description: \"Red Hat Enterprise Linux\", }, { HostId: 10, HostType: \"Linux\", HostName: \"Linuxtest3\", IPadd: \"192.168.100.109\", Description: \"Red Hat Enterprise Linux\", }, { HostId: 11, HostType: \"Linux\", HostName: \"Linuxtest4\", IPadd: \"192.168.100.110\", Description: \"Red Hat Enterprise Linux\", }, { HostId: 12, HostType: \"Linux\", HostName: \"Linuxtest5\", IPadd: \"192.168.100.111\", Description: \"Red Hat Enterprise Linux\", },] } }, } export default modeller; 结束   到现在为止，基本的框架搭建完成，后续主要是功能设计，根据自己的项目需求来添加相应的功能，前端设计完成后，还有后端开发，学习的过程还很漫长。 "},"18-简单WEB项目/10-学习及使用中记录的笔记/":{"url":"18-简单WEB项目/10-学习及使用中记录的笔记/","title":"学习及使用中记录的笔记","keywords":"","body":"学习及使用中记录的笔记 边学边做过程中，学到或使用到一些方法进行记录。 内容 Vue-CLI-使用笔记 "},"18-简单WEB项目/10-学习及使用中记录的笔记/01-Vue-CLI-使用笔记.html":{"url":"18-简单WEB项目/10-学习及使用中记录的笔记/01-Vue-CLI-使用笔记.html","title":"Vue-CLI-使用笔记","keywords":"","body":"Vue-CLI-使用笔记 记录学习和使用过程中知识点。 UI组件引入   在Vue-CLI中，通常components是存放组件的位置，views是存放页面位置。在脚手架中，Home.vue页面中引入了HelloWorld.vue组件，没用导航栏，导航栏在根组件App.vue中，这样所有页面都会有导航。这里想把导航作为一个组件，在需求的页面中引用。 组件引入示例 原本APP.vue中内容： Home | Login | Gump 修改成如下： 在components中新建navbar.vue组件，内容如下： Home | Login | Gump export default { name: 'Navbar', } 例如在Home.vue中进入navbar.vue组件，Home.vue内容如下： // @ is an alias to /src import Navbar from '@/components/navbar.vue' import HelloWorld from '@/components/HelloWorld.vue' export default { name: 'Home', components: { Navbar, HelloWorld } } 说明 在template加入Navbar内容，注意格式 在script中需要import，注意名称 待补充 "},"18-简单WEB项目/10-学习及使用中记录的笔记/02-Vue-CLI-报错记录.html":{"url":"18-简单WEB项目/10-学习及使用中记录的笔记/02-Vue-CLI-报错记录.html","title":"Vue-CLI-报错记录","keywords":"","body":"Vue-CLI-报错记录 记录使用过程中遇到的报错及解决方法。 版本差异 示例一 报错示例： \"export 'default' (imported as 'Vue') was not found in 'vue' 报错代码行： import Vue from 'vue' 版本原因，我使用的@vue/cli 4.5.12版本格式应该是： import { createApp } from 'vue' 示例二 报错示例： `slot` attributes are deprecated 原因是在较新的Vue-CLI版本中使用了slot-scope，新版本使用v-slot取代了slot和slot-scope。 参考链接： rfcs/active-rfcs/0001-new-slot-syntax.md vue 插槽，slot和 slot-scope已被废弃 语法错误 示例一 报错示例： [vue/no-multiple-template-root] The template root requires exactly one element.eslint-plugin-vue vue的模版中只有能一个根节点，在template标签中加一个div标签即可 参考链接：https://www.jianshu.com/p/6c6cc02a9001 待补充 "},"18-简单WEB项目/10-学习及使用中记录的笔记/03-Vue-CLI-数据问题记录.html":{"url":"18-简单WEB项目/10-学习及使用中记录的笔记/03-Vue-CLI-数据问题记录.html","title":"Vue-CLI-数据问题记录","keywords":"","body":"Vue-CLI-数据问题记录 记录学习和使用过程中知识点和遇到的问题。 数据获取 数据获取问题   在SHM项目学习和编写过程中，发现menu数据格式始终获取不到，刚开始以为是Vue中获取数据的递归渲染的方式写的有问题，后来怀疑是Mock数据格式可能有问题，但是测试感觉数据没有问题。数据如下所示： 'GET /test': { statusCode: \"200\", statusMessage: \"succcess\", data: [{ menuId: \"1-1\", menuType: 1, menuName: 'AIX system', children: [ { menuId: \"1-1-1\", menuType: 2, menuName: 'AIXtest1', path: '/modeller', }, { menuId: \"1-1-2\", menuType: 2, menuName: 'AIXtest2', path: '/modeller', }] }, { menuId: \"1-2\", menuType: 2, menuName: 'Linux system', children: [ { menuId: \"1-2-1\", menuType: 2, menuName: 'Linuxtest1', path: '/modeller', }, { menuId: \"1-2-2\", menuType: 2, menuName: 'LinuxXtest2', path: '/modeller', }] }] } 数据测试 先把数据简化： 'GET /test': { statusCode: \"200\", statusMessage: \"succcess\", data: { menuId: \"1-1\", menuType: 1, menuName: 'AIX system', children: [ { menuId: \"1-1-1\", menuType: 2, menuName: 'AIXtest1', path: '/modeller', }, { menuId: \"1-1-2\", menuType: 2, menuName: 'AIXtest2', path: '/modeller', }] }, } 在Modeller.vue中使用下面方式获取数据并查看： {{ index }}:{{ value }} 输出示例： · menuId:1-1 · menuType:1 · menuName:AIX system · children:[ { \"menuId\": \"1-1-1\", \"menuType\": 2, \"menuName\": \"AIXtest1\", \"path\": \"/modeller\" }, { \"menuId\": \"1-1-2\", \"menuType\": 2, \"menuName\": \"AIXtest2\", \"path\": \"/modeller\" } ] 使用下面方式获取数据并查看： {{ index }}:{{ item.menuName }} 输出示例： · 0:AIXtest1 · 1:AIXtest2 回到最开始比较完整的数据，使用下面方法获取数据： {{ index }}:{{ item.menuId }}:{{ item.menuName }} 输出示例： · 0:1-1:AIX system · 1:1-2:Linux system 添加一个条件语句： {{ index }}:{{ item.menuId }}:{{ item.menuName }} 输出示例： · 1:1-2:Linux system 把数据弄到表格中示例： 字段管理 编辑 删除 表格中会获取到Linux system那组数据相关信息。 问题原因   上面测试说明数据没有问题，数据展示的逻辑也没用问题,回到Aside.vue组件和ChildrenMenu.vue中，也就是从Mock中获取数据方式有问题，API很简单应该没问题，最后排查到了原因，是因为把mounted()写到了methods里面，错误代码示例： methods: { openPage(url) { this.$router.push(url); }, handleOpen(key, keyPath) { console.log(key, keyPath); }, handleClose(key, keyPath) { console.log(key, keyPath); }, click:function(){ if(this.isCollapse){ this.foldicon = 'el-icon-s-fold'; }else{ this.foldicon = 'el-icon-s-unfold'; } this.isCollapse = !this.isCollapse; }, mounted(){ getMenu().then(resp => { this.sideMenuList = resp }) } } 把mounted()写错了位置，导致数据获取不到，后面处理的就都是空的数据。 待补充 "},"18-简单WEB项目/10-学习及使用中记录的笔记/05-Element_Plus-学习笔记.html":{"url":"18-简单WEB项目/10-学习及使用中记录的笔记/05-Element_Plus-学习笔记.html","title":"Element_Plus-学习笔记","keywords":"","body":"Element_Plus-学习笔记. 记录学习和使用过程中知识点，避免忘记。 Table表格组件 官方参考文档：https://element-plus.gitee.io/#/zh-CN/component/table 合并行或列 官方示例 官方文档中，展示了两个示例，分别是列合并和行合并，官方示例中HTML代码： JavaScript代码： methods: { arraySpanMethod({ row, column, rowIndex, columnIndex }) { if (rowIndex % 2 === 0) { if (columnIndex === 0) { return [1, 2]; } else if (columnIndex === 1) { return [0, 0]; } } }, objectSpanMethod({ row, column, rowIndex, columnIndex }) { if (columnIndex === 0) { if (rowIndex % 2 === 0) { return { rowspan: 2, colspan: 1 }; } else { return { rowspan: 0, colspan: 0 }; } } } } 说明： 官方示例中使用了arraySpanMethod和objectSpanMethod分别进行和列合并，合并的条件进行了多次判断，具体效果参考官方文档 通过给table传入span-method方法可以实现合并行或列，方法的参数是一个对象，里面包含当前行row、当前列column、当前行号rowIndex、当前列号columnIndex四个属性 该函数可以返回一个包含两个元素的数组，第一个元素代表rowspan，第二个元素代表colspan,例如arraySpanMethod中返回的数组；也可以返回一个键名为rowspan和colspan的对象，例如objectSpanMethod中返回的对象 使用示例   官方文档只是演示功能，实际使用需求肯定不一样，编写不同的JavaSript实现不同功能。我的需求就只是想把每一行的第五列和第六列合并，表头还是分开的，实现很简单，但个人对JavaSript不熟，所以看懂官方说明后，记录下来避免忘记。 在HTML代码中： JavaScript代码： methods: { arraySpanMethod({ columnIndex }) { if (columnIndex === 4) { return [1, 2]; } }, } 说明： 使用border后有表格边界，方便查看是否合并了，不需要可以删除 示例中只使用到了columnIndex，其它row, column, rowIndex等没使用就不用写，写了还会报错：'row' is declared but its value is never read.Vetur(6133) 返回[1, 2]代表rowspan为1，colspan为2，代表意思和HTML5中td标签一样，用法也一样，此值在HTML基础学习中有相应记录：HTML-基础学习笔记 待补充 "},"18-简单WEB项目/10-学习及使用中记录的笔记/20-ECharts-基础学习笔记.html":{"url":"18-简单WEB项目/10-学习及使用中记录的笔记/20-ECharts-基础学习笔记.html","title":"ECharts-基础学习笔记","keywords":"","body":"ECharts-基础学习笔记 学习和使用过程中记录的笔记，参考链接： ECharts官网：Apache ECharts vue-echarts GitHub: vue-echarts runoob.com网站教程：ECharts 教程 ECharts在线编辑工具：ECharts在线编辑工具 runoob.com网站在线编辑：runoob.com网站在线编辑 ECharts安装 直接引用 直接官网下载：https://echarts.apache.org/zh/download.html 通过标签方式直接引入构建好的echarts文件 使用CDN方法 使用CDN方法引入,以jsdelivr为例： 示例： ECharts示例 // 基于准备好的dom，初始化echarts实例 var myChart = echarts.init(document.getElementById('main')); // 指定图表的配置项和数据 var option = { title: { text: 'ECharts Example' }, tooltip: {}, legend: { data:['故障量'] }, xAxis: { data: [\"CPU\",\"内存\",\"主板\",\"控制器\",\"电源\",\"硬盘\",\"电池\"] }, yAxis: {}, series: [{ name: '故障量', type: 'bar', data: [1, 3, 0, 3, 10, 27,8] }] }; // 使用上面配置项和数据显示图表 myChart.setOption(option); 说明： 注意series里面name名称要和legend中data数据值一样 注意数据对应关系，会根据顺序来对应 npm获取echarts   例如在最近搭建的基于@vue/cli和Element+的项目中添加使用echarts。首先在项目中安装ECharts，示例如下： $ npm install echarts vue-echarts ...... + vue-echarts@6.0.0-rc.6 + echarts@5.1.2 added 7 packages from 4 contributors and audited 1361 packages in 25.92s 安装成功后，在node_modules下就会有echarts和vue-echarts两个文件包。 Vue3中使用方法： import { createApp } from 'vue' import ECharts from 'vue-echarts' import { use } from \"echarts/core\" // import ECharts modules manually to reduce bundle size import { CanvasRenderer } from 'echarts/renderers' import { BarChart } from 'echarts/charts' import { GridComponent, TooltipComponent } from 'echarts/components' use([ CanvasRenderer, BarChart, GridComponent, TooltipComponent ]) const app = createApp(...) // register globally (or you can do it locally) app.component('v-chart', ECharts) app.mount(...) 在我的shm项目中，在main.js加入如下代码进行全局引用： import ECharts from 'vue-echarts' app.component('v-chart', ECharts) 然后在组件中进行使用，示例代码： import { use } from \"echarts/core\"; import { CanvasRenderer } from \"echarts/renderers\"; import { LineChart } from \"echarts/charts\"; import { TitleComponent, ToolboxComponent, TooltipComponent, LegendComponent, GridComponent, } from \"echarts/components\"; import VChart, { THEME_KEY } from \"vue-echarts\"; import { ref, defineComponent } from \"vue\"; use([ CanvasRenderer, GridComponent, LineChart, TitleComponent, TooltipComponent, ToolboxComponent, LegendComponent ]); export default defineComponent({ name: \"ProcessorPerf\", components: { VChart }, provide: { [THEME_KEY]: \"dark\" }, setup () { const option = ref({ title: { text: 'CPU使用率' }, tooltip: { trigger: 'axis' }, legend: { data: ['user', 'sys', 'idel', 'iowait', 'entc'] }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, toolbox: { feature: { saveAsImage: {test} } }, xAxis: { type: 'category', boundaryGap: false, data: ['08:00','09:00','10:00','11:00', '12:00', '13:00', '14:00', '15:00', '16:00', '17:00', '18:00'] }, yAxis: { type: 'value' }, series: [ { name: 'user', type: 'line', data: [8,18,14,12, 13, 10, 13, 9, 23, 21,16] }, { name: 'sys', type: 'line', data: [7,13,15,22, 18, 19, 23, 29, 33, 31,21] }, { name: 'idel', type: 'line', data: [85,69,71,66, 69, 71, 64, 62, 44, 48,63] }, { name: 'iowait', type: 'line', data: [2,3,1,1, 0, 3, 0, 2, 1, 3,7] }, { name: 'entc', type: 'line', data: [15,31,29,34, 31, 29, 36, 38, 56, 52,37] } ] }); return { option }; } }); .chart { height: 400px; width: 600px; } 说明： [THEME_KEY]定义了图表背景颜色，示例中是深色模式 示例中图表主要有四个部分： 标题（title）：通过title实现 提示信息（tooltip）：鼠标移动到图表上位置，提示数据信息 图例（legend）：示例中legend对应的每条折线，指出折线类型 X轴（xAxis）：配置X轴上的项目 Y轴（yAxis）：配置Y轴上的项目 列表（series）：即要展示的数据的列表 在series中type决定图表类型，示例中是line 官方示例series中还有stack,设置成总量可以求和，示例中没有使用到 待补充 "},"18-简单WEB项目/10-学习及使用中记录的笔记/21-Echarts-数据获取问题.html":{"url":"18-简单WEB项目/10-学习及使用中记录的笔记/21-Echarts-数据获取问题.html","title":"Echarts-数据获取问题","keywords":"","body":"ECharts-基础学习笔记 学习和使用过程中记录的笔记，参考链接： ECharts官网：Apache ECharts vue-echarts GitHub: vue-echarts runoob.com网站教程：ECharts 教程 ECharts在线编辑工具：ECharts在线编辑工具 runoob.com网站在线编辑：runoob.com网站在线编辑 数据传入 例如下面代码，数据在代码中已经定义了： import VChart, { THEME_KEY } from \"vue-echarts\"; import { ref, defineComponent } from \"vue\"; export default defineComponent({ name: \"ProcessorPerf\", components: { VChart }, provide: { [THEME_KEY]: \"\" }, setup () { const option = ref({ title: { text: 'Usage Rate(%)' }, tooltip: { trigger: 'axis' }, legend: { data: ['user', 'sys', 'idel', 'iowait', 'entc'] }, grid: { left: '3%', right: '4%', bottom: '3%', containLabel: true }, toolbox: { feature: { saveAsImage: {} } }, xAxis: { type: 'category', boundaryGap: false, data: ['01:00','02:00','03:00','04:00','05:00', '06:00','07:00','08:00','09:00','10:00','11:00', '12:00', '13:00', '14:00', '15:00', '16:00', '17:00', '18:00', '19:00', '20:00', '21:00', '22:00', '23:00', '00:00',] }, yAxis: { type: 'value' }, series: [ { name: 'user', type: 'line', smooth: true, data: [3,28,32,34,12,10,11,9,8,18,14,12, 13,10,13,9,23,21,16,14,13,15,17,14] }, { name: 'sys', type: 'line', smooth: true, data: [8,14,18,16,10,9,9,6,7,13,15,22, 18,19,23,29,33,31,21,17,14,19,11,9] }, { name: 'idel', type: 'line', smooth: true, data: [89,58,50,50,78,81,80,85,85,69,71,66, 69,71,64,62,44,48,63,69,73,66,72,77] }, { name: 'iowait', type: 'line', smooth: true, data: [1,7,8,6,8,5,6,3,2,3,1,1,0,3,0,2,1,3,7,4,1,4,2,1] }, { name: 'entc', type: 'line', smooth: true, data: [11,42,50,50,22,19,20,15,15,31,29,34, 31,29,36,38,56,52,37,31,27,34,28,23] } ] }); return { option }; } }); .chart { height: 300px; width: 1060px; } 想把上面代码中series数据通过API获取，使用axios， "}}